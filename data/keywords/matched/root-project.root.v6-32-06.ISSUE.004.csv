id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/928:3966,availability,ERROR,ERROR,3966,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3983,availability,error,errors,3983,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:693,deployability,integr,integrations,693,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:128,energy efficiency,Alloc,Allocate,128,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:170,energy efficiency,alloc,allocates,170,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:434,energy efficiency,alloc,allocated,434,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:555,energy efficiency,Alloc,Allocate,555,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1658,energy efficiency,alloc,allocs,1658,"m, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1698,energy efficiency,alloc,allocated,1698,"ns inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full -",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2036,energy efficiency,Alloc,Allocate,2036,"d i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a m",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3388,energy efficiency,alloc,allocs,3388,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3428,energy efficiency,alloc,allocated,3428,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:693,integrability,integr,integrations,693,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:738,integrability,discover,discovered,738,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:693,interoperability,integr,integrations,693,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:738,interoperability,discover,discovered,738,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:693,modifiability,integr,integrations,693,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:4,performance,memor,memory,4,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:180,performance,memor,memory,180,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:444,performance,memor,memory,444,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:634,performance,memor,memory,634,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1256,performance,error,errors,1256,"Integrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1304,performance,memor,memory,1304," is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== defin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1311,performance,error,error,1311,"oked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely l",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2784,performance,error,errors,2784," 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are n",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2818,performance,ERROR,ERROR,2818," in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2835,performance,error,errors,2835,",515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2991,performance,error,errors,2991,"ibgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3039,performance,memor,memory,3039,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3046,performance,error,error,3046,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3932,performance,error,errors,3932,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3966,performance,ERROR,ERROR,3966,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3983,performance,error,errors,3983,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:693,reliability,integr,integrations,693,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1256,safety,error,errors,1256,"Integrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1311,safety,error,error,1311,"oked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely l",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1317,safety,detect,detector,1317,"ich deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 31",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2760,safety,detect,detected,2760,",000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2784,safety,error,errors,2784," 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are n",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2818,safety,ERROR,ERROR,2818," in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2835,safety,error,errors,2835,",515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2991,safety,error,errors,2991,"ibgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3046,safety,error,error,3046,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3052,safety,detect,detector,3052,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3908,safety,detect,detected,3908,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3932,safety,error,errors,3932,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3966,safety,ERROR,ERROR,3966,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3983,safety,error,errors,3983,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:693,security,integr,integrations,693,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1317,security,detect,detector,1317,"ich deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 31",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1825,security,loss,loss,1825,"e <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUM",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2760,security,detect,detected,2760,",000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3052,security,detect,detector,3052,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3908,security,detect,detected,3908,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:693,testability,integr,integrations,693,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2849,testability,context,contexts,2849,"==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3997,testability,context,contexts,3997,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:4,usability,memor,memory,4,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:180,usability,memor,memory,180,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:444,usability,memor,memory,444,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:634,usability,memor,memory,634,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:738,usability,discov,discovered,738,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:794,usability,Minim,Minimal,794,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1180,usability,tool,tool,1180,"mory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1256,usability,error,errors,1256,"Integrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1304,usability,memor,memory,1304," is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== defin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1311,usability,error,error,1311,"oked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely l",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1489,usability,Command,Command,1489,"ch is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachabl",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2784,usability,error,errors,2784," 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are n",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2818,usability,ERROR,ERROR,2818," in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2835,usability,error,errors,2835,",515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2915,usability,tool,tool,2915,"emcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2991,usability,error,errors,2991,"ibgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3039,usability,memor,memory,3039,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3046,usability,error,error,3046,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3224,usability,Command,Command,3224,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3932,usability,error,errors,3932,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3966,usability,ERROR,ERROR,3966,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3983,usability,error,errors,3983,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/930:30,deployability,modul,modules,30,[cxxmodules] Start generating modules in rootcling.; See the specific commits for changes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:61,interoperability,specif,specific,61,[cxxmodules] Start generating modules in rootcling.; See the specific commits for changes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:30,modifiability,modul,modules,30,[cxxmodules] Start generating modules in rootcling.; See the specific commits for changes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/930:30,safety,modul,modules,30,[cxxmodules] Start generating modules in rootcling.; See the specific commits for changes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/930
https://github.com/root-project/root/pull/931:112,deployability,modul,modules,112,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/931:211,deployability,patch,patch,211,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/931:318,deployability,modul,modules-bugs,318,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/931:148,interoperability,semant,semantic,148,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/931:112,modifiability,modul,modules,112,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/931:318,modifiability,modul,modules-bugs,318,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/931:112,safety,modul,modules,112,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/931:211,safety,patch,patch,211,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/931:318,safety,modul,modules-bugs,318,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/931:211,security,patch,patch,211,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/931:157,usability,behavi,behavior,157,"[cxxmodules] Mark libc/STL as system; As seen in the posix_memalign workaround in clang, it seems that. marking modules as system actually has more semantic behavior. than just disabling warnings for them. This patch marks both. STL and libc as system to fix those issues. Also see: https://github.com/Teemperor/clang-modules-bugs/issues/3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/931
https://github.com/root-project/root/pull/932:5,usability,support,support,5,"Also support ctors, dtors in TListOfFunctions::GetListForObject().;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/932
https://github.com/root-project/root/pull/933:158,safety,test,test,158,"[DOC] Improve TDataFrame-related entries in codeowners file.; Hi,. I noticed the TDataFrame entries for the code owners were a bit weird. I'm not sure how to test I did not screw up the syntax (the `**` pattern was explained [here](https://git-scm.com/docs/gitignore) and codeowners should allow the same pattern matching syntax).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/933
https://github.com/root-project/root/pull/933:158,testability,test,test,158,"[DOC] Improve TDataFrame-related entries in codeowners file.; Hi,. I noticed the TDataFrame entries for the code owners were a bit weird. I'm not sure how to test I did not screw up the syntax (the `**` pattern was explained [here](https://git-scm.com/docs/gitignore) and codeowners should allow the same pattern matching syntax).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/933
https://github.com/root-project/root/pull/934:175,availability,slo,slot,175,"[IMT] Add TThreadedObject::GetAtSlotRaw; Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more. safety for some more performance: not only it avoids checking for. slot initialization (as `GetAtSlotUnchecked` does) but it also avoids. (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:129,performance,perform,performance,129,"[IMT] Add TThreadedObject::GetAtSlotRaw; Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more. safety for some more performance: not only it avoids checking for. slot initialization (as `GetAtSlotUnchecked` does) but it also avoids. (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:175,reliability,slo,slot,175,"[IMT] Add TThreadedObject::GetAtSlotRaw; Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more. safety for some more performance: not only it avoids checking for. slot initialization (as `GetAtSlotUnchecked` does) but it also avoids. (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:220,reliability,doe,does,220,"[IMT] Add TThreadedObject::GetAtSlotRaw; Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more. safety for some more performance: not only it avoids checking for. slot initialization (as `GetAtSlotUnchecked` does) but it also avoids. (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:108,safety,safe,safety,108,"[IMT] Add TThreadedObject::GetAtSlotRaw; Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more. safety for some more performance: not only it avoids checking for. slot initialization (as `GetAtSlotUnchecked` does) but it also avoids. (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:154,safety,avoid,avoids,154,"[IMT] Add TThreadedObject::GetAtSlotRaw; Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more. safety for some more performance: not only it avoids checking for. slot initialization (as `GetAtSlotUnchecked` does) but it also avoids. (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:238,safety,avoid,avoids,238,"[IMT] Add TThreadedObject::GetAtSlotRaw; Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more. safety for some more performance: not only it avoids checking for. slot initialization (as `GetAtSlotUnchecked` does) but it also avoids. (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:297,safety,test,test,297,"[IMT] Add TThreadedObject::GetAtSlotRaw; Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more. safety for some more performance: not only it avoids checking for. slot initialization (as `GetAtSlotUnchecked` does) but it also avoids. (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:297,testability,test,test,297,"[IMT] Add TThreadedObject::GetAtSlotRaw; Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more. safety for some more performance: not only it avoids checking for. slot initialization (as `GetAtSlotUnchecked` does) but it also avoids. (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/934:129,usability,perform,performance,129,"[IMT] Add TThreadedObject::GetAtSlotRaw; Compared to `GetAtSlotUnchecked`, `GetAtSlotRaw` trades some more. safety for some more performance: not only it avoids checking for. slot initialization (as `GetAtSlotUnchecked` does) but it also avoids. (copy-)construction of a `shared_ptr`. I can add a test, just tell me where :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/934
https://github.com/root-project/root/pull/935:87,deployability,API,API,87,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:274,deployability,build,build,274,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:444,deployability,build,build,444,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:536,deployability,version,version,536,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:87,integrability,API,API,87,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:536,integrability,version,version,536,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:87,interoperability,API,API,87,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:0,modifiability,Exten,Extending,0,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:207,modifiability,exten,extended,207,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:536,modifiability,version,version,536,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:644,modifiability,exten,extended,644,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:398,reliability,doe,doesn,398,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:47,security,checksum,checksum,47,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/935:126,security,checksum,checksum,126,"Extending FindLZ4 with a xxhash needed for LZ4 checksum func. and adding ""pure"" xxhash API in case standalone lz4; With a new checksum functionality, it is required to have xxhash library: FindLZ4.cmake was extended to check if you have xxhash includes (for the case if you build your own standalone LZ4, where xxhash is a part of project) and find library in case if you are using system LZ4 that doesn't have xxhash (in this case you need to build standalone xxhash library), otherwise to fall back to builtin_lz4 option. Builtin LZ4 version has xxhash library built inside by itself and provides different xxhash symbols for the LZ4 library extended with LZ4 namespace, while if it is used standalone LZ4 with standalone xxhash. To separate them, it was introduced LZ4_DEFINITIONS. @amadio @bbockelm can you look please?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/935
https://github.com/root-project/root/pull/936:55,deployability,modul,modules,55,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:96,deployability,modul,module,96,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:120,deployability,modul,module,120,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:127,deployability,contain,contains,127,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:399,deployability,modul,module,399,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:189,energy efficiency,current,currently,189,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:55,modifiability,modul,modules,55,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:96,modifiability,modul,module,96,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:120,modifiability,modul,module,120,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:399,modifiability,modul,module,399,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:213,performance,content,contents,213,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:454,performance,content,contents,454,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:55,safety,modul,modules,55,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:96,safety,modul,module,96,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:120,safety,modul,module,120,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/936:399,safety,modul,module,399,"[cxxmodules] Unify *32 dictionaries into one; With C++ modules we are supposed to have a unique module name where. each module contains different headers. But smatrix(32) or genvector(32). currently have the same contents and also the same name. As we. anyway also have a combined LinkDef file for both cases, we just. unify those two dictionaries when using runtime_modules and have. only a single module in the end which has an unique name and. unique contents.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/936
https://github.com/root-project/root/pull/937:83,safety,Avoid,Avoid,83,"[TDF] More string_views, less strings.; Prefer string_view in function signatures. Avoid instantiating strings whenever possible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/937
https://github.com/root-project/root/pull/937:71,security,sign,signatures,71,"[TDF] More string_views, less strings.; Prefer string_view in function signatures. Avoid instantiating strings whenever possible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/937
https://github.com/root-project/root/pull/937:40,usability,Prefer,Prefer,40,"[TDF] More string_views, less strings.; Prefer string_view in function signatures. Avoid instantiating strings whenever possible.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/937
https://github.com/root-project/root/pull/938:42,deployability,build,build,42,Properly implement the memory_termination build option.; It seems my last commit doesn't properly implement the way we. add a define to the dictionary. It seems this is the proper way. to do it instead of just calling add_definitions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/938:81,reliability,doe,doesn,81,Properly implement the memory_termination build option.; It seems my last commit doesn't properly implement the way we. add a define to the dictionary. It seems this is the proper way. to do it instead of just calling add_definitions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/938
https://github.com/root-project/root/pull/940:30,availability,failur,failures,30,"Do not diagnose instantiation failures during function lookup.; Fixes an issue for ATLAS, where Property<string>::Property<string&> cannot be instantiated by ROOT. ROOT is trying to do that because the function is templated, with all template parameters having defaults. (This ""let us instantiate if all template params have defaults"" is needed e.g. to see pair::pair() which is sfinae protected.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:30,deployability,fail,failures,30,"Do not diagnose instantiation failures during function lookup.; Fixes an issue for ATLAS, where Property<string>::Property<string&> cannot be instantiated by ROOT. ROOT is trying to do that because the function is templated, with all template parameters having defaults. (This ""let us instantiate if all template params have defaults"" is needed e.g. to see pair::pair() which is sfinae protected.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:243,modifiability,paramet,parameters,243,"Do not diagnose instantiation failures during function lookup.; Fixes an issue for ATLAS, where Property<string>::Property<string&> cannot be instantiated by ROOT. ROOT is trying to do that because the function is templated, with all template parameters having defaults. (This ""let us instantiate if all template params have defaults"" is needed e.g. to see pair::pair() which is sfinae protected.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:30,performance,failur,failures,30,"Do not diagnose instantiation failures during function lookup.; Fixes an issue for ATLAS, where Property<string>::Property<string&> cannot be instantiated by ROOT. ROOT is trying to do that because the function is templated, with all template parameters having defaults. (This ""let us instantiate if all template params have defaults"" is needed e.g. to see pair::pair() which is sfinae protected.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:7,reliability,diagno,diagnose,7,"Do not diagnose instantiation failures during function lookup.; Fixes an issue for ATLAS, where Property<string>::Property<string&> cannot be instantiated by ROOT. ROOT is trying to do that because the function is templated, with all template parameters having defaults. (This ""let us instantiate if all template params have defaults"" is needed e.g. to see pair::pair() which is sfinae protected.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:30,reliability,fail,failures,30,"Do not diagnose instantiation failures during function lookup.; Fixes an issue for ATLAS, where Property<string>::Property<string&> cannot be instantiated by ROOT. ROOT is trying to do that because the function is templated, with all template parameters having defaults. (This ""let us instantiate if all template params have defaults"" is needed e.g. to see pair::pair() which is sfinae protected.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/940:7,testability,diagno,diagnose,7,"Do not diagnose instantiation failures during function lookup.; Fixes an issue for ATLAS, where Property<string>::Property<string&> cannot be instantiated by ROOT. ROOT is trying to do that because the function is templated, with all template parameters having defaults. (This ""let us instantiate if all template params have defaults"" is needed e.g. to see pair::pair() which is sfinae protected.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/940
https://github.com/root-project/root/pull/941:181,usability,confirm,confirm,181,"[TDF] Remove `gROOTMutex->UnLock()` from jitted code; IIUC, commit 7ee8950bed removes the need for explicit unlocking of the global mutex from jitted code. I hope @Axel-Naumann can confirm :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/941
https://github.com/root-project/root/pull/942:733,energy efficiency,current,current,733,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:1217,energy efficiency,current,currently,1217,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:8,integrability,INTERFAC,INTERFACE,8,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:222,integrability,INTERFAC,INTERFACE,222,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:236,integrability,PUB,PUBLIC,236,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:401,integrability,PUB,PUBLIC,401,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:414,integrability,INTERFAC,INTERFACE,414,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:582,integrability,PUB,PUBLIC,582,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:598,integrability,INTERFAC,INTERFACE,598,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:686,integrability,INTERFAC,INTERFACE,686,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:1007,integrability,INTERFAC,INTERFACE,1007,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:1041,integrability,PUB,PUBLIC,1041,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:8,interoperability,INTERFAC,INTERFACE,8,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:222,interoperability,INTERFAC,INTERFACE,222,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:414,interoperability,INTERFAC,INTERFACE,414,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:598,interoperability,INTERFAC,INTERFACE,598,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:686,interoperability,INTERFAC,INTERFACE,686,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:1007,interoperability,INTERFAC,INTERFACE,1007,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:8,modifiability,INTERFAC,INTERFACE,8,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:222,modifiability,INTERFAC,INTERFACE,222,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:414,modifiability,INTERFAC,INTERFACE,414,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:598,modifiability,INTERFAC,INTERFACE,598,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:686,modifiability,INTERFAC,INTERFACE,686,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:1007,modifiability,INTERFAC,INTERFACE,1007,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:0,usability,Support,Support,0,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:493,usability,prefer,preferred,493,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:554,usability,user,user,554,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/942:741,usability,behavi,behaviour,741,"Support INTERFACE include directories in ROOT_GENERATE_DICTIONARY; CMake offers three visibility qualifiers for target include. directories, which are populated to target properties as shown in the. following table:. | | `INTERFACE` | `PUBLIC` | `PRIVATE` |. | --- | --- | --- | --- |. | `INCLUDE_DIRECTORIES` | | x | x |. | `INTERFACE_INCLUDE_DIRECTORIES` | X | x | |. For dictionary generation the `PUBLIC` and `INTERFACE` qualifiers and. hence the `INTERFACE_INCLUDE_DIRECTORIES` are to be preferred, because. header files meant to be consumed by the user are usually put into. `PUBLIC` and/or `INTERFACE` qualified directories. Furthermore, the CMake. imported targets always have `INTERFACE` visibility. This commit changes the current behaviour to read the. `INTERFACE_INCLUDE_DIRECTORIES` (as opposed to the `INCLUDE_DIRECTORIES`). target property which will catch more desired use cases, including. imported targets. In other words, this will now ignore `PRIVATE` include. directories, but include `INTERFACE` include directories - `PUBLIC` ones. stay unchanged. In addition, this commit adds a condition which ignores include. directories formulated as a CMake generator expression. Unfortunately,. there is currently no way to evaluate those seperately.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/942
https://github.com/root-project/root/pull/943:70,deployability,API,APIs,70,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:210,deployability,API,APIs,210,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:704,deployability,version,version,704,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:773,deployability,API,APIs,773,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:797,deployability,API,APIs,797,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1137,deployability,API,APIs,1137," here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1269,deployability,API,APIs,1269,"ere the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1399,deployability,API,API,1399,"xisting memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2408,deployability,depend,depends,2408,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:696,energy efficiency,current,current,696,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:70,integrability,API,APIs,70,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:210,integrability,API,APIs,210,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:416,integrability,buffer,buffers,416,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:704,integrability,version,version,704,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:773,integrability,API,APIs,773,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:797,integrability,API,APIs,797,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:859,integrability,event,event,859,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:977,integrability,event,event,977,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1104,integrability,event,event,1104,"al` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1137,integrability,API,APIs,1137," here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1194,integrability,interfac,interfaces,1194,"he bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to furth",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1226,integrability,interfac,interface,1226,"s fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1269,integrability,API,APIs,1269,"ere the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1293,integrability,buffer,buffer,1293,"atively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1399,integrability,API,API,1399,"xisting memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1435,integrability,interfac,interface,1435,"primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've de",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1526,integrability,interfac,interface,1526,"ite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thank",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1563,integrability,buffer,buffer,1563,"eful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this wo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1815,integrability,interfac,interface,1815,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1966,integrability,interfac,interface,1966,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2146,integrability,interfac,interface,2146,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2231,integrability,interfac,interface,2231,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2345,integrability,interfac,interface,2345,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2408,integrability,depend,depends,2408,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2600,integrability,interfac,interface,2600,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:70,interoperability,API,APIs,70,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:210,interoperability,API,APIs,210,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:738,interoperability,format,format,738,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:773,interoperability,API,APIs,773,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:797,interoperability,API,APIs,797,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1137,interoperability,API,APIs,1137," here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1194,interoperability,interfac,interfaces,1194,"he bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to furth",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1226,interoperability,interfac,interface,1226,"s fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1269,interoperability,API,APIs,1269,"ere the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1399,interoperability,API,API,1399,"xisting memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1435,interoperability,interfac,interface,1435,"primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've de",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1526,interoperability,interfac,interface,1526,"ite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thank",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1815,interoperability,interfac,interface,1815,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1966,interoperability,interfac,interface,1966,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2146,interoperability,interfac,interface,2146,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2231,interoperability,interfac,interface,2231,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2345,interoperability,interfac,interface,2345,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2600,interoperability,interfac,interface,2600,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:704,modifiability,version,version,704,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1194,modifiability,interfac,interfaces,1194,"he bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to furth",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1226,modifiability,interfac,interface,1226,"s fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1435,modifiability,interfac,interface,1435,"primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've de",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1526,modifiability,interfac,interface,1526,"ite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thank",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1815,modifiability,interfac,interface,1815,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1832,modifiability,exten,extended,1832,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1966,modifiability,interfac,interface,1966,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2146,modifiability,interfac,interface,2146,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2231,modifiability,interfac,interface,2231,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2345,modifiability,interfac,interface,2345,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2408,modifiability,depend,depends,2408,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2600,modifiability,interfac,interface,2600,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:409,performance,memor,memory,409,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1027,performance,overhead,overheads,1027,"first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1717,performance,memor,memory,1717,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2016,performance,memor,memory,2016,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2478,performance,time,time,2478,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:165,safety,review,reviewer,165,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2408,safety,depend,depends,2408,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:238,security,access,access,238,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1982,security,expos,exposes,1982,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2072,security,access,access,2072,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:165,testability,review,reviewer,165,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:304,testability,simpl,simple,304,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2408,testability,depend,depends,2408,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:188,usability,feedback,feedback,188,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:279,usability,user,user,279,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:304,usability,simpl,simple,304,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:409,usability,memor,memory,409,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:479,usability,support,supported,479,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:604,usability,support,supported,604,"[WIP] Bulk IO - v2; This is the first attempt for merging the bulk IO APIs (hidden inside the `ROOT::Internal` namespace). The initial goal here is to start getting reviewer attention and feedback. The bulk IO APIs aim to provide as fast access as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1241,usability,user,user,1241,"s as possible in the case where the user is using relatively simple datatypes and the objects can be deserialized ""non-destructively"" (i.e., in-place in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1385,usability,user,users,1385,"lace in the existing memory buffers). For example - primitives and lists of primitives are supported; anything needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1493,usability,user,users,1493,"ng needing references are not. Despite the fact many of ROOT's very useful deserialization features are not supported, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talk",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1717,usability,memor,memory,1717,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:1761,usability,user,user,1761,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2016,usability,memor,memory,2016,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/943:2062,usability,efficien,efficient,2062,"ed, the limited feature set covers a range of analysis use cases. In particular, the current version of CMS's proposed NanoAOD format can be read solely via bulk APIs. Where the bulk IO APIs are applicable, we see an order-magnitude improvement in event rates for some use cases (including CMS NanoAOD). The speedup becomes more noticeable as the data read from the event is smaller (meaning the traditional ROOT IO overheads are larger). Somewhere in the neighborhood of 5KB objects read per event is the point where bulk IO APIs should be noticeably faster. This PR provides three interfaces:. - A raw, low-level interface. The user can invoke the bulk IO APIs directly and get a buffer of primitive types, serialized or deserialized. It is not envisioned this is used by users, but by API writers. - A `TTreeReader`-like interface, `TTreeReaderFast`. This is meant to be used by users; it utilizes the low-level interface to retrieve the serialized buffer and templated code will inline the deserializing as part of iterating through the tree. The speed here is gained by the fact only a single pass in memory is needed to deserialize *and* apply user code, rather than two. - The intent is that this interface can be extended in the future and used by `TDataFrame`, provided we can make `TDataFrame` sufficiently fast. - A Python-based `numpy` export interface. This exposes the (possibly serialized) memory directly as numpy arrays, allowing for efficient access to ROOT-serialized objects from the Python language. - The `numpy` interface is low-level for Python; we intend to further explore the ideal high-level interface through projects such as https://github.com/diana-hep/plur. So indeed, lot's of experimental / internal interface work here - but we felt that (a) a sufficient amount depends on this and (b) we've demonstrated enough utility that it was time to start talking about merging. (With many thanks to @jpivarski for driving this work home with his work on a python interface!)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/943
https://github.com/root-project/root/pull/944:77,deployability,modul,modules,77,"[cxxmodules] Set ROOT_MODULES=DEBUG for rootcling invocations, also activate modules in the interpreter outside rootcling.; We need to set ROOT_MODULES to DEBUG when we want rootcling to. create C++ modules. For this we wrap all rootcling invocations. in cmake wrappers that set this environment variable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:199,deployability,modul,modules,199,"[cxxmodules] Set ROOT_MODULES=DEBUG for rootcling invocations, also activate modules in the interpreter outside rootcling.; We need to set ROOT_MODULES to DEBUG when we want rootcling to. create C++ modules. For this we wrap all rootcling invocations. in cmake wrappers that set this environment variable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:220,integrability,wrap,wrap,220,"[cxxmodules] Set ROOT_MODULES=DEBUG for rootcling invocations, also activate modules in the interpreter outside rootcling.; We need to set ROOT_MODULES to DEBUG when we want rootcling to. create C++ modules. For this we wrap all rootcling invocations. in cmake wrappers that set this environment variable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:261,integrability,wrap,wrappers,261,"[cxxmodules] Set ROOT_MODULES=DEBUG for rootcling invocations, also activate modules in the interpreter outside rootcling.; We need to set ROOT_MODULES to DEBUG when we want rootcling to. create C++ modules. For this we wrap all rootcling invocations. in cmake wrappers that set this environment variable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:261,interoperability,wrapper,wrappers,261,"[cxxmodules] Set ROOT_MODULES=DEBUG for rootcling invocations, also activate modules in the interpreter outside rootcling.; We need to set ROOT_MODULES to DEBUG when we want rootcling to. create C++ modules. For this we wrap all rootcling invocations. in cmake wrappers that set this environment variable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:77,modifiability,modul,modules,77,"[cxxmodules] Set ROOT_MODULES=DEBUG for rootcling invocations, also activate modules in the interpreter outside rootcling.; We need to set ROOT_MODULES to DEBUG when we want rootcling to. create C++ modules. For this we wrap all rootcling invocations. in cmake wrappers that set this environment variable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:199,modifiability,modul,modules,199,"[cxxmodules] Set ROOT_MODULES=DEBUG for rootcling invocations, also activate modules in the interpreter outside rootcling.; We need to set ROOT_MODULES to DEBUG when we want rootcling to. create C++ modules. For this we wrap all rootcling invocations. in cmake wrappers that set this environment variable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:296,modifiability,variab,variable,296,"[cxxmodules] Set ROOT_MODULES=DEBUG for rootcling invocations, also activate modules in the interpreter outside rootcling.; We need to set ROOT_MODULES to DEBUG when we want rootcling to. create C++ modules. For this we wrap all rootcling invocations. in cmake wrappers that set this environment variable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:77,safety,modul,modules,77,"[cxxmodules] Set ROOT_MODULES=DEBUG for rootcling invocations, also activate modules in the interpreter outside rootcling.; We need to set ROOT_MODULES to DEBUG when we want rootcling to. create C++ modules. For this we wrap all rootcling invocations. in cmake wrappers that set this environment variable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/944:199,safety,modul,modules,199,"[cxxmodules] Set ROOT_MODULES=DEBUG for rootcling invocations, also activate modules in the interpreter outside rootcling.; We need to set ROOT_MODULES to DEBUG when we want rootcling to. create C++ modules. For this we wrap all rootcling invocations. in cmake wrappers that set this environment variable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/944
https://github.com/root-project/root/pull/945:0,safety,Test,Test,0,Test PR to trigger jenkins;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/945
https://github.com/root-project/root/pull/945:0,testability,Test,Test,0,Test PR to trigger jenkins;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/945
https://github.com/root-project/root/pull/946:17,availability,error,error,17,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:118,availability,error,error,118,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:157,availability,down,downgrade,157,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:322,modifiability,variab,variable,322,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:17,performance,error,error,17,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:118,performance,error,error,118,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:80,reliability,doe,doesn,80,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:17,safety,error,error,17,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:118,safety,error,error,118,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:17,usability,error,error,17,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/946:118,usability,error,error,118,"Make the missing error in rootcling a warning; This code assumed that rootcling doesn't return zero when we. print an error, but this is not the case. Let's downgrade it to. a warning that we actually still return a zero exit code. Also the method now just returns true instead of writing 'true'. twice to the same result variable and then returning that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/946
https://github.com/root-project/root/pull/947:98,interoperability,XML,XML,98,Equip custom streamer for TPolyLine3D and TMaterial; Let normally store these classes in JSON and XML. Required to run some ROOT macros (like graphs/annotations.C) in webcanvas and JSROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/947
https://github.com/root-project/root/pull/947:6,usability,custom,custom,6,Equip custom streamer for TPolyLine3D and TMaterial; Let normally store these classes in JSON and XML. Required to run some ROOT macros (like graphs/annotations.C) in webcanvas and JSROOT,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/947
https://github.com/root-project/root/pull/948:239,deployability,instal,install,239,"[cmake] Stop searching headers in the default paths; find_file without NO_DEFAULT_PATH searches pretty much the whole. file system for the given file. As we are looking for a root. header here that we then turn into a dictionary, copy and install. it we should probably limit us to just the ROOT directories here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/948:8,usability,Stop,Stop,8,"[cmake] Stop searching headers in the default paths; find_file without NO_DEFAULT_PATH searches pretty much the whole. file system for the given file. As we are looking for a root. header here that we then turn into a dictionary, copy and install. it we should probably limit us to just the ROOT directories here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/948
https://github.com/root-project/root/pull/949:48,energy efficiency,current,currently,48,"Limit CMake search for RootTestDriver.cmake; We currently search for the RootTestDriver.cmake on the whole. system, which could lead to some very funny behaviour if we. pick up the wrong file. Especially since the given paths to. this search function are not the first paths that CMake will. search.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/949
https://github.com/root-project/root/pull/949:152,usability,behavi,behaviour,152,"Limit CMake search for RootTestDriver.cmake; We currently search for the RootTestDriver.cmake on the whole. system, which could lead to some very funny behaviour if we. pick up the wrong file. Especially since the given paths to. this search function are not the first paths that CMake will. search.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/949
https://github.com/root-project/root/pull/950:33,deployability,build,build,33,Fix Imt configure in the classic build; Obviously we shouldn't activate C++ modules when people want Imt.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:76,deployability,modul,modules,76,Fix Imt configure in the classic build; Obviously we shouldn't activate C++ modules when people want Imt.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:8,integrability,configur,configure,8,Fix Imt configure in the classic build; Obviously we shouldn't activate C++ modules when people want Imt.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:8,modifiability,configur,configure,8,Fix Imt configure in the classic build; Obviously we shouldn't activate C++ modules when people want Imt.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:76,modifiability,modul,modules,76,Fix Imt configure in the classic build; Obviously we shouldn't activate C++ modules when people want Imt.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:76,safety,modul,modules,76,Fix Imt configure in the classic build; Obviously we shouldn't activate C++ modules when people want Imt.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/950:8,security,configur,configure,8,Fix Imt configure in the classic build; Obviously we shouldn't activate C++ modules when people want Imt.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/950
https://github.com/root-project/root/pull/951:75,deployability,modul,modules,75,[cxxmodules] Add missing includes to TF1AbsComposition; This fixes the C++ modules builds as they struggle on this missing. include and fail to compile the module containing it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/951
https://github.com/root-project/root/pull/951:83,deployability,build,builds,83,[cxxmodules] Add missing includes to TF1AbsComposition; This fixes the C++ modules builds as they struggle on this missing. include and fail to compile the module containing it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/951
https://github.com/root-project/root/pull/951:136,deployability,fail,fail,136,[cxxmodules] Add missing includes to TF1AbsComposition; This fixes the C++ modules builds as they struggle on this missing. include and fail to compile the module containing it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/951
https://github.com/root-project/root/pull/951:156,deployability,modul,module,156,[cxxmodules] Add missing includes to TF1AbsComposition; This fixes the C++ modules builds as they struggle on this missing. include and fail to compile the module containing it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/951
https://github.com/root-project/root/pull/951:163,deployability,contain,containing,163,[cxxmodules] Add missing includes to TF1AbsComposition; This fixes the C++ modules builds as they struggle on this missing. include and fail to compile the module containing it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/951
https://github.com/root-project/root/pull/951:75,modifiability,modul,modules,75,[cxxmodules] Add missing includes to TF1AbsComposition; This fixes the C++ modules builds as they struggle on this missing. include and fail to compile the module containing it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/951
https://github.com/root-project/root/pull/951:156,modifiability,modul,module,156,[cxxmodules] Add missing includes to TF1AbsComposition; This fixes the C++ modules builds as they struggle on this missing. include and fail to compile the module containing it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/951
https://github.com/root-project/root/pull/951:136,reliability,fail,fail,136,[cxxmodules] Add missing includes to TF1AbsComposition; This fixes the C++ modules builds as they struggle on this missing. include and fail to compile the module containing it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/951
https://github.com/root-project/root/pull/951:75,safety,modul,modules,75,[cxxmodules] Add missing includes to TF1AbsComposition; This fixes the C++ modules builds as they struggle on this missing. include and fail to compile the module containing it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/951
https://github.com/root-project/root/pull/951:156,safety,modul,module,156,[cxxmodules] Add missing includes to TF1AbsComposition; This fixes the C++ modules builds as they struggle on this missing. include and fail to compile the module containing it.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/951
https://github.com/root-project/root/pull/952:104,availability,error,errors,104,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:163,availability,down,download,163,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:323,availability,error,error,323,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:417,availability,error,error,417,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:119,energy efficiency,current,currently,119,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:527,interoperability,standard,standard,527,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:625,interoperability,standard,standard,625,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:688,interoperability,standard,standard,688,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:773,interoperability,standard,standard,773,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:836,interoperability,standard,standard,836,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:921,interoperability,standard,standard,921,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:986,interoperability,standard,standard,986,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:1074,interoperability,standard,standard,1074,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:613,modifiability,extens,extensions,613,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:761,modifiability,extens,extensions,761,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:909,modifiability,extens,extensions,909,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:1062,modifiability,extens,extensions,1062,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:104,performance,error,errors,104,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:323,performance,error,error,323,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:417,performance,error,error,417,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:104,safety,error,errors,104,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:304,safety,avoid,avoiding,304,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:323,safety,error,error,323,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:417,safety,error,error,417,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:497,security,ISO,ISO,497,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:575,security,ISO,ISO,575,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:658,security,ISO,ISO,658,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:723,security,ISO,ISO,723,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:806,security,ISO,ISO,806,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:871,security,ISO,ISO,871,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:972,security,ISO,ISO,972,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:1039,security,ISO,ISO,1039,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:17,usability,support,support,17,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:104,usability,error,errors,104,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:187,usability,support,support,187,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:209,usability,support,support,209,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:323,usability,error,error,323,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/952:417,usability,error,error,417,cling-PR181: Add support C++1z for Jupyter kernel; When run C++17 kernel in Jupyter notebook cause some errors. due to currently clang-5.0 in https://root.cern.ch/download/cling/ is not. support c++17. So add support to C++1z for Jupyter kernel and we can try some new. features in Jupyter notebook. for avoiding following error:. [I 05:46:38.253 NotebookApp] Kernel restarted:. d3413fa0-7046-4b63-912b-a286610eacc1. error: invalid value 'c++17' in '-std=c++17'. note: use 'c++98' or 'c++03' for 'ISO C++ 1998 with amendments' standard. note: use 'gnu++98' or 'gnu++03' for 'ISO C++ 1998 with amendments and. GNU extensions' standard. note: use 'c++11' for 'ISO C++ 2011 with amendments' standard. note: use 'gnu++11' for 'ISO C++ 2011 with amendments and GNU. extensions' standard. note: use 'c++14' for 'ISO C++ 2014 with amendments' standard. note: use 'gnu++14' for 'ISO C++ 2014 with amendments and GNU. extensions' standard. note: use 'c++1z' for 'Working draft for ISO C++ 2017' standard. note: use 'gnu++1z' for 'Working draft for ISO C++ 2017 with GNU. extensions' standard,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/952
https://github.com/root-project/root/pull/953:87,integrability,wrap,wrap,87,"ROOT I/O bug fixes and improvements; Fix nullptr dereference bugs in TClass and TList, wrap TClass.cxx to 120 columns to follow coding conventions, and avoid StreamerInfo lookup when it is cached.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:5,performance,I/O,I/O,5,"ROOT I/O bug fixes and improvements; Fix nullptr dereference bugs in TClass and TList, wrap TClass.cxx to 120 columns to follow coding conventions, and avoid StreamerInfo lookup when it is cached.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:189,performance,cach,cached,189,"ROOT I/O bug fixes and improvements; Fix nullptr dereference bugs in TClass and TList, wrap TClass.cxx to 120 columns to follow coding conventions, and avoid StreamerInfo lookup when it is cached.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/953:152,safety,avoid,avoid,152,"ROOT I/O bug fixes and improvements; Fix nullptr dereference bugs in TClass and TList, wrap TClass.cxx to 120 columns to follow coding conventions, and avoid StreamerInfo lookup when it is cached.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/953
https://github.com/root-project/root/pull/956:186,availability,operat,operations,186,"New Zlib CMS/CloudFlare v1.2.11; Here you can find reports about performance of new zlib: https://indico.cern.ch/event/658075/. New zlib is showing ~3 ~4 times faster in case of ""write"" operations for 109 and 106 compression settings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:13,energy efficiency,Cloud,CloudFlare,13,"New Zlib CMS/CloudFlare v1.2.11; Here you can find reports about performance of new zlib: https://indico.cern.ch/event/658075/. New zlib is showing ~3 ~4 times faster in case of ""write"" operations for 109 and 106 compression settings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:113,integrability,event,event,113,"New Zlib CMS/CloudFlare v1.2.11; Here you can find reports about performance of new zlib: https://indico.cern.ch/event/658075/. New zlib is showing ~3 ~4 times faster in case of ""write"" operations for 109 and 106 compression settings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:65,performance,perform,performance,65,"New Zlib CMS/CloudFlare v1.2.11; Here you can find reports about performance of new zlib: https://indico.cern.ch/event/658075/. New zlib is showing ~3 ~4 times faster in case of ""write"" operations for 109 and 106 compression settings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:154,performance,time,times,154,"New Zlib CMS/CloudFlare v1.2.11; Here you can find reports about performance of new zlib: https://indico.cern.ch/event/658075/. New zlib is showing ~3 ~4 times faster in case of ""write"" operations for 109 and 106 compression settings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/956:65,usability,perform,performance,65,"New Zlib CMS/CloudFlare v1.2.11; Here you can find reports about performance of new zlib: https://indico.cern.ch/event/658075/. New zlib is showing ~3 ~4 times faster in case of ""write"" operations for 109 and 106 compression settings.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/956
https://github.com/root-project/root/pull/957:5,energy efficiency,Reduc,Reduce,5,WIP: Reduce scope of interpreter lock in TClass::GetListOfBases(); Avoid taking a lock if list of bases has already been computed. Still need to reason about thread-safety prior to merging.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:33,performance,lock,lock,33,WIP: Reduce scope of interpreter lock in TClass::GetListOfBases(); Avoid taking a lock if list of bases has already been computed. Still need to reason about thread-safety prior to merging.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:82,performance,lock,lock,82,WIP: Reduce scope of interpreter lock in TClass::GetListOfBases(); Avoid taking a lock if list of bases has already been computed. Still need to reason about thread-safety prior to merging.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:67,safety,Avoid,Avoid,67,WIP: Reduce scope of interpreter lock in TClass::GetListOfBases(); Avoid taking a lock if list of bases has already been computed. Still need to reason about thread-safety prior to merging.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:165,safety,safe,safety,165,WIP: Reduce scope of interpreter lock in TClass::GetListOfBases(); Avoid taking a lock if list of bases has already been computed. Still need to reason about thread-safety prior to merging.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:33,security,lock,lock,33,WIP: Reduce scope of interpreter lock in TClass::GetListOfBases(); Avoid taking a lock if list of bases has already been computed. Still need to reason about thread-safety prior to merging.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/957:82,security,lock,lock,82,WIP: Reduce scope of interpreter lock in TClass::GetListOfBases(); Avoid taking a lock if list of bases has already been computed. Still need to reason about thread-safety prior to merging.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/957
https://github.com/root-project/root/pull/958:0,deployability,Updat,Update,0,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:42,deployability,version,version,42,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:175,deployability,version,version,175,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:250,deployability,version,versions,250,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:388,deployability,version,version,388,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:433,deployability,build,builds,433,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:488,deployability,build,buildSummary,488,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:505,deployability,build,buildid,505,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:927,deployability,version,versions,927,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:396,energy efficiency,current,currently,396,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:42,integrability,version,version,42,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:175,integrability,version,version,175,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:250,integrability,version,versions,250,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:388,integrability,version,version,388,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:927,integrability,version,versions,927,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:902,interoperability,compatib,compatibility,902,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:42,modifiability,version,version,42,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:175,modifiability,version,version,175,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:250,modifiability,version,versions,250,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:388,modifiability,version,version,388,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:927,modifiability,version,versions,927,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:0,safety,Updat,Update,0,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:406,safety,test,tested,406,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:572,safety,test,test,572,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:0,security,Updat,Update,0,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:13,security,polic,policy,13,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:157,security,polic,policies-by-cmake-version,157,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:197,security,polic,policy,197,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:230,security,polic,policies,230,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:319,security,polic,policies,319,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:541,security,polic,policy,541,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:603,security,polic,policy,603,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:689,security,Polic,Policy,689,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:787,security,polic,policy,787,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:807,security,polic,policy,807,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:864,security,polic,policy,864,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:406,testability,test,tested,406,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:572,testability,test,test,572,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:111,usability,help,help,111,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:123,usability,command,command,123,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:782,usability,help,help-policy,782,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/958:845,usability,command,command,845,"Update CMake policy settings to use CMake version 3.4.3; This is the [recommended way](https://cmake.org/cmake/help/latest/command/cmake_policy.html#setting-policies-by-cmake-version) to set CMake policy settings. This means that policies created in versions prior to 3.9 will use the NEW setting by default, and newer policies will generate warnings. Set to 3.9 since that's the highest version currently tested in Jenkins. The Mac builds are generating a [warning](http://cdash.cern.ch/buildSummary.php?buildid=393980) (shown below) about policy CMP0068, so I'd like to test this. and move to the new policy mechanism once any problems that show up are fixed. ```. CMake Warning (dev):. Policy CMP0068 is not set: RPATH settings on macOS do not affect. install_name. Run ""cmake --help-policy CMP0068"" for policy details. Use. the cmake_policy command to set the policy and suppress this warning. For compatibility with older versions of CMake, the install_name fields for. the following targets are still affected by RPATH settings:. LTO. libclang. This warning is for project developers. Use -Wno-dev to suppres-- Generating done. s it. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/958
https://github.com/root-project/root/pull/959:472,availability,error,error,472,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:251,deployability,version,version,251,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:357,deployability,version,versions,357,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:602,deployability,version,versions,602,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:251,integrability,version,version,251,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:357,integrability,version,versions,357,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:478,integrability,messag,message,478,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:602,integrability,version,versions,602,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:11,interoperability,compatib,compatibility,11,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:103,interoperability,compatib,compatibility,103,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:303,interoperability,compatib,compatibility,303,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:478,interoperability,messag,message,478,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:251,modifiability,version,version,251,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:357,modifiability,version,versions,357,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:602,modifiability,version,versions,602,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:472,performance,error,error,472,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:70,safety,test,tests,70,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:472,safety,error,error,472,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:186,security,ident,identify,186,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:65,testability,unit,unit,65,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:70,testability,test,tests,70,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:700,testability,plan,plan,700,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/959:472,usability,error,error,472,"IO forward-compatibility feature flags; This PR introduces (with unit tests!) the concept of a forward-compatibility feature break flag for `TBasket`. This allows the `TBasket` class to identify if the object being deserialized was written by a newer version of ROOT using a feature that breaks forward-compatibility. Note that much care was taken so older versions of ROOT that *don't* recognize the new flag will believe the file is corrupt; they will give a misleading error message, but will not silently serve corrupted data. If this approach goes forward, I intend to backport the flags to older versions of ROOT -- they should be able to recognize files they aren't supposed to read. I do not plan to backport the new IO features themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/959
https://github.com/root-project/root/pull/960:0,deployability,Updat,Updated,0,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:172,deployability,log,log,172,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:270,deployability,log,log-scale,270,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:274,energy efficiency,scale,scale,274,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:274,modifiability,scal,scale,274,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:274,performance,scale,scale,274,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:0,safety,Updat,Updated,0,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:172,safety,log,log,172,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:270,safety,log,log-scale,270,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:0,security,Updat,Updated,0,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:172,security,log,log,172,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:270,security,log,log-scale,270,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:172,testability,log,log,172,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:270,testability,log,log-scale,270,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:8,usability,document,documentation,8,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/960:117,usability,help,helps,117,Updated documentation for TPad::GetUxmax etc.; Added some brief information about the function of GetUxmax etc. This helps clarify its return value when the axis is set to log. Some of this was mentioned on the [ROOT forum](https://root-forum.cern.ch/t/tpolyline3d-with-log-scale/26115/9) with @couet.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/960
https://github.com/root-project/root/pull/961:1863,availability,operat,operator,1863,"ad::RecursiveRemove(TObject*) (TPad.cxx:5143). ==7117== by 0x51B73B7: TList::RecursiveRemove(TObject*) (TList.cxx:722). ==7117== by 0x51B96CB: THashList::RecursiveRemove(TObject*) (THashList.cxx:286). ==7117== by 0x514245A: TObject::~TObject() (TObject.cxx:88). ==7117== by 0x50EDC1D: TNamed::~TNamed() (TNamed.h:41). ==7117== by 0x14535B0F: TF1::~TF1() (TF1.cxx:827). ==7117== by 0x1454CA07: TF2::~TF2() (TF2.cxx:153). ==7117== by 0x1454CA3D: TF2::~TF2() (TF2.cxx:155). ==7117== by 0x51B09D4: TCollection::GarbageCollect(TObject*) (TCollection.cxx:748). ==7117== by 0x51B6BE8: TList::Delete(char const*) (TList.cxx:501). ==7117== by 0x518E05D: TROOT::EndOfProcessCleanups() (TROOT.cxx:1171). ==7117== by 0x524F659: TUnixSystem::Exit(int, bool) (TUnixSystem.cxx:2153). ==7117== by 0x5169BE1: TApplication::Terminate(int) (TApplication.cxx:1279). ==7117== by 0x4049925: TRint::Terminate(int) (TRint.cxx:686). ==7117== by 0x40486D5: TRint::Run(bool) (TRint.cxx:437). ==7117== by 0x4012AA: main (rmain.cxx:30). ==7117== Address 0x6e72ff8 is 8 bytes inside a block of size 56 free'd. ==7117== at 0x4C2918D: operator delete(void*) (vg_replace_malloc.c:576). ==7117== by 0x51B8B11: TObjOptLink::~TObjOptLink() (TList.h:163). ==7117== by 0x51B6DAF: TList::DeleteLink(TObjLink*) (TList.cxx:530). ==7117== by 0x51B74C0: TList::RecursiveRemove(TObject*) (TList.cxx:742). ==7117== by 0x4164444: TPad::RecursiveRemove(TObject*) (TPad.cxx:5143). ==7117== by 0x51B73B7: TList::RecursiveRemove(TObject*) (TList.cxx:722). ==7117== by 0x4164444: TPad::RecursiveRemove(TObject*) (TPad.cxx:5143). ==7117== by 0x51B73B7: TList::RecursiveRemove(TObject*) (TList.cxx:722). ==7117== by 0x51B96CB: THashList::RecursiveRemove(TObject*) (THashList.cxx:286). ==7117== by 0x514245A: TObject::~TObject() (TObject.cxx:88). ==7117== by 0x50EDC1D: TNamed::~TNamed() (TNamed.h:41). ==7117== by 0x14535B0F: TF1::~TF1() (TF1.cxx:827). ==7117== by 0x1454CA07: TF2::~TF2() (TF2.cxx:153). ==7117== by 0x1454CA3D: TF2::~TF2() (TF2.cxx:155)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/961
https://github.com/root-project/root/pull/962:0,safety,Test,Test,0,"Test PR, ignore please;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/962
https://github.com/root-project/root/pull/962:0,testability,Test,Test,0,"Test PR, ignore please;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/962
https://github.com/root-project/root/pull/963:111,deployability,depend,dependencies,111,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:188,deployability,modul,modules,188,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:268,deployability,depend,dependencies,268,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:523,deployability,depend,dependency,523,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:592,deployability,depend,dependencies,592,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:782,deployability,depend,dependencies,782,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:459,energy efficiency,current,current,459,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:607,energy efficiency,current,currently,607,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:111,integrability,depend,dependencies,111,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:268,integrability,depend,dependencies,268,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:523,integrability,depend,dependency,523,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:592,integrability,depend,dependencies,592,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:782,integrability,depend,dependencies,782,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:111,modifiability,depend,dependencies,111,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:188,modifiability,modul,modules,188,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:268,modifiability,depend,dependencies,268,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:523,modifiability,depend,dependency,523,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:592,modifiability,depend,dependencies,592,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:782,modifiability,depend,dependencies,782,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:111,safety,depend,dependencies,111,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:188,safety,modul,modules,188,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:268,safety,depend,dependencies,268,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:492,safety,safe,safely,492,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:523,safety,depend,dependency,523,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:592,safety,depend,dependencies,592,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:782,safety,depend,dependencies,782,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:111,testability,depend,dependencies,111,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:268,testability,depend,dependencies,268,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:523,testability,depend,dependency,523,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:592,testability,depend,dependencies,592,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:782,testability,depend,dependencies,782,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:577,usability,custom,custom,577,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/963:584,usability,command,command,584,"[cmake] Removed unnecessary ROOTCLING_ targets; I introduced those targets because I thought we actually have. dependencies between the different rootcling invocations because. of the C++ modules. After some discussion with Axel, it turns out. we actually always have dependencies here, as the dictionaries. should regenerate the dictionary when one of the referenced. libraries/headers change (as the declarations in there change,. which might influence the current dictionary). We can just safely remove this, the actual dependency which is. ARG_DEPENDENCIES is still in the custom command dependencies. (currently the ROOTCLING_ targets where just a no-op that was. supposed to activated in a later commit when we remove the. ARG_DEPENDENCIES and replace it with the ROOTCLING_. dependencies if runtime_modules was set to ON).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/963
https://github.com/root-project/root/pull/964:38,deployability,modul,modulemap,38,[cxxmodules] Rename stl.cppmap -> stl.modulemap;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/964
https://github.com/root-project/root/pull/964:38,modifiability,modul,modulemap,38,[cxxmodules] Rename stl.cppmap -> stl.modulemap;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/964
https://github.com/root-project/root/pull/964:38,safety,modul,modulemap,38,[cxxmodules] Rename stl.cppmap -> stl.modulemap;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/964
https://github.com/root-project/root/pull/965:10,interoperability,Specif,Specify,10,"ROOT-8874 Specify compression algorithm, compression ratio, and basket size to Snapshot;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/965
https://github.com/root-project/root/pull/967:313,deployability,patch,patch,313,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:443,deployability,fail,failing,443,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:8,performance,Synch,Synchronize,8,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:290,performance,memor,memory,290,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:443,reliability,fail,failing,443,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:313,safety,patch,patch,313,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:491,safety,test,test,491,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:313,security,patch,patch,313,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:411,security,hardcod,hardcoding,411,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:491,testability,test,test,491,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/967:290,usability,memor,memory,290,"[cmake] Synchronize LLVM flags with cling flags.; So far we just hard-coded the default definitions that LLVM uses to. the CLING_CXXFLAGS. This means that once LLVM actually changes. its compile defintions, code that uses the CLING_CXXFLAGS is no. longer in sync and starts reading invalid memory and so on. This patch extracts these flags from LLVM now and properly adds. them to the CLING_CXXFLAGS instead of hardcoding them. This fixes the failing roottest-root-aclic-misc-assertROOT7027 test. Thanks to Axel for debugging this!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/967
https://github.com/root-project/root/pull/968:19,safety,valid,validation,19,"ROOT-8985 TMVA DNN validation set; Introduces a new option to the DNN, ValidationSize, which can be used to split the training data into two parts, one for training and one for validation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/968
https://github.com/root-project/root/pull/968:71,safety,Valid,ValidationSize,71,"ROOT-8985 TMVA DNN validation set; Introduces a new option to the DNN, ValidationSize, which can be used to split the training data into two parts, one for training and one for validation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/968
https://github.com/root-project/root/pull/968:177,safety,valid,validation,177,"ROOT-8985 TMVA DNN validation set; Introduces a new option to the DNN, ValidationSize, which can be used to split the training data into two parts, one for training and one for validation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/968
https://github.com/root-project/root/pull/968:19,security,validat,validation,19,"ROOT-8985 TMVA DNN validation set; Introduces a new option to the DNN, ValidationSize, which can be used to split the training data into two parts, one for training and one for validation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/968
https://github.com/root-project/root/pull/968:71,security,Validat,ValidationSize,71,"ROOT-8985 TMVA DNN validation set; Introduces a new option to the DNN, ValidationSize, which can be used to split the training data into two parts, one for training and one for validation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/968
https://github.com/root-project/root/pull/968:177,security,validat,validation,177,"ROOT-8985 TMVA DNN validation set; Introduces a new option to the DNN, ValidationSize, which can be used to split the training data into two parts, one for training and one for validation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/968
https://github.com/root-project/root/pull/969:25,deployability,log,log,25,"[TMVA] Make ROC calc O(N log N) instead of O(N * T); Makes the roc calc loop through the input data vector only once. instead of one time per threshold, or ""point"". With N = 10000 the average running time goes from. ~80 to about ~30 ms. Does not respect `num_points` any more since the running time is small (There is room for improvement here).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:133,performance,time,time,133,"[TMVA] Make ROC calc O(N log N) instead of O(N * T); Makes the roc calc loop through the input data vector only once. instead of one time per threshold, or ""point"". With N = 10000 the average running time goes from. ~80 to about ~30 ms. Does not respect `num_points` any more since the running time is small (There is room for improvement here).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:200,performance,time,time,200,"[TMVA] Make ROC calc O(N log N) instead of O(N * T); Makes the roc calc loop through the input data vector only once. instead of one time per threshold, or ""point"". With N = 10000 the average running time goes from. ~80 to about ~30 ms. Does not respect `num_points` any more since the running time is small (There is room for improvement here).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:294,performance,time,time,294,"[TMVA] Make ROC calc O(N log N) instead of O(N * T); Makes the roc calc loop through the input data vector only once. instead of one time per threshold, or ""point"". With N = 10000 the average running time goes from. ~80 to about ~30 ms. Does not respect `num_points` any more since the running time is small (There is room for improvement here).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:237,reliability,Doe,Does,237,"[TMVA] Make ROC calc O(N log N) instead of O(N * T); Makes the roc calc loop through the input data vector only once. instead of one time per threshold, or ""point"". With N = 10000 the average running time goes from. ~80 to about ~30 ms. Does not respect `num_points` any more since the running time is small (There is room for improvement here).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:25,safety,log,log,25,"[TMVA] Make ROC calc O(N log N) instead of O(N * T); Makes the roc calc loop through the input data vector only once. instead of one time per threshold, or ""point"". With N = 10000 the average running time goes from. ~80 to about ~30 ms. Does not respect `num_points` any more since the running time is small (There is room for improvement here).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:89,safety,input,input,89,"[TMVA] Make ROC calc O(N log N) instead of O(N * T); Makes the roc calc loop through the input data vector only once. instead of one time per threshold, or ""point"". With N = 10000 the average running time goes from. ~80 to about ~30 ms. Does not respect `num_points` any more since the running time is small (There is room for improvement here).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:25,security,log,log,25,"[TMVA] Make ROC calc O(N log N) instead of O(N * T); Makes the roc calc loop through the input data vector only once. instead of one time per threshold, or ""point"". With N = 10000 the average running time goes from. ~80 to about ~30 ms. Does not respect `num_points` any more since the running time is small (There is room for improvement here).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:25,testability,log,log,25,"[TMVA] Make ROC calc O(N log N) instead of O(N * T); Makes the roc calc loop through the input data vector only once. instead of one time per threshold, or ""point"". With N = 10000 the average running time goes from. ~80 to about ~30 ms. Does not respect `num_points` any more since the running time is small (There is room for improvement here).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/969:89,usability,input,input,89,"[TMVA] Make ROC calc O(N log N) instead of O(N * T); Makes the roc calc loop through the input data vector only once. instead of one time per threshold, or ""point"". With N = 10000 the average running time goes from. ~80 to about ~30 ms. Does not respect `num_points` any more since the running time is small (There is room for improvement here).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/969
https://github.com/root-project/root/pull/971:73,deployability,build,builds,73,"Fixing filemerger test and usage of __FAST_MATH__ with gcc for Optimized builds; If -Ofast is the optimization level, then -ffast-math should be enabled for GCC builds (Linux) to be able to activate ```__FAST_MATH__``` macros (order of flags is important apparently too)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:161,deployability,build,builds,161,"Fixing filemerger test and usage of __FAST_MATH__ with gcc for Optimized builds; If -Ofast is the optimization level, then -ffast-math should be enabled for GCC builds (Linux) to be able to activate ```__FAST_MATH__``` macros (order of flags is important apparently too)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:63,energy efficiency,Optim,Optimized,63,"Fixing filemerger test and usage of __FAST_MATH__ with gcc for Optimized builds; If -Ofast is the optimization level, then -ffast-math should be enabled for GCC builds (Linux) to be able to activate ```__FAST_MATH__``` macros (order of flags is important apparently too)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:98,energy efficiency,optim,optimization,98,"Fixing filemerger test and usage of __FAST_MATH__ with gcc for Optimized builds; If -Ofast is the optimization level, then -ffast-math should be enabled for GCC builds (Linux) to be able to activate ```__FAST_MATH__``` macros (order of flags is important apparently too)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:63,performance,Optimiz,Optimized,63,"Fixing filemerger test and usage of __FAST_MATH__ with gcc for Optimized builds; If -Ofast is the optimization level, then -ffast-math should be enabled for GCC builds (Linux) to be able to activate ```__FAST_MATH__``` macros (order of flags is important apparently too)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:98,performance,optimiz,optimization,98,"Fixing filemerger test and usage of __FAST_MATH__ with gcc for Optimized builds; If -Ofast is the optimization level, then -ffast-math should be enabled for GCC builds (Linux) to be able to activate ```__FAST_MATH__``` macros (order of flags is important apparently too)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:18,safety,test,test,18,"Fixing filemerger test and usage of __FAST_MATH__ with gcc for Optimized builds; If -Ofast is the optimization level, then -ffast-math should be enabled for GCC builds (Linux) to be able to activate ```__FAST_MATH__``` macros (order of flags is important apparently too)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/971:18,testability,test,test,18,"Fixing filemerger test and usage of __FAST_MATH__ with gcc for Optimized builds; If -Ofast is the optimization level, then -ffast-math should be enabled for GCC builds (Linux) to be able to activate ```__FAST_MATH__``` macros (order of flags is important apparently too)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/971
https://github.com/root-project/root/pull/974:77,deployability,modul,module,77,"[cxxmodules] Fix cyclic include between STL<->clang builtin; This breaks the module nightlies. There is no nice way for now. to fix this, so we just skip this header and fix any upcoming. merging issues from having it multiple times.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/974
https://github.com/root-project/root/pull/974:77,modifiability,modul,module,77,"[cxxmodules] Fix cyclic include between STL<->clang builtin; This breaks the module nightlies. There is no nice way for now. to fix this, so we just skip this header and fix any upcoming. merging issues from having it multiple times.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/974
https://github.com/root-project/root/pull/974:227,performance,time,times,227,"[cxxmodules] Fix cyclic include between STL<->clang builtin; This breaks the module nightlies. There is no nice way for now. to fix this, so we just skip this header and fix any upcoming. merging issues from having it multiple times.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/974
https://github.com/root-project/root/pull/974:77,safety,modul,module,77,"[cxxmodules] Fix cyclic include between STL<->clang builtin; This breaks the module nightlies. There is no nice way for now. to fix this, so we just skip this header and fix any upcoming. merging issues from having it multiple times.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/974
https://github.com/root-project/root/pull/975:39,deployability,modul,modulemap,39,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/975:64,deployability,fail,failed,64,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/975:210,deployability,modul,modules,210,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/975:218,deployability,build,builds,218,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/975:34,energy efficiency,Core,Core,34,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/975:39,modifiability,modul,modulemap,39,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/975:135,modifiability,variab,variable,135,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/975:210,modifiability,modul,modules,210,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/975:64,reliability,fail,failed,64,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/975:39,safety,modul,modulemap,39,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/975:210,safety,modul,modules,210,[cxxmodules] Fix headers paths in Core modulemap.; This replace failed to actually make the paths relative because. of the typo in the variable name and the surrounding parentheses. This also fixes the nightly modules builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/975
https://github.com/root-project/root/pull/976:28,availability,error,error,28,Throw on dynamic expression error;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/976
https://github.com/root-project/root/pull/976:28,performance,error,error,28,Throw on dynamic expression error;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/976
https://github.com/root-project/root/pull/976:28,safety,error,error,28,Throw on dynamic expression error;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/976
https://github.com/root-project/root/pull/976:28,usability,error,error,28,Throw on dynamic expression error;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/976
https://github.com/root-project/root/pull/977:65,availability,operat,operator,65,Root 8994 tformula modulus; Remedies an inconsistency in how the operator `%` was treated in comparison to e.g. `&`. Also adds documentation on operators and the difference between variables and parameters.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:144,availability,operat,operators,144,Root 8994 tformula modulus; Remedies an inconsistency in how the operator `%` was treated in comparison to e.g. `&`. Also adds documentation on operators and the difference between variables and parameters.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:19,deployability,modul,modulus,19,Root 8994 tformula modulus; Remedies an inconsistency in how the operator `%` was treated in comparison to e.g. `&`. Also adds documentation on operators and the difference between variables and parameters.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:19,modifiability,modul,modulus,19,Root 8994 tformula modulus; Remedies an inconsistency in how the operator `%` was treated in comparison to e.g. `&`. Also adds documentation on operators and the difference between variables and parameters.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:181,modifiability,variab,variables,181,Root 8994 tformula modulus; Remedies an inconsistency in how the operator `%` was treated in comparison to e.g. `&`. Also adds documentation on operators and the difference between variables and parameters.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:195,modifiability,paramet,parameters,195,Root 8994 tformula modulus; Remedies an inconsistency in how the operator `%` was treated in comparison to e.g. `&`. Also adds documentation on operators and the difference between variables and parameters.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:19,safety,modul,modulus,19,Root 8994 tformula modulus; Remedies an inconsistency in how the operator `%` was treated in comparison to e.g. `&`. Also adds documentation on operators and the difference between variables and parameters.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:28,safety,Reme,Remedies,28,Root 8994 tformula modulus; Remedies an inconsistency in how the operator `%` was treated in comparison to e.g. `&`. Also adds documentation on operators and the difference between variables and parameters.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/977:127,usability,document,documentation,127,Root 8994 tformula modulus; Remedies an inconsistency in how the operator `%` was treated in comparison to e.g. `&`. Also adds documentation on operators and the difference between variables and parameters.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/977
https://github.com/root-project/root/pull/978:92,deployability,instal,installed,92,RooFit related libraries in rootlibs; Add the RooFit related libraries if RooFit feature is installed. Tested and tested with a cmake build and a main that creates RooRealVar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/978
https://github.com/root-project/root/pull/978:134,deployability,build,build,134,RooFit related libraries in rootlibs; Add the RooFit related libraries if RooFit feature is installed. Tested and tested with a cmake build and a main that creates RooRealVar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/978
https://github.com/root-project/root/pull/978:103,safety,Test,Tested,103,RooFit related libraries in rootlibs; Add the RooFit related libraries if RooFit feature is installed. Tested and tested with a cmake build and a main that creates RooRealVar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/978
https://github.com/root-project/root/pull/978:114,safety,test,tested,114,RooFit related libraries in rootlibs; Add the RooFit related libraries if RooFit feature is installed. Tested and tested with a cmake build and a main that creates RooRealVar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/978
https://github.com/root-project/root/pull/978:103,testability,Test,Tested,103,RooFit related libraries in rootlibs; Add the RooFit related libraries if RooFit feature is installed. Tested and tested with a cmake build and a main that creates RooRealVar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/978
https://github.com/root-project/root/pull/978:114,testability,test,tested,114,RooFit related libraries in rootlibs; Add the RooFit related libraries if RooFit feature is installed. Tested and tested with a cmake build and a main that creates RooRealVar.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/978
https://github.com/root-project/root/pull/980:334,deployability,fail,fail,334,"[cmake] Fix that clingutils headers are found in /bin; The ROOT macros use at the moment use a very expansive list. of paths when looking for headers. And right now clingutils rely on. the ROOT_GENERATE_DICTIONARY behaviour that a header that can't. be found will be deferred to runtime loading in cling, but this. strategy starts to fail once people have files named 'map',. 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay. the lookup of for example 'map' to the runtime but instead directly. include '/bin/map' (which is then causing Cling to fail as this. is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead. fix this from clingutils' side by looking up the STL headers. manually via our cling search paths which means we no longer. rely on the 'if-not-found-load-at-runtime' branch in the. ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:627,deployability,fail,fail,627,"[cmake] Fix that clingutils headers are found in /bin; The ROOT macros use at the moment use a very expansive list. of paths when looking for headers. And right now clingutils rely on. the ROOT_GENERATE_DICTIONARY behaviour that a header that can't. be found will be deferred to runtime loading in cling, but this. strategy starts to fail once people have files named 'map',. 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay. the lookup of for example 'map' to the runtime but instead directly. include '/bin/map' (which is then causing Cling to fail as this. is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead. fix this from clingutils' side by looking up the STL headers. manually via our cling search paths which means we no longer. rely on the 'if-not-found-load-at-runtime' branch in the. ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:287,energy efficiency,load,loading,287,"[cmake] Fix that clingutils headers are found in /bin; The ROOT macros use at the moment use a very expansive list. of paths when looking for headers. And right now clingutils rely on. the ROOT_GENERATE_DICTIONARY behaviour that a header that can't. be found will be deferred to runtime loading in cling, but this. strategy starts to fail once people have files named 'map',. 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay. the lookup of for example 'map' to the runtime but instead directly. include '/bin/map' (which is then causing Cling to fail as this. is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead. fix this from clingutils' side by looking up the STL headers. manually via our cling search paths which means we no longer. rely on the 'if-not-found-load-at-runtime' branch in the. ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:906,energy efficiency,load,load-at-runtime,906,"[cmake] Fix that clingutils headers are found in /bin; The ROOT macros use at the moment use a very expansive list. of paths when looking for headers. And right now clingutils rely on. the ROOT_GENERATE_DICTIONARY behaviour that a header that can't. be found will be deferred to runtime loading in cling, but this. strategy starts to fail once people have files named 'map',. 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay. the lookup of for example 'map' to the runtime but instead directly. include '/bin/map' (which is then causing Cling to fail as this. is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead. fix this from clingutils' side by looking up the STL headers. manually via our cling search paths which means we no longer. rely on the 'if-not-found-load-at-runtime' branch in the. ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:287,performance,load,loading,287,"[cmake] Fix that clingutils headers are found in /bin; The ROOT macros use at the moment use a very expansive list. of paths when looking for headers. And right now clingutils rely on. the ROOT_GENERATE_DICTIONARY behaviour that a header that can't. be found will be deferred to runtime loading in cling, but this. strategy starts to fail once people have files named 'map',. 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay. the lookup of for example 'map' to the runtime but instead directly. include '/bin/map' (which is then causing Cling to fail as this. is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead. fix this from clingutils' side by looking up the STL headers. manually via our cling search paths which means we no longer. rely on the 'if-not-found-load-at-runtime' branch in the. ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:906,performance,load,load-at-runtime,906,"[cmake] Fix that clingutils headers are found in /bin; The ROOT macros use at the moment use a very expansive list. of paths when looking for headers. And right now clingutils rely on. the ROOT_GENERATE_DICTIONARY behaviour that a header that can't. be found will be deferred to runtime loading in cling, but this. strategy starts to fail once people have files named 'map',. 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay. the lookup of for example 'map' to the runtime but instead directly. include '/bin/map' (which is then causing Cling to fail as this. is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead. fix this from clingutils' side by looking up the STL headers. manually via our cling search paths which means we no longer. rely on the 'if-not-found-load-at-runtime' branch in the. ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:334,reliability,fail,fail,334,"[cmake] Fix that clingutils headers are found in /bin; The ROOT macros use at the moment use a very expansive list. of paths when looking for headers. And right now clingutils rely on. the ROOT_GENERATE_DICTIONARY behaviour that a header that can't. be found will be deferred to runtime loading in cling, but this. strategy starts to fail once people have files named 'map',. 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay. the lookup of for example 'map' to the runtime but instead directly. include '/bin/map' (which is then causing Cling to fail as this. is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead. fix this from clingutils' side by looking up the STL headers. manually via our cling search paths which means we no longer. rely on the 'if-not-found-load-at-runtime' branch in the. ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:627,reliability,fail,fail,627,"[cmake] Fix that clingutils headers are found in /bin; The ROOT macros use at the moment use a very expansive list. of paths when looking for headers. And right now clingutils rely on. the ROOT_GENERATE_DICTIONARY behaviour that a header that can't. be found will be deferred to runtime loading in cling, but this. strategy starts to fail once people have files named 'map',. 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay. the lookup of for example 'map' to the runtime but instead directly. include '/bin/map' (which is then causing Cling to fail as this. is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead. fix this from clingutils' side by looking up the STL headers. manually via our cling search paths which means we no longer. rely on the 'if-not-found-load-at-runtime' branch in the. ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:214,usability,behavi,behaviour,214,"[cmake] Fix that clingutils headers are found in /bin; The ROOT macros use at the moment use a very expansive list. of paths when looking for headers. And right now clingutils rely on. the ROOT_GENERATE_DICTIONARY behaviour that a header that can't. be found will be deferred to runtime loading in cling, but this. strategy starts to fail once people have files named 'map',. 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay. the lookup of for example 'map' to the runtime but instead directly. include '/bin/map' (which is then causing Cling to fail as this. is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead. fix this from clingutils' side by looking up the STL headers. manually via our cling search paths which means we no longer. rely on the 'if-not-found-load-at-runtime' branch in the. ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/980:734,usability,behavi,behavior,734,"[cmake] Fix that clingutils headers are found in /bin; The ROOT macros use at the moment use a very expansive list. of paths when looking for headers. And right now clingutils rely on. the ROOT_GENERATE_DICTIONARY behaviour that a header that can't. be found will be deferred to runtime loading in cling, but this. strategy starts to fail once people have files named 'map',. 'vector' in any path that CMake's find_file searches by default. When those files are found by our CMake macros, they won't delay. the lookup of for example 'map' to the runtime but instead directly. include '/bin/map' (which is then causing Cling to fail as this. is usually an executable or something like that). As we can't seem to just fix the find_file behavior, we instead. fix this from clingutils' side by looking up the STL headers. manually via our cling search paths which means we no longer. rely on the 'if-not-found-load-at-runtime' branch in the. ROOT_GENERATE_DICTINARY macro.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/980
https://github.com/root-project/root/pull/981:28,security,ident,identifier,28,Also recognize templates as identifier.; Fixes root-project/cling#182,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/981
https://github.com/root-project/root/pull/982:274,availability,slo,slot,274,"[TDF] Add `DefineSlot` transformation; Example usage:. ```c++. // generate random numbers and fill a histogram in parallel. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<TRandom, nSlots> r;. TDataFrame d(1e8);. d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}). .Histo1D(""x"");. ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:291,availability,slo,slot,291,"[TDF] Add `DefineSlot` transformation; Example usage:. ```c++. // generate random numbers and fill a histogram in parallel. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<TRandom, nSlots> r;. TDataFrame d(1e8);. d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}). .Histo1D(""x"");. ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:23,integrability,transform,transformation,23,"[TDF] Add `DefineSlot` transformation; Example usage:. ```c++. // generate random numbers and fill a histogram in parallel. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<TRandom, nSlots> r;. TDataFrame d(1e8);. d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}). .Histo1D(""x"");. ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:23,interoperability,transform,transformation,23,"[TDF] Add `DefineSlot` transformation; Example usage:. ```c++. // generate random numbers and fill a histogram in parallel. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<TRandom, nSlots> r;. TDataFrame d(1e8);. d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}). .Histo1D(""x"");. ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:114,performance,parallel,parallel,114,"[TDF] Add `DefineSlot` transformation; Example usage:. ```c++. // generate random numbers and fill a histogram in parallel. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<TRandom, nSlots> r;. TDataFrame d(1e8);. d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}). .Histo1D(""x"");. ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:274,reliability,slo,slot,274,"[TDF] Add `DefineSlot` transformation; Example usage:. ```c++. // generate random numbers and fill a histogram in parallel. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<TRandom, nSlots> r;. TDataFrame d(1e8);. d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}). .Histo1D(""x"");. ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:291,reliability,slo,slot,291,"[TDF] Add `DefineSlot` transformation; Example usage:. ```c++. // generate random numbers and fill a histogram in parallel. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<TRandom, nSlots> r;. TDataFrame d(1e8);. d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}). .Histo1D(""x"");. ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:344,safety,test,tests,344,"[TDF] Add `DefineSlot` transformation; Example usage:. ```c++. // generate random numbers and fill a histogram in parallel. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<TRandom, nSlots> r;. TDataFrame d(1e8);. d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}). .Histo1D(""x"");. ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:339,testability,unit,unit,339,"[TDF] Add `DefineSlot` transformation; Example usage:. ```c++. // generate random numbers and fill a histogram in parallel. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<TRandom, nSlots> r;. TDataFrame d(1e8);. d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}). .Histo1D(""x"");. ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/982:344,testability,test,tests,344,"[TDF] Add `DefineSlot` transformation; Example usage:. ```c++. // generate random numbers and fill a histogram in parallel. constexpr auto nSlots = 4u;. ROOT::EnableImplicitMT(nSlots);. std::array<TRandom, nSlots> r;. TDataFrame d(1e8);. d.DefineSlot(""x"", [&r](unsigned int slot) { return r[slot].Gaus(); }, {}). .Histo1D(""x"");. ```. More unit tests are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/982
https://github.com/root-project/root/pull/983:69,deployability,build,build,69,[TDF] Let TDataFrame use TDataSources to read data; Test PR to check build issues and incompatibilities with current test suite.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:109,energy efficiency,current,current,109,[TDF] Let TDataFrame use TDataSources to read data; Test PR to check build issues and incompatibilities with current test suite.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:86,interoperability,incompatib,incompatibilities,86,[TDF] Let TDataFrame use TDataSources to read data; Test PR to check build issues and incompatibilities with current test suite.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:52,safety,Test,Test,52,[TDF] Let TDataFrame use TDataSources to read data; Test PR to check build issues and incompatibilities with current test suite.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:117,safety,test,test,117,[TDF] Let TDataFrame use TDataSources to read data; Test PR to check build issues and incompatibilities with current test suite.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:52,testability,Test,Test,52,[TDF] Let TDataFrame use TDataSources to read data; Test PR to check build issues and incompatibilities with current test suite.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/983:117,testability,test,test,117,[TDF] Let TDataFrame use TDataSources to read data; Test PR to check build issues and incompatibilities with current test suite.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/983
https://github.com/root-project/root/pull/984:14,availability,error,error,14,[TDF] Make an error message slightly more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/984
https://github.com/root-project/root/pull/984:28,availability,sli,slightly,28,[TDF] Make an error message slightly more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/984
https://github.com/root-project/root/pull/984:20,integrability,messag,message,20,[TDF] Make an error message slightly more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/984
https://github.com/root-project/root/pull/984:20,interoperability,messag,message,20,[TDF] Make an error message slightly more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/984
https://github.com/root-project/root/pull/984:14,performance,error,error,14,[TDF] Make an error message slightly more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/984
https://github.com/root-project/root/pull/984:28,reliability,sli,slightly,28,[TDF] Make an error message slightly more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/984
https://github.com/root-project/root/pull/984:14,safety,error,error,14,[TDF] Make an error message slightly more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/984
https://github.com/root-project/root/pull/984:14,usability,error,error,14,[TDF] Make an error message slightly more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/984
https://github.com/root-project/root/pull/984:42,usability,help,helpful,42,[TDF] Make an error message slightly more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/984
https://github.com/root-project/root/pull/985:12,safety,Avoid,Avoid,12,[TDF+CLING] Avoid instrumenting jitted code when possible; Backport of [PR 972](https://github.com/root-project/root/pull/972) to v6.10.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/985
https://github.com/root-project/root/pull/985:18,testability,instrument,instrumenting,18,[TDF+CLING] Avoid instrumenting jitted code when possible; Backport of [PR 972](https://github.com/root-project/root/pull/972) to v6.10.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/985
https://github.com/root-project/root/pull/988:81,deployability,modul,modules,81,[cxxmodules] CIFactory now uses MultiplexConsumer; This is a preparation for C++ modules as they will require that. we attach multiple consumers to the CI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:81,modifiability,modul,modules,81,[cxxmodules] CIFactory now uses MultiplexConsumer; This is a preparation for C++ modules as they will require that. we attach multiple consumers to the CI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:32,performance,Multiplex,MultiplexConsumer,32,[cxxmodules] CIFactory now uses MultiplexConsumer; This is a preparation for C++ modules as they will require that. we attach multiple consumers to the CI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/988:81,safety,modul,modules,81,[cxxmodules] CIFactory now uses MultiplexConsumer; This is a preparation for C++ modules as they will require that. we attach multiple consumers to the CI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/988
https://github.com/root-project/root/pull/989:28,security,modif,modification,28,Backporting all LZ4 related modification on v6-10-00; @pcanal Can you check please? @bbockelm I start to backport all our changes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/989
https://github.com/root-project/root/pull/991:39,performance,Multiplex,Multiplexer,39,[llvm] Fix InvalidTagDeclDefinition in Multiplexer;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/991
https://github.com/root-project/root/pull/992:75,interoperability,specif,specified,75,"http: correctly handle CORS parameter when creating THttpServer; It can be specified as extra option of THttpServer itself like:. new THttpServer(""http:8080;cors""). . But also as in original code: . new THttpServer(""http:8080?cors""). . Second form is formally belongs to the TCivetweb engine and now handled. appropriately",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/992
https://github.com/root-project/root/pull/992:28,modifiability,paramet,parameter,28,"http: correctly handle CORS parameter when creating THttpServer; It can be specified as extra option of THttpServer itself like:. new THttpServer(""http:8080;cors""). . But also as in original code: . new THttpServer(""http:8080?cors""). . Second form is formally belongs to the TCivetweb engine and now handled. appropriately",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/992
https://github.com/root-project/root/pull/993:6,usability,Support,Support,6,"[WIP] Support of C++ list initializers in Python using tuples; The idea here is to allow users to provide a python tuple to implicitly construct and initialize an object that is needed in a function or method argument. Instead of doing the flowing when calling a function/methods that requires `const A&`. ```. a = ROOT.A(arg1,arg2) . ROOT.function(a) . ```. the user can do . ```. ROOT.function((arg1,arg2)). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/993
https://github.com/root-project/root/pull/993:89,usability,user,users,89,"[WIP] Support of C++ list initializers in Python using tuples; The idea here is to allow users to provide a python tuple to implicitly construct and initialize an object that is needed in a function or method argument. Instead of doing the flowing when calling a function/methods that requires `const A&`. ```. a = ROOT.A(arg1,arg2) . ROOT.function(a) . ```. the user can do . ```. ROOT.function((arg1,arg2)). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/993
https://github.com/root-project/root/pull/993:363,usability,user,user,363,"[WIP] Support of C++ list initializers in Python using tuples; The idea here is to allow users to provide a python tuple to implicitly construct and initialize an object that is needed in a function or method argument. Instead of doing the flowing when calling a function/methods that requires `const A&`. ```. a = ROOT.A(arg1,arg2) . ROOT.function(a) . ```. the user can do . ```. ROOT.function((arg1,arg2)). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/993
https://github.com/root-project/root/pull/994:589,deployability,patch,patch,589,[llvm] Backport D37416 - Use the VFS from the CompilerInvocation; Necessary to make cling pickup the VFS from root which fixes all the merging. problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the. user has to manually create the VFS before creating the FileManager even though. `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked. around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the. point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:722,deployability,API,API,722,[llvm] Backport D37416 - Use the VFS from the CompilerInvocation; Necessary to make cling pickup the VFS from root which fixes all the merging. problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the. user has to manually create the VFS before creating the FileManager even though. `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked. around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the. point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:722,integrability,API,API,722,[llvm] Backport D37416 - Use the VFS from the CompilerInvocation; Necessary to make cling pickup the VFS from root which fixes all the merging. problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the. user has to manually create the VFS before creating the FileManager even though. `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked. around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the. point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:722,interoperability,API,API,722,[llvm] Backport D37416 - Use the VFS from the CompilerInvocation; Necessary to make cling pickup the VFS from root which fixes all the merging. problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the. user has to manually create the VFS before creating the FileManager even though. `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked. around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the. point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:589,safety,patch,patch,589,[llvm] Backport D37416 - Use the VFS from the CompilerInvocation; Necessary to make cling pickup the VFS from root which fixes all the merging. problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the. user has to manually create the VFS before creating the FileManager even though. `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked. around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the. point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:641,safety,test,tests,641,[llvm] Backport D37416 - Use the VFS from the CompilerInvocation; Necessary to make cling pickup the VFS from root which fixes all the merging. problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the. user has to manually create the VFS before creating the FileManager even though. `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked. around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the. point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:589,security,patch,patch,589,[llvm] Backport D37416 - Use the VFS from the CompilerInvocation; Necessary to make cling pickup the VFS from root which fixes all the merging. problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the. user has to manually create the VFS before creating the FileManager even though. `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked. around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the. point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:641,testability,test,tests,641,[llvm] Backport D37416 - Use the VFS from the CompilerInvocation; Necessary to make cling pickup the VFS from root which fixes all the merging. problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the. user has to manually create the VFS before creating the FileManager even though. `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked. around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the. point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:356,usability,user,user,356,[llvm] Backport D37416 - Use the VFS from the CompilerInvocation; Necessary to make cling pickup the VFS from root which fixes all the merging. problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the. user has to manually create the VFS before creating the FileManager even though. `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked. around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the. point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/994:652,usability,behavi,behavior,652,[llvm] Backport D37416 - Use the VFS from the CompilerInvocation; Necessary to make cling pickup the VFS from root which fixes all the merging. problems that we have in STL/libc. Original description:. Title: Use the VFS from the CompilerInvocation by default. The CompilerInstance should create its default VFS from its CompilerInvocation. Right now the. user has to manually create the VFS before creating the FileManager even though. `-ivfsoverlay file.yaml` was passed via the CompilerInvocation (which is exactly how we worked. around this issue in `FrontendAction.cpp` so far). This patch uses the invocation's VFS by default and also tests this behavior now from the. point of view of a program that uses the clang API.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/994
https://github.com/root-project/root/pull/995:321,availability,error,errors,321,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:379,availability,error,error,379,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:67,deployability,modul,module,67,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:138,deployability,modul,module,138,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:340,deployability,modul,module,340,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:510,deployability,modul,module,510,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:580,deployability,patch,patch,580,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:417,integrability,sub,submodules,417,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:67,modifiability,modul,module,67,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:138,modifiability,modul,module,138,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:340,modifiability,modul,module,340,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:510,modifiability,modul,module,510,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:321,performance,error,errors,321,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:379,performance,error,error,379,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:598,performance,multiplex,multiplexer,598,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:184,reliability,doe,doesn,184,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:67,safety,modul,module,67,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:138,safety,modul,module,138,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:321,safety,error,errors,321,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:340,safety,modul,module,340,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:379,safety,error,error,379,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:510,safety,modul,module,510,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:580,safety,patch,patch,580,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:580,security,patch,patch,580,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:321,usability,error,errors,321,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/995:379,usability,error,error,379,"[cxxmodules] Don't overrite the DeserializationListener.; With the module generation in rootcling Clang rlies on AST consumers. to do the module generation work for it. Right now this doesn't work. however with the interpreter, as we just overwrite the deserialization. listener that clang added which will cause strange errors during. the module generation (the most prompinent error is that the number. of recorded submodules will be incorrect, as this it the first thing. that Clang checks before writing a module and which is recorded by. an ASTDeserializationListener). This patch just adds a multiplexer here that allows us to keep the. old listener while also adding the one we have.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/995
https://github.com/root-project/root/pull/996:15,performance,lock,lock,15,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:168,performance,lock,locked,168,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:191,performance,lock,locking,191,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:225,performance,lock,lock,225,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:257,performance,deadlock,deadlocks,257,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:249,safety,prevent,prevent,249,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:15,security,lock,lock,15,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:168,security,lock,locked,168,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:191,security,lock,locking,191,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:225,security,lock,lock,225,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:249,security,preven,prevent,249,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:70,testability,instrument,instrumentation,70,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:49,usability,user,user,49,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:109,usability,user,user,109,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/996:216,usability,User,UserCode,216,"Cling explicit lock; cling might be invoked from user code because of instrumentation that cling did to that user code. An examples is `printValue()`. This needs to be locked, using the same locking mechanism as the UserCode lock already in use, to prevent deadlocks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/996
https://github.com/root-project/root/pull/998:38,modifiability,pac,packs,38,rootcling now supports template param packs.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/998
https://github.com/root-project/root/pull/998:14,usability,support,supports,14,rootcling now supports template param packs.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/998
https://github.com/root-project/root/pull/1000:14,safety,test,tests,14,V7 TPadExtent tests;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1000
https://github.com/root-project/root/pull/1000:14,testability,test,tests,14,V7 TPadExtent tests;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1000
https://github.com/root-project/root/pull/1001:215,integrability,queue,queue,215,"Implement non-blocking callback mechanism in TBufferMerger; Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user. to control the rate at which data is pushed into the merging queue. In our test, we use the callback. function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1001:281,integrability,asynchron,asynchronously,281,"Implement non-blocking callback mechanism in TBufferMerger; Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user. to control the rate at which data is pushed into the merging queue. In our test, we use the callback. function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1001:307,integrability,buffer,buffer,307,"Implement non-blocking callback mechanism in TBufferMerger; Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user. to control the rate at which data is pushed into the merging queue. In our test, we use the callback. function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1001:215,performance,queue,queue,215,"Implement non-blocking callback mechanism in TBufferMerger; Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user. to control the rate at which data is pushed into the merging queue. In our test, we use the callback. function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1001:281,performance,asynch,asynchronously,281,"Implement non-blocking callback mechanism in TBufferMerger; Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user. to control the rate at which data is pushed into the merging queue. In our test, we use the callback. function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1001:229,safety,test,test,229,"Implement non-blocking callback mechanism in TBufferMerger; Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user. to control the rate at which data is pushed into the merging queue. In our test, we use the callback. function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1001:157,security,control,control,157,"Implement non-blocking callback mechanism in TBufferMerger; Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user. to control the rate at which data is pushed into the merging queue. In our test, we use the callback. function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1001:157,testability,control,control,157,"Implement non-blocking callback mechanism in TBufferMerger; Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user. to control the rate at which data is pushed into the merging queue. In our test, we use the callback. function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1001:229,testability,test,test,229,"Implement non-blocking callback mechanism in TBufferMerger; Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user. to control the rate at which data is pushed into the merging queue. In our test, we use the callback. function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1001:148,usability,user,user,148,"Implement non-blocking callback mechanism in TBufferMerger; Add methods TBufferMerger::GetQueueSize() and TBufferMerger::RegisterCallback() to alow user. to control the rate at which data is pushed into the merging queue. In our test, we use the callback. function to launch tasks asynchronously whenever a buffer is done processing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1001
https://github.com/root-project/root/pull/1002:47,deployability,instal,install,47,"Adding RooFit/ RooStat libraries; Test if root install has roofit, if yes add the roofit and other libraries to rootlibs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:34,safety,Test,Test,34,"Adding RooFit/ RooStat libraries; Test if root install has roofit, if yes add the roofit and other libraries to rootlibs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1002:34,testability,Test,Test,34,"Adding RooFit/ RooStat libraries; Test if root install has roofit, if yes add the roofit and other libraries to rootlibs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1002
https://github.com/root-project/root/pull/1003:301,integrability,event,event,301,"Dynamically calculated basket offsets; If possible -- and the appropriate IO bit is set -- calculate the basket offset arrays on demand, as opposed to storing them in the file. If the IO bit is set -- but basket offset arrays cannot be dynamically calculated -- the basket offset arrays are stored as event sizes in bytes. This means the array is stored as `{4, 4, 4, 4}` instead of as `{72, 76, 80, 84}`. Storing event sizes instead of offsets helps with overall compression of the basket. Must be merged after #959.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:414,integrability,event,event,414,"Dynamically calculated basket offsets; If possible -- and the appropriate IO bit is set -- calculate the basket offset arrays on demand, as opposed to storing them in the file. If the IO bit is set -- but basket offset arrays cannot be dynamically calculated -- the basket offset arrays are stored as event sizes in bytes. This means the array is stored as `{4, 4, 4, 4}` instead of as `{72, 76, 80, 84}`. Storing event sizes instead of offsets helps with overall compression of the basket. Must be merged after #959.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1003:445,usability,help,helps,445,"Dynamically calculated basket offsets; If possible -- and the appropriate IO bit is set -- calculate the basket offset arrays on demand, as opposed to storing them in the file. If the IO bit is set -- but basket offset arrays cannot be dynamically calculated -- the basket offset arrays are stored as event sizes in bytes. This means the array is stored as `{4, 4, 4, 4}` instead of as `{72, 76, 80, 84}`. Storing event sizes instead of offsets helps with overall compression of the basket. Must be merged after #959.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1003
https://github.com/root-project/root/pull/1004:115,deployability,Updat,Update,115,"Let ImplicitMT influence on THN::Fit() execution policy; ...so we don't need to write ""MULTITHREAD"" as fit option. Update the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:115,safety,Updat,Update,115,"Let ImplicitMT influence on THN::Fit() execution policy; ...so we don't need to write ""MULTITHREAD"" as fit option. Update the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:126,safety,test,test,126,"Let ImplicitMT influence on THN::Fit() execution policy; ...so we don't need to write ""MULTITHREAD"" as fit option. Update the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:49,security,polic,policy,49,"Let ImplicitMT influence on THN::Fit() execution policy; ...so we don't need to write ""MULTITHREAD"" as fit option. Update the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:115,security,Updat,Update,115,"Let ImplicitMT influence on THN::Fit() execution policy; ...so we don't need to write ""MULTITHREAD"" as fit option. Update the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1004:126,testability,test,test,126,"Let ImplicitMT influence on THN::Fit() execution policy; ...so we don't need to write ""MULTITHREAD"" as fit option. Update the test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1004
https://github.com/root-project/root/pull/1005:4,availability,error,error,4,Fix error handling in pyroot for python 3; This fixes pyroot for python 3.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:4,performance,error,error,4,Fix error handling in pyroot for python 3; This fixes pyroot for python 3.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:4,safety,error,error,4,Fix error handling in pyroot for python 3; This fixes pyroot for python 3.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1005:4,usability,error,error,4,Fix error handling in pyroot for python 3; This fixes pyroot for python 3.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1005
https://github.com/root-project/root/pull/1006:27,modifiability,pac,pack,27,Fwd decl templ templ param pack;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1006
https://github.com/root-project/root/pull/1007:118,interoperability,share,shared,118,[cmake] Link all VC symbols into mathcore; To resolve all VC symbols during runtime we need to put them all. into the shared libraries linking Vc. This should add the required. symbols to the Vc linking flags.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1007
https://github.com/root-project/root/pull/1009:11,availability,error,error,11,[TDF] Make error message more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1009
https://github.com/root-project/root/pull/1009:17,integrability,messag,message,17,[TDF] Make error message more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1009
https://github.com/root-project/root/pull/1009:17,interoperability,messag,message,17,[TDF] Make error message more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1009
https://github.com/root-project/root/pull/1009:11,performance,error,error,11,[TDF] Make error message more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1009
https://github.com/root-project/root/pull/1009:11,safety,error,error,11,[TDF] Make error message more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1009
https://github.com/root-project/root/pull/1009:11,usability,error,error,11,[TDF] Make error message more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1009
https://github.com/root-project/root/pull/1009:30,usability,help,helpful,30,[TDF] Make error message more helpful;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1009
https://github.com/root-project/root/pull/1010:275,availability,degrad,degradation,275,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1469,availability,degrad,degrade,1469,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:220,energy efficiency,CPU,CPU,220,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:721,energy efficiency,schedul,scheduler,721,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1507,energy efficiency,schedul,scheduler,1507,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1700,energy efficiency,schedul,scheduler,1700,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:2086,energy efficiency,current,current,2086,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:2207,energy efficiency,current,current,2207,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15,integrability,interfac,interface,15,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:138,integrability,interfac,interface,138,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1984,integrability,interfac,interface,1984,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15,interoperability,interfac,interface,15,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:138,interoperability,interfac,interface,138,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1984,interoperability,interfac,interface,1984,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:15,modifiability,interfac,interface,15,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:138,modifiability,interfac,interface,138,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1984,modifiability,interfac,interface,1984,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:45,performance,parallel,parallel,45,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:206,performance,Time,Time,206,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:220,performance,CPU,CPU,220,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:224,performance,Time,Time,224,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:230,performance,perform,performance,230,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:721,performance,schedul,scheduler,721,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1481,performance,perform,performance,1481,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1507,performance,schedul,scheduler,1507,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1534,performance,time,time,1534,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1668,performance,perform,performance,1668,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1700,performance,schedul,scheduler,1700,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1837,performance,perform,performance,1837,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:2111,performance,synch,synchronously,2111,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:2184,performance,perform,performance,2184,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:275,reliability,degrad,degradation,275,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1469,reliability,degrad,degrade,1469,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:808,safety,except,except,808,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1910,safety,except,except,1910,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:230,usability,perform,performance,230,"Use TTaskGroup interface to unzip baskets in parallel.; @bbockelm @pcanal @dpiparo . Here is the new imt unzipping basket with TTaskGroup interface. Comparing to #785 , I noticed there are still 3%(in Real Time) ~ 5%(in CPU Time) performance drops in new implementation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1481,usability,perform,performance,1481,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1668,usability,perform,performance,1668,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1686,usability,efficien,efficient,1686,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:1837,usability,perform,performance,1837,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1010:2184,usability,perform,performance,2184,"mentation. The degradation is caused by tbb function:. tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task(long&). I suspect the reason is because #785 in the following function:. https://github.com/zzxuanyuan/root/blob/15cceff19b48dfe4a4b0c69c1ec07ea75bd1ccb5/tree/tree/src/TTreeCacheUnzip.cxx#L708. CreateTasks() explicitly creates 2 tasks (empty_task and MappingTask; and set_ref_count(2) means 2 tasks in total). The scheduler might make a better decision here since it knows there will be only one task except empty_task running in future. On the other hand, TTaskGroup uses tbb::task_group which calls the following function:. https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L108. task_group_base() also first creates a empty_task. However, it only creates 1 task(itself) by setting reference count as 1 (set_ref_count(1)). When it invoke another task by calling . https://github.com/01org/tbb/blob/b9805bacadd4d0474fd3358cf0c7153042ce50c3/include/tbb/task_group.h#L103. allocate_additional_child() will create a new task as child and increment reference count by 1. I guess accumulating tasks on-the-fly might degrade the performance since the tbb scheduler could spend more time on finding tasks to work on. In a short, I think explicitly defining the total number of tasks and task graph should have better performance (more efficient for scheduler I guess) than adding more tasks to task_group as the program runs. There are two alternative approaches that might improve the performance. . 1. Since we have already know we will only have one task (except empty_task) to add into the task_group, we could revise TTaskGroup interface and notify it what task is going to run in advance. 2. We could get rid of TTaskGroup in my current implemention and synchronously map baskets to different tasks. If we do not mind a little performance drops, the current implementation should be fine. Thanks,. Zhe .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1010
https://github.com/root-project/root/pull/1011:0,safety,test,test,0,test PR for runtime_modules;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1011
https://github.com/root-project/root/pull/1011:0,testability,test,test,0,test PR for runtime_modules;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1011
https://github.com/root-project/root/pull/1012:80,deployability,build,build,80,Fixing and backporting LZ4 related changes on v5-34-00; Fixing built of classic build for builtin lz4 and non-builtin case. Updated version of PR#926 https://github.com/root-project/root/pull/926,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:124,deployability,Updat,Updated,124,Fixing and backporting LZ4 related changes on v5-34-00; Fixing built of classic build for builtin lz4 and non-builtin case. Updated version of PR#926 https://github.com/root-project/root/pull/926,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:132,deployability,version,version,132,Fixing and backporting LZ4 related changes on v5-34-00; Fixing built of classic build for builtin lz4 and non-builtin case. Updated version of PR#926 https://github.com/root-project/root/pull/926,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:132,integrability,version,version,132,Fixing and backporting LZ4 related changes on v5-34-00; Fixing built of classic build for builtin lz4 and non-builtin case. Updated version of PR#926 https://github.com/root-project/root/pull/926,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:132,modifiability,version,version,132,Fixing and backporting LZ4 related changes on v5-34-00; Fixing built of classic build for builtin lz4 and non-builtin case. Updated version of PR#926 https://github.com/root-project/root/pull/926,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:124,safety,Updat,Updated,124,Fixing and backporting LZ4 related changes on v5-34-00; Fixing built of classic build for builtin lz4 and non-builtin case. Updated version of PR#926 https://github.com/root-project/root/pull/926,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1012:124,security,Updat,Updated,124,Fixing and backporting LZ4 related changes on v5-34-00; Fixing built of classic build for builtin lz4 and non-builtin case. Updated version of PR#926 https://github.com/root-project/root/pull/926,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1012
https://github.com/root-project/root/pull/1013:22,safety,test,test,22,Disable TBufferMerger test using TTaskGroup when IMT is disabled;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1013
https://github.com/root-project/root/pull/1013:22,testability,test,test,22,Disable TBufferMerger test using TTaskGroup when IMT is disabled;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1013
https://github.com/root-project/root/pull/1014:20,deployability,modul,modulemap,20,[cxxmodules] Enable modulemap with runtime_modules; We need the VFS we generated during runtime to prevent merging. issues coming from libc/STL when running rootcling. This patch. adds the relevant flag to the normal compilation args (where. it does nothing as we don't have cxxmodules enabled by default). and then let them propagate to cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1014
https://github.com/root-project/root/pull/1014:173,deployability,patch,patch,173,[cxxmodules] Enable modulemap with runtime_modules; We need the VFS we generated during runtime to prevent merging. issues coming from libc/STL when running rootcling. This patch. adds the relevant flag to the normal compilation args (where. it does nothing as we don't have cxxmodules enabled by default). and then let them propagate to cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1014
https://github.com/root-project/root/pull/1014:20,modifiability,modul,modulemap,20,[cxxmodules] Enable modulemap with runtime_modules; We need the VFS we generated during runtime to prevent merging. issues coming from libc/STL when running rootcling. This patch. adds the relevant flag to the normal compilation args (where. it does nothing as we don't have cxxmodules enabled by default). and then let them propagate to cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1014
https://github.com/root-project/root/pull/1014:245,reliability,doe,does,245,[cxxmodules] Enable modulemap with runtime_modules; We need the VFS we generated during runtime to prevent merging. issues coming from libc/STL when running rootcling. This patch. adds the relevant flag to the normal compilation args (where. it does nothing as we don't have cxxmodules enabled by default). and then let them propagate to cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1014
https://github.com/root-project/root/pull/1014:20,safety,modul,modulemap,20,[cxxmodules] Enable modulemap with runtime_modules; We need the VFS we generated during runtime to prevent merging. issues coming from libc/STL when running rootcling. This patch. adds the relevant flag to the normal compilation args (where. it does nothing as we don't have cxxmodules enabled by default). and then let them propagate to cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1014
https://github.com/root-project/root/pull/1014:99,safety,prevent,prevent,99,[cxxmodules] Enable modulemap with runtime_modules; We need the VFS we generated during runtime to prevent merging. issues coming from libc/STL when running rootcling. This patch. adds the relevant flag to the normal compilation args (where. it does nothing as we don't have cxxmodules enabled by default). and then let them propagate to cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1014
https://github.com/root-project/root/pull/1014:173,safety,patch,patch,173,[cxxmodules] Enable modulemap with runtime_modules; We need the VFS we generated during runtime to prevent merging. issues coming from libc/STL when running rootcling. This patch. adds the relevant flag to the normal compilation args (where. it does nothing as we don't have cxxmodules enabled by default). and then let them propagate to cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1014
https://github.com/root-project/root/pull/1014:99,security,preven,prevent,99,[cxxmodules] Enable modulemap with runtime_modules; We need the VFS we generated during runtime to prevent merging. issues coming from libc/STL when running rootcling. This patch. adds the relevant flag to the normal compilation args (where. it does nothing as we don't have cxxmodules enabled by default). and then let them propagate to cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1014
https://github.com/root-project/root/pull/1014:173,security,patch,patch,173,[cxxmodules] Enable modulemap with runtime_modules; We need the VFS we generated during runtime to prevent merging. issues coming from libc/STL when running rootcling. This patch. adds the relevant flag to the normal compilation args (where. it does nothing as we don't have cxxmodules enabled by default). and then let them propagate to cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1014
https://github.com/root-project/root/pull/1015:37,deployability,patch,patch,37,[cxxmodules] Revert broken VFS CMake patch / add -vfsoverlay to rootcling/TCling; See the specific comments for the changes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1015
https://github.com/root-project/root/pull/1015:90,interoperability,specif,specific,90,[cxxmodules] Revert broken VFS CMake patch / add -vfsoverlay to rootcling/TCling; See the specific comments for the changes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1015
https://github.com/root-project/root/pull/1015:37,safety,patch,patch,37,[cxxmodules] Revert broken VFS CMake patch / add -vfsoverlay to rootcling/TCling; See the specific comments for the changes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1015
https://github.com/root-project/root/pull/1015:37,security,patch,patch,37,[cxxmodules] Revert broken VFS CMake patch / add -vfsoverlay to rootcling/TCling; See the specific comments for the changes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1015
https://github.com/root-project/root/pull/1016:245,availability,error,error,245,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:910,availability,error,error,910,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1146,availability,error,error,1146,"c LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1380,availability,error,error,1380,"ncluded from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1599,availability,error,error,1599,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:75,deployability,modul,modules,75,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:268,deployability,patch,patch,268,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:290,deployability,build,building,290,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:299,deployability,modul,module,299,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:321,deployability,build,building,321,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:330,deployability,modul,module,330,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:397,deployability,modul,module-includes,397,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1649,deployability,modul,module,1649,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1995,deployability,patch,patch,1995,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2031,deployability,modul,module,2031,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2126,deployability,modul,module,2126,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2163,deployability,modul,module,2163,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:86,energy efficiency,current,currently,86,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:307,energy efficiency,Core,Core,307,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1696,integrability,pub,public,1696,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2235,integrability,Translat,TranslationUnitDecl,2235,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:142,interoperability,specif,specific,142,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2055,interoperability,specif,specification,2055,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2090,interoperability,specif,specification,2090,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2235,interoperability,Translat,TranslationUnitDecl,2235,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:75,modifiability,modul,modules,75,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:299,modifiability,modul,module,299,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:330,modifiability,modul,module,330,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:397,modifiability,modul,module-includes,397,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1649,modifiability,modul,module,1649,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2031,modifiability,modul,module,2031,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2126,modifiability,modul,module,2126,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2163,modifiability,modul,module,2163,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2273,modifiability,paramet,parameters,2273,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2298,modifiability,paramet,parameters,2298,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:245,performance,error,error,245,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:910,performance,error,error,910,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1146,performance,error,error,1146,"c LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1380,performance,error,error,1380,"ncluded from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1599,performance,error,error,1599,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:75,safety,modul,modules,75,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:245,safety,error,error,245,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:268,safety,patch,patch,268,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:299,safety,modul,module,299,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:330,safety,modul,module,330,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:397,safety,modul,module-includes,397,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:736,safety,compl,complex,736,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:910,safety,error,error,910,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1146,safety,error,error,1146,"c LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1380,safety,error,error,1380,"ncluded from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1599,safety,error,error,1599,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1649,safety,modul,module,1649,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1995,safety,patch,patch,1995,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2031,safety,modul,module,2031,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2126,safety,modul,module,2126,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:2163,safety,modul,module,2163,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:268,security,patch,patch,268,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:736,security,compl,complex,736,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:935,security,ident,identifier,935,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1171,security,ident,identifier,1171,"ng in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module owners",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1995,security,patch,patch,1995,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:245,usability,error,error,245,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:910,usability,error,error,910,"[cxxmodules][llvm] Backport r303373; When running rootcling to produce C++ modules we currently run. into this issue that is an issue in this specific LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1146,usability,error,error,1146,"c LLVM revision. we are using in ROOT. The issue was fixed by Richard upstream. in r303373. The error we fix with this patch is:. ```. While building module 'Core':. While building module 'stl' imported from input_line_1:1:. In file included from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1380,usability,error,error,1380,"ncluded from <module-includes>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1016:1599,usability,error,error,1599,"des>:5:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/ccomplex:39:. In file included from /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/complex:42:. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:102:23: error: use of undeclared identifier '_Tp'. struct __are_same<_Tp, _Tp>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:25: error: use of undeclared identifier '_Tp'. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:318:29: error: expected expression. struct __is_pointer<_Tp*>. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:329:37: error: declaration of '_Tp' must be imported from module 'stl.ccomplex' before it is required. : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >. ^. /cvmfs/sft.cern.ch/lcg/contrib/gcc/6.2.0native/x86_64-slc6/bin/../lib/gcc/x86_64-pc-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/cpp_type_traits.h:327:21: note: previous declaration is here. template<typename _Tp>. ^. ```. Original patch description:. When we enter a module within a linkage specification, switch the linkage. specification and the TU to the new module. This is necessary to get the module ownership correct for entities that we. temporarily hang off the TranslationUnitDecl, such as template parameters and. function parameters. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@303373 91177308-0d34-0410-b5e6-96231b3b80d8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1016
https://github.com/root-project/root/pull/1017:163,deployability,modul,modules,163,[cxxmodules] Remove unnecessary assert; After some discussion with Axel we decided that there is no point to. assert here. This feature here is not related to C++ modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:163,modifiability,modul,modules,163,[cxxmodules] Remove unnecessary assert; After some discussion with Axel we decided that there is no point to. assert here. This feature here is not related to C++ modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:163,safety,modul,modules,163,[cxxmodules] Remove unnecessary assert; After some discussion with Axel we decided that there is no point to. assert here. This feature here is not related to C++ modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:32,testability,assert,assert,32,[cxxmodules] Remove unnecessary assert; After some discussion with Axel we decided that there is no point to. assert here. This feature here is not related to C++ modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1017:110,testability,assert,assert,110,[cxxmodules] Remove unnecessary assert; After some discussion with Axel we decided that there is no point to. assert here. This feature here is not related to C++ modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1017
https://github.com/root-project/root/pull/1018:40,energy efficiency,CPU,CPUs,40,Introduce a helper returning the system CPUs; ...refactoring the old way of obtaining it. Just for convenience.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:49,modifiability,refact,refactoring,49,Introduce a helper returning the system CPUs; ...refactoring the old way of obtaining it. Just for convenience.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:40,performance,CPU,CPUs,40,Introduce a helper returning the system CPUs; ...refactoring the old way of obtaining it. Just for convenience.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:49,performance,refactor,refactoring,49,Introduce a helper returning the system CPUs; ...refactoring the old way of obtaining it. Just for convenience.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1018:12,usability,help,helper,12,Introduce a helper returning the system CPUs; ...refactoring the old way of obtaining it. Just for convenience.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1018
https://github.com/root-project/root/pull/1019:94,availability,slo,slots,94,"Let IMT influence TThreadedObject; If IMT is enabled, TThreadedObject should allocate as many slots as threads the pool has been set with. This PR will be updated with another default value for fgMaxSlots once PR https://github.com/root-project/root/pull/1018 has been agreed upon and merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:155,deployability,updat,updated,155,"Let IMT influence TThreadedObject; If IMT is enabled, TThreadedObject should allocate as many slots as threads the pool has been set with. This PR will be updated with another default value for fgMaxSlots once PR https://github.com/root-project/root/pull/1018 has been agreed upon and merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:77,energy efficiency,alloc,allocate,77,"Let IMT influence TThreadedObject; If IMT is enabled, TThreadedObject should allocate as many slots as threads the pool has been set with. This PR will be updated with another default value for fgMaxSlots once PR https://github.com/root-project/root/pull/1018 has been agreed upon and merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:94,reliability,slo,slots,94,"Let IMT influence TThreadedObject; If IMT is enabled, TThreadedObject should allocate as many slots as threads the pool has been set with. This PR will be updated with another default value for fgMaxSlots once PR https://github.com/root-project/root/pull/1018 has been agreed upon and merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:155,safety,updat,updated,155,"Let IMT influence TThreadedObject; If IMT is enabled, TThreadedObject should allocate as many slots as threads the pool has been set with. This PR will be updated with another default value for fgMaxSlots once PR https://github.com/root-project/root/pull/1018 has been agreed upon and merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1019:155,security,updat,updated,155,"Let IMT influence TThreadedObject; If IMT is enabled, TThreadedObject should allocate as many slots as threads the pool has been set with. This PR will be updated with another default value for fgMaxSlots once PR https://github.com/root-project/root/pull/1018 has been agreed upon and merged.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1019
https://github.com/root-project/root/pull/1020:108,availability,error,error,108,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:452,availability,error,error,452,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1405,availability,Error,Error,1405,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1544,availability,failur,failure,1544,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1754,availability,Error,Error,1754,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:29,deployability,modul,modulemap,29,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:53,deployability,fail,fail,53,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:70,deployability,modul,module,70,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:227,deployability,build,build,227,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:283,deployability,BUILD,BUILDTYPE,283,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:325,deployability,build,build,325,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:713,deployability,modul,module,713,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:742,deployability,build,build,742,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:798,deployability,BUILD,BUILDTYPE,798,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:840,deployability,build,build,840,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:854,deployability,modul,module,854,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:861,deployability,modul,modulemap,861,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:914,deployability,modul,module,914,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1104,deployability,modul,module,1104,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1147,deployability,build,build,1147,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1203,deployability,BUILD,BUILDTYPE,1203,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1245,deployability,build,build,1245,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1259,deployability,modul,module,1259,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1266,deployability,modul,modulemap,1266,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1334,deployability,modul,module,1334,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1413,deployability,build,build,1413,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1469,deployability,BUILD,BUILDTYPE,1469,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1511,deployability,build,build,1511,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1544,deployability,fail,failure,1544,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1554,deployability,build,build,1554,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1610,deployability,BUILD,BUILDTYPE,1610,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1652,deployability,build,build,1652,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1773,deployability,patch,patch,1773,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1802,deployability,modul,modulemap,1802,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:43,energy efficiency,current,currently,43,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:115,integrability,messag,message,115,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:115,interoperability,messag,message,115,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:29,modifiability,modul,modulemap,29,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:70,modifiability,modul,module,70,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:713,modifiability,modul,module,713,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:854,modifiability,modul,module,854,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:861,modifiability,modul,modulemap,861,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:914,modifiability,modul,module,914,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1104,modifiability,modul,module,1104,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1259,modifiability,modul,module,1259,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1266,modifiability,modul,modulemap,1266,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1334,modifiability,modul,module,1334,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1802,modifiability,modul,modulemap,1802,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:108,performance,error,error,108,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:452,performance,error,error,452,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:667,performance,time,times,667,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1058,performance,time,times,1058,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1405,performance,Error,Error,1405,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1544,performance,failur,failure,1544,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1754,performance,Error,Error,1754,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:53,reliability,fail,fail,53,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1544,reliability,fail,failure,1544,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:29,safety,modul,modulemap,29,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:70,safety,modul,module,70,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:108,safety,error,error,108,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:452,safety,error,error,452,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:713,safety,modul,module,713,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:854,safety,modul,module,854,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:861,safety,modul,modulemap,861,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:914,safety,modul,module,914,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1104,safety,modul,module,1104,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1259,safety,modul,module,1259,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1266,safety,modul,modulemap,1266,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1334,safety,modul,module,1334,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1405,safety,Error,Error,1405,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1754,safety,Error,Error,1754,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1773,safety,patch,patch,1773,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1802,safety,modul,modulemap,1802,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1818,safety,prevent,prevents,1818,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:17,security,sign,signal,17,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:147,security,sign,signal,147,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:397,security,sign,signal,397,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:982,security,sign,signal,982,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1773,security,patch,patch,1773,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1818,security,preven,prevents,1818,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:108,usability,error,error,108,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:452,usability,error,error,452,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1405,usability,Error,Error,1405,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1020:1754,usability,Error,Error,1754,"[cxxmodules] Add signal.h to modulemap; We currently fail to create a module for RootFit with the following error. message when merging a union in signal.h:. ```. In file included from input_line_12:67:. In file included from /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/RooErrorHandler.h:20:. In file included from /usr/include/signal.h:394:. /usr/include/bits/pthreadtypes.h:130:3: error: typedef redefinition with different types ('union pthread_cond_t' vs 'union pthread_cond_t'). } pthread_cond_t;. ^. /usr/include/sys/types.h:271:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'Hist.Foption.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:820:10: note: Hist.Foption.h defined here. module ""Foption.h"" { header ""Foption.h"" export * }. ^. /usr/include/signal.h:394:11: note: '/usr/include/bits/pthreadtypes.h' included multiple times, additional include site in header from module 'RooFitCore.RooErrorHandler.h'. ^. /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/include/module.modulemap:2449:10: note: RooFitCore.RooErrorHandler.h defined here. module ""RooErrorHandler.h"" { header ""RooErrorHandler.h"" export * }. ^. Error: /build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/bin/rootcling: compilation failure (/build/jenkins/workspace/root-nightly-runtime-cxxmodules/BUILDTYPE/Debug/COMPILER/gcc62/LABEL/slc6/build/lib/libRooFitCorecbd7d3c40e_dictUmbrella.h). make[2]: *** [roofit/roofitcore/G__RooFitCore.cxx] Error 1. ```. This patch adds the header to the modulemap which prevents us from. trying to merge this struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1020
https://github.com/root-project/root/pull/1021:46,deployability,modul,module,46,[cxxmodules] Split out xlocale.h into its own module; This fixes the compilation on systems that no longer have xlocale.h. which is no longer part of glibc since 2.26 it seems.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1021
https://github.com/root-project/root/pull/1021:46,modifiability,modul,module,46,[cxxmodules] Split out xlocale.h into its own module; This fixes the compilation on systems that no longer have xlocale.h. which is no longer part of glibc since 2.26 it seems.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1021
https://github.com/root-project/root/pull/1021:46,safety,modul,module,46,[cxxmodules] Split out xlocale.h into its own module; This fixes the compilation on systems that no longer have xlocale.h. which is no longer part of glibc since 2.26 it seems.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1021
https://github.com/root-project/root/pull/1023:98,safety,test,tests,98,[TDF] Datasource fixes; * fix interaction of data-source columns and user-defined columns . * add tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:98,testability,test,tests,98,[TDF] Datasource fixes; * fix interaction of data-source columns and user-defined columns . * add tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:30,usability,interact,interaction,30,[TDF] Datasource fixes; * fix interaction of data-source columns and user-defined columns . * add tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1023:69,usability,user,user-defined,69,[TDF] Datasource fixes; * fix interaction of data-source columns and user-defined columns . * add tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1023
https://github.com/root-project/root/pull/1025:6,deployability,patch,patches,6,V6-10-patches fix order commits; Fixing failed builds for aarch and fedora24/fedora25,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1025
https://github.com/root-project/root/pull/1025:40,deployability,fail,failed,40,V6-10-patches fix order commits; Fixing failed builds for aarch and fedora24/fedora25,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1025
https://github.com/root-project/root/pull/1025:47,deployability,build,builds,47,V6-10-patches fix order commits; Fixing failed builds for aarch and fedora24/fedora25,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1025
https://github.com/root-project/root/pull/1025:40,reliability,fail,failed,40,V6-10-patches fix order commits; Fixing failed builds for aarch and fedora24/fedora25,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1025
https://github.com/root-project/root/pull/1025:6,safety,patch,patches,6,V6-10-patches fix order commits; Fixing failed builds for aarch and fedora24/fedora25,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1025
https://github.com/root-project/root/pull/1025:6,security,patch,patches,6,V6-10-patches fix order commits; Fixing failed builds for aarch and fedora24/fedora25,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1025
https://github.com/root-project/root/pull/1026:41,deployability,contain,container,41,[TypeTraits] std::array_view is always a container;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1026
https://github.com/root-project/root/pull/1027:54,interoperability,semant,semantics,54,Define histograms of TDF via histomodels and not move semantics; This allows seamless usage of PyROOT and the forthcoming list initialisation.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1027
https://github.com/root-project/root/pull/1028:134,interoperability,specif,specified,134,"Avoid warnings when overriding nChunks; The warnings were raised by TThreadExecutor trying to be smart when chunking, overriding user specified number of chunks to avoid accessing uninitialized positions of the results vector. This is annoying f.e. when Fitting, with several calls to Map() with the same ""conflictive when chunking"" data.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1028:306,interoperability,conflict,conflictive,306,"Avoid warnings when overriding nChunks; The warnings were raised by TThreadExecutor trying to be smart when chunking, overriding user specified number of chunks to avoid accessing uninitialized positions of the results vector. This is annoying f.e. when Fitting, with several calls to Map() with the same ""conflictive when chunking"" data.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1028:0,safety,Avoid,Avoid,0,"Avoid warnings when overriding nChunks; The warnings were raised by TThreadExecutor trying to be smart when chunking, overriding user specified number of chunks to avoid accessing uninitialized positions of the results vector. This is annoying f.e. when Fitting, with several calls to Map() with the same ""conflictive when chunking"" data.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1028:164,safety,avoid,avoid,164,"Avoid warnings when overriding nChunks; The warnings were raised by TThreadExecutor trying to be smart when chunking, overriding user specified number of chunks to avoid accessing uninitialized positions of the results vector. This is annoying f.e. when Fitting, with several calls to Map() with the same ""conflictive when chunking"" data.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1028:170,security,access,accessing,170,"Avoid warnings when overriding nChunks; The warnings were raised by TThreadExecutor trying to be smart when chunking, overriding user specified number of chunks to avoid accessing uninitialized positions of the results vector. This is annoying f.e. when Fitting, with several calls to Map() with the same ""conflictive when chunking"" data.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1028:129,usability,user,user,129,"Avoid warnings when overriding nChunks; The warnings were raised by TThreadExecutor trying to be smart when chunking, overriding user specified number of chunks to avoid accessing uninitialized positions of the results vector. This is annoying f.e. when Fitting, with several calls to Map() with the same ""conflictive when chunking"" data.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1028
https://github.com/root-project/root/pull/1029:48,integrability,transform,transformations,48,[TDF] Fix reading of c-style arrays from jitted transformations and actions; Solves the reading-related part of issue [ROOT-8979](https://sft.its.cern.ch/jira/browse/ROOT-8979).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1029
https://github.com/root-project/root/pull/1029:48,interoperability,transform,transformations,48,[TDF] Fix reading of c-style arrays from jitted transformations and actions; Solves the reading-related part of issue [ROOT-8979](https://sft.its.cern.ch/jira/browse/ROOT-8979).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1029
https://github.com/root-project/root/pull/1030:98,interoperability,architectur,architectures,98,"Fix massive parallel execution of TThreadedObject; ...to support more than 64 threads in manycore architectures that support it, like KNL.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1030
https://github.com/root-project/root/pull/1030:12,performance,parallel,parallel,12,"Fix massive parallel execution of TThreadedObject; ...to support more than 64 threads in manycore architectures that support it, like KNL.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1030
https://github.com/root-project/root/pull/1030:57,usability,support,support,57,"Fix massive parallel execution of TThreadedObject; ...to support more than 64 threads in manycore architectures that support it, like KNL.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1030
https://github.com/root-project/root/pull/1030:117,usability,support,support,117,"Fix massive parallel execution of TThreadedObject; ...to support more than 64 threads in manycore architectures that support it, like KNL.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1030
https://github.com/root-project/root/pull/1031:176,integrability,messag,message,176,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:295,integrability,interfac,interface,295,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:176,interoperability,messag,message,176,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:295,interoperability,interfac,interface,295,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:295,modifiability,interfac,interface,295,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:37,safety,test,tests,37,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:47,safety,test,test,47,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:133,safety,test,tests,133,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:249,safety,test,tests,249,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:270,safety,test,tests,270,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:32,testability,unit,unit,32,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:37,testability,test,tests,37,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:47,testability,test,test,47,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:128,testability,unit,unit,128,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:133,testability,test,tests,133,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:244,testability,unit,unit,244,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:249,testability,test,tests,249,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1031:270,testability,test,tests,270,Streamline expression of Python unit tests and test TDF histogramming in python; This PR introduces a new way to express python unit tests with two CMake functions (see commit message) and leverages the new mechanism to re-formulate the PyROOT unit tests and to add new tests for the TDF pyROOT interface.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1031
https://github.com/root-project/root/pull/1033:97,deployability,build,build,97,Fix ROOT-8359: the first compiler we look for is the one the path; then the one that was used to build cling and finally the one. in the absolute path (e.g. usr/bin/g++),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1033
https://github.com/root-project/root/pull/1034:213,deployability,modul,modules,213,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:254,deployability,modul,module,254,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:213,modifiability,modul,modules,213,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:227,modifiability,reu,reuse,227,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:254,modifiability,modul,module,254,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:213,safety,modul,modules,213,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:254,safety,modul,module,254,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:283,safety,review,reviews,283,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:319,safety,test,test,319,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:335,safety,test,tests,335,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:283,testability,review,reviews,283,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:319,testability,test,test,319,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:335,testability,test,tests,335,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1034:345,testability,regress,regressions,345,"Revert ""Don't try to remove decls that are not part of the lookup.""; This reverts commit 180cd90afe663f2e04017d03bc63111d124010c6. It breaks lookup of functions with 'using ParentClass::Func'. in combination with modules which reuse the hidden flag for. module purposes. See https://reviews.llvm.org/D37180 for a clang test case that. tests for regressions like this in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1034
https://github.com/root-project/root/pull/1035:41,deployability,modul,modulemap,41,"[cxxmodules] Add sys/types.h to the libc modulemap; In commit b8dbe76844923 we added signal.h to the modulemap to. fix a merging issue coming from sys/types.h. However, we include. this header directly in some other places so we can still encounter. this merging issue. This adds now the sys/types.h header also. to the modulemap to fix this once and for all.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1035
https://github.com/root-project/root/pull/1035:101,deployability,modul,modulemap,101,"[cxxmodules] Add sys/types.h to the libc modulemap; In commit b8dbe76844923 we added signal.h to the modulemap to. fix a merging issue coming from sys/types.h. However, we include. this header directly in some other places so we can still encounter. this merging issue. This adds now the sys/types.h header also. to the modulemap to fix this once and for all.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1035
https://github.com/root-project/root/pull/1035:320,deployability,modul,modulemap,320,"[cxxmodules] Add sys/types.h to the libc modulemap; In commit b8dbe76844923 we added signal.h to the modulemap to. fix a merging issue coming from sys/types.h. However, we include. this header directly in some other places so we can still encounter. this merging issue. This adds now the sys/types.h header also. to the modulemap to fix this once and for all.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1035
https://github.com/root-project/root/pull/1035:41,modifiability,modul,modulemap,41,"[cxxmodules] Add sys/types.h to the libc modulemap; In commit b8dbe76844923 we added signal.h to the modulemap to. fix a merging issue coming from sys/types.h. However, we include. this header directly in some other places so we can still encounter. this merging issue. This adds now the sys/types.h header also. to the modulemap to fix this once and for all.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1035
https://github.com/root-project/root/pull/1035:101,modifiability,modul,modulemap,101,"[cxxmodules] Add sys/types.h to the libc modulemap; In commit b8dbe76844923 we added signal.h to the modulemap to. fix a merging issue coming from sys/types.h. However, we include. this header directly in some other places so we can still encounter. this merging issue. This adds now the sys/types.h header also. to the modulemap to fix this once and for all.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1035
https://github.com/root-project/root/pull/1035:320,modifiability,modul,modulemap,320,"[cxxmodules] Add sys/types.h to the libc modulemap; In commit b8dbe76844923 we added signal.h to the modulemap to. fix a merging issue coming from sys/types.h. However, we include. this header directly in some other places so we can still encounter. this merging issue. This adds now the sys/types.h header also. to the modulemap to fix this once and for all.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1035
https://github.com/root-project/root/pull/1035:41,safety,modul,modulemap,41,"[cxxmodules] Add sys/types.h to the libc modulemap; In commit b8dbe76844923 we added signal.h to the modulemap to. fix a merging issue coming from sys/types.h. However, we include. this header directly in some other places so we can still encounter. this merging issue. This adds now the sys/types.h header also. to the modulemap to fix this once and for all.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1035
https://github.com/root-project/root/pull/1035:101,safety,modul,modulemap,101,"[cxxmodules] Add sys/types.h to the libc modulemap; In commit b8dbe76844923 we added signal.h to the modulemap to. fix a merging issue coming from sys/types.h. However, we include. this header directly in some other places so we can still encounter. this merging issue. This adds now the sys/types.h header also. to the modulemap to fix this once and for all.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1035
https://github.com/root-project/root/pull/1035:320,safety,modul,modulemap,320,"[cxxmodules] Add sys/types.h to the libc modulemap; In commit b8dbe76844923 we added signal.h to the modulemap to. fix a merging issue coming from sys/types.h. However, we include. this header directly in some other places so we can still encounter. this merging issue. This adds now the sys/types.h header also. to the modulemap to fix this once and for all.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1035
https://github.com/root-project/root/pull/1035:85,security,sign,signal,85,"[cxxmodules] Add sys/types.h to the libc modulemap; In commit b8dbe76844923 we added signal.h to the modulemap to. fix a merging issue coming from sys/types.h. However, we include. this header directly in some other places so we can still encounter. this merging issue. This adds now the sys/types.h header also. to the modulemap to fix this once and for all.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1035
https://github.com/root-project/root/pull/1036:329,availability,down,down,329,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:608,availability,down,down,608,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:53,deployability,modul,modules,53,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:74,deployability,modul,modules,74,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:250,deployability,modul,modules,250,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:275,deployability,modul,module-includes,275,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:753,deployability,modul,modules,753,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:873,deployability,modul,module,873,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:944,deployability,modul,module,944,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:53,modifiability,modul,modules,53,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:74,modifiability,modul,modules,74,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:250,modifiability,modul,modules,250,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:275,modifiability,modul,module-includes,275,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:753,modifiability,modul,modules,753,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:873,modifiability,modul,module,873,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:944,modifiability,modul,module,944,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:53,safety,modul,modules,53,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:74,safety,modul,modules,74,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:250,safety,modul,modules,250,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:275,safety,modul,module-includes,275,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:753,safety,modul,modules,753,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:873,safety,modul,module,873,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:944,safety,modul,module,944,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1036:903,usability,stop,stop,903,"[cxxmodules] Fix TMetaUtils::GetFileName with system modules; When we add modules for system headers we are breaking this part. of the code that tries to track back via the include chain. the original header that includes this system header. In the. modules case we hit the ""module-includes:X"" include which. we then can't track down with the normal PP anymore. The reason for this code seems to be that we never know what header. is actually possible to be included and what is just some internal. (possibly non-standalone) header like ""bits/sys/types.h"". For normal rootcling informations we have to track down until. we leave the system includes or reach the top-level system. include to be sure that we can now actually include the. given path. For modules we already know when we are in the header that. is possible to be included by someone as this is the top. level module header, so we can just stop tracking once we hit the. top-level module header.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1036
https://github.com/root-project/root/pull/1037:536,deployability,updat,update,536,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:651,deployability,updat,update,651,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:742,deployability,Updat,Update,742,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:514,energy efficiency,draw,draw,514,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:732,energy efficiency,Draw,Draw,732,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:786,energy efficiency,Draw,Draw,786,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:825,energy efficiency,Draw,Draw,825,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:433,integrability,event,event,433,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:494,integrability,event,event,494,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:768,integrability,event,event,768,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:6,interoperability,Registr,Registration,6,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:800,performance,perform,performed,800,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:930,performance,concurren,concurrently,930,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:983,performance,multi-thread,multi-threading,983,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:536,safety,updat,update,536,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:651,safety,updat,update,651,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:742,safety,Updat,Update,742,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:536,security,updat,update,536,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:651,security,updat,update,651,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:742,security,Updat,Update,742,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:84,usability,User,Users,84,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:339,usability,user,users,339,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1037:800,usability,perform,performed,800,"[TDF] Registration of callbacks called on partial analysis results every N entries; Users can now register one or more callbacks to TResultProxies (i.e. the results of TDF actions). A callback is just a callable that takes. a reference to the result type as argument and is going to be invoked. by each worker thread once every N entries (users choose N). It is meant to be used to inspect partial results of the analysis. while the event loop is still running. For example, in a single-thread event loop, one can draw a histogram. and update the canvas every 100 entries like this:. . ```c++. auto h = tdf.Histo1D(""x"");. TCanvas c(""c"",""x hist"");. // update the canvas every 100 entries. h.RegisterCallback(100, [&c](TH1D &h_) { h_.Draw(); c.Update(); });. // trigger event loop, this `Draw` will be performed afterwards. h->Draw();. ```. Each worker thread invokes callbacks sequentially, but the same callback. might be invoked concurrently by different worker threads if implicit multi-threading. is enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1037
https://github.com/root-project/root/pull/1038:17,deployability,depend,dependencies,17,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:37,deployability,modul,modules,37,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:84,deployability,modul,modules,84,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:181,deployability,depend,dependencies,181,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:272,deployability,depend,dependency,272,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:302,deployability,patch,patch,302,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:322,deployability,modul,module,322,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:17,integrability,depend,dependencies,17,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:181,integrability,depend,dependencies,181,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:272,integrability,depend,dependency,272,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:17,modifiability,depend,dependencies,17,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:37,modifiability,modul,modules,37,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:84,modifiability,modul,modules,84,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:116,modifiability,variab,variable,116,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:181,modifiability,depend,dependencies,181,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:272,modifiability,depend,dependency,272,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:322,modifiability,modul,module,322,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:17,safety,depend,dependencies,17,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:37,safety,modul,modules,37,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:84,safety,modul,modules,84,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:181,safety,depend,dependencies,181,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:272,safety,depend,dependency,272,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:302,safety,patch,patch,302,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:322,safety,modul,module,322,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:302,security,patch,patch,302,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:17,testability,depend,dependencies,17,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:181,testability,depend,dependencies,181,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1038:272,testability,depend,dependency,272,"[cxxmodules] Add dependencies to C++ modules generated by rootcling; Previously the modules were only a environment variable, so we never. had any CMake code that added the correct dependencies here. Now we. do have runtime_cxxmodules, and we can actually properly add a. dependency here. Without this patch a deleted C++ module file actually will never be regenerated.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1038
https://github.com/root-project/root/pull/1039:96,deployability,build,build,96,"Filemerger test fix: fixing compilation flags for interpreter; For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel. Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:119,deployability,Releas,Release,119,"Filemerger test fix: fixing compilation flags for interpreter; For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel. Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:280,deployability,Releas,Release,280,"Filemerger test fix: fixing compilation flags for interpreter; For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel. Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:288,deployability,build,build,288,"Filemerger test fix: fixing compilation flags for interpreter; For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel. Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:86,energy efficiency,Optim,Optimized,86,"Filemerger test fix: fixing compilation flags for interpreter; For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel. Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:86,performance,Optimiz,Optimized,86,"Filemerger test fix: fixing compilation flags for interpreter; For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel. Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:11,safety,test,test,11,"Filemerger test fix: fixing compilation flags for interpreter; For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel. Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1039:11,testability,test,test,11,"Filemerger test fix: fixing compilation flags for interpreter; For LLVM we don't have Optimized build, but only Debug, Release, RelWithDebInfo, and MinSizeRel. Thats why to have correctly interpreted __FAST_MATH__ in ROOT macroses we need to add -ffast-math flag for LLVM default Release build type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1039
https://github.com/root-project/root/pull/1040:23,interoperability,specif,specified,23,Check cuda support for specified cxx standard;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:37,interoperability,standard,standard,37,Check cuda support for specified cxx standard;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1040:11,usability,support,support,11,Check cuda support for specified cxx standard;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1040
https://github.com/root-project/root/pull/1041:27,safety,test,test,27,Activate DS in MT mode and test its basic functionalites;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1041
https://github.com/root-project/root/pull/1041:27,testability,test,test,27,Activate DS in MT mode and test its basic functionalites;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1041
https://github.com/root-project/root/pull/1044:212,availability,state,statements,212,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:605,availability,state,statements,605,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:212,integrability,state,statements,212,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:605,integrability,state,statements,605,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:369,performance,parallel,parallel,369,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:464,performance,time,time,464,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:577,safety,test,tests,577,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:664,safety,input,inputs,664,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:747,safety,input,inputs,747,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:235,testability,unit,unit,235,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:392,testability,unit,unit,392,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:577,testability,test,tests,577,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:664,usability,input,inputs,664,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1044:747,usability,input,inputs,747,"adding approximation of tanh (Manuel Schiller); @lmoneta as discussed yesterday this is just the dump of our tanh approximation. I leave it up to you to decide how to do vectorisation. As seen between the ifndef statements, the vector unit is already used for a single evaluation of tanh (it is implemented as a fraction and numerator and denominator are calculated in parallel in the vector unit). I recon if one needs to do multiple tanh evaluations at the same time, one might want to swap between horizontal and vertical vectorisation. In the original, the if( x is large) tests were kept in UNLIKELY statements, I didn't follow up if this was because typical inputs in our use case are known, or because tanh is generally evaluated for small inputs ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1044
https://github.com/root-project/root/pull/1045:37,interoperability,format,format,37,[TDF] Revert some doc-breaking clang-format fixes (NFC); This reverts part of commit 5059f594.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1045
https://github.com/root-project/root/pull/1046:170,deployability,updat,updates,170,"[TDF] `Count` should really return ULong64_t, not unsigned; `Count` should return the same type that we use to enumerate entries, by definition. A related PR in roottest updates `test_misc` to comply with the interface change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:209,integrability,interfac,interface,209,"[TDF] `Count` should really return ULong64_t, not unsigned; `Count` should return the same type that we use to enumerate entries, by definition. A related PR in roottest updates `test_misc` to comply with the interface change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:209,interoperability,interfac,interface,209,"[TDF] `Count` should really return ULong64_t, not unsigned; `Count` should return the same type that we use to enumerate entries, by definition. A related PR in roottest updates `test_misc` to comply with the interface change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:209,modifiability,interfac,interface,209,"[TDF] `Count` should really return ULong64_t, not unsigned; `Count` should return the same type that we use to enumerate entries, by definition. A related PR in roottest updates `test_misc` to comply with the interface change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:170,safety,updat,updates,170,"[TDF] `Count` should really return ULong64_t, not unsigned; `Count` should return the same type that we use to enumerate entries, by definition. A related PR in roottest updates `test_misc` to comply with the interface change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:193,safety,compl,comply,193,"[TDF] `Count` should really return ULong64_t, not unsigned; `Count` should return the same type that we use to enumerate entries, by definition. A related PR in roottest updates `test_misc` to comply with the interface change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:170,security,updat,updates,170,"[TDF] `Count` should really return ULong64_t, not unsigned; `Count` should return the same type that we use to enumerate entries, by definition. A related PR in roottest updates `test_misc` to comply with the interface change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1046:193,security,compl,comply,193,"[TDF] `Count` should really return ULong64_t, not unsigned; `Count` should return the same type that we use to enumerate entries, by definition. A related PR in roottest updates `test_misc` to comply with the interface change.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1046
https://github.com/root-project/root/pull/1047:25,deployability,Modul,Module,25,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:76,deployability,upgrad,upgrade,76,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:149,deployability,Modul,Module,149,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:193,deployability,Modul,Module,193,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:280,deployability,Modul,Module,280,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:162,energy efficiency,current,current,162,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:216,interoperability,convers,conversions,216,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:25,modifiability,Modul,Module,25,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:76,modifiability,upgrad,upgrade,76,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:113,modifiability,layer,layer,113,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:149,modifiability,Modul,Module,149,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:193,modifiability,Modul,Module,193,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:280,modifiability,Modul,Module,280,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:25,safety,Modul,Module,25,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:149,safety,Modul,Module,149,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:193,safety,Modul,Module,193,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1047:280,safety,Modul,Module,280,shared_ptr-ize the llvm::Module*.; This is in prepare for the upcoming llvm upgrade. The future orc jit compile. layer needs a std::shared_ptr<llvm::Module>. The current design passes a. llvm::Module* around and any conversions to a shared_ptr cause the. destruction of the llvm::Module which is a long-lived object in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1047
https://github.com/root-project/root/pull/1048:260,integrability,transform,transformations,260,"Column aliases can be defined by the user; Highlights:. - Aliases to columns can be defined. - Aliases to column aliases can be defined. - Early detection of mistakes: non-existing column names, incoherent aliasing. - Support of aliased columns in actions and transformations, also jitted",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1048
https://github.com/root-project/root/pull/1048:260,interoperability,transform,transformations,260,"Column aliases can be defined by the user; Highlights:. - Aliases to columns can be defined. - Aliases to column aliases can be defined. - Early detection of mistakes: non-existing column names, incoherent aliasing. - Support of aliased columns in actions and transformations, also jitted",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1048
https://github.com/root-project/root/pull/1048:145,safety,detect,detection,145,"Column aliases can be defined by the user; Highlights:. - Aliases to columns can be defined. - Aliases to column aliases can be defined. - Early detection of mistakes: non-existing column names, incoherent aliasing. - Support of aliased columns in actions and transformations, also jitted",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1048
https://github.com/root-project/root/pull/1048:145,security,detect,detection,145,"Column aliases can be defined by the user; Highlights:. - Aliases to columns can be defined. - Aliases to column aliases can be defined. - Early detection of mistakes: non-existing column names, incoherent aliasing. - Support of aliased columns in actions and transformations, also jitted",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1048
https://github.com/root-project/root/pull/1048:37,usability,user,user,37,"Column aliases can be defined by the user; Highlights:. - Aliases to columns can be defined. - Aliases to column aliases can be defined. - Early detection of mistakes: non-existing column names, incoherent aliasing. - Support of aliased columns in actions and transformations, also jitted",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1048
https://github.com/root-project/root/pull/1048:218,usability,Support,Support,218,"Column aliases can be defined by the user; Highlights:. - Aliases to columns can be defined. - Aliases to column aliases can be defined. - Early detection of mistakes: non-existing column names, incoherent aliasing. - Support of aliased columns in actions and transformations, also jitted",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1048
https://github.com/root-project/root/pull/1049:13,deployability,Modul,ModuleGenForModules,13,"[WIP] Remove ModuleGenForModules; So, we just removed the assert that makes us aware that we need to. rethink this flag. I don't see a clear solution at the moment, but. this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains. about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:13,modifiability,Modul,ModuleGenForModules,13,"[WIP] Remove ModuleGenForModules; So, we just removed the assert that makes us aware that we need to. rethink this flag. I don't see a clear solution at the moment, but. this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains. about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:13,safety,Modul,ModuleGenForModules,13,"[WIP] Remove ModuleGenForModules; So, we just removed the assert that makes us aware that we need to. rethink this flag. I don't see a clear solution at the moment, but. this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains. about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:294,safety,compl,complains,294,"[WIP] Remove ModuleGenForModules; So, we just removed the assert that makes us aware that we need to. rethink this flag. I don't see a clear solution at the moment, but. this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains. about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:328,safety,test,tests,328,"[WIP] Remove ModuleGenForModules; So, we just removed the assert that makes us aware that we need to. rethink this flag. I don't see a clear solution at the moment, but. this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains. about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:294,security,compl,complains,294,"[WIP] Remove ModuleGenForModules; So, we just removed the assert that makes us aware that we need to. rethink this flag. I don't see a clear solution at the moment, but. this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains. about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:58,testability,assert,assert,58,"[WIP] Remove ModuleGenForModules; So, we just removed the assert that makes us aware that we need to. rethink this flag. I don't see a clear solution at the moment, but. this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains. about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:328,testability,test,tests,328,"[WIP] Remove ModuleGenForModules; So, we just removed the assert that makes us aware that we need to. rethink this flag. I don't see a clear solution at the moment, but. this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains. about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1049:135,usability,clear,clear,135,"[WIP] Remove ModuleGenForModules; So, we just removed the assert that makes us aware that we need to. rethink this flag. I don't see a clear solution at the moment, but. this PR at least makes us aware that we need to solve this issue. For now I just removed it and we see what exactly Jenkins complains. about when it runs the tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1049
https://github.com/root-project/root/pull/1050:15,deployability,Modul,Module,15,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:104,deployability,modul,module,104,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:149,deployability,API,API,149,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:165,deployability,modul,module,165,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:206,deployability,infrastructur,infrastructure,206,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:316,deployability,Modul,Modules,316,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:330,deployability,patch,patch,330,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:350,deployability,upgrad,upgrade,350,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:149,integrability,API,API,149,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:149,interoperability,API,API,149,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:15,modifiability,Modul,Module,15,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:104,modifiability,modul,module,104,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:165,modifiability,modul,module,165,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:316,modifiability,Modul,Modules,316,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:350,modifiability,upgrad,upgrade,350,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:116,performance,time,time,116,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:15,safety,Modul,Module,15,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:104,safety,modul,module,104,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:165,safety,modul,module,165,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:316,safety,Modul,Modules,316,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:330,safety,patch,patch,330,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:330,security,patch,patch,330,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:0,testability,Simpl,Simplify,0,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1050:0,usability,Simpl,Simplify,0,"Simplify llvm::Module emission in the JIT.; This teaches again the IncrementalExecutor to emit only one module at a time. In the old MCJIT days, the API worked with module sets and cling assumed llvm's jit infrastructure is moving in this direction. LLVM 5.0 moves away from this concept and works with single llvm::Modules. This patch will make the upgrade to LLVM 5.0 smoother.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1050
https://github.com/root-project/root/pull/1051:114,deployability,build,builds,114,Fixing running of fast-math enabled macroses in interpreter; Adding -ffast-math flag to really activate Optimized builds for interpreter,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1051
https://github.com/root-project/root/pull/1051:104,energy efficiency,Optim,Optimized,104,Fixing running of fast-math enabled macroses in interpreter; Adding -ffast-math flag to really activate Optimized builds for interpreter,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1051
https://github.com/root-project/root/pull/1051:104,performance,Optimiz,Optimized,104,Fixing running of fast-math enabled macroses in interpreter; Adding -ffast-math flag to really activate Optimized builds for interpreter,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1051
https://github.com/root-project/root/pull/1052:24,integrability,buffer,buffered,24,"ROOT-9002 TBufferMerger buffered flush to disk; This introduces a `SetAutoSave()` function to `TBufferMerger` that lets users choose how often data is merged into the output file. This avoid excessive writing of TTree headers, which are compressed and causes the output thread to do too much work if merges happen at every buffer read from the queue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:323,integrability,buffer,buffer,323,"ROOT-9002 TBufferMerger buffered flush to disk; This introduces a `SetAutoSave()` function to `TBufferMerger` that lets users choose how often data is merged into the output file. This avoid excessive writing of TTree headers, which are compressed and causes the output thread to do too much work if merges happen at every buffer read from the queue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:344,integrability,queue,queue,344,"ROOT-9002 TBufferMerger buffered flush to disk; This introduces a `SetAutoSave()` function to `TBufferMerger` that lets users choose how often data is merged into the output file. This avoid excessive writing of TTree headers, which are compressed and causes the output thread to do too much work if merges happen at every buffer read from the queue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:42,performance,disk,disk,42,"ROOT-9002 TBufferMerger buffered flush to disk; This introduces a `SetAutoSave()` function to `TBufferMerger` that lets users choose how often data is merged into the output file. This avoid excessive writing of TTree headers, which are compressed and causes the output thread to do too much work if merges happen at every buffer read from the queue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:344,performance,queue,queue,344,"ROOT-9002 TBufferMerger buffered flush to disk; This introduces a `SetAutoSave()` function to `TBufferMerger` that lets users choose how often data is merged into the output file. This avoid excessive writing of TTree headers, which are compressed and causes the output thread to do too much work if merges happen at every buffer read from the queue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:185,safety,avoid,avoid,185,"ROOT-9002 TBufferMerger buffered flush to disk; This introduces a `SetAutoSave()` function to `TBufferMerger` that lets users choose how often data is merged into the output file. This avoid excessive writing of TTree headers, which are compressed and causes the output thread to do too much work if merges happen at every buffer read from the queue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1052:120,usability,user,users,120,"ROOT-9002 TBufferMerger buffered flush to disk; This introduces a `SetAutoSave()` function to `TBufferMerger` that lets users choose how often data is merged into the output file. This avoid excessive writing of TTree headers, which are compressed and causes the output thread to do too much work if merges happen at every buffer read from the queue.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1052
https://github.com/root-project/root/pull/1053:92,deployability,updat,update,92,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:296,deployability,Stack,StackTrace,296,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:385,deployability,updat,update,385,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:0,modifiability,Refact,Refactor,0,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:0,performance,Refactor,Refactor,0,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:65,safety,safe,safe,65,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:92,safety,updat,update,92,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:385,safety,updat,update,385,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:9,security,sign,signal,9,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:37,security,sign,signal,37,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:92,security,updat,update,92,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:385,security,updat,update,385,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:236,usability,progress,progress,236,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:337,usability,support,support,337,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:404,usability,support,support,404,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1053:443,usability,support,support,443,Refactor signal handling and replace signal handlers with thread-safe functions; This is an update of https://github.com/root-project/root/pull/134 to work compile on MacOS and rename TSigHandling into TSignalManager. This is a work in progress as the new TSignalManager no longer calls TSystem::StackTrace but is also only implementing support for unix systems. @zzxuanyuan Could you update the code to support at least MacOS (and attempt to support Windows)?,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1053
https://github.com/root-project/root/pull/1054:184,availability,error,error,184,"[cxxmodules] Fix too late nullptr check in rootcling; It should happen before we use the module the first time and not. afterwards, otherwise we just crash instead of printing a nice. error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:89,deployability,modul,module,89,"[cxxmodules] Fix too late nullptr check in rootcling; It should happen before we use the module the first time and not. afterwards, otherwise we just crash instead of printing a nice. error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:89,modifiability,modul,module,89,"[cxxmodules] Fix too late nullptr check in rootcling; It should happen before we use the module the first time and not. afterwards, otherwise we just crash instead of printing a nice. error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:106,performance,time,time,106,"[cxxmodules] Fix too late nullptr check in rootcling; It should happen before we use the module the first time and not. afterwards, otherwise we just crash instead of printing a nice. error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:184,performance,error,error,184,"[cxxmodules] Fix too late nullptr check in rootcling; It should happen before we use the module the first time and not. afterwards, otherwise we just crash instead of printing a nice. error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:89,safety,modul,module,89,"[cxxmodules] Fix too late nullptr check in rootcling; It should happen before we use the module the first time and not. afterwards, otherwise we just crash instead of printing a nice. error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:184,safety,error,error,184,"[cxxmodules] Fix too late nullptr check in rootcling; It should happen before we use the module the first time and not. afterwards, otherwise we just crash instead of printing a nice. error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1054:184,usability,error,error,184,"[cxxmodules] Fix too late nullptr check in rootcling; It should happen before we use the module the first time and not. afterwards, otherwise we just crash instead of printing a nice. error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1054
https://github.com/root-project/root/pull/1055:759,deployability,automat,automatic,759,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:301,energy efficiency,draw,drawing,301,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:366,energy efficiency,draw,draw,366,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:599,energy efficiency,draw,draw,599,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:849,energy efficiency,draw,draw,849,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:942,energy efficiency,draw,draw,942,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1360,energy efficiency,draw,drawing,1360,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1404,energy efficiency,draw,draw,1404,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1515,energy efficiency,draw,draw,1515,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1688,integrability,compon,components,1688,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1688,interoperability,compon,components,1688,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1744,interoperability,specif,specify,1744,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1264,modifiability,paramet,parameters,1264,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1688,modifiability,compon,components,1688,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1428,safety,valid,valid,1428,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:759,testability,automat,automatic,759,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:21,usability,support,supported,21,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:154,usability,support,supported,154,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:693,usability,support,support,693,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1079,usability,support,supports,1079,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1283,usability,tool,tooltips,1283,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1055:1635,usability,support,supported,1635,"JSROOT 5.3.0; 1. New supported classes:. - TGraphPolar. - TGraphTime. - TSpline3. - TSpline5. - TPolyLine3D. - TPolyMarker. - TEfficiency. - TH1K. 2. New supported options:. ""PFC"" - auto fill color (histograms and graphs). ""PLC"" - auto line color. ""PMC"" - auto marker color. ""A"" - fully disables axes drawing for histograms painters. ""TEXT"" - for TH2Poly. ""SAMES"" - draw stat box for superimposed histograms. ""NOCOL"" - ignore stored in the TCanvas colors list. ""NOPAL"" - ignore stored in the TCanvas color palette. 3. Improvements in existing painters:. - use color palette stored in the TCanvas. - draw stats box when really required. - let resize frames and paves in all eight directions. - support lines, boxes and arbitrary text positions in TPaveText. - automatic title positioning of vertical axis when fTitleOffset==0. - when pad.fTickx/y==2 draw axes labels on opposite side. - editing of TGraph objects - moving of the graph bins. - draw X/Y/Z axis titles in lego plots. - use canvas Theta/Phi angles to set initial camera position in 3D. plots. 4. New TLatex processor supports most ROOT features, still MathJax can. be used. 5. New X/Y projections display for TH2 histograms (aka. TH2::SetShowProjectionX/Y). 6. New in geometry viewer:. - provide shape parameters in TGeo tooltips. - let inspect selected TGeoNode. - provide text info when geometry drawing takes too long. 7. Change in JSROOT.draw functionality. Now valid painter instance can. be only. obtained via call-back - forth argument of JSROOT.draw() function. 8. Use latest three.js r86 with improved Projector and CanvasRenderer. Still use own SVGRenderer which supported direct SVG text dump. 9. Introduce openui5 components for webgui functionality. 10. In all sources specify ""use strict"" directive",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1055
https://github.com/root-project/root/pull/1056:10,performance,cach,caching,10,"[WIP] TDF caching mechanism; First implementation of the caching mechanism and minimal testing. . This is here to start the testing in the CI, the development is not finished yet.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:57,performance,cach,caching,57,"[WIP] TDF caching mechanism; First implementation of the caching mechanism and minimal testing. . This is here to start the testing in the CI, the development is not finished yet.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:87,safety,test,testing,87,"[WIP] TDF caching mechanism; First implementation of the caching mechanism and minimal testing. . This is here to start the testing in the CI, the development is not finished yet.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:124,safety,test,testing,124,"[WIP] TDF caching mechanism; First implementation of the caching mechanism and minimal testing. . This is here to start the testing in the CI, the development is not finished yet.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:87,testability,test,testing,87,"[WIP] TDF caching mechanism; First implementation of the caching mechanism and minimal testing. . This is here to start the testing in the CI, the development is not finished yet.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:124,testability,test,testing,124,"[WIP] TDF caching mechanism; First implementation of the caching mechanism and minimal testing. . This is here to start the testing in the CI, the development is not finished yet.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1056:79,usability,minim,minimal,79,"[WIP] TDF caching mechanism; First implementation of the caching mechanism and minimal testing. . This is here to start the testing in the CI, the development is not finished yet.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1056
https://github.com/root-project/root/pull/1058:59,availability,operat,operations,59,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:52,deployability,modul,modulo,52,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:10,energy efficiency,Optim,Optimize,10,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:341,integrability,coupl,couple,341,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:52,modifiability,modul,modulo,52,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:341,modifiability,coupl,couple,341,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:10,performance,Optimiz,Optimize,10,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:228,performance,time,timediff,228,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:36,safety,avoid,avoid,36,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:52,safety,modul,modulo,52,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:351,safety,test,tests,351,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:459,safety,test,test,459,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:468,safety,review,review,468,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:341,testability,coupl,couple,341,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:351,testability,test,tests,351,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:459,testability,test,test,459,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:468,testability,review,review,468,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1058:246,usability,user,user-images,246,"ROOT-8872 Optimize TTree::Fill() to avoid expensive modulo operations; The figure below gives an idea of possible improvement. For more information see [ROOT-8872](https://sft.its.cern.ch/jira/browse/ROOT-8872). ![ttree-fill-ge-timediff](https://user-images.githubusercontent.com/249404/30871641-cd327d8c-a2e7-11e7-8839-4c770ea32173.png). A couple of tests don't work after this change, so I will later break this up into several commits to make it easier to test and review.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1058
https://github.com/root-project/root/pull/1059:36,modifiability,Exten,Extending,36,Forgotten cherry-pick for v6-08-00; Extending FindLZ4.cmake with xxhash includes/library needed for LZ4 checksum functionality,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1059
https://github.com/root-project/root/pull/1059:104,security,checksum,checksum,104,Forgotten cherry-pick for v6-08-00; Extending FindLZ4.cmake with xxhash includes/library needed for LZ4 checksum functionality,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1059
https://github.com/root-project/root/pull/1060:15,deployability,log,logic,15,"[TDF] Simplify logic, reduce instructions in column value reading;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1060
https://github.com/root-project/root/pull/1060:22,energy efficiency,reduc,reduce,22,"[TDF] Simplify logic, reduce instructions in column value reading;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1060
https://github.com/root-project/root/pull/1060:15,safety,log,logic,15,"[TDF] Simplify logic, reduce instructions in column value reading;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1060
https://github.com/root-project/root/pull/1060:15,security,log,logic,15,"[TDF] Simplify logic, reduce instructions in column value reading;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1060
https://github.com/root-project/root/pull/1060:6,testability,Simpl,Simplify,6,"[TDF] Simplify logic, reduce instructions in column value reading;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1060
https://github.com/root-project/root/pull/1060:15,testability,log,logic,15,"[TDF] Simplify logic, reduce instructions in column value reading;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1060
https://github.com/root-project/root/pull/1060:6,usability,Simpl,Simplify,6,"[TDF] Simplify logic, reduce instructions in column value reading;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1060
https://github.com/root-project/root/pull/1061:181,availability,sli,slightly,181,"In TPad::ExecuteAxisEvent protect from using empty zoombox; Sometime happens that `zoombox == 0` and ROOT crashes. It happens in our QtROOT interface, where event sequence could be slightly different as with normal X. Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1061:236,deployability,patch,patch,236,"In TPad::ExecuteAxisEvent protect from using empty zoombox; Sometime happens that `zoombox == 0` and ROOT crashes. It happens in our QtROOT interface, where event sequence could be slightly different as with normal X. Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1061:140,integrability,interfac,interface,140,"In TPad::ExecuteAxisEvent protect from using empty zoombox; Sometime happens that `zoombox == 0` and ROOT crashes. It happens in our QtROOT interface, where event sequence could be slightly different as with normal X. Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1061:157,integrability,event,event,157,"In TPad::ExecuteAxisEvent protect from using empty zoombox; Sometime happens that `zoombox == 0` and ROOT crashes. It happens in our QtROOT interface, where event sequence could be slightly different as with normal X. Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1061:140,interoperability,interfac,interface,140,"In TPad::ExecuteAxisEvent protect from using empty zoombox; Sometime happens that `zoombox == 0` and ROOT crashes. It happens in our QtROOT interface, where event sequence could be slightly different as with normal X. Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1061:140,modifiability,interfac,interface,140,"In TPad::ExecuteAxisEvent protect from using empty zoombox; Sometime happens that `zoombox == 0` and ROOT crashes. It happens in our QtROOT interface, where event sequence could be slightly different as with normal X. Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1061:181,reliability,sli,slightly,181,"In TPad::ExecuteAxisEvent protect from using empty zoombox; Sometime happens that `zoombox == 0` and ROOT crashes. It happens in our QtROOT interface, where event sequence could be slightly different as with normal X. Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1061:236,safety,patch,patch,236,"In TPad::ExecuteAxisEvent protect from using empty zoombox; Sometime happens that `zoombox == 0` and ROOT crashes. It happens in our QtROOT interface, where event sequence could be slightly different as with normal X. Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1061:236,security,patch,patch,236,"In TPad::ExecuteAxisEvent protect from using empty zoombox; Sometime happens that `zoombox == 0` and ROOT crashes. It happens in our QtROOT interface, where event sequence could be slightly different as with normal X. Would be nice, if patch also will go into 6.10 branch",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1061
https://github.com/root-project/root/pull/1062:24,deployability,patch,patch,24,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:107,integrability,repositor,repository,107,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:107,interoperability,repositor,repository,107,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:278,modifiability,exten,extend,278,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:178,performance,time,times,178,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:193,performance,disk,disk,193,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:246,performance,disk,disk,246,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:442,performance,memor,memory,442,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:24,safety,patch,patch,24,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:24,security,patch,patch,24,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:490,testability,emul,emulate,490,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1062:442,usability,memor,memory,442,"Add IO benchmarks; This patch adds a few IO benchmarks. Some of them were hosted by @amadio in an external repository. The nature of some of the benchmarks is to create multiple times files on disk. Running repeatedly, this can wear out machines disk drives. For that reason we extend the `TFileMerger` to work with `TFile*` directly. Passing an externally created `TFile*` allows us to pass a `TMemFile`. Being able to benchmark based on in-memory files gives us another advantage: we can emulate very fast drives or certain delay patterns.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1062
https://github.com/root-project/root/pull/1063:15,deployability,build,build,15,Fixing classic build for v6-08-00; Fixing cherry-picking for LZ4 support for makefile ROOT v6-08-00 (classic build),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1063
https://github.com/root-project/root/pull/1063:109,deployability,build,build,109,Fixing classic build for v6-08-00; Fixing cherry-picking for LZ4 support for makefile ROOT v6-08-00 (classic build),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1063
https://github.com/root-project/root/pull/1063:65,usability,support,support,65,Fixing classic build for v6-08-00; Fixing cherry-picking for LZ4 support for makefile ROOT v6-08-00 (classic build),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1063
https://github.com/root-project/root/pull/1064:111,integrability,repositor,repository,111,"Revert ""Add google benchmark""; Reverts root-project/root#688. It was decided that this should be in a separate repository.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1064
https://github.com/root-project/root/pull/1064:111,interoperability,repositor,repository,111,"Revert ""Add google benchmark""; Reverts root-project/root#688. It was decided that this should be in a separate repository.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1064
https://github.com/root-project/root/pull/1065:314,availability,cluster,clusters,314,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:490,availability,cluster,clusters,490,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:627,availability,cluster,clusters,627,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:722,availability,cluster,clusters,722,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:835,availability,cluster,cluster,835,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1032,availability,cluster,clusters,1032,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1062,availability,cluster,clusters,1062,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1309,availability,cluster,cluster,1309,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1497,availability,consist,consisting,1497,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:314,deployability,cluster,clusters,314,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:490,deployability,cluster,clusters,490,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:627,deployability,cluster,clusters,627,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:722,deployability,cluster,clusters,722,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:835,deployability,cluster,cluster,835,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1032,deployability,cluster,clusters,1032,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1062,deployability,cluster,clusters,1062,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1309,deployability,cluster,cluster,1309,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1322,deployability,contain,contains,1322,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:507,energy efficiency,load,loaded,507,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:819,energy efficiency,load,load,819,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1638,energy efficiency,current,current,1638,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:69,integrability,repositor,repository,69,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:416,integrability,event,events,416,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:69,interoperability,repositor,repository,69,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1126,modifiability,reu,reuses,1126,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1185,modifiability,Reu,Reusing,1185,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1372,modifiability,reu,reused,1372,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:0,performance,Cach,Cache,0,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:261,performance,multi-thread,multi-threaded,261,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:507,performance,load,loaded,507,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:519,performance,memor,memory,519,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:747,performance,memor,memory,747,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:764,performance,Cach,CacheDoClusterPrefetch,764,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:819,performance,load,load,819,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:848,performance,memor,memory,848,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1046,performance,memor,memory,1046,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1398,performance,perform,performance,1398,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1758,performance,Cach,CacheDoClusterPrefetch,1758,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:363,safety,prevent,prevent,363,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1249,safety,compl,complexity,1249,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1389,safety,test,test,1389,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:363,security,preven,prevent,363,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:908,security,modif,modified,908,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1237,security,sign,significant,1237,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1249,security,compl,complexity,1249,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1389,testability,test,test,1389,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:83,usability,close,closed,83,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:276,usability,workflow,workflows,276,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:519,usability,memor,memory,519,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:692,usability,indicat,indicates,692,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:747,usability,memor,memory,747,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:848,usability,memor,memory,848,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1019,usability,clear,clearing,1019,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1046,usability,memor,memory,1046,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1154,usability,clear,clear,1154,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1217,usability,efficien,efficient,1217,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1398,usability,perform,performance,1398,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1065:1497,usability,consist,consisting,1497,"Cache improvements for non-sequential reads; After messing up my git repository, I closed pull request 796 and re-created this one with the same changes. This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets. By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained - the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory. If TTree CacheDoClusterPrefetch is set to true, GetEntry() will load the entire cluster into memory, not just the first basket. For this, GetBasket() is modified to call a new function GetFreshCluster(). This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, GetFreshCluster() reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. Without the change enables there were 1.5 GB read in 31102 read calls. With MaxVirtualSize set to -1 and CacheDoClusterPrefetch true, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1065
https://github.com/root-project/root/pull/1066:71,deployability,patch,patch,71,In TPad::ExecuteAxisEvent protect from using empty zoombox; Apply same patch for 6.10 branch,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1066
https://github.com/root-project/root/pull/1066:71,safety,patch,patch,71,In TPad::ExecuteAxisEvent protect from using empty zoombox; Apply same patch for 6.10 branch,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1066
https://github.com/root-project/root/pull/1066:71,security,patch,patch,71,In TPad::ExecuteAxisEvent protect from using empty zoombox; Apply same patch for 6.10 branch,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1066
https://github.com/root-project/root/pull/1067:30,deployability,version,version,30,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:136,deployability,version,version,136,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:212,deployability,version,version,212,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:30,integrability,version,version,30,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:92,integrability,configur,configure,92,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:136,integrability,version,version,136,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:212,integrability,version,version,212,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:30,modifiability,version,version,30,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:92,modifiability,configur,configure,92,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:136,modifiability,version,version,136,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:212,modifiability,version,version,212,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1067:92,security,configur,configure,92,"Fix for new mysql_config; New version of mysql_config returns more than one -I option, make configure and cmake pick the right one. New version:. $ mysql_config --cflags. -I/usr/include -I/usr/include/mysql. Old version:. $ mysql_config --cflags. -I/usr/include/mysql .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1067
https://github.com/root-project/root/pull/1068:66,modifiability,refact,refactorization,66,"Improve BinnedFit test; Add speedup printing, improve legibility, refactorization. Speedup printing can still be improved.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1068
https://github.com/root-project/root/pull/1068:66,performance,refactor,refactorization,66,"Improve BinnedFit test; Add speedup printing, improve legibility, refactorization. Speedup printing can still be improved.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1068
https://github.com/root-project/root/pull/1068:18,safety,test,test,18,"Improve BinnedFit test; Add speedup printing, improve legibility, refactorization. Speedup printing can still be improved.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1068
https://github.com/root-project/root/pull/1068:18,testability,test,test,18,"Improve BinnedFit test; Add speedup printing, improve legibility, refactorization. Speedup printing can still be improved.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1068
https://github.com/root-project/root/pull/1069:220,availability,restor,restored,220,ROOT-9027 Multi-thread Snapshot action writes only part of the events for large input files; This reverts commit 931f39bbec65b2757e725744e357ff8609047f0a. The trees in the snapshot action rely on the directory not being restored to write to the right place. Creating a context prevented that from working.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1069
https://github.com/root-project/root/pull/1069:63,integrability,event,events,63,ROOT-9027 Multi-thread Snapshot action writes only part of the events for large input files; This reverts commit 931f39bbec65b2757e725744e357ff8609047f0a. The trees in the snapshot action rely on the directory not being restored to write to the right place. Creating a context prevented that from working.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1069
https://github.com/root-project/root/pull/1069:10,performance,Multi-thread,Multi-thread,10,ROOT-9027 Multi-thread Snapshot action writes only part of the events for large input files; This reverts commit 931f39bbec65b2757e725744e357ff8609047f0a. The trees in the snapshot action rely on the directory not being restored to write to the right place. Creating a context prevented that from working.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1069
https://github.com/root-project/root/pull/1069:220,reliability,restor,restored,220,ROOT-9027 Multi-thread Snapshot action writes only part of the events for large input files; This reverts commit 931f39bbec65b2757e725744e357ff8609047f0a. The trees in the snapshot action rely on the directory not being restored to write to the right place. Creating a context prevented that from working.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1069
https://github.com/root-project/root/pull/1069:80,safety,input,input,80,ROOT-9027 Multi-thread Snapshot action writes only part of the events for large input files; This reverts commit 931f39bbec65b2757e725744e357ff8609047f0a. The trees in the snapshot action rely on the directory not being restored to write to the right place. Creating a context prevented that from working.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1069
https://github.com/root-project/root/pull/1069:277,safety,prevent,prevented,277,ROOT-9027 Multi-thread Snapshot action writes only part of the events for large input files; This reverts commit 931f39bbec65b2757e725744e357ff8609047f0a. The trees in the snapshot action rely on the directory not being restored to write to the right place. Creating a context prevented that from working.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1069
https://github.com/root-project/root/pull/1069:277,security,preven,prevented,277,ROOT-9027 Multi-thread Snapshot action writes only part of the events for large input files; This reverts commit 931f39bbec65b2757e725744e357ff8609047f0a. The trees in the snapshot action rely on the directory not being restored to write to the right place. Creating a context prevented that from working.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1069
https://github.com/root-project/root/pull/1069:269,testability,context,context,269,ROOT-9027 Multi-thread Snapshot action writes only part of the events for large input files; This reverts commit 931f39bbec65b2757e725744e357ff8609047f0a. The trees in the snapshot action rely on the directory not being restored to write to the right place. Creating a context prevented that from working.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1069
https://github.com/root-project/root/pull/1069:80,usability,input,input,80,ROOT-9027 Multi-thread Snapshot action writes only part of the events for large input files; This reverts commit 931f39bbec65b2757e725744e357ff8609047f0a. The trees in the snapshot action rely on the directory not being restored to write to the right place. Creating a context prevented that from working.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1069
https://github.com/root-project/root/pull/1070:16,energy efficiency,draw,draw,16,jsroot: correct draw of TH2 projections in web canvas; plus few other small fixes from current JSROOT master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1070
https://github.com/root-project/root/pull/1070:87,energy efficiency,current,current,87,jsroot: correct draw of TH2 projections in web canvas; plus few other small fixes from current JSROOT master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1070
https://github.com/root-project/root/pull/1071:24,integrability,interfac,interface,24,GetColumn method of the interface; Give the possibility to the user to get the column names from the TDataFrame nodes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1071
https://github.com/root-project/root/pull/1071:24,interoperability,interfac,interface,24,GetColumn method of the interface; Give the possibility to the user to get the column names from the TDataFrame nodes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1071
https://github.com/root-project/root/pull/1071:24,modifiability,interfac,interface,24,GetColumn method of the interface; Give the possibility to the user to get the column names from the TDataFrame nodes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1071
https://github.com/root-project/root/pull/1071:63,usability,user,user,63,GetColumn method of the interface; Give the possibility to the user to get the column names from the TDataFrame nodes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1071
https://github.com/root-project/root/pull/1072:0,modifiability,Reu,Reuse,0,Reuse trees in TDataFrame snapshot action;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1072
https://github.com/root-project/root/pull/1073:53,deployability,patch,patch,53,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:204,performance,memor,memory,204,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:286,performance,disk,disks,286,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:317,performance,disk,disk,317,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:53,safety,patch,patch,53,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:311,safety,avoid,avoid,311,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:53,security,patch,patch,53,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:134,security,control,control,134,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:134,testability,control,control,134,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:271,testability,simul,simulate,271,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:204,usability,memor,memory,204,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1073:231,usability,help,helpful,231,Teach TFileMerger to work with TFile* handles.; This patch allows TFileMerger to work with externally created TFile-s. Being. able to control the creation of the TFile objects give us a chance to use. in-memory files. This is very helpful in benchmarking when we want to simulate. fast disks or we just want to avoid disk wearout.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1073
https://github.com/root-project/root/pull/1074:25,deployability,modul,module,25,"[cxxmodules] Fix path to module file in CMake; Currently CMake has the wrong path to check for this file, which. means it always regenerates the modules with runtime_cxxmodules. enabled as it never sees the generated file (which is in another. path).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1074
https://github.com/root-project/root/pull/1074:145,deployability,modul,modules,145,"[cxxmodules] Fix path to module file in CMake; Currently CMake has the wrong path to check for this file, which. means it always regenerates the modules with runtime_cxxmodules. enabled as it never sees the generated file (which is in another. path).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1074
https://github.com/root-project/root/pull/1074:47,energy efficiency,Current,Currently,47,"[cxxmodules] Fix path to module file in CMake; Currently CMake has the wrong path to check for this file, which. means it always regenerates the modules with runtime_cxxmodules. enabled as it never sees the generated file (which is in another. path).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1074
https://github.com/root-project/root/pull/1074:25,modifiability,modul,module,25,"[cxxmodules] Fix path to module file in CMake; Currently CMake has the wrong path to check for this file, which. means it always regenerates the modules with runtime_cxxmodules. enabled as it never sees the generated file (which is in another. path).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1074
https://github.com/root-project/root/pull/1074:145,modifiability,modul,modules,145,"[cxxmodules] Fix path to module file in CMake; Currently CMake has the wrong path to check for this file, which. means it always regenerates the modules with runtime_cxxmodules. enabled as it never sees the generated file (which is in another. path).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1074
https://github.com/root-project/root/pull/1074:25,safety,modul,module,25,"[cxxmodules] Fix path to module file in CMake; Currently CMake has the wrong path to check for this file, which. means it always regenerates the modules with runtime_cxxmodules. enabled as it never sees the generated file (which is in another. path).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1074
https://github.com/root-project/root/pull/1074:145,safety,modul,modules,145,"[cxxmodules] Fix path to module file in CMake; Currently CMake has the wrong path to check for this file, which. means it always regenerates the modules with runtime_cxxmodules. enabled as it never sees the generated file (which is in another. path).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1074
https://github.com/root-project/root/pull/1075:34,deployability,Patch,Patch,34,Add new projections to TGLViewer; Patch currently applied to the SHiP software stack. It would be nice if this could be merged upstream after review.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1075
https://github.com/root-project/root/pull/1075:79,deployability,stack,stack,79,Add new projections to TGLViewer; Patch currently applied to the SHiP software stack. It would be nice if this could be merged upstream after review.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1075
https://github.com/root-project/root/pull/1075:40,energy efficiency,current,currently,40,Add new projections to TGLViewer; Patch currently applied to the SHiP software stack. It would be nice if this could be merged upstream after review.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1075
https://github.com/root-project/root/pull/1075:34,safety,Patch,Patch,34,Add new projections to TGLViewer; Patch currently applied to the SHiP software stack. It would be nice if this could be merged upstream after review.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1075
https://github.com/root-project/root/pull/1075:142,safety,review,review,142,Add new projections to TGLViewer; Patch currently applied to the SHiP software stack. It would be nice if this could be merged upstream after review.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1075
https://github.com/root-project/root/pull/1075:34,security,Patch,Patch,34,Add new projections to TGLViewer; Patch currently applied to the SHiP software stack. It would be nice if this could be merged upstream after review.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1075
https://github.com/root-project/root/pull/1075:142,testability,review,review,142,Add new projections to TGLViewer; Patch currently applied to the SHiP software stack. It would be nice if this could be merged upstream after review.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1075
https://github.com/root-project/root/pull/1076:232,deployability,fail,fails,232,"Revert ""[cmake] Fix that clingutils headers are found in /bin""; This reverts commit ea64c7a2a2bb51e8181e8287f39b542b4d344cd6. This. commit broke the dictionaries as the absolute paths to the STL. headers confuse rootcling which now fails to properly add the. include paths to the dictionary payload. E.g. in the new dictionaries. we no longer have the information that we need to include. <set> for this header in there.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1076
https://github.com/root-project/root/pull/1076:232,reliability,fail,fails,232,"Revert ""[cmake] Fix that clingutils headers are found in /bin""; This reverts commit ea64c7a2a2bb51e8181e8287f39b542b4d344cd6. This. commit broke the dictionaries as the absolute paths to the STL. headers confuse rootcling which now fails to properly add the. include paths to the dictionary payload. E.g. in the new dictionaries. we no longer have the information that we need to include. <set> for this header in there.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1076
https://github.com/root-project/root/pull/1077:37,integrability,batch,batch,37,"Adjust http docu, add info about CEF batch mode;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1077
https://github.com/root-project/root/pull/1077:37,performance,batch,batch,37,"Adjust http docu, add info about CEF batch mode;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1077
https://github.com/root-project/root/pull/1078:143,availability,error,error,143,[TDF] Misc Fixes; 1) Match only the custom columns of the node and not all when using regexpressions. 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested. 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:138,performance,time,time,138,[TDF] Misc Fixes; 1) Match only the custom columns of the node and not all when using regexpressions. 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested. 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:143,performance,error,error,143,[TDF] Misc Fixes; 1) Match only the custom columns of the node and not all when using regexpressions. 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested. 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:159,performance,cach,cache,159,[TDF] Misc Fixes; 1) Match only the custom columns of the node and not all when using regexpressions. 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested. 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:143,safety,error,error,143,[TDF] Misc Fixes; 1) Match only the custom columns of the node and not all when using regexpressions. 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested. 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:227,safety,Test,Test,227,[TDF] Misc Fixes; 1) Match only the custom columns of the node and not all when using regexpressions. 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested. 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:115,testability,understand,understandable,115,[TDF] Misc Fixes; 1) Match only the custom columns of the node and not all when using regexpressions. 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested. 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:227,testability,Test,Test,227,[TDF] Misc Fixes; 1) Match only the custom columns of the node and not all when using regexpressions. 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested. 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:36,usability,custom,custom,36,[TDF] Misc Fixes; 1) Match only the custom columns of the node and not all when using regexpressions. 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested. 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1078:143,usability,error,error,143,[TDF] Misc Fixes; 1) Match only the custom columns of the node and not all when using regexpressions. 2) Prompt an understandable compile time error in case a cache of columns the type of which is non copyable is requested. 3) Test the ability of the data source to serve non copyable items,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1078
https://github.com/root-project/root/pull/1080:43,safety,test,test,43,Fix for ROOT-9032; Asked the originator to test. See https://sft.its.cern.ch/jira/browse/ROOT-9032.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1080
https://github.com/root-project/root/pull/1080:43,testability,test,test,43,Fix for ROOT-9032; Asked the originator to test. See https://sft.its.cern.ch/jira/browse/ROOT-9032.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1080
https://github.com/root-project/root/pull/1081:175,integrability,event,eventIds,175,[TDF] Coverity fixes; One more complicated [issue](https://coverity.cern.ch/reports.htm#v14989/p10001/fileInstanceId=761497765&defectInstanceId=395401393&mergedDefectId=97393&eventIds=395393458-0) remains to be addressed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1081
https://github.com/root-project/root/pull/1081:31,safety,compl,complicated,31,[TDF] Coverity fixes; One more complicated [issue](https://coverity.cern.ch/reports.htm#v14989/p10001/fileInstanceId=761497765&defectInstanceId=395401393&mergedDefectId=97393&eventIds=395393458-0) remains to be addressed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1081
https://github.com/root-project/root/pull/1081:31,security,compl,complicated,31,[TDF] Coverity fixes; One more complicated [issue](https://coverity.cern.ch/reports.htm#v14989/p10001/fileInstanceId=761497765&defectInstanceId=395401393&mergedDefectId=97393&eventIds=395393458-0) remains to be addressed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1081
https://github.com/root-project/root/pull/1082:93,deployability,updat,updated,93,"Improved readability of Spectrum.md; Better English, better Markdown formatting, less typos, updated references.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1082
https://github.com/root-project/root/pull/1082:69,interoperability,format,formatting,69,"Improved readability of Spectrum.md; Better English, better Markdown formatting, less typos, updated references.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1082
https://github.com/root-project/root/pull/1082:93,safety,updat,updated,93,"Improved readability of Spectrum.md; Better English, better Markdown formatting, less typos, updated references.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1082
https://github.com/root-project/root/pull/1082:93,security,updat,updated,93,"Improved readability of Spectrum.md; Better English, better Markdown formatting, less typos, updated references.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1082
https://github.com/root-project/root/pull/1083:7,energy efficiency,Draw,Draw,7,"TTree::Draw(): Respect histogram binning when drawing TProfile2D with;  'col'. When drawing a TProfile2D with TTree::Draw() the histogram Y-axis binning was. not set correctly in case the options 'col' and 'prof' where used at the same. time in the TTree::Draw() option argument. For example:. tree->Draw(""var:y:x>>h(100,-1,1,200,-2,2)"", """", ""colzprof). produced a TProfile2D with 100 bins from -1 to 1 in X, but only 40 bins from -2. to 2 in Y. This fixes ROOT-9034.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1083
https://github.com/root-project/root/pull/1083:46,energy efficiency,draw,drawing,46,"TTree::Draw(): Respect histogram binning when drawing TProfile2D with;  'col'. When drawing a TProfile2D with TTree::Draw() the histogram Y-axis binning was. not set correctly in case the options 'col' and 'prof' where used at the same. time in the TTree::Draw() option argument. For example:. tree->Draw(""var:y:x>>h(100,-1,1,200,-2,2)"", """", ""colzprof). produced a TProfile2D with 100 bins from -1 to 1 in X, but only 40 bins from -2. to 2 in Y. This fixes ROOT-9034.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1083
https://github.com/root-project/root/pull/1083:86,energy efficiency,draw,drawing,86,"TTree::Draw(): Respect histogram binning when drawing TProfile2D with;  'col'. When drawing a TProfile2D with TTree::Draw() the histogram Y-axis binning was. not set correctly in case the options 'col' and 'prof' where used at the same. time in the TTree::Draw() option argument. For example:. tree->Draw(""var:y:x>>h(100,-1,1,200,-2,2)"", """", ""colzprof). produced a TProfile2D with 100 bins from -1 to 1 in X, but only 40 bins from -2. to 2 in Y. This fixes ROOT-9034.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1083
https://github.com/root-project/root/pull/1083:119,energy efficiency,Draw,Draw,119,"TTree::Draw(): Respect histogram binning when drawing TProfile2D with;  'col'. When drawing a TProfile2D with TTree::Draw() the histogram Y-axis binning was. not set correctly in case the options 'col' and 'prof' where used at the same. time in the TTree::Draw() option argument. For example:. tree->Draw(""var:y:x>>h(100,-1,1,200,-2,2)"", """", ""colzprof). produced a TProfile2D with 100 bins from -1 to 1 in X, but only 40 bins from -2. to 2 in Y. This fixes ROOT-9034.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1083
https://github.com/root-project/root/pull/1083:258,energy efficiency,Draw,Draw,258,"TTree::Draw(): Respect histogram binning when drawing TProfile2D with;  'col'. When drawing a TProfile2D with TTree::Draw() the histogram Y-axis binning was. not set correctly in case the options 'col' and 'prof' where used at the same. time in the TTree::Draw() option argument. For example:. tree->Draw(""var:y:x>>h(100,-1,1,200,-2,2)"", """", ""colzprof). produced a TProfile2D with 100 bins from -1 to 1 in X, but only 40 bins from -2. to 2 in Y. This fixes ROOT-9034.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1083
https://github.com/root-project/root/pull/1083:302,energy efficiency,Draw,Draw,302,"TTree::Draw(): Respect histogram binning when drawing TProfile2D with;  'col'. When drawing a TProfile2D with TTree::Draw() the histogram Y-axis binning was. not set correctly in case the options 'col' and 'prof' where used at the same. time in the TTree::Draw() option argument. For example:. tree->Draw(""var:y:x>>h(100,-1,1,200,-2,2)"", """", ""colzprof). produced a TProfile2D with 100 bins from -1 to 1 in X, but only 40 bins from -2. to 2 in Y. This fixes ROOT-9034.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1083
https://github.com/root-project/root/pull/1083:239,performance,time,time,239,"TTree::Draw(): Respect histogram binning when drawing TProfile2D with;  'col'. When drawing a TProfile2D with TTree::Draw() the histogram Y-axis binning was. not set correctly in case the options 'col' and 'prof' where used at the same. time in the TTree::Draw() option argument. For example:. tree->Draw(""var:y:x>>h(100,-1,1,200,-2,2)"", """", ""colzprof). produced a TProfile2D with 100 bins from -1 to 1 in X, but only 40 bins from -2. to 2 in Y. This fixes ROOT-9034.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1083
https://github.com/root-project/root/pull/1084:118,availability,cluster,clusters,118,Fix snapshot in v610; After the fix for ROOT-9027 `Snapshot` could crash or silently write bogus data when more ttree clusters than worker threads were present in the file.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1084
https://github.com/root-project/root/pull/1084:118,deployability,cluster,clusters,118,Fix snapshot in v610; After the fix for ROOT-9027 `Snapshot` could crash or silently write bogus data when more ttree clusters than worker threads were present in the file.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1084
https://github.com/root-project/root/pull/1085:31,availability,slo,slot,31,"Revert ""[TDF] Create TTree per slot, instead of per task in snapshot""; This reverts commit 4e7e379f8e8afb8fed9ab602c606bfab00577d8c. We need to create one TTree per slot per task as the input variables. (and their addresses) change each time.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1085
https://github.com/root-project/root/pull/1085:165,availability,slo,slot,165,"Revert ""[TDF] Create TTree per slot, instead of per task in snapshot""; This reverts commit 4e7e379f8e8afb8fed9ab602c606bfab00577d8c. We need to create one TTree per slot per task as the input variables. (and their addresses) change each time.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1085
https://github.com/root-project/root/pull/1085:192,modifiability,variab,variables,192,"Revert ""[TDF] Create TTree per slot, instead of per task in snapshot""; This reverts commit 4e7e379f8e8afb8fed9ab602c606bfab00577d8c. We need to create one TTree per slot per task as the input variables. (and their addresses) change each time.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1085
https://github.com/root-project/root/pull/1085:237,performance,time,time,237,"Revert ""[TDF] Create TTree per slot, instead of per task in snapshot""; This reverts commit 4e7e379f8e8afb8fed9ab602c606bfab00577d8c. We need to create one TTree per slot per task as the input variables. (and their addresses) change each time.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1085
https://github.com/root-project/root/pull/1085:31,reliability,slo,slot,31,"Revert ""[TDF] Create TTree per slot, instead of per task in snapshot""; This reverts commit 4e7e379f8e8afb8fed9ab602c606bfab00577d8c. We need to create one TTree per slot per task as the input variables. (and their addresses) change each time.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1085
https://github.com/root-project/root/pull/1085:165,reliability,slo,slot,165,"Revert ""[TDF] Create TTree per slot, instead of per task in snapshot""; This reverts commit 4e7e379f8e8afb8fed9ab602c606bfab00577d8c. We need to create one TTree per slot per task as the input variables. (and their addresses) change each time.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1085
https://github.com/root-project/root/pull/1085:186,safety,input,input,186,"Revert ""[TDF] Create TTree per slot, instead of per task in snapshot""; This reverts commit 4e7e379f8e8afb8fed9ab602c606bfab00577d8c. We need to create one TTree per slot per task as the input variables. (and their addresses) change each time.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1085
https://github.com/root-project/root/pull/1085:186,usability,input,input,186,"Revert ""[TDF] Create TTree per slot, instead of per task in snapshot""; This reverts commit 4e7e379f8e8afb8fed9ab602c606bfab00577d8c. We need to create one TTree per slot per task as the input variables. (and their addresses) change each time.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1085
https://github.com/root-project/root/pull/1086:172,deployability,fail,fail,172,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:6,modifiability,Refact,Refactor,6,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:6,performance,Refactor,Refactor,6,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:172,reliability,fail,fail,172,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:24,safety,test,tests,24,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:59,safety,test,testing,59,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:107,safety,test,test,107,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:152,safety,test,test,152,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:24,testability,test,tests,24,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:43,testability,coverag,coverage,43,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:59,testability,test,testing,59,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:107,testability,test,test,107,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1086:152,testability,test,test,152,[TDF] Refactor snapshot tests and add more coverage; Moved testing of `Snapshot` to its own gtest. Added a test with many tasks per worker thread. This test is expected to fail until #1085 is merged.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1086
https://github.com/root-project/root/pull/1087:24,availability,failur,failure,24,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:24,deployability,fail,failure,24,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:66,deployability,modul,modules,66,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:77,deployability,fail,fail,77,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:233,deployability,modul,modules,233,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:302,deployability,modul,modules,302,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:66,modifiability,modul,modules,66,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:233,modifiability,modul,modules,233,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:302,modifiability,modul,modules,302,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:24,performance,failur,failure,24,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:24,reliability,fail,failure,24,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:77,reliability,fail,fail,77,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:66,safety,modul,modules,66,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:233,safety,modul,modules,233,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:302,safety,modul,modules,302,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1087:17,testability,assert,assert,17,"[cxxmodules] Fix assert failure when printing fwd delcs; With C++ modules we fail here because we get this extra 'include '. text before the actual header. As the header itself is correct. it seems, we just skip this extra text with modules enabled as. this code is anyway supposed to be replaced with modules. functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1087
https://github.com/root-project/root/pull/1088:53,deployability,infrastructur,infrastructure,53,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1088:249,deployability,build,build,249,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1088:440,integrability,Filter,Filter,440,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1088:465,integrability,sub,sub-directory,465,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1088:155,interoperability,bind,bindexplib,155,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1088:155,modifiability,bind,bindexplib,155,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1088:4,usability,support,support,4,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1088:25,usability,Visual,Visual,25,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1088:323,usability,support,support,323,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1088:335,usability,Visual,Visual,335,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1088:484,usability,support,supported,484,Add support for Windows (Visual Studio) in the cmake infrastructure; - Add missing includes (gdk/glib) for TGWin32 dictionary generation. - Replace use of bindexplib by CMake's built-in WINDOWS_EXPORT_ALL_SYMBOLS property. - Replace old nmake based build by the CMake based one for builtin_freetype and builtin_pcre. - Add support for Visual Studio for LZ4. - Fix compilation of builtin_afterimage. - Add a few missing compilation flags. - Filter out the multiproc sub-directory (not supported on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1088
https://github.com/root-project/root/pull/1089:28,availability,error,errors,28,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:125,availability,error,errors,125,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:187,availability,error,error,187,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:243,availability,error,error,243,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:263,availability,error,error,263,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:311,availability,operat,operator,311,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:28,performance,error,errors,28,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:125,performance,error,errors,125,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:187,performance,error,error,187,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:243,performance,error,error,243,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:263,performance,error,error,263,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:28,safety,error,errors,28,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:91,safety,prevent,prevent,91,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:125,safety,error,errors,125,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:187,safety,error,error,187,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:243,safety,error,error,243,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:263,safety,error,error,263,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:91,security,preven,prevent,91,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:214,security,token,token,214,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:28,usability,error,errors,28,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:125,usability,error,errors,125,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:170,usability,Visual,Visual,170,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:187,usability,error,error,187,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:243,usability,error,error,243,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:263,usability,error,error,263,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1089:371,usability,Visual,Visual,371,Fix string_view compilation errors on Windows; - enclose min() and max() in parentheses to prevent the following compilation errors (min and max are defined as macros in Visual Studio):. error C2589: '(' : illegal token on right side of '::'. error C2059: syntax error : '::'. - implement the basic_string_view operator == (for const char *) (was somehow not resolved by Visual Studio). Thanks Axel for fixing it,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1089
https://github.com/root-project/root/pull/1091:41,deployability,modul,modulemaps,41,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:81,deployability,modul,modulemaps,81,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:324,deployability,fail,fail,324,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:391,deployability,modul,modulemap,391,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:545,deployability,modul,modulemap,545,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:565,deployability,patch,patch,565,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:617,deployability,modul,modulemaps,617,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:727,deployability,modul,module,727,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:41,modifiability,modul,modulemaps,41,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:81,modifiability,modul,modulemaps,81,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:391,modifiability,modul,modulemap,391,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:545,modifiability,modul,modulemap,545,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:571,modifiability,reu,reuses,571,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:617,modifiability,modul,modulemaps,617,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:727,modifiability,modul,module,727,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:324,reliability,fail,fail,324,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:41,safety,modul,modulemaps,41,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:81,safety,modul,modulemaps,81,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:391,safety,modul,modulemap,391,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:473,safety,test,tests,473,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:545,safety,modul,modulemap,545,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:565,safety,patch,patch,565,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:617,safety,modul,modulemaps,617,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:727,safety,modul,module,727,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:126,security,expos,exposed,126,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:221,security,expos,exposed,221,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:565,security,patch,patch,565,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:473,testability,test,tests,473,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:141,usability,user,user,141,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1091:236,usability,user,user,236,"[cxxmodules] Generating private/non-ROOT modulemaps.; Right now we only generate modulemaps for the ROOT libraries which. are exposed to the user. But we also have generate dictionary. calls for dictionaries that are not exposed to the user and should. only be private (such as TBench, TMathCoreUnitDict etc.). Right now we fail when compiling root on those dictionaries as we. don't have a modulemap for those dictionaries and we don't generate. one. This will also break tests that use the generate dictionary. call as those also don't have a modulemap now. This patch reuses the existing CMake code for generating modulemaps. and also uses it in those cases to provide a dictionary that. rootcling can use to generate a C++ module.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1091
https://github.com/root-project/root/pull/1092:16,availability,error,errors,16,"Fix compilation errors on Windows; - Fix error C2057: expected constant expression in several array declarations. - Outline (move from header to source) the IsCandleScaled() and IsViolinScaled() to export them from DLL. - In fontembedps.cxx, replace unsupported memmem() function by std::search()",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1092
https://github.com/root-project/root/pull/1092:41,availability,error,error,41,"Fix compilation errors on Windows; - Fix error C2057: expected constant expression in several array declarations. - Outline (move from header to source) the IsCandleScaled() and IsViolinScaled() to export them from DLL. - In fontembedps.cxx, replace unsupported memmem() function by std::search()",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1092
https://github.com/root-project/root/pull/1092:16,performance,error,errors,16,"Fix compilation errors on Windows; - Fix error C2057: expected constant expression in several array declarations. - Outline (move from header to source) the IsCandleScaled() and IsViolinScaled() to export them from DLL. - In fontembedps.cxx, replace unsupported memmem() function by std::search()",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1092
https://github.com/root-project/root/pull/1092:41,performance,error,error,41,"Fix compilation errors on Windows; - Fix error C2057: expected constant expression in several array declarations. - Outline (move from header to source) the IsCandleScaled() and IsViolinScaled() to export them from DLL. - In fontembedps.cxx, replace unsupported memmem() function by std::search()",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1092
https://github.com/root-project/root/pull/1092:16,safety,error,errors,16,"Fix compilation errors on Windows; - Fix error C2057: expected constant expression in several array declarations. - Outline (move from header to source) the IsCandleScaled() and IsViolinScaled() to export them from DLL. - In fontembedps.cxx, replace unsupported memmem() function by std::search()",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1092
https://github.com/root-project/root/pull/1092:41,safety,error,error,41,"Fix compilation errors on Windows; - Fix error C2057: expected constant expression in several array declarations. - Outline (move from header to source) the IsCandleScaled() and IsViolinScaled() to export them from DLL. - In fontembedps.cxx, replace unsupported memmem() function by std::search()",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1092
https://github.com/root-project/root/pull/1092:16,usability,error,errors,16,"Fix compilation errors on Windows; - Fix error C2057: expected constant expression in several array declarations. - Outline (move from header to source) the IsCandleScaled() and IsViolinScaled() to export them from DLL. - In fontembedps.cxx, replace unsupported memmem() function by std::search()",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1092
https://github.com/root-project/root/pull/1092:41,usability,error,error,41,"Fix compilation errors on Windows; - Fix error C2057: expected constant expression in several array declarations. - Outline (move from header to source) the IsCandleScaled() and IsViolinScaled() to export them from DLL. - In fontembedps.cxx, replace unsupported memmem() function by std::search()",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1092
https://github.com/root-project/root/pull/1093:16,availability,error,errors,16,Fix compilation errors in win32gdk (typos) and winnt (interface changes);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1093
https://github.com/root-project/root/pull/1093:54,integrability,interfac,interface,54,Fix compilation errors in win32gdk (typos) and winnt (interface changes);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1093
https://github.com/root-project/root/pull/1093:54,interoperability,interfac,interface,54,Fix compilation errors in win32gdk (typos) and winnt (interface changes);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1093
https://github.com/root-project/root/pull/1093:54,modifiability,interfac,interface,54,Fix compilation errors in win32gdk (typos) and winnt (interface changes);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1093
https://github.com/root-project/root/pull/1093:16,performance,error,errors,16,Fix compilation errors in win32gdk (typos) and winnt (interface changes);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1093
https://github.com/root-project/root/pull/1093:16,safety,error,errors,16,Fix compilation errors in win32gdk (typos) and winnt (interface changes);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1093
https://github.com/root-project/root/pull/1093:16,usability,error,errors,16,Fix compilation errors in win32gdk (typos) and winnt (interface changes);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1093
https://github.com/root-project/root/pull/1095:50,availability,Restor,Restore,50,Add missing TWin32Mutex::Reset() and TWin32Mutex::Restore() methods;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1095
https://github.com/root-project/root/pull/1095:50,reliability,Restor,Restore,50,Add missing TWin32Mutex::Reset() and TWin32Mutex::Restore() methods;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1095
https://github.com/root-project/root/pull/1096:32,safety,test,tests,32,[TDF] Fix ROOT-9037; ...and add tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1096
https://github.com/root-project/root/pull/1096:32,testability,test,tests,32,[TDF] Fix ROOT-9037; ...and add tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1096
https://github.com/root-project/root/pull/1098:16,availability,error,errors,16,Fix compilation errors on Windows; Use the std::atomic load() method to access its content,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1098
https://github.com/root-project/root/pull/1098:55,energy efficiency,load,load,55,Fix compilation errors on Windows; Use the std::atomic load() method to access its content,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1098
https://github.com/root-project/root/pull/1098:16,performance,error,errors,16,Fix compilation errors on Windows; Use the std::atomic load() method to access its content,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1098
https://github.com/root-project/root/pull/1098:55,performance,load,load,55,Fix compilation errors on Windows; Use the std::atomic load() method to access its content,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1098
https://github.com/root-project/root/pull/1098:83,performance,content,content,83,Fix compilation errors on Windows; Use the std::atomic load() method to access its content,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1098
https://github.com/root-project/root/pull/1098:16,safety,error,errors,16,Fix compilation errors on Windows; Use the std::atomic load() method to access its content,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1098
https://github.com/root-project/root/pull/1098:72,security,access,access,72,Fix compilation errors on Windows; Use the std::atomic load() method to access its content,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1098
https://github.com/root-project/root/pull/1098:16,usability,error,errors,16,Fix compilation errors on Windows; Use the std::atomic load() method to access its content,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1098
https://github.com/root-project/root/pull/1099:16,availability,error,errors,16,Fix compilation errors on Windows; - Use TMath::Pi() instead of M_PI (undefined on Windows). - Replace 'uint' with 'unsigned int'. - Fix error C2057: expected constant expression with newX and newY arrays,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1099
https://github.com/root-project/root/pull/1099:137,availability,error,error,137,Fix compilation errors on Windows; - Use TMath::Pi() instead of M_PI (undefined on Windows). - Replace 'uint' with 'unsigned int'. - Fix error C2057: expected constant expression with newX and newY arrays,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1099
https://github.com/root-project/root/pull/1099:16,performance,error,errors,16,Fix compilation errors on Windows; - Use TMath::Pi() instead of M_PI (undefined on Windows). - Replace 'uint' with 'unsigned int'. - Fix error C2057: expected constant expression with newX and newY arrays,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1099
https://github.com/root-project/root/pull/1099:137,performance,error,error,137,Fix compilation errors on Windows; - Use TMath::Pi() instead of M_PI (undefined on Windows). - Replace 'uint' with 'unsigned int'. - Fix error C2057: expected constant expression with newX and newY arrays,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1099
https://github.com/root-project/root/pull/1099:16,safety,error,errors,16,Fix compilation errors on Windows; - Use TMath::Pi() instead of M_PI (undefined on Windows). - Replace 'uint' with 'unsigned int'. - Fix error C2057: expected constant expression with newX and newY arrays,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1099
https://github.com/root-project/root/pull/1099:137,safety,error,error,137,Fix compilation errors on Windows; - Use TMath::Pi() instead of M_PI (undefined on Windows). - Replace 'uint' with 'unsigned int'. - Fix error C2057: expected constant expression with newX and newY arrays,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1099
https://github.com/root-project/root/pull/1099:16,usability,error,errors,16,Fix compilation errors on Windows; - Use TMath::Pi() instead of M_PI (undefined on Windows). - Replace 'uint' with 'unsigned int'. - Fix error C2057: expected constant expression with newX and newY arrays,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1099
https://github.com/root-project/root/pull/1099:104,usability,ui,uint,104,Fix compilation errors on Windows; - Use TMath::Pi() instead of M_PI (undefined on Windows). - Replace 'uint' with 'unsigned int'. - Fix error C2057: expected constant expression with newX and newY arrays,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1099
https://github.com/root-project/root/pull/1099:137,usability,error,error,137,Fix compilation errors on Windows; - Use TMath::Pi() instead of M_PI (undefined on Windows). - Replace 'uint' with 'unsigned int'. - Fix error C2057: expected constant expression with newX and newY arrays,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1099
https://github.com/root-project/root/pull/1101:45,deployability,build,builds,45,[TDF] Do not run IMT Snapshot tests in noimt builds; `EnableImplicitMT` and friends print warnings or do not exist in `noimt` builds. Disable IMT tests in this case. @amadio what is the correct syntax to start a noimt PR build? :),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1101
https://github.com/root-project/root/pull/1101:126,deployability,build,builds,126,[TDF] Do not run IMT Snapshot tests in noimt builds; `EnableImplicitMT` and friends print warnings or do not exist in `noimt` builds. Disable IMT tests in this case. @amadio what is the correct syntax to start a noimt PR build? :),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1101
https://github.com/root-project/root/pull/1101:221,deployability,build,build,221,[TDF] Do not run IMT Snapshot tests in noimt builds; `EnableImplicitMT` and friends print warnings or do not exist in `noimt` builds. Disable IMT tests in this case. @amadio what is the correct syntax to start a noimt PR build? :),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1101
https://github.com/root-project/root/pull/1101:30,safety,test,tests,30,[TDF] Do not run IMT Snapshot tests in noimt builds; `EnableImplicitMT` and friends print warnings or do not exist in `noimt` builds. Disable IMT tests in this case. @amadio what is the correct syntax to start a noimt PR build? :),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1101
https://github.com/root-project/root/pull/1101:146,safety,test,tests,146,[TDF] Do not run IMT Snapshot tests in noimt builds; `EnableImplicitMT` and friends print warnings or do not exist in `noimt` builds. Disable IMT tests in this case. @amadio what is the correct syntax to start a noimt PR build? :),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1101
https://github.com/root-project/root/pull/1101:30,testability,test,tests,30,[TDF] Do not run IMT Snapshot tests in noimt builds; `EnableImplicitMT` and friends print warnings or do not exist in `noimt` builds. Disable IMT tests in this case. @amadio what is the correct syntax to start a noimt PR build? :),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1101
https://github.com/root-project/root/pull/1101:146,testability,test,tests,146,[TDF] Do not run IMT Snapshot tests in noimt builds; `EnableImplicitMT` and friends print warnings or do not exist in `noimt` builds. Disable IMT tests in this case. @amadio what is the correct syntax to start a noimt PR build? :),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1101
https://github.com/root-project/root/pull/1102:140,availability,avail,available,140,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:221,availability,avail,available,221,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:387,availability,avail,available,387,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:82,deployability,version,version,82,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:231,deployability,automat,automatically,231,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:82,integrability,version,version,82,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:82,modifiability,version,version,82,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:140,reliability,availab,available,140,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:221,reliability,availab,available,221,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:387,reliability,availab,available,387,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:140,safety,avail,available,140,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:221,safety,avail,available,221,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:387,safety,avail,available,387,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:140,security,availab,available,140,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:221,security,availab,available,221,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:387,security,availab,available,387,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1102:231,testability,automat,automatically,231,"Instantiate VecVore math functions for vector types; This PR makes the vectorised version of the mathematical functions provided by VecCore available to ROOT vey instantiating them in ROOT Mathcore. . The symbols will be available automatically at the ROOT prompt and by bringing in the Vc symbols, functions like std::sin or std::cos with vector types (std::sin(ROOT::Double_v) will be available",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1102
https://github.com/root-project/root/pull/1103:120,availability,robust,robust,120,"ROOT-9021 Allow more complex jitted defines using lambdas; Still need to change the `find(""return "")` to something more robust, but this allows defines to be a bit more complex. For filters, we need to do a bit more work (i.e., ensure we get something convertible to boolean).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1103
https://github.com/root-project/root/pull/1103:182,integrability,filter,filters,182,"ROOT-9021 Allow more complex jitted defines using lambdas; Still need to change the `find(""return "")` to something more robust, but this allows defines to be a bit more complex. For filters, we need to do a bit more work (i.e., ensure we get something convertible to boolean).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1103
https://github.com/root-project/root/pull/1103:120,reliability,robust,robust,120,"ROOT-9021 Allow more complex jitted defines using lambdas; Still need to change the `find(""return "")` to something more robust, but this allows defines to be a bit more complex. For filters, we need to do a bit more work (i.e., ensure we get something convertible to boolean).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1103
https://github.com/root-project/root/pull/1103:21,safety,compl,complex,21,"ROOT-9021 Allow more complex jitted defines using lambdas; Still need to change the `find(""return "")` to something more robust, but this allows defines to be a bit more complex. For filters, we need to do a bit more work (i.e., ensure we get something convertible to boolean).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1103
https://github.com/root-project/root/pull/1103:120,safety,robust,robust,120,"ROOT-9021 Allow more complex jitted defines using lambdas; Still need to change the `find(""return "")` to something more robust, but this allows defines to be a bit more complex. For filters, we need to do a bit more work (i.e., ensure we get something convertible to boolean).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1103
https://github.com/root-project/root/pull/1103:169,safety,compl,complex,169,"ROOT-9021 Allow more complex jitted defines using lambdas; Still need to change the `find(""return "")` to something more robust, but this allows defines to be a bit more complex. For filters, we need to do a bit more work (i.e., ensure we get something convertible to boolean).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1103
https://github.com/root-project/root/pull/1103:21,security,compl,complex,21,"ROOT-9021 Allow more complex jitted defines using lambdas; Still need to change the `find(""return "")` to something more robust, but this allows defines to be a bit more complex. For filters, we need to do a bit more work (i.e., ensure we get something convertible to boolean).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1103
https://github.com/root-project/root/pull/1103:169,security,compl,complex,169,"ROOT-9021 Allow more complex jitted defines using lambdas; Still need to change the `find(""return "")` to something more robust, but this allows defines to be a bit more complex. For filters, we need to do a bit more work (i.e., ensure we get something convertible to boolean).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1103
https://github.com/root-project/root/pull/1104:90,energy efficiency,reduc,reduce,90,"[TDF] When no data-source is present, spawn two tasks per worker; This is a simple fix to reduce imbalance in multi-thread event-loops. with no data-source: previously we spawned one task per worker thread. Expected to break `test_emptysource`, which is fixed by [PR 96](https://github.com/root-project/roottest/pull/96) in roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1104
https://github.com/root-project/root/pull/1104:123,integrability,event,event-loops,123,"[TDF] When no data-source is present, spawn two tasks per worker; This is a simple fix to reduce imbalance in multi-thread event-loops. with no data-source: previously we spawned one task per worker thread. Expected to break `test_emptysource`, which is fixed by [PR 96](https://github.com/root-project/roottest/pull/96) in roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1104
https://github.com/root-project/root/pull/1104:110,performance,multi-thread,multi-thread,110,"[TDF] When no data-source is present, spawn two tasks per worker; This is a simple fix to reduce imbalance in multi-thread event-loops. with no data-source: previously we spawned one task per worker thread. Expected to break `test_emptysource`, which is fixed by [PR 96](https://github.com/root-project/roottest/pull/96) in roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1104
https://github.com/root-project/root/pull/1104:76,testability,simpl,simple,76,"[TDF] When no data-source is present, spawn two tasks per worker; This is a simple fix to reduce imbalance in multi-thread event-loops. with no data-source: previously we spawned one task per worker thread. Expected to break `test_emptysource`, which is fixed by [PR 96](https://github.com/root-project/roottest/pull/96) in roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1104
https://github.com/root-project/root/pull/1104:76,usability,simpl,simple,76,"[TDF] When no data-source is present, spawn two tasks per worker; This is a simple fix to reduce imbalance in multi-thread event-loops. with no data-source: previously we spawned one task per worker thread. Expected to break `test_emptysource`, which is fixed by [PR 96](https://github.com/root-project/roottest/pull/96) in roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1104
https://github.com/root-project/root/pull/1105:42,safety,prevent,preventing,42,Split dictionary in two parts on Windows (preventing compiler limitation);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1105
https://github.com/root-project/root/pull/1105:42,security,preven,preventing,42,Split dictionary in two parts on Windows (preventing compiler limitation);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1105
https://github.com/root-project/root/pull/1106:39,deployability,depend,dependencies,39,Remove imt and multiproc (unsupported) dependencies on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1106
https://github.com/root-project/root/pull/1106:39,integrability,depend,dependencies,39,Remove imt and multiproc (unsupported) dependencies on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1106
https://github.com/root-project/root/pull/1106:39,modifiability,depend,dependencies,39,Remove imt and multiproc (unsupported) dependencies on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1106
https://github.com/root-project/root/pull/1106:39,safety,depend,dependencies,39,Remove imt and multiproc (unsupported) dependencies on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1106
https://github.com/root-project/root/pull/1106:39,testability,depend,dependencies,39,Remove imt and multiproc (unsupported) dependencies on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1106
https://github.com/root-project/root/pull/1109:29,deployability,releas,release,29,[DOC] Callbacks tutorial and release notes;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1109
https://github.com/root-project/root/pull/1113:33,availability,sla,slashes,33,Replace backslashes with forward slashes on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1113
https://github.com/root-project/root/pull/1113:33,reliability,sla,slashes,33,Replace backslashes with forward slashes on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1113
https://github.com/root-project/root/pull/1114:107,availability,error,errors,107,"Fix makepchinput on Windows; - remove ""future"" from the list of STL includes on Windows (it generates many errors). - replace backslashes by forward slashes in paths",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1114
https://github.com/root-project/root/pull/1114:149,availability,sla,slashes,149,"Fix makepchinput on Windows; - remove ""future"" from the list of STL includes on Windows (it generates many errors). - replace backslashes by forward slashes in paths",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1114
https://github.com/root-project/root/pull/1114:107,performance,error,errors,107,"Fix makepchinput on Windows; - remove ""future"" from the list of STL includes on Windows (it generates many errors). - replace backslashes by forward slashes in paths",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1114
https://github.com/root-project/root/pull/1114:149,reliability,sla,slashes,149,"Fix makepchinput on Windows; - remove ""future"" from the list of STL includes on Windows (it generates many errors). - replace backslashes by forward slashes in paths",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1114
https://github.com/root-project/root/pull/1114:107,safety,error,errors,107,"Fix makepchinput on Windows; - remove ""future"" from the list of STL includes on Windows (it generates many errors). - replace backslashes by forward slashes in paths",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1114
https://github.com/root-project/root/pull/1114:107,usability,error,errors,107,"Fix makepchinput on Windows; - remove ""future"" from the list of STL includes on Windows (it generates many errors). - replace backslashes by forward slashes in paths",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1114
https://github.com/root-project/root/pull/1116:9,deployability,build,build,9,Allow to build (built-in) zlib on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1116
https://github.com/root-project/root/pull/1117:16,availability,error,errors,16,Fix compilation errors on Windows; - Add a couple of missing #include <algorithm>. - Replace _N by _NN (_N is already defined and used in some system math headers on Windows). - Add #define __thread __declspec(thread),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1117
https://github.com/root-project/root/pull/1117:43,integrability,coupl,couple,43,Fix compilation errors on Windows; - Add a couple of missing #include <algorithm>. - Replace _N by _NN (_N is already defined and used in some system math headers on Windows). - Add #define __thread __declspec(thread),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1117
https://github.com/root-project/root/pull/1117:43,modifiability,coupl,couple,43,Fix compilation errors on Windows; - Add a couple of missing #include <algorithm>. - Replace _N by _NN (_N is already defined and used in some system math headers on Windows). - Add #define __thread __declspec(thread),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1117
https://github.com/root-project/root/pull/1117:16,performance,error,errors,16,Fix compilation errors on Windows; - Add a couple of missing #include <algorithm>. - Replace _N by _NN (_N is already defined and used in some system math headers on Windows). - Add #define __thread __declspec(thread),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1117
https://github.com/root-project/root/pull/1117:16,safety,error,errors,16,Fix compilation errors on Windows; - Add a couple of missing #include <algorithm>. - Replace _N by _NN (_N is already defined and used in some system math headers on Windows). - Add #define __thread __declspec(thread),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1117
https://github.com/root-project/root/pull/1117:43,testability,coupl,couple,43,Fix compilation errors on Windows; - Add a couple of missing #include <algorithm>. - Replace _N by _NN (_N is already defined and used in some system math headers on Windows). - Add #define __thread __declspec(thread),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1117
https://github.com/root-project/root/pull/1117:16,usability,error,errors,16,Fix compilation errors on Windows; - Add a couple of missing #include <algorithm>. - Replace _N by _NN (_N is already defined and used in some system math headers on Windows). - Add #define __thread __declspec(thread),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1117
https://github.com/root-project/root/pull/1118:16,availability,error,errors,16,Fix compilation errors and disable JupyROOT on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1118
https://github.com/root-project/root/pull/1118:16,performance,error,errors,16,Fix compilation errors and disable JupyROOT on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1118
https://github.com/root-project/root/pull/1118:16,safety,error,errors,16,Fix compilation errors and disable JupyROOT on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1118
https://github.com/root-project/root/pull/1118:16,usability,error,errors,16,Fix compilation errors and disable JupyROOT on Windows;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1118
https://github.com/root-project/root/pull/1119:55,deployability,build,builds,55,[TDF] Fix no-imt warning: only define variable for imt builds; Missed it because there are only imt builds in the PRs :sweat_smile:,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1119
https://github.com/root-project/root/pull/1119:100,deployability,build,builds,100,[TDF] Fix no-imt warning: only define variable for imt builds; Missed it because there are only imt builds in the PRs :sweat_smile:,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1119
https://github.com/root-project/root/pull/1119:38,modifiability,variab,variable,38,[TDF] Fix no-imt warning: only define variable for imt builds; Missed it because there are only imt builds in the PRs :sweat_smile:,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1119
https://github.com/root-project/root/pull/1120:6,performance,cach,caching,6,Allow caching and Taking of columns of C-style arrays;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1120
https://github.com/root-project/root/pull/1121:38,safety,Avoid,Avoid,38,[WIP] [TDF] Workaround for ROOT-9041; Avoid to deal with unique_ptrs created by the compiler in jitted code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1121
https://github.com/root-project/root/pull/1122:244,availability,sla,slashs,244,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:43,deployability,depend,dependencied,43,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:179,deployability,version,version,179,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:59,energy efficiency,Core,Core,59,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:43,integrability,depend,dependencied,43,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:179,integrability,version,version,179,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:43,modifiability,depend,dependencied,43,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:179,modifiability,version,version,179,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:110,performance,time,time,110,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:244,reliability,sla,slashs,244,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:43,safety,depend,dependencied,43,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1122:43,testability,depend,dependencied,43,Fix libCling compilation on Windows; - add dependencied on Core and IO (needed to resolve the symbols at link time on Windows). - add a few symbols to be exported. - use the ANSI version of system functions. - convert the backslashs to forward slashs in the rootmap file path,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1122
https://github.com/root-project/root/pull/1123:114,usability,custom,custom-class-broken-with-xcode-,114,Fix constructor for pointer to functor; Bug found in the forum: https://root-forum.cern.ch/t/tf1-constructor-with-custom-class-broken-with-xcode-9-0/26422/9,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1123
https://github.com/root-project/root/pull/1125:14,energy efficiency,Profil,Profile,14,[TDF] Move to Profile models also the Profile1D and Profile2D methods of TInterface; This is done to get rid of the move semantics and make PyROOT's life easier.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1125
https://github.com/root-project/root/pull/1125:22,energy efficiency,model,models,22,[TDF] Move to Profile models also the Profile1D and Profile2D methods of TInterface; This is done to get rid of the move semantics and make PyROOT's life easier.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1125
https://github.com/root-project/root/pull/1125:121,interoperability,semant,semantics,121,[TDF] Move to Profile models also the Profile1D and Profile2D methods of TInterface; This is done to get rid of the move semantics and make PyROOT's life easier.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1125
https://github.com/root-project/root/pull/1125:14,performance,Profil,Profile,14,[TDF] Move to Profile models also the Profile1D and Profile2D methods of TInterface; This is done to get rid of the move semantics and make PyROOT's life easier.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1125
https://github.com/root-project/root/pull/1125:22,security,model,models,22,[TDF] Move to Profile models also the Profile1D and Profile2D methods of TInterface; This is done to get rid of the move semantics and make PyROOT's life easier.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1125
https://github.com/root-project/root/pull/1126:470,availability,sla,slashs,470,"Fix the dictionary generation on Windows; - In SelectionRules.cxx: #define fnmatch (Unix filename pattern matching) as PathMatchSpec (MS-DOS). - In TModuleGenerator::WriteRegistrationSource, since Visual sudio has a limitation of 2048 characters max in raw strings, split the potentially huge DICTFWDDCLS raw string into multiple smaller ones. - In rootcling_impl.cxx, implement the Windows specific mangled/demangled checks, and convert several backslashs into forward slashs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1126
https://github.com/root-project/root/pull/1126:391,interoperability,specif,specific,391,"Fix the dictionary generation on Windows; - In SelectionRules.cxx: #define fnmatch (Unix filename pattern matching) as PathMatchSpec (MS-DOS). - In TModuleGenerator::WriteRegistrationSource, since Visual sudio has a limitation of 2048 characters max in raw strings, split the potentially huge DICTFWDDCLS raw string into multiple smaller ones. - In rootcling_impl.cxx, implement the Windows specific mangled/demangled checks, and convert several backslashs into forward slashs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1126
https://github.com/root-project/root/pull/1126:470,reliability,sla,slashs,470,"Fix the dictionary generation on Windows; - In SelectionRules.cxx: #define fnmatch (Unix filename pattern matching) as PathMatchSpec (MS-DOS). - In TModuleGenerator::WriteRegistrationSource, since Visual sudio has a limitation of 2048 characters max in raw strings, split the potentially huge DICTFWDDCLS raw string into multiple smaller ones. - In rootcling_impl.cxx, implement the Windows specific mangled/demangled checks, and convert several backslashs into forward slashs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1126
https://github.com/root-project/root/pull/1126:197,usability,Visual,Visual,197,"Fix the dictionary generation on Windows; - In SelectionRules.cxx: #define fnmatch (Unix filename pattern matching) as PathMatchSpec (MS-DOS). - In TModuleGenerator::WriteRegistrationSource, since Visual sudio has a limitation of 2048 characters max in raw strings, split the potentially huge DICTFWDDCLS raw string into multiple smaller ones. - In rootcling_impl.cxx, implement the Windows specific mangled/demangled checks, and convert several backslashs into forward slashs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1126
https://github.com/root-project/root/pull/1127:113,availability,state,state,113,[Imt] Do not trigger the construction of TROOT when invoking IsImplicitMTEnabled(); but rather keep track of the state as a boolean.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1127
https://github.com/root-project/root/pull/1127:113,integrability,state,state,113,[Imt] Do not trigger the construction of TROOT when invoking IsImplicitMTEnabled(); but rather keep track of the state as a boolean.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1127
https://github.com/root-project/root/pull/1129:25,integrability,filter,filter-out,25,Add missing includes and filter-out all MultiProc related code;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1129
https://github.com/root-project/root/pull/1131:247,performance,cach,cache,247,"[TDF] Generate datasets in the C++ tutorials with TDF and Snapshot; This work on the C++ tutorial really shows that we need a fake column with the entry number. If we agree, this would be easy to achieve thanks to the recent developments done for cache :)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1131
https://github.com/root-project/root/pull/1132:415,availability,operat,operator,415,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:448,availability,error,error,448,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:462,availability,operat,operator,462,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:33,energy efficiency,core,core,33,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:207,integrability,coupl,couple,207,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:207,modifiability,coupl,couple,207,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:448,performance,error,error,448,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:197,safety,prevent,prevent,197,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:345,safety,prevent,prevent,345,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:448,safety,error,error,448,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:197,security,preven,prevent,197,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:345,security,preven,prevent,345,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:207,testability,coupl,couple,207,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:58,usability,Visual,Visual,58,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1132:448,usability,error,error,448,Fix several issues on Windows in core/base; - Force using Visual Studio 2017 or higher. - Undefine unsupported __attribute__ keyword. - Move the TObject constructors from the header to the source (prevent a couple of static members to be externally unresolved). - Use the AreAllSignalsBlocked() method instead of the static fgAllSignalsBlocked (prevent it to be externally unresolved). - Comment out inline TString operator==() to fix the compiler error C2593: 'operator ==' is ambiguous (!!!). - Implement a working dlsym function. - Remove some obsolete code,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1132
https://github.com/root-project/root/pull/1134:258,availability,recov,recoverable,258,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:271,availability,failur,failure,271,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:258,deployability,recov,recoverable,258,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:271,deployability,fail,failure,271,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:17,performance,cach,cache,17,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:271,performance,failur,failure,271,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:258,reliability,recov,recoverable,258,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:271,reliability,fail,failure,271,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:23,safety,test,test,23,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:208,safety,test,test,208,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:221,safety,test,test,221,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:258,safety,recov,recoverable,258,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:319,safety,test,test,319,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:137,security,expos,expose,137,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:258,security,recov,recoverable,258,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:23,testability,test,test,23,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:208,testability,test,test,208,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:221,testability,test,test,221,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:238,testability,assert,assert,238,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1134:319,testability,test,test,319,[TDF] Rework the cache test about non copiable items; 1) Do not put the non-copiable ds in a header. It's very cumbersome. at runtime to expose it to the interpreter. The code is now in a string. 2) Make the test a death test. The static assert causes a non-recoverable. failure which should be handled by this kind of test and not with a try/catch. block.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1134
https://github.com/root-project/root/pull/1135:20,safety,valid,valid,20,"[TDF] Also look for valid column names in friend trees; If friend trees are present, search them for valid column names.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1135
https://github.com/root-project/root/pull/1135:101,safety,valid,valid,101,"[TDF] Also look for valid column names in friend trees; If friend trees are present, search them for valid column names.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1135
https://github.com/root-project/root/pull/1136:30,deployability,modul,modules,30,"[cxxmodules] Disable PCH with modules activated for now.; At the moment we use modules for ROOT and the PCH conflicts with. that, so let's not when modules are activated (at least for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1136
https://github.com/root-project/root/pull/1136:79,deployability,modul,modules,79,"[cxxmodules] Disable PCH with modules activated for now.; At the moment we use modules for ROOT and the PCH conflicts with. that, so let's not when modules are activated (at least for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1136
https://github.com/root-project/root/pull/1136:148,deployability,modul,modules,148,"[cxxmodules] Disable PCH with modules activated for now.; At the moment we use modules for ROOT and the PCH conflicts with. that, so let's not when modules are activated (at least for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1136
https://github.com/root-project/root/pull/1136:108,interoperability,conflict,conflicts,108,"[cxxmodules] Disable PCH with modules activated for now.; At the moment we use modules for ROOT and the PCH conflicts with. that, so let's not when modules are activated (at least for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1136
https://github.com/root-project/root/pull/1136:30,modifiability,modul,modules,30,"[cxxmodules] Disable PCH with modules activated for now.; At the moment we use modules for ROOT and the PCH conflicts with. that, so let's not when modules are activated (at least for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1136
https://github.com/root-project/root/pull/1136:79,modifiability,modul,modules,79,"[cxxmodules] Disable PCH with modules activated for now.; At the moment we use modules for ROOT and the PCH conflicts with. that, so let's not when modules are activated (at least for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1136
https://github.com/root-project/root/pull/1136:148,modifiability,modul,modules,148,"[cxxmodules] Disable PCH with modules activated for now.; At the moment we use modules for ROOT and the PCH conflicts with. that, so let's not when modules are activated (at least for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1136
https://github.com/root-project/root/pull/1136:30,safety,modul,modules,30,"[cxxmodules] Disable PCH with modules activated for now.; At the moment we use modules for ROOT and the PCH conflicts with. that, so let's not when modules are activated (at least for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1136
https://github.com/root-project/root/pull/1136:79,safety,modul,modules,79,"[cxxmodules] Disable PCH with modules activated for now.; At the moment we use modules for ROOT and the PCH conflicts with. that, so let's not when modules are activated (at least for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1136
https://github.com/root-project/root/pull/1136:148,safety,modul,modules,148,"[cxxmodules] Disable PCH with modules activated for now.; At the moment we use modules for ROOT and the PCH conflicts with. that, so let's not when modules are activated (at least for now).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1136
https://github.com/root-project/root/pull/1137:28,usability,support,support,28,[TDF] Add a first gtest for support of friend trees;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1137
https://github.com/root-project/root/pull/1138:52,integrability,batch,batch,52,To get the same window size in interactive mode and batch mode.; This fix was suggested here: https://root-forum.cern.ch/t/tcanvas-setwindowsize-extension-proposal/26226,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1138
https://github.com/root-project/root/pull/1138:145,modifiability,extens,extension-proposal,145,To get the same window size in interactive mode and batch mode.; This fix was suggested here: https://root-forum.cern.ch/t/tcanvas-setwindowsize-extension-proposal/26226,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1138
https://github.com/root-project/root/pull/1138:52,performance,batch,batch,52,To get the same window size in interactive mode and batch mode.; This fix was suggested here: https://root-forum.cern.ch/t/tcanvas-setwindowsize-extension-proposal/26226,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1138
https://github.com/root-project/root/pull/1138:31,usability,interact,interactive,31,To get the same window size in interactive mode and batch mode.; This fix was suggested here: https://root-forum.cern.ch/t/tcanvas-setwindowsize-extension-proposal/26226,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1138
https://github.com/root-project/root/pull/1139:0,safety,Test,Test,0,Test reenable rootmap;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1139
https://github.com/root-project/root/pull/1139:0,testability,Test,Test,0,Test reenable rootmap;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1139
https://github.com/root-project/root/pull/1140:134,deployability,version,versions,134,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:134,integrability,version,versions,134,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:157,interoperability,registr,registry,157,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:134,modifiability,version,versions,134,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:286,modifiability,variab,variable,286,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:178,safety,compl,completely,178,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:304,safety,review,reviewed,304,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:63,security,hack,hack,63,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:178,security,compl,completely,178,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:304,testability,review,reviewed,304,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:8,usability,Visual,Visual,8,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1140:74,usability,Visual,Visual,74,"Fix the Visual Studio 2017 directory location (quick and dirty hack); The Visual Studio 2017 path is very different than the previous versions, and even the registry entries are completely different, so for now let's try the trivial way first (using the %VCToolsInstallDir% environment variable). (to be reviewed).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1140
https://github.com/root-project/root/pull/1142:0,deployability,Integr,Integration,0,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:73,deployability,integr,integration,73,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:0,integrability,Integr,Integration,0,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:25,integrability,repositor,repository,25,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:73,integrability,integr,integration,73,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:110,integrability,repositor,repository,110,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:0,interoperability,Integr,Integration,0,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:25,interoperability,repositor,repository,25,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:73,interoperability,integr,integration,73,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:110,interoperability,repositor,repository,110,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:0,modifiability,Integr,Integration,0,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:73,modifiability,integr,integration,73,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:0,reliability,Integr,Integration,0,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:73,reliability,integr,integration,73,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:0,security,Integr,Integration,0,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:73,security,integr,integration,73,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:0,testability,Integr,Integration,0,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1142:73,testability,integr,integration,73,"Integration of rootbench repository into ROOT; I did the same ""style"" of integration as was done for roottest repository",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1142
https://github.com/root-project/root/pull/1143:28,safety,valid,valid,28,"[TDF] Revert ""Also look for valid column names in friend trees""; Turns out this change was useless. Recent gtests (that absolutely need to be augmented) should show that we can run fine without this extra code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1143
https://github.com/root-project/root/pull/1144:5,security,hash,hash,5,Good hash; Improve speed of THashList::RecursiveRemove,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1144
https://github.com/root-project/root/pull/1145:83,availability,sli,slight,83,[TDF] Test friend trees' branches which contain arrays ; Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1145:40,deployability,contain,contain,40,[TDF] Test friend trees' branches which contain arrays ; Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1145:90,modifiability,refact,refactoring,90,[TDF] Test friend trees' branches which contain arrays ; Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1145:90,performance,refactor,refactoring,90,[TDF] Test friend trees' branches which contain arrays ; Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1145:83,reliability,sli,slight,83,[TDF] Test friend trees' branches which contain arrays ; Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1145:6,safety,Test,Test,6,[TDF] Test friend trees' branches which contain arrays ; Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1145:71,safety,test,tests,71,[TDF] Test friend trees' branches which contain arrays ; Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1145:6,testability,Test,Test,6,[TDF] Test friend trees' branches which contain arrays ; Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1145:66,testability,unit,unit,66,[TDF] Test friend trees' branches which contain arrays ; Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1145:71,testability,test,tests,71,[TDF] Test friend trees' branches which contain arrays ; Two more unit tests and a slight refactoring of the existing ones.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1145
https://github.com/root-project/root/pull/1146:14,deployability,build,build,14,[wip] Test if build works with ClangModules;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1146
https://github.com/root-project/root/pull/1146:6,safety,Test,Test,6,[wip] Test if build works with ClangModules;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1146
https://github.com/root-project/root/pull/1146:6,testability,Test,Test,6,[wip] Test if build works with ClangModules;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1146
https://github.com/root-project/root/pull/1147:52,availability,avail,available,52,[cxxmodules][wip] Add SetupModules call to load all available PCMs;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1147
https://github.com/root-project/root/pull/1147:43,energy efficiency,load,load,43,[cxxmodules][wip] Add SetupModules call to load all available PCMs;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1147
https://github.com/root-project/root/pull/1147:43,performance,load,load,43,[cxxmodules][wip] Add SetupModules call to load all available PCMs;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1147
https://github.com/root-project/root/pull/1147:52,reliability,availab,available,52,[cxxmodules][wip] Add SetupModules call to load all available PCMs;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1147
https://github.com/root-project/root/pull/1147:52,safety,avail,available,52,[cxxmodules][wip] Add SetupModules call to load all available PCMs;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1147
https://github.com/root-project/root/pull/1147:52,security,availab,available,52,[cxxmodules][wip] Add SetupModules call to load all available PCMs;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1147
https://github.com/root-project/root/pull/1148:77,deployability,version,version,77,[TDF] Add tests for using friend trees in `Define`; ...jitted and non-jitted version,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1148
https://github.com/root-project/root/pull/1148:77,integrability,version,version,77,[TDF] Add tests for using friend trees in `Define`; ...jitted and non-jitted version,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1148
https://github.com/root-project/root/pull/1148:77,modifiability,version,version,77,[TDF] Add tests for using friend trees in `Define`; ...jitted and non-jitted version,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1148
https://github.com/root-project/root/pull/1148:10,safety,test,tests,10,[TDF] Add tests for using friend trees in `Define`; ...jitted and non-jitted version,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1148
https://github.com/root-project/root/pull/1148:10,testability,test,tests,10,[TDF] Add tests for using friend trees in `Define`; ...jitted and non-jitted version,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1148
https://github.com/root-project/root/pull/1149:143,integrability,filter,filter,143,[ROOT-8839] Disabling usage of system zlib in LLVM (not used in ROOT case); Fixing https://sft.its.cern.ch/jira/projects/ROOT/issues/ROOT-8839?filter=allopenissues,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1149
https://github.com/root-project/root/pull/1150:16,availability,error,error,16,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:59,availability,error,error,59,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:72,availability,error,error,72,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:124,deployability,integr,integral,124,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:124,integrability,integr,integral,124,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:124,interoperability,integr,integral,124,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:756,interoperability,convers,conversions,756,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:124,modifiability,integr,integral,124,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:16,performance,error,error,16,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:59,performance,error,error,59,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:72,performance,error,error,72,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:743,performance,perform,performs,743,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:124,reliability,integr,integral,124,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:16,safety,error,error,16,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:59,safety,error,error,59,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:72,safety,error,error,72,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:124,security,integr,integral,124,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:124,testability,integr,integral,124,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:16,usability,error,error,16,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:59,usability,error,error,59,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:72,usability,error,error,72,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1150:743,usability,perform,performs,743,"Fix compilation error on Windows; This fixes the following error:. ```. error G34C21FBE: static_assert expression is not an integral constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:31: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. TEveProjections.h:174:71: note: in instantiation of member function 'TEveVectorT<float>::Arr' requested here. virtual Float_t* GetProjectedCenter() { return fProjectedCenter.Arr(); }. ^. TEveVector.h:55:21: note: cast that performs the conversions of a reinterpret_cast is not allowed in a constant expression. static_assert(offsetof(TEveVectorT, fZ) == offsetof(TEveVectorT, fX) + 2*sizeof(TT),. ^. C:\Program Files (x86)\Windows Kits\10\Include\10.0.15063.0\ucrt\stddef.h:42:32: note: expanded from macro 'offsetof'. #define offsetof(s,m) ((size_t)&reinterpret_cast<char const volatile&>((((s*)0)->m))). ^. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1150
https://github.com/root-project/root/pull/1151:33,availability,error,errors,33,"Fix std::make_unique compilation errors on Windows; This fixes the following errors:. ```. TRootDS.cxx(145): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]. C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&>(std::string_view &,std::string_view &)'. with. [. _Ty=ROOT::Experimental::TDF::TRootDS. ]. C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:. or 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&,void>(std::string_view &,std::string_view &)'. with. [. _Ty=ROOT::Experimental::TDF::TRootDS. ]. TRootDS.cxx(145): note: while trying to match the argument list '(std::string_view, std::string_view)'. TRootDS.cxx(145): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]. TTrivialDS.cxx. TTrivialDS.cxx(82): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]. C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&>(ULong64_t &)'. with. [. _Ty=ROOT::Experimental::TDF::TTrivialDS. ]. C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:. or 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&,void>(ULong64_t &)'. with. [. _Ty=ROOT::Experimental::TDF::TTrivialDS. ]. TTrivialDS.cxx(82): note: while trying to match the argument list '",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1151
https://github.com/root-project/root/pull/1151:77,availability,error,errors,77,"Fix std::make_unique compilation errors on Windows; This fixes the following errors:. ```. TRootDS.cxx(145): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]. C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&>(std::string_view &,std::string_view &)'. with. [. _Ty=ROOT::Experimental::TDF::TRootDS. ]. C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:. or 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&,void>(std::string_view &,std::string_view &)'. with. [. _Ty=ROOT::Experimental::TDF::TRootDS. ]. TRootDS.cxx(145): note: while trying to match the argument list '(std::string_view, std::string_view)'. TRootDS.cxx(145): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]. TTrivialDS.cxx. TTrivialDS.cxx(82): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]. C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&>(ULong64_t &)'. with. [. _Ty=ROOT::Experimental::TDF::TTrivialDS. ]. C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:. or 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&,void>(ULong64_t &)'. with. [. _Ty=ROOT::Experimental::TDF::TTrivialDS. ]. TTrivialDS.cxx(82): note: while trying to match the argument list '",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1151
https://github.com/root-project/root/pull/1151:109,availability,error,error,109,"Fix std::make_unique compilation errors on Windows; This fixes the following errors:. ```. TRootDS.cxx(145): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]. C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&>(std::string_view &,std::string_view &)'. with. [. _Ty=ROOT::Experimental::TDF::TRootDS. ]. C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:. or 'std::unique_ptr<ROOT::Experimental::TDF::TRootDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TRootDS,std::string_view&,std::string_view&,void>(std::string_view &,std::string_view &)'. with. [. _Ty=ROOT::Experimental::TDF::TRootDS. ]. TRootDS.cxx(145): note: while trying to match the argument list '(std::string_view, std::string_view)'. TRootDS.cxx(145): error C2512: 'ROOT::Experimental::TDataFrame::TDataFrame': no appropriate default constructor available [TreePlayer.vcxproj]. TTrivialDS.cxx. TTrivialDS.cxx(82): error C2668: 'std::make_unique': ambiguous call to overloaded function [TreePlayer.vcxproj]. C:\Users\bellenot\build\master-check\include\ROOT/RMakeUnique.hxx(26): note: could be 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&>(ULong64_t &)'. with. [. _Ty=ROOT::Experimental::TDF::TTrivialDS. ]. C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.11.25503\include\memory(2436): note:. or 'std::unique_ptr<ROOT::Experimental::TDF::TTrivialDS,std::default_delete<_Ty>> std::make_unique<ROOT::Experimental::TDF::TTrivialDS,ULong64_t&,void>(ULong64_t &)'. with. [. _Ty=ROOT::Experimental::TDF::TTrivialDS. ]. TTrivialDS.cxx(82): note: while trying to match the argument list '",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1151
