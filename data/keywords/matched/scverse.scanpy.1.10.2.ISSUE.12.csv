id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/1167:14070,performance,error,error,14070,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15672,performance,parallel,parallel,15672,"rning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16512,performance,error,error,16512,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18114,performance,parallel,parallel,18114,"rning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18954,performance,error,error,18954,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20556,performance,parallel,parallel,20556,"rning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20682,performance,batch,batch,20682,".7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20717,performance,batch,batch,20717,"ine 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_j",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22662,performance,schedul,scheduled,22662,"ine 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:25398,performance,batch,batch,25398,"1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1297,reliability,fail,failed,1297,"a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3739,reliability,fail,failed,3739,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6181,reliability,fail,failed,6181,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8623,reliability,fail,failed,8623,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11065,reliability,fail,failed,11065,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:13507,reliability,fail,failed,13507,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15949,reliability,fail,failed,15949,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18391,reliability,fail,failed,18391,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20949,reliability,fail,failed,20949,"ack from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-ba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:23480,reliability,fail,failed,23480,"rrection vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.z",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:25667,reliability,fail,failed,25667,"ject_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:219,safety,error,error,219,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:802,safety,Error,Error,802,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1860,safety,error,error,1860,"he block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2942,safety,detect,detected,2942,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:4302,safety,error,error,4302,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5384,safety,detect,detected,5384,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6744,safety,error,error,6744,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7826,safety,detect,detected,7826,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:9186,safety,error,error,9186,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10268,safety,detect,detected,10268,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11628,safety,error,error,11628,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12710,safety,detect,detected,12710,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14070,safety,error,error,14070,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15152,safety,detect,detected,15152,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16512,safety,error,error,16512,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17594,safety,detect,detected,17594,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18954,safety,error,error,18954,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20036,safety,detect,detected,20036,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22035,safety,detect,detected,22035," /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:24812,safety,detect,detected,24812,"ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:26957,safety,detect,detected,26957,"ta1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27524,safety,input,input-,27524,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27560,safety,modul,module,27560,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28203,safety,log,logging,28203,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2942,security,detect,detected,2942,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5384,security,detect,detected,5384,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7826,security,detect,detected,7826,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10268,security,detect,detected,10268,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12710,security,detect,detected,12710,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15152,security,detect,detected,15152,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17594,security,detect,detected,17594,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20036,security,detect,detected,20036,"med function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22035,security,detect,detected,22035," /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:24812,security,detect,detected,24812,"ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:26957,security,detect,detected,26957,"ta1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28203,security,log,logging,28203,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27473,testability,Trace,Traceback,27473,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28203,testability,log,logging,28203,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:76,usability,clear,clear,76,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:219,usability,error,error,219,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:302,usability,minim,minimal,302,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:802,usability,Error,Error,802,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1860,usability,error,error,1860,"he block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2971,usability,behavi,behaviour,2971,"lving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3114,usability,behavi,behaviour-when-using-jit,3114,"ckages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:4302,usability,error,error,4302,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5413,usability,behavi,behaviour,5413,"lving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5556,usability,behavi,behaviour-when-using-jit,5556,"ckages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6744,usability,error,error,6744,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7855,usability,behavi,behaviour,7855,"lving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7998,usability,behavi,behaviour-when-using-jit,7998,"ckages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:9186,usability,error,error,9186,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10297,usability,behavi,behaviour,10297,"lving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10440,usability,behavi,behaviour-when-using-jit,10440,"ckages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11628,usability,error,error,11628,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12739,usability,behavi,behaviour,12739,"lving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12882,usability,behavi,behaviour-when-using-jit,12882,"ckages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14070,usability,error,error,14070,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15181,usability,behavi,behaviour,15181,"lving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15324,usability,behavi,behaviour-when-using-jit,15324,"ckages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16512,usability,error,error,16512,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17623,usability,behavi,behaviour,17623,"lving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17766,usability,behavi,behaviour-when-using-jit,17766,"ckages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18954,usability,error,error,18954,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20065,usability,behavi,behaviour,20065,"lving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20208,usability,behavi,behaviour-when-using-jit,20208,"ckages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22064,usability,behavi,behaviour,22064,"canpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_ra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22207,usability,behavi,behaviour-when-using-jit,22207," find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:24841,usability,behavi,behaviour,24841," During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:24984,usability,behavi,behaviour-when-using-jit,24984,"jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_ra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:26986,usability,behavi,behaviour,26986,"or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27129,usability,behavi,behaviour-when-using-jit,27129,"jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27524,usability,input,input-,27524,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28323,usability,learn,learn,28323,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1168:182,availability,error,error,182,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:454,deployability,version,version,454,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:403,energy efficiency,current,currently,403,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:454,integrability,version,version,454,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:269,modifiability,pac,packages,269,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:413,modifiability,reu,reuses,413,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:454,modifiability,version,version,454,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:182,performance,error,error,182,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:182,safety,error,error,182,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:182,usability,error,error,182,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:226,usability,User,Users,226,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:573,usability,behavi,behavior,573,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:750,usability,user,user-images,750,"sc.pl.paga; Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1169:253,availability,mainten,maintenance,253,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:174,deployability,build,builds,174,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:291,deployability,build,build,291,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:733,deployability,Updat,Update,733,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:812,deployability,build,build,812,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:242,energy efficiency,reduc,reduce,242,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:96,interoperability,distribut,distributing,96,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:149,modifiability,maintain,maintaining,149,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:669,modifiability,pac,package,669,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:253,reliability,mainten,maintenance,253,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:149,safety,maintain,maintaining,149,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:500,safety,test,tests,500,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:638,safety,test,tests,638,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:733,safety,Updat,Update,733,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:800,safety,test,testing,800,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:733,security,Updat,Update,733,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:500,testability,test,tests,500,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:638,testability,test,tests,638,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:800,testability,test,testing,800,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:333,usability,tool,tooling,333,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:345,usability,document,documentation,345,"Switching to conda-forge?; @flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1170:18,availability,error,errors,18,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:150,availability,error,errors,150,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:344,availability,Error,Error,344,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:588,deployability,modul,module,588,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1168,deployability,Version,Versions,1168,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1201,deployability,log,logging,1201,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:121,integrability,batch,batch,121,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:272,integrability,batch,batch,272,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:608,integrability,batch,batch,608,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1168,integrability,Version,Versions,1168,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:588,modifiability,modul,module,588,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:712,modifiability,pac,packages,712,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1168,modifiability,Version,Versions,1168,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:18,performance,error,errors,18,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:121,performance,batch,batch,121,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:150,performance,error,errors,150,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:272,performance,batch,batch,272,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:344,performance,Error,Error,344,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:608,performance,batch,batch,608,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:18,safety,error,errors,18,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:150,safety,error,errors,150,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:344,safety,Error,Error,344,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:562,safety,input,input-,562,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:588,safety,modul,module,588,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1201,safety,log,logging,1201,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1201,security,log,logging,1201,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:518,testability,Trace,Traceback,518,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1201,testability,log,logging,1201,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:18,usability,error,errors,18,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:45,usability,clear,clear,45,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:150,usability,error,errors,150,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:169,usability,minim,minimal,169,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:344,usability,Error,Error,344,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:562,usability,input,input-,562,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1324,usability,learn,learn,1324,"combat processing errors; <!-- Please give a clear and concise description of what the bug is: -->. ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # ComBat batch correction. sc.pp.combat(adata, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-5-350690ae55dc> in <module>. 1 # ComBat batch correction. ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1171:14,availability,error,error,14,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:180,availability,error,error,180,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:894,availability,Error,Error,894,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:306,deployability,updat,updated,306,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:328,deployability,version,version,328,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1264,deployability,scale,scale,1264,"ot sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This cou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1359,deployability,modul,module,1359," I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.log",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2326,deployability,Version,Versions,2326,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2359,deployability,log,logging,2359,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1264,energy efficiency,scale,scale,1264,"ot sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This cou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:328,integrability,version,version,328,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:572,integrability,sub,subset,572,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2326,integrability,Version,Versions,2326,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:328,modifiability,version,version,328,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1099,modifiability,pac,packages,1099,"```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1264,modifiability,scal,scale,1264,"ot sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This cou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1359,modifiability,modul,module,1359," I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.log",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1468,modifiability,pac,packages,1468,"m/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1641,modifiability,pac,packages,1641,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1865,modifiability,pac,packages,1865,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2045,modifiability,pac,packages,2045,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2326,modifiability,Version,Versions,2326,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:14,performance,error,error,14,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:180,performance,error,error,180,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:894,performance,Error,Error,894,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1264,performance,scale,scale,1264,"ot sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This cou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:14,safety,error,error,14,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:180,safety,error,error,180,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:306,safety,updat,updated,306,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:894,safety,Error,Error,894,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1323,safety,input,input-,1323,"t version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1359,safety,modul,module,1359," I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.log",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2359,safety,log,logging,2359,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:306,security,updat,updated,306,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2359,security,log,logging,2359,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1016,testability,regress,regressing,1016,"<!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1272,testability,Trace,Traceback,1272,"ere the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a bo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2359,testability,log,logging,2359,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:14,usability,error,error,14,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:40,usability,clear,clear,40,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:180,usability,error,error,180,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:747,usability,minim,minimal,747,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:894,usability,Error,Error,894,"regress_out() error; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/aue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:1323,usability,input,input-,1323,"t version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb). I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1171:2480,usability,learn,learn,2480,"t this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:. ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.regress_out(adata, ['n_counts']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pp.regress_out(adata, ['n_counts']). regressing out ['n_counts']. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide. return np.sum(resid_dev * freq_weights * var_weights / scale). Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>. sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out. res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk. result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit. cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1142, in _fit_irls. raise ValueError(""The first guess on the deviance function "". ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171
https://github.com/scverse/scanpy/issues/1172:83,availability,error,error,83,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:546,availability,Error,Error,546,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:874,availability,avail,available,874,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:288,deployability,fail,fails,288,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:842,deployability,version,version,842,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1065,deployability,modul,module,1065,"nction outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1089,deployability,version,version,1089,"- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1125,deployability,version,version,1125,"scription of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1210,deployability,version,version,1210,"```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2319,deployability,modul,module,2319,"6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:3293,deployability,Version,Versions,3293,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:3326,deployability,log,logging,3326,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:785,energy efficiency,core,core,785,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:924,energy efficiency,core,core,924,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1591,energy efficiency,model,model,1591,"else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2828,energy efficiency,core,core,2828,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2969,energy efficiency,core,core,2969,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:842,integrability,version,version,842,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:855,integrability,pub,public,855,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1089,integrability,version,version,1089,"- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1125,integrability,version,version,1125,"scription of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1210,integrability,version,version,1210,"```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1461,integrability,Standardiz,Standardizing,1461,"(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1503,integrability,batch,batches,1503,"iable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:3293,integrability,Version,Versions,3293,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1461,interoperability,Standard,Standardizing,1461,"(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:725,modifiability,pac,packages,725,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:842,modifiability,version,version,842,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1008,modifiability,pac,packages,1008,"ates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: Run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1065,modifiability,modul,module,1065,"nction outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1089,modifiability,version,version,1089,"- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1125,modifiability,version,version,1125,"scription of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1210,modifiability,version,version,1210,"```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1530,modifiability,variab,variables,1530,"- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1625,modifiability,paramet,parametric,1625," [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1719,modifiability,pac,packages,1719,"e-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1963,modifiability,pac,packages,1963,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/panda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2216,modifiability,variab,variable,2216," six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). Y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2319,modifiability,modul,module,2319,"6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2424,modifiability,pac,packages,2424,"ls==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2594,modifiability,pac,packages,2594,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2812,modifiability,pac,packages,2812,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2953,modifiability,pac,packages,2953,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:3293,modifiability,Version,Versions,3293,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:83,performance,error,error,83,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:546,performance,Error,Error,546,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1503,performance,batch,batches,1503,"iable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:288,reliability,fail,fails,288,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:874,reliability,availab,available,874,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:83,safety,error,error,83,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:546,safety,Error,Error,546,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:874,safety,avail,available,874,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1065,safety,modul,module,1065,"nction outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2283,safety,input,input-,2283,"ix/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2319,safety,modul,module,2319,"6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:3326,safety,log,logging,3326,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:874,security,availab,available,874,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1591,security,model,model,1591,"else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:3326,security,log,logging,3326,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2232,testability,Trace,Traceback,2232,"i.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop dupli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:3326,testability,log,logging,3326,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:83,usability,error,error,83,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:109,usability,clear,clear,109,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:368,usability,minim,minimal,368,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:546,usability,Error,Error,546,"Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error; <!-- Please give a clear and concise description of what the bug is: -->. After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1158,usability,support,support,1158,". After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1399,usability,learn,learn,1399,"reproduces the bug in the code block below: -->. ```. sc.pp.combat(adata, key='sample'). sc.pp.highly_variable_genes(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2283,usability,input,input-,2283,"ix/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:3447,usability,learn,learn,3447,"es. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). In [2]: sc.pp.highly_variable_genes(adata). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-2-7727f5f928cd>"", line 1, in <module>. sc.pp.highly_variable_genes(adata). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/pull/1173:192,deployability,observ,observations,192,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:291,deployability,scale,scale,291,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:482,deployability,scale,scale,482,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:512,deployability,version,version,512,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:690,deployability,automat,automatic,690,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:291,energy efficiency,scale,scale,291,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:482,energy efficiency,scale,scale,482,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:429,integrability,standardiz,standardized,429,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:512,integrability,version,version,512,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:429,interoperability,standard,standardized,429,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:291,modifiability,scal,scale,291,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:374,modifiability,refact,refactor,374,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:482,modifiability,scal,scale,482,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:512,modifiability,version,version,512,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:724,modifiability,variab,variables,724,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:291,performance,scale,scale,291,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:374,performance,refactor,refactor,374,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:482,performance,scale,scale,482,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:225,safety,test,testing,225,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:756,safety,compl,completion,756,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:756,security,compl,completion,756,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:192,testability,observ,observations,192,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:225,testability,test,testing,225,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:690,testability,automat,automatic,690,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:442,usability,behavi,behaviors,442,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:649,usability,document,documentation,649,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:700,usability,document,documentation,700,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/pull/1173:840,usability,Close,Close,840,"Getters and setters for X; This PR adds some utilities for choosing which values to use for `X` inside scanpy functions. These utilities include a getter and setter for representations of the observations and some checks for testing these functions. This approach has been applied to `sc.pp.scale` and `sc.pp.log1p` as demonstrations, and because that code was in need of a refactor. I think it results in cleaner code with more standardized behaviors. The implementation of `sc.pp.scale` is just a hammered out version of what I commented here: https://github.com/theislab/scanpy/pull/1135#issuecomment-608200735. Still todo:. - [x] Figure out how documentation should work. In particular automatic documentation with type variables. - [x] Figure out tab completion for arguments not in the default/ fallback definition. This PR would:. * Close #1089. * Supercede #1135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1173
https://github.com/scverse/scanpy/issues/1174:239,availability,replic,replicate,239,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:408,availability,replic,replicate,408,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:437,availability,replic,replica,437,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:643,availability,replic,replicate,643,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:675,availability,Error,Error,675,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:845,availability,replic,replicate,845,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1042,availability,replic,replicate,1042,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1709,availability,replic,replicate,1709,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:276,deployability,contain,containing,276,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:945,deployability,modul,module,945,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1731,deployability,Version,Versions,1731,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1764,deployability,log,logging,1764,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1731,integrability,Version,Versions,1731,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:945,modifiability,modul,module,945,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1115,modifiability,pac,packages,1115,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1244,modifiability,pac,packages,1244,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1393,modifiability,pac,packages,1393,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1579,modifiability,pac,packages,1579,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1731,modifiability,Version,Versions,1731,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:223,performance,time,timepoint,223,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:319,performance,time,timepoint,319,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:609,performance,time,timepoint,609,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:675,performance,Error,Error,675,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:811,performance,time,timepoint,811,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1008,performance,time,timepoint,1008,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:377,safety,isol,isolated,377,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:675,safety,Error,Error,675,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:909,safety,input,input-,909,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:945,safety,modul,module,945,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1702,safety,input,input,1702,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1764,safety,log,logging,1764,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:377,security,iso,isolated,377,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1764,security,log,logging,1764,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:377,testability,isol,isolated,377,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:858,testability,Trace,Traceback,858,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1764,testability,log,logging,1764,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:69,usability,clear,clear,69,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:467,usability,minim,minimal,467,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:675,usability,Error,Error,675,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:909,usability,input,input-,909,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1702,usability,input,input,1702,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1174:1885,usability,learn,learn,1885,"pl.violin will not take ""hue"" kwarg for seaborn?; <!-- Please give a clear and concise description of what the bug is: -->. Trying to make a violin plot adding the seaborn hue argument will result in ValueError. In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>. sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin. **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot. color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__. self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables. raise ValueError(err). ValueError: Could not interpret input 'replicate'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174
https://github.com/scverse/scanpy/issues/1175:457,availability,error,errors,457,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:576,availability,Error,Error,576,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:911,availability,avail,available,911,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:61,deployability,contain,contains,61,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:879,deployability,version,version,879,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1102,deployability,modul,module,1102,"ar and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1126,deployability,version,version,1126,"n of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most rec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1162,deployability,version,version,1162,"ted [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-inpu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1247,deployability,version,version,1247,"t might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2198,deployability,modul,module,2198,"t for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:3179,deployability,Version,Versions,3179,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:3212,deployability,log,logging,3212,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:822,energy efficiency,core,core,822,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:961,energy efficiency,core,core,961,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1594,energy efficiency,model,model,1594,"code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2714,energy efficiency,core,core,2714,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2855,energy efficiency,core,core,2855,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:53,integrability,batch,batches,53,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:485,integrability,sub,subsequent,485,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:879,integrability,version,version,879,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:892,integrability,pub,public,892,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1126,integrability,version,version,1126,"n of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most rec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1162,integrability,version,version,1162,"ted [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-inpu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1247,integrability,version,version,1247,"t might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1498,integrability,Standardiz,Standardizing,1498,"``sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preproces",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1540,integrability,batch,batches,1540,"sult in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:3179,integrability,Version,Versions,3179,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1498,interoperability,Standard,Standardizing,1498,"``sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preproces",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:400,modifiability,scenario,scenario,400,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:762,modifiability,pac,packages,762,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:879,modifiability,version,version,879,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1045,modifiability,pac,packages,1045,"the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1102,modifiability,modul,module,1102,"ar and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1126,modifiability,version,version,1126,"n of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most rec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1162,modifiability,version,version,1162,"ted [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-inpu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1247,modifiability,version,version,1247,"t might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1567,modifiability,variab,variables,1567,"our Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1628,modifiability,paramet,parametric,1628,"te the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1706,modifiability,pac,packages,1706,"ome/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2095,modifiability,variab,variable,2095,"he module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2198,modifiability,modul,module,2198,"t for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2310,modifiability,pac,packages,2310,"project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2480,modifiability,pac,packages,2480,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2698,modifiability,pac,packages,2698,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2839,modifiability,pac,packages,2839,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:3179,modifiability,Version,Versions,3179,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:53,performance,batch,batches,53,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:457,performance,error,errors,457,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:576,performance,Error,Error,576,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1540,performance,batch,batches,1540,"sult in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:911,reliability,availab,available,911,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:422,safety,compl,complete,422,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:457,safety,error,errors,457,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:576,safety,Error,Error,576,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:911,safety,avail,available,911,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1102,safety,modul,module,1102,"ar and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2162,safety,input,input-,2162,"sion 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2198,safety,modul,module,2198,"t for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:3212,safety,log,logging,3212,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:422,security,compl,complete,422,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:911,security,availab,available,911,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1594,security,model,model,1594,"code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:3212,security,log,logging,3212,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2111,testability,Trace,Traceback,2111,"ecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can dro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:3212,testability,log,logging,3212,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:102,usability,clear,clear,102,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:288,usability,user,user,288,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:457,usability,error,errors,457,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:576,usability,Error,Error,576,"Combat will return all NaNs in adata.X if one of the batches contains only 1 cell; <!-- Please give a clear and concise description of what the bug is: -->. As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1195,usability,support,support,1195,"eislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide. In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:1436,usability,learn,learn,1436,"ysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:2162,usability,input,input-,2162,"sion 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1175:3332,usability,learn,learn,3332,"==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175
https://github.com/scverse/scanpy/issues/1176:322,energy efficiency,current,current,322,"Question about neighbors and obsp; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python. conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']. adata.obsp[neighbor_key][conn_key]. ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:157,modifiability,design decis,design decisions,157,"Question about neighbors and obsp; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python. conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']. adata.obsp[neighbor_key][conn_key]. ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:237,modifiability,extens,extension,237,"Question about neighbors and obsp; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python. conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']. adata.obsp[neighbor_key][conn_key]. ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:252,performance,perform,performs,252,"Question about neighbors and obsp; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python. conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']. adata.obsp[neighbor_key][conn_key]. ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:721,safety,except,except,721,"Question about neighbors and obsp; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python. conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']. adata.obsp[neighbor_key][conn_key]. ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:519,security,access,access,519,"Question about neighbors and obsp; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python. conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']. adata.obsp[neighbor_key][conn_key]. ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:570,testability,understand,understand,570,"Question about neighbors and obsp; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python. conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']. adata.obsp[neighbor_key][conn_key]. ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:55,usability,help,help,55,"Question about neighbors and obsp; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python. conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']. adata.obsp[neighbor_key][conn_key]. ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:252,usability,perform,performs,252,"Question about neighbors and obsp; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python. conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']. adata.obsp[neighbor_key][conn_key]. ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:330,usability,statu,status,330,"Question about neighbors and obsp; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Since I'm writing an extension that performs some analysis on neighbor graph I'm a bit confused about the current status of scanpy's way to store that information. Will connectivity matrix always be stored into `adata.obsp` making `adata.uns['neighbors']['connectivities']` deprecated? I always need to access the connectivity sparse matrix, as far as I understand the path will be. ```python. conn_key = adata.uns[neighbor_key][f'{neighbor_key}_connectivities']. adata.obsp[neighbor_key][conn_key]. ```. except when no `neighbor_key` is given and matrix is `adata.obsp['connectivities']`, correct?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1177:24,energy efficiency,GPU,GPU,24,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:119,energy efficiency,GPU,GPU,119,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:218,energy efficiency,GPU,GPU,218,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:383,modifiability,paramet,parameters,383,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:660,modifiability,pac,package,660,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:24,performance,GPU,GPU,24,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:119,performance,GPU,GPU,119,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:182,performance,perform,perform,182,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:218,performance,GPU,GPU,218,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:307,testability,simpl,simply,307,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:465,testability,simpl,simple,465,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:11,usability,workflow,workflows,11,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:182,usability,perform,perform,182,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:201,usability,workflow,workflows,201,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:307,usability,simpl,simply,307,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:457,usability,tool,tool,457,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:465,usability,simpl,simple,465,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:481,usability,tool,tool,481,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:529,usability,tool,tools,529,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:629,usability,tool,tools,629,"End to end workflows on GPU; <!-- What kind of feature would you like to request? -->. It would be very useful for the GPU data science and research community if Scanpy were able to perform end to end workflows on the GPU, using either Cupy, CuDF or both. An initial iteration of this feature could include simply swapping out the numpy imports for cupy. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1178:159,availability,cluster,clustering,159,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:159,deployability,cluster,clustering,159,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:341,deployability,API,API,341,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:371,deployability,version,versions,371,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:119,energy efficiency,GPU,GPU,119,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:341,integrability,API,API,341,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:371,integrability,version,versions,371,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:341,interoperability,API,API,341,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:359,interoperability,distribut,distributed,359,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:437,interoperability,distribut,distributed,437,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:371,modifiability,version,versions,371,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:508,modifiability,paramet,parameters,508,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:785,modifiability,pac,package,785,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:119,performance,GPU,GPU,119,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:590,testability,simpl,simple,590,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:5,usability,tool,tools,5,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:235,usability,tool,tools,235,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:351,usability,support,support,351,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:418,usability,support,support,418,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:449,usability,workflow,workflows,449,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:582,usability,tool,tool,582,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:590,usability,simpl,simple,590,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:606,usability,tool,tool,606,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:654,usability,tool,tools,654,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1178:754,usability,tool,tools,754,"More tools to offer RAPIDS backend; <!-- What kind of feature would you like to request? -->. It is a huge win for the GPU community to be able to use Louvain clustering and UMAP from RAPIDS. It would be very useful to see more of the tools providing options to use RAPIDS, such as PCA, T-SNE, and KNN. It would also be useful if the Scanpy API could support distributed versions of these algorithms, and perhaps even support end to end distributed workflows using Dask or Spark. . - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1178
https://github.com/scverse/scanpy/issues/1181:239,availability,error,error,239,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:983,availability,Error,Error,983,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:108,deployability,integr,integrate,108,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1151,deployability,modul,module,1151,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1348,deployability,fail,fails,1348,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1638,deployability,Version,Versions,1638,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1671,deployability,log,logging,1671,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:108,integrability,integr,integrate,108,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:245,integrability,messag,message,245,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1283,integrability,transform,transform,1283,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1638,integrability,Version,Versions,1638,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:108,interoperability,integr,integrate,108,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:245,interoperability,messag,message,245,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1283,interoperability,transform,transform,1283,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:108,modifiability,integr,integrate,108,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1151,modifiability,modul,module,1151,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1257,modifiability,pac,packages,1257,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1638,modifiability,Version,Versions,1638,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:239,performance,error,error,239,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:318,performance,time,time,318,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:983,performance,Error,Error,983,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:108,reliability,integr,integrate,108,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1348,reliability,fail,fails,1348,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:239,safety,error,error,239,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:983,safety,Error,Error,983,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1124,safety,input,input-,1124,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1151,safety,modul,module,1151,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1671,safety,log,logging,1671,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:108,security,integr,integrate,108,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1671,security,log,logging,1671,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:108,testability,integr,integrate,108,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1080,testability,Trace,Traceback,1080,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1671,testability,log,logging,1671,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:38,usability,clear,clear,38,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:239,usability,error,error,239,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:338,usability,command,command,338,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:517,usability,minim,minimal,517,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:983,usability,Error,Error,983,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1124,usability,input,input-,1124,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1792,usability,learn,learn,1792,"Issue with ingest; <!-- Please give a clear and concise description of what the bug is: -->. I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). # problem occurs here. sc.tl.ingest(adata, adata_ref, obs='louvain'). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. AttributeError Traceback (most recent call last). <ipython-input-12-27e22cc8f823> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames. /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X). 2006 try:. 2007 # sklearn pairwise_distances fails for callable metric on sparse data. -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func. 2009 dmat = pairwise_distances(. 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/pull/1182:180,availability,avail,available,180,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:388,deployability,integr,integrate,388,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:280,integrability,batch,batches,280,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:388,integrability,integr,integrate,388,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:388,interoperability,integr,integrate,388,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:388,modifiability,integr,integrate,388,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:280,performance,batch,batches,280,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:180,reliability,availab,available,180,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:388,reliability,integr,integrate,388,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:180,safety,avail,available,180,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:255,safety,input,input,255,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:180,security,availab,available,180,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:388,security,integr,integrate,388,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:388,testability,integr,integrate,388,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:255,usability,input,input,255,"Seurat v3 HVG method; Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/issues/1183:126,availability,error,error,126,"normalize_total throws ValueError when passed a large view; When I run sc.pp.normalize_total(adata, target_sum=1e4),I got the error:ValueError: could not convert integer scalar,and How can I fixed this issue?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:170,modifiability,scal,scalar,170,"normalize_total throws ValueError when passed a large view; When I run sc.pp.normalize_total(adata, target_sum=1e4),I got the error:ValueError: could not convert integer scalar,and How can I fixed this issue?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:126,performance,error,error,126,"normalize_total throws ValueError when passed a large view; When I run sc.pp.normalize_total(adata, target_sum=1e4),I got the error:ValueError: could not convert integer scalar,and How can I fixed this issue?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:126,safety,error,error,126,"normalize_total throws ValueError when passed a large view; When I run sc.pp.normalize_total(adata, target_sum=1e4),I got the error:ValueError: could not convert integer scalar,and How can I fixed this issue?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:126,usability,error,error,126,"normalize_total throws ValueError when passed a large view; When I run sc.pp.normalize_total(adata, target_sum=1e4),I got the error:ValueError: could not convert integer scalar,and How can I fixed this issue?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1184:183,availability,replic,replicate,183,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:355,availability,Error,Error,355,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:864,deployability,Version,Versions,864,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:864,integrability,Version,Versions,864,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:585,modifiability,interm,intermediate,585,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:864,modifiability,Version,Versions,864,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:355,performance,Error,Error,355,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:355,safety,Error,Error,355,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:54,usability,clear,clear,54,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:211,usability,visual,visualization,211,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:355,usability,Error,Error,355,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:499,usability,User,Users,499,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/issues/1184:980,usability,learn,learn,980,"Bug in _download_visium_dataset(); <!-- Please give a clear and concise description of what the bug is: -->. After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python. adata = sc.datasets.visium_sge(). ```. I get . <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'. ```. I figured it is because the intermediate folder ""/data"" is missing as well - . ```python. sample_dir.mkdir(exist_ok=True). ```. in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184
https://github.com/scverse/scanpy/pull/1185:35,reliability,doe,doesn,35,Fix datasets.visium_sge if `data/` doesn’t exist; Fixes #1184,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1185
https://github.com/scverse/scanpy/pull/1186:119,modifiability,pac,package,119,Add link to Scanpy in R guide; Hi. I have written a guide to interacting with Scanpy from R using the **{reticulate}** package which you can view at https://theislab.github.io/scanpy-in-R/. This PR just adds a link to the guide to the tutorials page in the documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/pull/1186:24,usability,guid,guide,24,Add link to Scanpy in R guide; Hi. I have written a guide to interacting with Scanpy from R using the **{reticulate}** package which you can view at https://theislab.github.io/scanpy-in-R/. This PR just adds a link to the guide to the tutorials page in the documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/pull/1186:52,usability,guid,guide,52,Add link to Scanpy in R guide; Hi. I have written a guide to interacting with Scanpy from R using the **{reticulate}** package which you can view at https://theislab.github.io/scanpy-in-R/. This PR just adds a link to the guide to the tutorials page in the documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/pull/1186:61,usability,interact,interacting,61,Add link to Scanpy in R guide; Hi. I have written a guide to interacting with Scanpy from R using the **{reticulate}** package which you can view at https://theislab.github.io/scanpy-in-R/. This PR just adds a link to the guide to the tutorials page in the documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/pull/1186:222,usability,guid,guide,222,Add link to Scanpy in R guide; Hi. I have written a guide to interacting with Scanpy from R using the **{reticulate}** package which you can view at https://theislab.github.io/scanpy-in-R/. This PR just adds a link to the guide to the tutorials page in the documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/pull/1186:257,usability,document,documentation,257,Add link to Scanpy in R guide; Hi. I have written a guide to interacting with Scanpy from R using the **{reticulate}** package which you can view at https://theislab.github.io/scanpy-in-R/. This PR just adds a link to the guide to the tutorials page in the documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/issues/1187:301,availability,cluster,clustering,301,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4346,availability,Error,Error,4346,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:301,deployability,cluster,clustering,301,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1423,deployability,scale,scale,1423,"-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2285,deployability,scale,scale,2285," sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4446,deployability,Version,Versions,4446,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4479,deployability,log,logging,4479,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:88,energy efficiency,cpu,cpus,88,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:388,energy efficiency,CPU,CPUs,388,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:408,energy efficiency,CPU,CPUs,408,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1068,energy efficiency,CPU,CPUs,1068,"ferent numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1423,energy efficiency,scale,scale,1423,"-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1930,energy efficiency,CPU,CPUs,1930,"!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2285,energy efficiency,scale,scale,2285," sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2793,energy efficiency,CPU,CPUs,2793,"neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:3347,energy efficiency,CPU,CPUs,3347,"in_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Err",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4446,integrability,Version,Versions,4446,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:185,interoperability,platform,platforms,185,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:687,interoperability,platform,platforms,687,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1423,modifiability,scal,scale,1423,"-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2285,modifiability,scal,scale,2285," sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4446,modifiability,Version,Versions,4446,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:88,performance,cpu,cpus,88,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:388,performance,CPU,CPUs,388,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:408,performance,CPU,CPUs,408,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1068,performance,CPU,CPUs,1068,"ferent numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1233,performance,cach,cache,1233,"ince reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1423,performance,scale,scale,1423,"-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1930,performance,CPU,CPUs,1930,"!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2095,performance,cach,cache,2095,"rt pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2285,performance,scale,scale,2285," sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2793,performance,CPU,CPUs,2793,"neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:3347,performance,CPU,CPUs,3347,"in_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Err",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4346,performance,Error,Error,4346,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:453,reliability,doe,doesn,453,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4346,safety,Error,Error,4346,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4479,safety,log,logging,4479,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:427,security,ident,identical,427,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4479,security,log,logging,4479,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4479,testability,log,logging,4479,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:275,usability,minim,minimal,275,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:599,usability,learn,learn,599,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:942,usability,minim,minimal,942,"Inconsistent results from arpack pca implementation using VMs with different numbers of cpus; I am finding that my analysis is not perfectly reproducible across different computational platforms. I thought I was going crazy but I have since reproduced this finding using the minimal 3000 PBMC dataset clustering example. Essentially I run the same code either on a virtual machine with 8 CPUs or one with 16 CPUs and I get non-identical PCA results. It doesn't seem to matter if I use the arpack or the randomized solver even though using the randomized solver gives the warning:. `Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.`. I'd like to just attach the jupyter notebook but it won't seem to let me do that so I'm copying the code below. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. # First run on a machine with 8 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). # Then run on a machine with 16 CPUs. import numpy as np. import pandas as pd. import scanpy as sc. ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4346,usability,Error,Error,4346,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:4606,usability,learn,learn,4606,"bors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```. This outputs the following. ```. 0. 134513. 37696. 0 659. 1 605. 2 398. 3 352. 4 342. 5 174. 6 118. 7 41. 8 11. Name: leiden, dtype: int64. 0 527. 1 484. 2 398. 3 324. 4 320. 5 301. 6 174. 7 109. 8 52. 9 11. Name: leiden, dtype: int64. 0. 134127. 37278. 0 646. 1 617. 2 382. 3 362. 4 334. 5 173. 6 129. 7 46. 8 11. Name: leiden, dtype: int64. 0 646. 1 631. 2 408. 3 349. 4 334. 5 170. 6 106. 7 45. 8 11. Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions(). -->. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/pull/1188:112,energy efficiency,core,core,112,Make normalize_total actualize views; Fixes #1183. Only thing I'm not sure of here is if this breaks any out-of-core workflows.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1188
https://github.com/scverse/scanpy/pull/1188:117,usability,workflow,workflows,117,Make normalize_total actualize views; Fixes #1183. Only thing I'm not sure of here is if this breaks any out-of-core workflows.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1188
https://github.com/scverse/scanpy/issues/1190:160,availability,error,error,160,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:978,availability,Avail,Available,978,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:8,deployability,instal,install,8,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:109,deployability,instal,install,109,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:286,deployability,instal,install,286,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:394,deployability,fail,failed,394,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:479,deployability,fail,failed,479,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:638,deployability,fail,failed,638,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:833,deployability,fail,failed,833,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:988,deployability,version,versions,988,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:988,integrability,version,versions,988,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:733,interoperability,conflict,conflicts,733,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:756,interoperability,incompatib,incompatible,756,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:876,interoperability,specif,specifications,876,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:908,interoperability,incompatib,incompatible,908,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:949,interoperability,format,format,949,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:325,modifiability,pac,package,325,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:577,modifiability,pac,package,577,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:769,modifiability,pac,packages,769,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:967,modifiability,pac,package,967,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:988,modifiability,version,versions,988,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:160,performance,error,error,160,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:394,reliability,fail,failed,394,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:479,reliability,fail,failed,479,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:638,reliability,fail,failed,638,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:833,reliability,fail,failed,833,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:978,reliability,Availab,Available,978,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:160,safety,error,error,160,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:978,safety,Avail,Available,978,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:978,security,Availab,Available,978,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:42,usability,clear,clear,42,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:160,usability,error,error,160,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:178,usability,minim,minimal,178,"unknown install issue; <!-- Please give a clear and concise description of what the bug is: -->. Not able to install with conda and no info about the source of error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```bash. (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: | . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1191:158,availability,cluster,clustering,158,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:181,availability,error,error,181,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:0,deployability,modul,module,0,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:158,deployability,cluster,clustering,158,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:361,deployability,modul,module,361,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:691,deployability,log,logg,691,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1194,deployability,modul,module,1194,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1426,deployability,Version,Versions,1426,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1459,deployability,log,logging,1459,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1426,integrability,Version,Versions,1426,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:0,modifiability,modul,module,0,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:361,modifiability,modul,module,361,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:459,modifiability,pac,packages,459,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:723,modifiability,pac,package,723,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:897,modifiability,pac,packages,897,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1194,modifiability,modul,module,1194,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1426,modifiability,Version,Versions,1426,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:181,performance,error,error,181,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:0,safety,modul,module,0,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:181,safety,error,error,181,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:334,safety,input,input-,334,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:361,safety,modul,module,361,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:691,safety,log,logg,691,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1194,safety,modul,module,1194,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1459,safety,log,logging,1459,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:691,security,log,logg,691,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1459,security,log,logging,1459,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:290,testability,Trace,Traceback,290,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:691,testability,log,logg,691,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1459,testability,log,logging,1459,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:81,usability,clear,clear,81,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:181,usability,error,error,181,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:334,usability,input,input-,334,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:475,usability,tool,tools,475,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1272,usability,minim,minimal,1272,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:1580,usability,learn,learn,1580,"module 'louvain._c_louvain' has no attribute '_set_rng_seed'; <!-- Please give a clear and concise description of what the bug is: -->. trying to run louvain clustering but got the error:. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-fe1390cdc24a> in <module>. ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed). 23 def set_rng_seed(seed):. 24 """""" Set seed for internal random number generator. """""". ---> 25 _c_louvain._set_rng_seed(seed). 26 . 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.tl.louvain(adata, resolution=1.0). ```. Python 3.7. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1192:18,deployability,version,version,18,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:75,deployability,version,version,75,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:225,deployability,version,versions,225,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:251,deployability,depend,dependencies,251,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:18,integrability,version,version,18,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:75,integrability,version,version,75,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:225,integrability,version,versions,225,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:251,integrability,depend,dependencies,251,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:139,interoperability,share,shared,139,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:18,modifiability,version,version,18,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:75,modifiability,version,version,75,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:225,modifiability,version,versions,225,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:251,modifiability,depend,dependencies,251,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:251,safety,depend,dependencies,251,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:0,testability,Trace,Trace,0,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:60,testability,trace,trace,60,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1192:251,testability,depend,dependencies,251,Trace back Scanpy version from h5ad file; Is there a way to trace back the version of Scanpy used from an h5ad file ? Our collaborator has shared some h5ad files generated over a year ago and I wanted to figure out the exact versions Scanpy and other dependencies used. Thank you.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1192
https://github.com/scverse/scanpy/issues/1193:155,availability,error,error,155,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:188,availability,fault,fault,188,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:194,availability,error,error,194,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:298,availability,error,error,298,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:833,availability,error,errors,833,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:938,availability,fault,fault,938,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:944,availability,error,error,944,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1507,availability,Error,Error,1507,"pylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2851,availability,error,errors,2851,"rallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4173,availability,error,errors,4173,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4364,availability,error,error,4364,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:884,deployability,log,logging,884,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1670,deployability,modul,module,1670," scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2871,deployability,Fail,Failed,2871,"e ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2949,deployability,Modul,Module,2949,"c.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features su",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2957,deployability,modul,module,2957,"ine 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:3974,deployability,releas,release,3974,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4488,deployability,Version,Versions,4488,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4521,deployability,log,logging,4521,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4558,deployability,Version,Version,4558,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:188,energy efficiency,fault,fault,188,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:938,energy efficiency,fault,fault,938,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1133,energy efficiency,load,load,1133,"it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4370,integrability,messag,message,4370,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4488,integrability,Version,Versions,4488,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4558,integrability,Version,Version,4558,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4370,interoperability,messag,message,4370,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:147,modifiability,pac,package,147,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1670,modifiability,modul,module,1670," scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1778,modifiability,pac,packages,1778,".getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1920,modifiability,pac,packages,1920," segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2100,modifiability,pac,packages,2100,"tered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2286,modifiability,pac,packages,2286,"pyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2492,modifiability,pac,packages,2492,"- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../..",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2632,modifiability,pac,packages,2632,"imeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_cs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2767,modifiability,pac,packages,2767,"7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:max",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2949,modifiability,Modul,Module,2949,"c.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features su",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2957,modifiability,modul,module,2957,"ine 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:3021,modifiability,pac,packages,3021,", percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:3121,modifiability,pac,packages,3121,"sing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:3435,modifiability,pac,packages,3435,"s). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:3548,modifiability,pac,packages,3548,"s. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4488,modifiability,Version,Versions,4488,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4558,modifiability,Version,Version,4558,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4579,modifiability,pac,packages,4579,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:155,performance,error,error,155,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:188,performance,fault,fault,188,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:194,performance,error,error,194,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:298,performance,error,error,298,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:833,performance,error,errors,833,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:938,performance,fault,fault,938,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:944,performance,error,error,944,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1133,performance,load,load,1133,"it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1507,performance,Error,Error,1507,"pylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1635,performance,time,timeseriesScanpy,1635,"ython. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1852,performance,parallel,parallel,1852,"), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1861,performance,parallel,parallel,1861,"2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2040,performance,parallel,parallel,2040,"enomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2227,performance,parallel,parallel,2227,"rganoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2851,performance,error,errors,2851,"rallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4173,performance,error,errors,4173,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4364,performance,error,error,4364,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:188,reliability,fault,fault,188,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:938,reliability,fault,fault,938,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2871,reliability,Fail,Failed,2871,"e ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4282,reliability,doe,doesn-t-compile,4282,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:155,safety,error,error,155,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:188,safety,fault,fault,188,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:194,safety,error,error,194,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:298,safety,error,error,298,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:833,safety,error,errors,833,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:884,safety,log,logging,884,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:938,safety,fault,fault,938,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:944,safety,error,error,944,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1507,safety,Error,Error,1507,"pylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1670,safety,modul,module,1670," scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2851,safety,error,errors,2851,"rallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2949,safety,Modul,Module,2949,"c.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features su",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2957,safety,modul,module,2957,"ine 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4173,safety,error,errors,4173,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4364,safety,error,error,4364,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4521,safety,log,logging,4521,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:884,security,log,logging,884,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4521,security,log,logging,4521,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:884,testability,log,logging,884,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1593,testability,Trace,Traceback,1593,"block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4383,testability,trace,traceback,4383,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4521,testability,log,logging,4521,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:62,usability,clear,clear,62,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:155,usability,error,error,155,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:194,usability,error,error,194,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:298,usability,error,error,298,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:533,usability,minim,minimal,533,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:833,usability,error,errors,833,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:869,usability,hint,hints,869,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:944,usability,error,error,944,"TypeError with sc.pp.calculate_qc_metrics; <!-- Please give a clear and concise description of what the bug is: -->. ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. . [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:1507,usability,Error,Error,1507,"pylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. #!/usr/bin/env python. import os, sys . import scanpy as sc. import scanpy.external as sce. import scipy as sp. import numpy as np. import pandas as pd. os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file . #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file. ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 65, in <module>. sc.pp.calculate_qc_metrics(ext_AD, inplace=True). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics. parallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:2851,usability,error,errors,2851,"rallel=parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs. proportions = top_segment_proportions(X, percent_top, parallel). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions. mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr. return _top_segment_proportions_sparse_csr_cached(data, indptr, ns). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args. error_rewrite(e, 'typing'). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite. reraise(type(e), e, None). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:3950,usability,support,supported,3950,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4173,usability,error,errors,4173,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4251,usability,user,user,4251,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4364,usability,error,error,4364,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4407,usability,minim,minimal,4407,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4665,usability,learn,learn,4665,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:4727,usability,learn,learn,4727,"n reraise. raise value.with_traceback(tb). numba.errors.TypingError: Failed at nopython (nopython frontend). Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:. def _top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. elif (end - start) > maxidx:. partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]. ^. This is not usually a problem with Numba itself but instead often caused by. the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:. http://numba.pydata.org/numba-doc/dev/reference/pysupported.html. and. http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:. http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message. and traceback, along with a minimal reproducer at:. https://github.com/numba/numba/issues/new. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... [Version](url) of the packages in path : . scanpy 1.4.4.post1. anndata 0.6.22.post1. anndata2ri 1.0.1. umap-learn 0.3.10. numpy 1.16.5. scipy 1.3.1. pandas 1.0.1. scikit-learn 0.21.3. statsmodels 0.10.1. python-igraph 0.7.1.post6. louvain 0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/pull/1194:18,safety,except,exception,18,"fixed regress out exception for constant genes; bug-fix/workaround and test for exception thrown in sc.pp.regress_out, if constant genes are part of the data, i.e. genes without variation.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1194
https://github.com/scverse/scanpy/pull/1194:71,safety,test,test,71,"fixed regress out exception for constant genes; bug-fix/workaround and test for exception thrown in sc.pp.regress_out, if constant genes are part of the data, i.e. genes without variation.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1194
https://github.com/scverse/scanpy/pull/1194:80,safety,except,exception,80,"fixed regress out exception for constant genes; bug-fix/workaround and test for exception thrown in sc.pp.regress_out, if constant genes are part of the data, i.e. genes without variation.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1194
https://github.com/scverse/scanpy/pull/1194:6,testability,regress,regress,6,"fixed regress out exception for constant genes; bug-fix/workaround and test for exception thrown in sc.pp.regress_out, if constant genes are part of the data, i.e. genes without variation.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1194
https://github.com/scverse/scanpy/pull/1194:71,testability,test,test,71,"fixed regress out exception for constant genes; bug-fix/workaround and test for exception thrown in sc.pp.regress_out, if constant genes are part of the data, i.e. genes without variation.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1194
https://github.com/scverse/scanpy/issues/1195:210,availability,cluster,cluster,210,"trackplot enhancement ; Hi,. I am recently playing around with trackplot and would like to see if there's more arguments I could manually edit the trackplot. . I am wondering if 1) we could change the order of cluster in the x axis. 2) we could change the peak shape to the bar shape so make it crowded. 3) we could add a mean (black line) within each cluster so there would be a . discontinuous horizontal black line across clusters. I am trying to get this done by looking into the code but still welcome any help!! Thanks! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1195
https://github.com/scverse/scanpy/issues/1195:352,availability,cluster,cluster,352,"trackplot enhancement ; Hi,. I am recently playing around with trackplot and would like to see if there's more arguments I could manually edit the trackplot. . I am wondering if 1) we could change the order of cluster in the x axis. 2) we could change the peak shape to the bar shape so make it crowded. 3) we could add a mean (black line) within each cluster so there would be a . discontinuous horizontal black line across clusters. I am trying to get this done by looking into the code but still welcome any help!! Thanks! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1195
https://github.com/scverse/scanpy/issues/1195:425,availability,cluster,clusters,425,"trackplot enhancement ; Hi,. I am recently playing around with trackplot and would like to see if there's more arguments I could manually edit the trackplot. . I am wondering if 1) we could change the order of cluster in the x axis. 2) we could change the peak shape to the bar shape so make it crowded. 3) we could add a mean (black line) within each cluster so there would be a . discontinuous horizontal black line across clusters. I am trying to get this done by looking into the code but still welcome any help!! Thanks! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1195
https://github.com/scverse/scanpy/issues/1195:210,deployability,cluster,cluster,210,"trackplot enhancement ; Hi,. I am recently playing around with trackplot and would like to see if there's more arguments I could manually edit the trackplot. . I am wondering if 1) we could change the order of cluster in the x axis. 2) we could change the peak shape to the bar shape so make it crowded. 3) we could add a mean (black line) within each cluster so there would be a . discontinuous horizontal black line across clusters. I am trying to get this done by looking into the code but still welcome any help!! Thanks! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1195
https://github.com/scverse/scanpy/issues/1195:352,deployability,cluster,cluster,352,"trackplot enhancement ; Hi,. I am recently playing around with trackplot and would like to see if there's more arguments I could manually edit the trackplot. . I am wondering if 1) we could change the order of cluster in the x axis. 2) we could change the peak shape to the bar shape so make it crowded. 3) we could add a mean (black line) within each cluster so there would be a . discontinuous horizontal black line across clusters. I am trying to get this done by looking into the code but still welcome any help!! Thanks! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1195
https://github.com/scverse/scanpy/issues/1195:425,deployability,cluster,clusters,425,"trackplot enhancement ; Hi,. I am recently playing around with trackplot and would like to see if there's more arguments I could manually edit the trackplot. . I am wondering if 1) we could change the order of cluster in the x axis. 2) we could change the peak shape to the bar shape so make it crowded. 3) we could add a mean (black line) within each cluster so there would be a . discontinuous horizontal black line across clusters. I am trying to get this done by looking into the code but still welcome any help!! Thanks! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1195
https://github.com/scverse/scanpy/issues/1195:511,usability,help,help,511,"trackplot enhancement ; Hi,. I am recently playing around with trackplot and would like to see if there's more arguments I could manually edit the trackplot. . I am wondering if 1) we could change the order of cluster in the x axis. 2) we could change the peak shape to the bar shape so make it crowded. 3) we could add a mean (black line) within each cluster so there would be a . discontinuous horizontal black line across clusters. I am trying to get this done by looking into the code but still welcome any help!! Thanks! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1195
https://github.com/scverse/scanpy/pull/1196:452,deployability,build,build,452,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:461,deployability,fail,failing,461,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:108,energy efficiency,Current,Currently,108,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:9,performance,memor,memory,9,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:274,performance,memor,memory,274,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:213,reliability,doe,doesn,213,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:461,reliability,fail,failing,461,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:54,safety,Avoid,Avoids,54,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:362,safety,compl,completely,362,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:373,safety,avoid,avoided,373,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:476,safety,compl,completely,476,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:362,security,compl,completely,362,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:476,security,compl,completely,476,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:9,usability,memor,memory,9,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:16,usability,efficien,efficiency,16,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:274,usability,memor,memory,274,"improved memory efficiency in _score_genes; In short: Avoids creating dense matrices for score calculation. Currently, `_score_genes()` unnecessarily creates dense matrices to use the `np.nanmean` function (which doesn't work on sparse matrices out of the box). This causes memory problems for larger datasets (anything 50k cells got me into trouble) and can be completely avoided with a `nanmean()` implementation of sparse matrices. Not sure why the build is failing now in completely unrelated functions though!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1197:29,deployability,API,API,29,"Fix for louvain 0.7+ compat; API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197
https://github.com/scverse/scanpy/pull/1197:59,deployability,updat,updated,59,"Fix for louvain 0.7+ compat; API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197
https://github.com/scverse/scanpy/pull/1197:186,deployability,version,versions,186,"Fix for louvain 0.7+ compat; API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197
https://github.com/scverse/scanpy/pull/1197:29,integrability,API,API,29,"Fix for louvain 0.7+ compat; API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197
https://github.com/scverse/scanpy/pull/1197:186,integrability,version,versions,186,"Fix for louvain 0.7+ compat; API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197
https://github.com/scverse/scanpy/pull/1197:29,interoperability,API,API,29,"Fix for louvain 0.7+ compat; API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197
https://github.com/scverse/scanpy/pull/1197:186,modifiability,version,versions,186,"Fix for louvain 0.7+ compat; API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197
https://github.com/scverse/scanpy/pull/1197:59,safety,updat,updated,59,"Fix for louvain 0.7+ compat; API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197
https://github.com/scverse/scanpy/pull/1197:59,security,updat,updated,59,"Fix for louvain 0.7+ compat; API for louvain 0.7+ has been updated to have the seed passed to the partition function, like in `leidenalg`. This PR makes our function work with the newer versions of `louvain`. Issue from louvain repo: https://github.com/vtraag/louvain-igraph/issues/54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1197
https://github.com/scverse/scanpy/issues/1198:0,availability,Error,Error,0,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:452,availability,error,error,452,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:471,availability,Error,Error,471,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:777,availability,Error,Error,777,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:864,deployability,Version,Versions,864,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:897,deployability,log,logging,897,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:547,integrability,sub,subset,547,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:864,integrability,Version,Versions,864,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:418,modifiability,pac,package,418,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:864,modifiability,Version,Versions,864,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:0,performance,Error,Error,0,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:452,performance,error,error,452,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:471,performance,Error,Error,471,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:777,performance,Error,Error,777,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:0,safety,Error,Error,0,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:102,safety,input,inputting,102,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:452,safety,error,error,452,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:471,safety,Error,Error,471,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:777,safety,Error,Error,777,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:897,safety,log,logging,897,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:897,security,log,logging,897,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:897,testability,log,logging,897,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:0,usability,Error,Error,0,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:102,usability,input,inputting,102,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:151,usability,tool,tools,151,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:201,usability,clear,clear,201,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:294,usability,workflow,workflow,294,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:452,usability,error,error,452,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:471,usability,Error,Error,471,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:649,usability,minim,minimal,649,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:777,usability,Error,Error,777,"Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting ; Hi all,. Thanks to develop the great tools for singlecell analysis. <!-- Please give a clear and concise description of what the bug is: -->. The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, . as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:. Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset. What happen in this situation? . and how to fix it? any advices would be grateful. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. Python 3.8.2 . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy 1.4.6. > .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1199:216,availability,error,error,216,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2514,availability,Error,Error,2514,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:311,deployability,modul,module,311,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:668,deployability,scale,scale,668,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2614,deployability,Version,Versions,2614,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2647,deployability,log,logging,2647,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:668,energy efficiency,scale,scale,668,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:971,energy efficiency,core,core,971,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:1196,energy efficiency,core,core,1196,"ction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:1449,energy efficiency,core,core,1449,"adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:1753,energy efficiency,core,core,1753,"ray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2070,energy efficiency,core,core,2070,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2165,integrability,sub,subarr,2165,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2291,integrability,sub,subarr,2291,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2614,integrability,Version,Versions,2614,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:311,modifiability,modul,module,311,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:525,modifiability,pac,packages,525,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:668,modifiability,scal,scale,668,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:955,modifiability,pac,packages,955,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:1180,modifiability,pac,packages,1180,"oups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:1433,modifiability,pac,packages,1433,"groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reprod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:1737,modifiability,pac,packages,1737,"l = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2054,modifiability,pac,packages,2054,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2614,modifiability,Version,Versions,2614,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:216,performance,error,error,216,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:668,performance,scale,scale,668,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2514,performance,Error,Error,2514,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:0,safety,Except,Exception,0,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:216,safety,error,error,216,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:229,safety,Except,Exception,229,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:283,safety,input,input-,283,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:311,safety,modul,module,311,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:1616,safety,except,except,1616,", gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2235,safety,Except,Exception,2235,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2342,safety,Except,Exception,2342,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2514,safety,Error,Error,2514,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2647,safety,log,logging,2647,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2647,security,log,logging,2647,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:239,testability,Trace,Traceback,239,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2647,testability,log,logging,2647,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:94,usability,clear,clear,94,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:216,usability,error,error,216,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:283,usability,input,input-,283,"Exception: Data must be 1-dimensional from sc.pl.rank_genes_groups_violin; <!-- Please give a clear and concise description of what the bug is: -->. I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```. Exception Traceback (most recent call last). <ipython-input-195-8f87448845a3> in <module>. 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'). ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2397,usability,minim,minimal,2397,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2514,usability,Error,Error,2514,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:2768,usability,learn,learn,2768,"ta.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 2936 else:. 2937 # set column. -> 2938 self._set_item(key, value). 2939 . 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 2997 """""". 2998 . -> 2999 self._ensure_valid_index(value). 3000 value = self._sanitize_column(key, value). 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3052 if not len(self.index) and is_list_like(value) and len(value):. 3053 try:. -> 3054 value = Series(value). 3055 except (ValueError, NotImplementedError, TypeError):. 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 303 data = data.copy(). 304 else:. --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). 306 . 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure). 480 elif subarr.ndim > 1:. 481 if isinstance(data, np.ndarray):. --> 482 raise Exception(""Data must be 1-dimensional""). 483 else:. 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional. ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/pull/1200:7,deployability,scale,scale,7,Bugfix scale centering;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1200
https://github.com/scverse/scanpy/pull/1200:7,energy efficiency,scale,scale,7,Bugfix scale centering;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1200
https://github.com/scverse/scanpy/pull/1200:7,modifiability,scal,scale,7,Bugfix scale centering;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1200
https://github.com/scverse/scanpy/pull/1200:7,performance,scale,scale,7,Bugfix scale centering;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1200
https://github.com/scverse/scanpy/issues/1201:7,availability,error,error,7,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:213,availability,avail,available,213,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:887,availability,Error,Error,887,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:226,deployability,fail,fails,226,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:1215,deployability,Version,Versions,1215,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:1248,deployability,log,logging,1248,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:595,integrability,batch,batch,595,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:617,integrability,batch,batch,617,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:764,integrability,batch,batch,764,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:1215,integrability,Version,Versions,1215,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:1215,modifiability,Version,Versions,1215,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:7,performance,error,error,7,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:595,performance,batch,batch,595,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:617,performance,batch,batch,617,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:764,performance,batch,batch,764,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:887,performance,Error,Error,887,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:213,reliability,availab,available,213,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:226,reliability,fail,fails,226,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:7,safety,error,error,7,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:213,safety,avail,available,213,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:887,safety,Error,Error,887,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:1248,safety,log,logging,1248,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:213,security,availab,available,213,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:1248,security,log,logging,1248,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:1248,testability,log,logging,1248,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:7,usability,error,error,7,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:59,usability,clear,clear,59,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:278,usability,minim,minimal,278,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:887,usability,Error,Error,887,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:987,usability,tool,tools,987,"Ingest error when neighbors from bbknn; <!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc68k_reduced(). adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # add fake batch. adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref). sc.external.pp.bbknn(adata_ref, batch_key='batch'). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 283 dist_args = (). 284 . --> 285 self._metric = neighbors['params']['metric']. 286 dist_func = named_distances[self._metric]. 287 . KeyError: 'metric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev83+g5345a50.d20200506.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1202:293,availability,Error,Error,293,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:503,deployability,Version,Versions,503,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:536,deployability,log,logging,536,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:503,integrability,Version,Versions,503,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:465,modifiability,pac,packages,465,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:503,modifiability,Version,Versions,503,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:293,performance,Error,Error,293,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:293,safety,Error,Error,293,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:536,safety,log,logging,536,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:536,security,log,logging,536,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:536,testability,log,logging,536,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:55,usability,clear,clear,55,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:293,usability,Error,Error,293,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:646,usability,learn,learn,646,"Wrong UMAP reference in _ingest.py; <!-- Please give a clear and concise description of what the bug is: -->. _ingest.py tries to import the UMAP function like so:. `from umap import UMAP`. I believe this is wrong, and it should be replaced with:. `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1203:78,energy efficiency,current,current,78,"sc.pl.paga: TypeError: paga() got an unexpected keyword argument 'ncols'; The current paga plot output a n_row =1 plot, which is not very user-friendly. It would be nice to have an option to control n_col as other plot functions in scanpy do. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1203
https://github.com/scverse/scanpy/issues/1203:191,security,control,control,191,"sc.pl.paga: TypeError: paga() got an unexpected keyword argument 'ncols'; The current paga plot output a n_row =1 plot, which is not very user-friendly. It would be nice to have an option to control n_col as other plot functions in scanpy do. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1203
https://github.com/scverse/scanpy/issues/1203:191,testability,control,control,191,"sc.pl.paga: TypeError: paga() got an unexpected keyword argument 'ncols'; The current paga plot output a n_row =1 plot, which is not very user-friendly. It would be nice to have an option to control n_col as other plot functions in scanpy do. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1203
https://github.com/scverse/scanpy/issues/1203:138,usability,user,user-friendly,138,"sc.pl.paga: TypeError: paga() got an unexpected keyword argument 'ncols'; The current paga plot output a n_row =1 plot, which is not very user-friendly. It would be nice to have an option to control n_col as other plot functions in scanpy do. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1203
https://github.com/scverse/scanpy/issues/1205:783,deployability,integr,integration,783,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:851,energy efficiency,current,currently,851,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:783,integrability,integr,integration,783,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:864,integrability,sub,submit,864,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:1098,integrability,abstract,abstract,1098,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:783,interoperability,integr,integration,783,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:149,modifiability,paramet,parameters,149,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:426,modifiability,pac,package,426,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:677,modifiability,pac,package,677,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:783,modifiability,integr,integration,783,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:1098,modifiability,abstract,abstract,1098,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:783,reliability,integr,integration,783,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:783,security,integr,integration,783,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:231,testability,simpl,simple,231,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:783,testability,integr,integration,783,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:914,testability,plan,plans,914,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:13,usability,learn,learning,13,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:223,usability,tool,tool,223,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:231,usability,simpl,simple,231,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:247,usability,tool,tool,247,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:295,usability,tool,tools,295,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:395,usability,tool,tools,395,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:578,usability,learn,learning,578,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:840,usability,experien,experience,840,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:961,usability,learn,learning,961,"Add transfer learning (TL) technique such as ProjectR to scanpy; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. We are increasingly using ProjectR as a transfer learning technique from one dataset onto others. It would be great if this were part of the scanpy package, since most of the rest of what we do with single-cell uses scanpy. I'm going to start working on integration of the two but doubt I have the data science experience currently to submit a PR to this project for it. Are there any plans already in the works to pull in transfer-learning techniques such as this? Relevant links:. - [Article in Bioinformatics](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btaa183/5804979?redirectedFrom=PDF). - [Article in Cell](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30146-2.pdf). - [GitHub](https://github.com/genesofeve/projectR)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/pull/1206:0,deployability,Log,Logging,0,Logging cosmetics and link to spatial tutorial;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1206
https://github.com/scverse/scanpy/pull/1206:0,safety,Log,Logging,0,Logging cosmetics and link to spatial tutorial;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1206
https://github.com/scverse/scanpy/pull/1206:0,security,Log,Logging,0,Logging cosmetics and link to spatial tutorial;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1206
https://github.com/scverse/scanpy/pull/1206:0,testability,Log,Logging,0,Logging cosmetics and link to spatial tutorial;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1206
https://github.com/scverse/scanpy/issues/1207:3,deployability,scale,scale,3,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:18,deployability,scale,scale,18,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:29,deployability,updat,update,29,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:3,energy efficiency,scale,scale,3,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:18,energy efficiency,scale,scale,18,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:3,modifiability,scal,scale,3,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:18,modifiability,scal,scale,18,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:3,performance,scale,scale,3,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:18,performance,scale,scale,18,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:10,reliability,Doe,Does,10,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:29,safety,updat,update,29,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1207:29,security,updat,update,29,pp.scale; Does pp.scale also update the raw expression matrix in the raw attribute?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1208:469,availability,Error,Error,469,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:274,deployability,version,version,274,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:644,deployability,modul,module,644,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:713,deployability,modul,module,713,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:793,deployability,Version,Versions,793,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:826,deployability,log,logging,826,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:274,integrability,version,version,274,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:793,integrability,Version,Versions,793,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:274,modifiability,version,version,274,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:644,modifiability,modul,module,644,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:713,modifiability,modul,module,713,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:793,modifiability,Version,Versions,793,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:469,performance,Error,Error,469,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:469,safety,Error,Error,469,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:617,safety,input,input-,617,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:644,safety,modul,module,644,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:713,safety,modul,module,713,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:826,safety,log,logging,826,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:117,security,team,team,117,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:826,security,log,logging,826,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:573,testability,Trace,Traceback,573,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:826,testability,log,logging,826,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:52,usability,clear,clear,52,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:308,usability,help,help,308,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:325,usability,minim,minimal,325,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:469,usability,Error,Error,469,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:617,usability,input,input-,617,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:965,usability,learn,learn,965,"pp.normalize_geometric(protein); <!-- Please give a clear and concise description of what the bug is: -->. Hi Scanpy team,. I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue? Thank you for your help! <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...AttributeError Traceback (most recent call last). <ipython-input-80-db93ca6d0f1d> in <module>. ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/pull/1209:34,safety,test,test,34,renamed coords to spatial and fix test; As discussed previously @falexwolf @ivirshup,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1209
https://github.com/scverse/scanpy/pull/1209:34,testability,test,test,34,renamed coords to spatial and fix test; As discussed previously @falexwolf @ivirshup,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1209
https://github.com/scverse/scanpy/pull/1210:2078,availability,consist,consistent,2078,". The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:380,deployability,log,log,380,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:629,deployability,Stack,StackedVioling,629,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:1911,deployability,log,log,1911,"ed to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the tota",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3659,deployability,log,log,3659,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3816,deployability,log,log,3816,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3858,deployability,updat,update,3858,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4131,deployability,Updat,Update,4131,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4151,deployability,Updat,Update,4151,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:167,energy efficiency,current,current,167,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:562,integrability,transform,transformed,562,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:579,integrability,wrap,wrappers,579,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:562,interoperability,transform,transformed,562,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:579,interoperability,wrapper,wrappers,579,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:1059,interoperability,share,shared,1059," addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:2176,interoperability,specif,specific,2176,"ws the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:836,modifiability,paramet,parameter,836,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:1292,modifiability,paramet,parameters,1292,"more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with op",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:2165,modifiability,paramet,parameters,2165," This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:285,performance,time,time,285,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:2880,performance,tune,tuned,2880,"1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:380,safety,log,log,380,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:1911,safety,log,log,1911,"ed to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the tota",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3659,safety,log,log,3659,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3816,safety,log,log,3816,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3858,safety,updat,update,3858,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4131,safety,Updat,Update,4131,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4138,safety,test,tests,4138,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4151,safety,Updat,Update,4151,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:380,security,log,log,380,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:654,security,Access,Accessing,654,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:1488,security,modif,modify,1488,"otplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-imag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:1911,security,log,log,1911,"ed to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the tota",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3255,security,modif,modified,3255,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3659,security,log,log,3659,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3816,security,log,log,3816,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3858,security,updat,update,3858,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4131,security,Updat,Update,4131,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4151,security,Updat,Update,4151,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:380,testability,log,log,380,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:1911,testability,log,log,1911,"ed to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the tota",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3659,testability,log,log,3659,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:3816,testability,log,log,3816,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4138,testability,test,tests,4138,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:874,usability,clarit,clarity,874,"improvements on plotting functions that use 'groupby'; This PR addresses issues from #979 and #1103 related to `sc.pl.dotplot` and replaces PR #1127. Furthermore, the current PR attempts to unify common code between `dotplot`, `matrixplot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_colo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:1230,usability,document,documented,1230,"lot` and `stacked_violin` plots while at the same time adding more flexibility to the plots. . This PR also makes possible to plot fold changes, log fold changes and p-values from `sc.tl.rank_genes_groups` as suggested in #562. To achieve this the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` method had been transformed into wrappers for the new `DotPlot`, `MatrixPlot` and `StackedVioling` classes. Accessing the new classes directly allows further fine tuning of the plots. The use of the `sc.pl.dotplot`, `sc.pl.matrixplot` and `sc.pl.stacked_violin` didn't change, only the new parameter `return_fig` was added. For clarity, the relevant code has been moved to `scanpy.plotting._groupby_plots.py`. . The new plot classes are all descendants of a `BasePlot` class that captures most of the common code shared between the plots. The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:2078,usability,consist,consistent,2078,". The design of the classes follows the method chaining (as found in Pandas or Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:2158,usability,visual,visual,2158," Altair). This allows the addition of independent features (via well documented methods) to the plot without increasing the number parameters of a single function. This was first suggested here #956. . For example, for dotplot is now is possible to `add category totals`, define the titles for the colorbar and size legend and modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:2482,usability,user,user-images,2482,"modify the values for edge color and edge line with for dot plot and the size exponent used (among may other options). For example:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], . 'myeloid': ['CST3', 'LYZ']}. dp = sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the Dot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:2853,usability,visual,visual,2853,"=True). dp.add_totals(size=1.2)\. .legend(color_title='log(UMI count+1)', width=1.6, show_size_legend=True)\. .style(cmap='Blues', dot_edge_color='black', dot_edge_lw=1, size_exponent=1.5)\. .show(). ```. All objects have consistent functions for `legend`, to set up titles and width, `style()` to set visual parameters specific to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:4106,usability,visual,visualized,4106,"ic to each plot like colormap, edge color, linewidth. `swap_axes` to transpose the figure, `add_dendrogram` with options to change the with of the dendrogran and `add_total` tho show a bar plot of the total number of cells per category. Also includes options to sort the categories. ![image](https://user-images.githubusercontent.com/4964309/81702505-a9d5e400-946b-11ea-823b-018f5dadac84.png). Here is description of changes:. **all figures**:. * Set a title to the image. . * Pass an `axe` where to plot the image. * Return a dictionary of axes for further manipulation. * using `return_fig` the plot object can be used to adjust the proportions to the legend and other visual aspects can be fine tuned. * a bar plot with the totals per category can be added. This will align at the left of the image if the categories are plotted in rows or at the top if they are plotted in columns. * legend can be removed. * `groupby` can be a list of categories. . **dotplot**. * Improved the colorbar and size legend for dotplots. Now the colorbar and size have titles, which can be modified using the `colorbar_title` and `size_title` arguments. They also align at the bottom of the image and do not shrink if the dotplot image is smaller. * Plot genes in rows and categories in columns (swap_axes). * Using the DotPlot object the dot_edge_color and line width can be set up, a grid added as well as several other features. * `sc.pl.rank_genes_groups_dotplot` can now plot `pvals` and `log fold changes`. **matrixplot**. * added title for colorbar and positioned as in dotplot. * `sc.pl.rank_genes_groups_matrixplot` can now plot `pvals` and `log fold changes`. **stacked_violin**. * [update] violin colors can be colored based on average gene expression as in dotplots. * made the linewidth of the violin plots smaller. * removed the tics for the y axis as they tend to overlap with each other. Using the `style` method they can be visualized. TODO:. - [x] Update tests. - [x] Update tutorial and readthedocs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/issues/1211:19,reliability,doe,does,19,"pca_variance_ratio does not return axis; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L120-L129. Is it meant that the `pca_variance_ratio` does not return the generated axis? There is no `return` in the function definition, in addition to it not handling the returned fig object from `ranking(...)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1211:210,reliability,doe,does,210,"pca_variance_ratio does not return axis; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L120-L129. Is it meant that the `pca_variance_ratio` does not return the generated axis? There is no `return` in the function definition, in addition to it not handling the returned fig object from `ranking(...)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/pull/1212:0,deployability,updat,update,0,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:12,deployability,version,version,12,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:30,deployability,Updat,Updating,30,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:44,deployability,version,version,44,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:12,integrability,version,version,12,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:44,integrability,version,version,44,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:12,modifiability,version,version,12,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:44,modifiability,version,version,44,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:0,safety,updat,update,0,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:30,safety,Updat,Updating,30,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:0,security,updat,update,0,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:30,security,Updat,Updating,30,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/pull/1212:69,usability,support,supports,69,update scvi version to 0.6.5; Updating scvi version to 0.6.5. It now supports Python 3.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1212
https://github.com/scverse/scanpy/issues/1213:539,availability,Error,Error,539,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:639,deployability,Version,Versions,639,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:672,deployability,log,logging,672,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:166,integrability,filter,filter,166,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:639,integrability,Version,Versions,639,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:639,modifiability,Version,Versions,639,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:539,performance,Error,Error,539,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:539,safety,Error,Error,539,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:672,safety,log,logging,672,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:672,security,log,logging,672,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:672,testability,log,logging,672,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:83,usability,clear,clear,83,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:422,usability,minim,minimal,422,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:539,usability,Error,Error,539,"filter_rank_genes_groups condition should be OR instead of AND; <!-- Please give a clear and concise description of what the bug is: -->. here is the code for marker filter. I think the 3 condition need to be OR instead of AND. gene_names = gene_names[. (fraction_in_cluster_matrix > min_in_group_fraction) &. (fraction_out_cluster_matrix < max_out_group_fraction) &. (fold_change_matrix > min_fold_change). ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/pull/1215:127,interoperability,format,formatting,127,Allow combat to run when `obs_names` are not unique; Fixes #1170 by not requiring unique `obs_names` to run combat. I also ran formatting over combat and the combat tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1215
https://github.com/scverse/scanpy/pull/1215:165,safety,test,tests,165,Allow combat to run when `obs_names` are not unique; Fixes #1170 by not requiring unique `obs_names` to run combat. I also ran formatting over combat and the combat tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1215
https://github.com/scverse/scanpy/pull/1215:165,testability,test,tests,165,Allow combat to run when `obs_names` are not unique; Fixes #1170 by not requiring unique `obs_names` to run combat. I also ran formatting over combat and the combat tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1215
https://github.com/scverse/scanpy/pull/1216:0,deployability,Updat,Update,0,Update install instructions to use leiden;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1216
https://github.com/scverse/scanpy/pull/1216:7,deployability,instal,install,7,Update install instructions to use leiden;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1216
https://github.com/scverse/scanpy/pull/1216:0,safety,Updat,Update,0,Update install instructions to use leiden;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1216
https://github.com/scverse/scanpy/pull/1216:0,security,Updat,Update,0,Update install instructions to use leiden;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1216
https://github.com/scverse/scanpy/pull/1217:156,availability,state,statements,156,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:181,deployability,version,version,181,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:143,integrability,coupl,couple,143,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:156,integrability,state,statements,156,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:181,integrability,version,version,181,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:143,modifiability,coupl,couple,143,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:181,modifiability,version,version,181,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:24,safety,test,test,24,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:24,testability,test,test,24,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:143,testability,coupl,couple,143,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:74,usability,close,closes,74,"fix inverted coords and test; This PR supersedes theislab/scanpy#1149 and closes theislab/scanpy#1148 and theislab/scanpy#1059. I have changed couple of if statements from previous version, now it plots circles and not scatterplot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1218:0,deployability,Updat,Update,0,Update release notes; Added a bunch of stuff to the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1218
https://github.com/scverse/scanpy/pull/1218:7,deployability,releas,release,7,Update release notes; Added a bunch of stuff to the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1218
https://github.com/scverse/scanpy/pull/1218:52,deployability,releas,release,52,Update release notes; Added a bunch of stuff to the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1218
https://github.com/scverse/scanpy/pull/1218:0,safety,Updat,Update,0,Update release notes; Added a bunch of stuff to the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1218
https://github.com/scverse/scanpy/pull/1218:0,security,Updat,Update,0,Update release notes; Added a bunch of stuff to the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1218
https://github.com/scverse/scanpy/pull/1219:0,deployability,updat,update,0,update with spatial functions;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1219
https://github.com/scverse/scanpy/pull/1219:0,safety,updat,update,0,update with spatial functions;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1219
https://github.com/scverse/scanpy/pull/1219:0,security,updat,update,0,update with spatial functions;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1219
https://github.com/scverse/scanpy/issues/1220:362,availability,error,error,362,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:87,deployability,fail,failed,87,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:113,deployability,instal,installation,113,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:171,deployability,fail,failed,171,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:181,deployability,instal,install,181,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:393,deployability,fail,failed,393,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:271,performance,content,contents,271,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:362,performance,error,error,362,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:87,reliability,fail,failed,87,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:171,reliability,fail,failed,171,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:393,reliability,fail,failed,393,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:362,safety,error,error,362,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:362,usability,error,error,362,ResolvePackageNotFound: - louvain - bioconductor-rhdf5lib /Also CondaEnvException: Pip failed; Hi. I'm facing an installation issue. The issues are explained below. I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** . error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1221:38,availability,error,errors,38,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:184,availability,error,error,184,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:196,availability,Error,Error,196,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:485,availability,Error,Error,485,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1023,availability,Down,Downloaded,1023,"tlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1571,availability,down,downloaded,1571,"----------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2488,availability,error,error,2488,"hook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2634,availability,error,error,2634," in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3466,availability,Error,Error,3466,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:220,deployability,version,version,220,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:728,deployability,modul,module,728,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1011,deployability,log,logg,1011,"bi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3489,deployability,Version,Versions,3489,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3522,deployability,log,logging,3522,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3561,deployability,version,version,3561,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3746,deployability,version,version,3746,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:220,integrability,version,version,220,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2205,integrability,protocol,protocol,2205," . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2821,integrability,abstract,abstract,2821,"aconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3489,integrability,Version,Versions,3489,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3561,integrability,version,version,3561,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3746,integrability,version,version,3746,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2205,interoperability,protocol,protocol,2205," . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:220,modifiability,version,version,220,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:728,modifiability,modul,module,728,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:844,modifiability,pac,packages,844,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1122,modifiability,pac,packages,1122," use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1379,modifiability,pac,packages,1379,"hon. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2821,modifiability,abstract,abstract,2821,"aconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3489,modifiability,Version,Versions,3489,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3561,modifiability,version,version,3561,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3746,modifiability,version,version,3746,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:38,performance,error,errors,38,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:184,performance,error,error,184,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:196,performance,Error,Error,196,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:485,performance,Error,Error,485,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1898,performance,time,timeout,1898,"xpression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2015,performance,time,timeout,2015,"o(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getatt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2148,performance,time,timeout,2148,"expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2488,performance,error,error,2488,"hook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2634,performance,error,error,2634," in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3466,performance,Error,Error,3466,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1552,reliability,doe,doesn,1552,": -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:38,safety,error,errors,38,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:184,safety,error,error,184,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:196,safety,Error,Error,196,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:485,safety,Error,Error,485,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:702,safety,input,input-,702,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:728,safety,modul,module,728,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1011,safety,log,logg,1011,"bi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1512,safety,except,except,1512,"k (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', req",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1519,safety,Except,Exception,1519,"licable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, res",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1898,safety,timeout,timeout,1898,"xpression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2015,safety,timeout,timeout,2015,"o(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getatt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2148,safety,timeout,timeout,2148,"expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2488,safety,error,error,2488,"hook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2634,safety,error,error,2634," in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3466,safety,Error,Error,3466,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3522,safety,log,logging,3522,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:918,security,access,accession,918,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:989,security,access,accession,989,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1011,security,log,logg,1011,"bi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1035,security,access,accession,1035,"rors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1195,security,access,accession,1195,"r 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3522,security,log,logging,3522,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:658,testability,Trace,Traceback,658,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1011,testability,log,logg,1011,"bi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1743,testability,context,contextlib,1743,"ta = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:1934,testability,context,context,1934,"ring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3522,testability,log,logging,3522,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:38,usability,error,errors,38,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:65,usability,clear,clear,65,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:184,usability,error,error,184,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:196,usability,Error,Error,196,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:294,usability,minim,minimal,294,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:485,usability,Error,Error,485,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:702,usability,input,input-,702,"sc.datasets.ebi_expression_atlas http errors; <!-- Please give a clear and concise description of what the bug is: -->. When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. HTTPError Traceback (most recent call last). <ipython-input-6-0ae186d1a0d7> in <module>. ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring). 117 pass. 118 . --> 119 download_experiment(accession). 120 . 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41 . 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path). 877 . 878 try:. --> 879 urlretrieve(url, str(path), reporthook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2488,usability,error,error,2488,"hook=update_to). 880 except Exception:. 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:2634,usability,error,error,2634," in urlretrieve(url, filename, reporthook, data). 246 url_type, path = splittype(url). 247 . --> 248 with contextlib.closing(urlopen(url, data)) as fp:. 249 headers = fp.info(). 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3466,usability,Error,Error,3466,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3662,usability,learn,learn,3662,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:3847,usability,learn,learn,3847,"url, data, timeout, cafile, capath, cadefault, context). 221 else:. 222 opener = _opener. --> 223 return opener.open(url, data, timeout). 224 . 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout). 530 for processor in self.process_response.get(protocol, []):. 531 meth = getattr(processor, meth_name). --> 532 response = meth(req, response). 533 . 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response). 640 if not (200 <= code < 300):. 641 response = self.parent.error(. --> 642 'http', request, response, code, msg, hdrs). 643 . 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args). 568 if http_err:. 569 args = (dict, 'default', 'http_error_default') + orig_args. --> 570 return self._call_chain(*args). 571 . 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args). 502 for handler in handlers:. 503 func = getattr(handler, meth_name). --> 504 result = func(*args). 505 if result is not None:. 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs). 648 class HTTPDefaultErrorHandler(BaseHandler):. 649 def http_error_default(self, req, fp, code, msg, hdrs):. --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp). 651 . 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: . ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. My local version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1222:361,availability,Error,Error,361,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:455,availability,error,error,455,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:107,deployability,fail,failing,107,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:553,deployability,modul,module,553,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1229,deployability,Version,Versions,1229,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1262,deployability,log,logging,1262,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:286,integrability,batch,batch,286,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1229,integrability,Version,Versions,1229,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:6,interoperability,mismatch,mismatch,6,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1120,interoperability,mismatch,mismatch,1120,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:553,modifiability,modul,module,553,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:614,modifiability,pac,packages,614,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:720,modifiability,pac,packages,720,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:845,modifiability,pac,packages,845,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:988,modifiability,pac,packages,988,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1229,modifiability,Version,Versions,1229,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:286,performance,batch,batch,286,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:361,performance,Error,Error,361,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:455,performance,error,error,455,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:107,reliability,fail,failing,107,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:361,safety,Error,Error,361,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:455,safety,error,error,455,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:553,safety,modul,module,553,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1262,safety,log,logging,1262,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1262,security,log,logging,1262,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:463,testability,Trace,Traceback,463,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1262,testability,log,logging,1262,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:150,usability,minim,minimal,150,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:361,usability,Error,Error,361,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:447,usability,Command,Command,447,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:455,usability,error,error,455,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1222:1383,usability,learn,learn,1383,"shape mismatch with bbknn; I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.external.pp.bbknn(. adata,. batch_key=""batch"",. n_pcs=21,. neighbors_within_batch=5,. trim=0). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Command error:. Traceback (most recent call last):. File ""~/sc_batch_effect_correction.py"", line 160, in <module>. trim=args.trim). File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn. **kwargs,. File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn. approx=approx, metric=metric, **kwargs). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix. neighbors_within_batch=neighbors_within_batch). File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph. knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]. ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222
https://github.com/scverse/scanpy/issues/1223:571,availability,Error,Error,571,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:673,availability,fault,fault,673,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:746,deployability,Version,Versions,746,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:779,deployability,log,logging,779,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:822,deployability,version,version,822,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:673,energy efficiency,fault,fault,673,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:680,energy efficiency,core,core,680,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:746,integrability,Version,Versions,746,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:822,integrability,version,version,822,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:158,modifiability,pac,packages,158,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:746,modifiability,Version,Versions,746,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:822,modifiability,version,version,822,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:323,performance,cach,cache,323,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:571,performance,Error,Error,571,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:673,performance,fault,fault,673,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:673,reliability,fault,fault,673,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:571,safety,Error,Error,571,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:673,safety,fault,fault,673,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:779,safety,log,logging,779,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:779,security,log,logging,779,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:779,testability,log,logging,779,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:70,usability,clear,clear,70,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:223,usability,User,UserWarning,223,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:343,usability,minim,minimal,343,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/issues/1223:571,usability,Error,Error,571,"Palantir: d.palantir.presults.compute_gene_trends; <!-- Please give a clear and concise description of what the bug is: -->. .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown. len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, . ...: d.imp_df.iloc[:, 0:1000], ['RG']) . ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ...Segmentation fault (core dumped). ```. it made me out of the python environment. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223
https://github.com/scverse/scanpy/pull/1224:74,deployability,API,API,74,"adds totalVI to external for CITE-seq analysis; This mostly uses the same API as the scvi external function. I'm not quite sure how you all will handle CITE-seq data within anndata, so I imagine we might have to change the data input a bit. . I also added a lightly filtered CITE-seq dataset that can be used in your tutorial. This is basically doublet removal (using DoubletDetection) followed by the same filters used in the basic tutorial with an additional protein library size filter. Though I understand also if you'd like the scanpy dataset to be the unfiltered one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:74,integrability,API,API,74,"adds totalVI to external for CITE-seq analysis; This mostly uses the same API as the scvi external function. I'm not quite sure how you all will handle CITE-seq data within anndata, so I imagine we might have to change the data input a bit. . I also added a lightly filtered CITE-seq dataset that can be used in your tutorial. This is basically doublet removal (using DoubletDetection) followed by the same filters used in the basic tutorial with an additional protein library size filter. Though I understand also if you'd like the scanpy dataset to be the unfiltered one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:266,integrability,filter,filtered,266,"adds totalVI to external for CITE-seq analysis; This mostly uses the same API as the scvi external function. I'm not quite sure how you all will handle CITE-seq data within anndata, so I imagine we might have to change the data input a bit. . I also added a lightly filtered CITE-seq dataset that can be used in your tutorial. This is basically doublet removal (using DoubletDetection) followed by the same filters used in the basic tutorial with an additional protein library size filter. Though I understand also if you'd like the scanpy dataset to be the unfiltered one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:407,integrability,filter,filters,407,"adds totalVI to external for CITE-seq analysis; This mostly uses the same API as the scvi external function. I'm not quite sure how you all will handle CITE-seq data within anndata, so I imagine we might have to change the data input a bit. . I also added a lightly filtered CITE-seq dataset that can be used in your tutorial. This is basically doublet removal (using DoubletDetection) followed by the same filters used in the basic tutorial with an additional protein library size filter. Though I understand also if you'd like the scanpy dataset to be the unfiltered one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:482,integrability,filter,filter,482,"adds totalVI to external for CITE-seq analysis; This mostly uses the same API as the scvi external function. I'm not quite sure how you all will handle CITE-seq data within anndata, so I imagine we might have to change the data input a bit. . I also added a lightly filtered CITE-seq dataset that can be used in your tutorial. This is basically doublet removal (using DoubletDetection) followed by the same filters used in the basic tutorial with an additional protein library size filter. Though I understand also if you'd like the scanpy dataset to be the unfiltered one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:74,interoperability,API,API,74,"adds totalVI to external for CITE-seq analysis; This mostly uses the same API as the scvi external function. I'm not quite sure how you all will handle CITE-seq data within anndata, so I imagine we might have to change the data input a bit. . I also added a lightly filtered CITE-seq dataset that can be used in your tutorial. This is basically doublet removal (using DoubletDetection) followed by the same filters used in the basic tutorial with an additional protein library size filter. Though I understand also if you'd like the scanpy dataset to be the unfiltered one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:228,safety,input,input,228,"adds totalVI to external for CITE-seq analysis; This mostly uses the same API as the scvi external function. I'm not quite sure how you all will handle CITE-seq data within anndata, so I imagine we might have to change the data input a bit. . I also added a lightly filtered CITE-seq dataset that can be used in your tutorial. This is basically doublet removal (using DoubletDetection) followed by the same filters used in the basic tutorial with an additional protein library size filter. Though I understand also if you'd like the scanpy dataset to be the unfiltered one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:499,testability,understand,understand,499,"adds totalVI to external for CITE-seq analysis; This mostly uses the same API as the scvi external function. I'm not quite sure how you all will handle CITE-seq data within anndata, so I imagine we might have to change the data input a bit. . I also added a lightly filtered CITE-seq dataset that can be used in your tutorial. This is basically doublet removal (using DoubletDetection) followed by the same filters used in the basic tutorial with an additional protein library size filter. Though I understand also if you'd like the scanpy dataset to be the unfiltered one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:228,usability,input,input,228,"adds totalVI to external for CITE-seq analysis; This mostly uses the same API as the scvi external function. I'm not quite sure how you all will handle CITE-seq data within anndata, so I imagine we might have to change the data input a bit. . I also added a lightly filtered CITE-seq dataset that can be used in your tutorial. This is basically doublet removal (using DoubletDetection) followed by the same filters used in the basic tutorial with an additional protein library size filter. Though I understand also if you'd like the scanpy dataset to be the unfiltered one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/issues/1225:96,availability,sli,slide,96,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:501,deployability,modul,module,501,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1452,deployability,patch,patches,1452,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1529,deployability,Patch,PatchCollection,1529,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1545,deployability,patch,patches,1545,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:945,integrability,compon,components,945,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:945,interoperability,compon,components,945,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:501,modifiability,modul,module,501,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:945,modifiability,compon,components,945,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:957,modifiability,layer,layer,957,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:96,reliability,sli,slide,96,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:475,safety,input,input-,475,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:501,safety,modul,module,501,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1452,safety,patch,patches,1452,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1529,safety,Patch,PatchCollection,1529,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1545,safety,patch,patches,1545,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1452,security,patch,patches,1452,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1529,security,Patch,PatchCollection,1529,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:1545,security,patch,patches,1545,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:431,testability,Trace,Traceback,431,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1225:475,usability,input,input-,475,"sc.pl.spatial throws AttributeError if not coloring by anything; I wanted to take a look at the slide image, without doing any computation, to pick a pretty example. This leads to an `AttributeError`:. ```python. import scanpy as sc. adata = sc.datasets.visium_sge(""V1_Mouse_Brain_Sagittal_Posterior""). sc.pl.spatial(adata). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-1ffa4586cef4> in <module>. ----> 1 sc.pl.spatial(adata). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, **kwargs). 785 bw=bw,. 786 library_id=library_id,. --> 787 **kwargs,. 788 ). 789 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 397 c=color_vector,. 398 rasterized=settings._vector_friendly,. --> 399 **kwargs,. 400 ). 401 . ~/github/scanpy/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, **kwargs). 1127 patches = [Circle((x_, y_), s_) for x_, y_, s_ in zipped]. 1128 collection = PatchCollection(patches, **kwargs). -> 1129 if c is not None and np.issubdtype(c.dtype, np.number):. 1130 collection.set_array(c). 1131 collection.set_clim(vmin, vmax). AttributeError: 'str' object has no attribute 'dtype'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1225
https://github.com/scverse/scanpy/issues/1227:300,availability,error,error,300,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2647,availability,down,downgrade,2647,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:0,deployability,modul,module,0,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:121,deployability,version,version,121,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:476,deployability,modul,module,476,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2289,deployability,modul,module,2289,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2485,deployability,stack,stackoverflow,2485,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2548,deployability,modul,module-matplotlib-cbook-has-no-attribute-define-a,2548,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:1773,energy efficiency,draw,draw,1773,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:1853,energy efficiency,draw,drawing,1853,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:121,integrability,version,version,121,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:0,modifiability,modul,module,0,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:121,modifiability,version,version,121,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:476,modifiability,modul,module,476,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:542,modifiability,pac,packages,542,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:1178,modifiability,pac,packages,1178,"l.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:1835,modifiability,pac,packages,1835,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2187,modifiability,scal,scalar,2187,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2289,modifiability,modul,module,2289,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2548,modifiability,modul,module-matplotlib-cbook-has-no-attribute-define-a,2548,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:300,performance,error,error,300,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:1844,performance,network,networkx,1844,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2625,reliability,doe,doesn,2625,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:0,safety,modul,module,0,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:300,safety,error,error,300,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:449,safety,input,input-,449,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:476,safety,modul,module,476,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2289,safety,modul,module,2289,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2548,safety,modul,module-matplotlib-cbook-has-no-attribute-define-a,2548,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:1844,security,network,networkx,1844,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:405,testability,Trace,Traceback,405,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:1653,testability,simpl,simplefilter,1653," single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:162,usability,command,commands,162,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:279,usability,command,command,279,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:300,usability,error,error,300,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:449,usability,input,input-,449,"module 'matplotlib.cbook' has no attribute 'is_numlike'; I was running Scanpy 1.4.5.1 on Jupyter Notebook. My matplotlib version is 3.1.3. I ran paga using these commands:. ```. sc.tl.paga(bdata,groups='leiden'). sc.pl.paga(bdata, plot=False). sc.pl.paga(bdata). ````. The third command gave me this error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-65-5027c99fe1bd> in <module>. ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:1653,usability,simpl,simplefilter,1653," single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:2096,usability,user,user,2096,"onent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/pull/1228:7,availability,state,statement,7,fix if statement for str color_vector in _utils; with this `sc.pl.spatial(adata)` correctly returns spots with light gray color. ![image](https://user-images.githubusercontent.com/25887487/82153459-d755cf80-9867-11ea-867d-eacd2e6a81ee.png).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1228
https://github.com/scverse/scanpy/pull/1228:7,integrability,state,statement,7,fix if statement for str color_vector in _utils; with this `sc.pl.spatial(adata)` correctly returns spots with light gray color. ![image](https://user-images.githubusercontent.com/25887487/82153459-d755cf80-9867-11ea-867d-eacd2e6a81ee.png).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1228
https://github.com/scverse/scanpy/pull/1228:146,usability,user,user-images,146,fix if statement for str color_vector in _utils; with this `sc.pl.spatial(adata)` correctly returns spots with light gray color. ![image](https://user-images.githubusercontent.com/25887487/82153459-d755cf80-9867-11ea-867d-eacd2e6a81ee.png).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1228
https://github.com/scverse/scanpy/pull/1229:6,deployability,integr,integration,6,added integration tutorial spatial; added link to second tutorial as well as image,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1229
https://github.com/scverse/scanpy/pull/1229:6,integrability,integr,integration,6,added integration tutorial spatial; added link to second tutorial as well as image,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1229
https://github.com/scverse/scanpy/pull/1229:6,interoperability,integr,integration,6,added integration tutorial spatial; added link to second tutorial as well as image,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1229
https://github.com/scverse/scanpy/pull/1229:6,modifiability,integr,integration,6,added integration tutorial spatial; added link to second tutorial as well as image,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1229
https://github.com/scverse/scanpy/pull/1229:6,reliability,integr,integration,6,added integration tutorial spatial; added link to second tutorial as well as image,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1229
https://github.com/scverse/scanpy/pull/1229:6,security,integr,integration,6,added integration tutorial spatial; added link to second tutorial as well as image,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1229
https://github.com/scverse/scanpy/pull/1229:6,testability,integr,integration,6,added integration tutorial spatial; added link to second tutorial as well as image,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1229
https://github.com/scverse/scanpy/pull/1230:0,deployability,Updat,Update,0,Update tutorials.rst;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1230
https://github.com/scverse/scanpy/pull/1230:0,safety,Updat,Update,0,Update tutorials.rst;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1230
https://github.com/scverse/scanpy/pull/1230:0,security,Updat,Update,0,Update tutorials.rst;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1230
https://github.com/scverse/scanpy/pull/1231:0,deployability,version,version,0,version 1.5.0a1;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1231
https://github.com/scverse/scanpy/pull/1231:0,integrability,version,version,0,version 1.5.0a1;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1231
https://github.com/scverse/scanpy/pull/1231:0,modifiability,version,version,0,version 1.5.0a1;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1231
https://github.com/scverse/scanpy/issues/1232:197,deployability,scale,scale,197,Can we use standard_scale in umap?; <!-- What kind of feature would you like to request? -->. - [ ] New plotting function: can we use standard_scale='var' in sc.pl.umap? so that we can use uniform scale for all umap fig.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1232
https://github.com/scverse/scanpy/issues/1232:197,energy efficiency,scale,scale,197,Can we use standard_scale in umap?; <!-- What kind of feature would you like to request? -->. - [ ] New plotting function: can we use standard_scale='var' in sc.pl.umap? so that we can use uniform scale for all umap fig.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1232
https://github.com/scverse/scanpy/issues/1232:197,modifiability,scal,scale,197,Can we use standard_scale in umap?; <!-- What kind of feature would you like to request? -->. - [ ] New plotting function: can we use standard_scale='var' in sc.pl.umap? so that we can use uniform scale for all umap fig.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1232
https://github.com/scverse/scanpy/issues/1232:197,performance,scale,scale,197,Can we use standard_scale in umap?; <!-- What kind of feature would you like to request? -->. - [ ] New plotting function: can we use standard_scale='var' in sc.pl.umap? so that we can use uniform scale for all umap fig.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1232
https://github.com/scverse/scanpy/issues/1233:203,availability,avail,available,203,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:344,availability,down,downstream,344,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:249,deployability,depend,depend,249,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:311,deployability,build,builds,311,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:78,energy efficiency,current,currently,78,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:439,energy efficiency,current,currently,439,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:249,integrability,depend,depend,249,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:294,interoperability,architectur,architecture,294,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:249,modifiability,depend,depend,249,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:584,modifiability,paramet,parameters,584,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1315,modifiability,paramet,parameters,1315,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:203,reliability,availab,available,203,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:203,safety,avail,available,203,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:249,safety,depend,depend,249,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:203,security,availab,available,203,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1071,security,polic,policar,1071,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:249,testability,depend,depend,249,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:272,testability,understand,understand,272,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:725,usability,learn,learning,725,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1241,usability,support,support,1241,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1335,usability,learn,learning,1335,"Switch t-SNE in scanpy to openTSNE; I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. 2. add tSNE support for `ingest` using openTSNE functionality. 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1234:60,availability,state,states,60,"misleading docs: docs & docstring for sc.pp.pca incorrectly states pca_sparse as a keyword arg; Both the docs here: https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.pca.html and the docstring on the function scanpy.pp.pca incorrectly states pca_sparse as a keyword arg. It looks like maybe at one point in the PR that produced this that was the case (been tracking the sparse PCA PRs), but it now looks like it is just the default now. . Should be removed from the docstring. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1234
https://github.com/scverse/scanpy/issues/1234:239,availability,state,states,239,"misleading docs: docs & docstring for sc.pp.pca incorrectly states pca_sparse as a keyword arg; Both the docs here: https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.pca.html and the docstring on the function scanpy.pp.pca incorrectly states pca_sparse as a keyword arg. It looks like maybe at one point in the PR that produced this that was the case (been tracking the sparse PCA PRs), but it now looks like it is just the default now. . Should be removed from the docstring. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1234
https://github.com/scverse/scanpy/issues/1234:156,deployability,api,api,156,"misleading docs: docs & docstring for sc.pp.pca incorrectly states pca_sparse as a keyword arg; Both the docs here: https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.pca.html and the docstring on the function scanpy.pp.pca incorrectly states pca_sparse as a keyword arg. It looks like maybe at one point in the PR that produced this that was the case (been tracking the sparse PCA PRs), but it now looks like it is just the default now. . Should be removed from the docstring. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1234
https://github.com/scverse/scanpy/issues/1234:60,integrability,state,states,60,"misleading docs: docs & docstring for sc.pp.pca incorrectly states pca_sparse as a keyword arg; Both the docs here: https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.pca.html and the docstring on the function scanpy.pp.pca incorrectly states pca_sparse as a keyword arg. It looks like maybe at one point in the PR that produced this that was the case (been tracking the sparse PCA PRs), but it now looks like it is just the default now. . Should be removed from the docstring. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1234
https://github.com/scverse/scanpy/issues/1234:156,integrability,api,api,156,"misleading docs: docs & docstring for sc.pp.pca incorrectly states pca_sparse as a keyword arg; Both the docs here: https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.pca.html and the docstring on the function scanpy.pp.pca incorrectly states pca_sparse as a keyword arg. It looks like maybe at one point in the PR that produced this that was the case (been tracking the sparse PCA PRs), but it now looks like it is just the default now. . Should be removed from the docstring. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1234
https://github.com/scverse/scanpy/issues/1234:239,integrability,state,states,239,"misleading docs: docs & docstring for sc.pp.pca incorrectly states pca_sparse as a keyword arg; Both the docs here: https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.pca.html and the docstring on the function scanpy.pp.pca incorrectly states pca_sparse as a keyword arg. It looks like maybe at one point in the PR that produced this that was the case (been tracking the sparse PCA PRs), but it now looks like it is just the default now. . Should be removed from the docstring. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1234
https://github.com/scverse/scanpy/issues/1234:156,interoperability,api,api,156,"misleading docs: docs & docstring for sc.pp.pca incorrectly states pca_sparse as a keyword arg; Both the docs here: https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.pca.html and the docstring on the function scanpy.pp.pca incorrectly states pca_sparse as a keyword arg. It looks like maybe at one point in the PR that produced this that was the case (been tracking the sparse PCA PRs), but it now looks like it is just the default now. . Should be removed from the docstring. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1234
https://github.com/scverse/scanpy/issues/1235:37,energy efficiency,heat,heatmap,37,"Highlighting key genes in matrixplot/heatmap; Is there way to highlight key genes in the `sc.pl.heatmap` or `sc.pl.matrixplot` instead of producing overlapping tick labels when plotting a huge number of genes say 1000? Could we obtain the axes and set tick labels to invisible for specific index? I understand one way is to expand the figure size but what if only genes of interest could be highlighted alongside showing there are more genes expressed in a particular group. In R, complexheatmap tool there is this function `anno_mark()` for this purpose. So looking for something similar. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:96,energy efficiency,heat,heatmap,96,"Highlighting key genes in matrixplot/heatmap; Is there way to highlight key genes in the `sc.pl.heatmap` or `sc.pl.matrixplot` instead of producing overlapping tick labels when plotting a huge number of genes say 1000? Could we obtain the axes and set tick labels to invisible for specific index? I understand one way is to expand the figure size but what if only genes of interest could be highlighted alongside showing there are more genes expressed in a particular group. In R, complexheatmap tool there is this function `anno_mark()` for this purpose. So looking for something similar. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:281,interoperability,specif,specific,281,"Highlighting key genes in matrixplot/heatmap; Is there way to highlight key genes in the `sc.pl.heatmap` or `sc.pl.matrixplot` instead of producing overlapping tick labels when plotting a huge number of genes say 1000? Could we obtain the axes and set tick labels to invisible for specific index? I understand one way is to expand the figure size but what if only genes of interest could be highlighted alongside showing there are more genes expressed in a particular group. In R, complexheatmap tool there is this function `anno_mark()` for this purpose. So looking for something similar. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:481,safety,compl,complexheatmap,481,"Highlighting key genes in matrixplot/heatmap; Is there way to highlight key genes in the `sc.pl.heatmap` or `sc.pl.matrixplot` instead of producing overlapping tick labels when plotting a huge number of genes say 1000? Could we obtain the axes and set tick labels to invisible for specific index? I understand one way is to expand the figure size but what if only genes of interest could be highlighted alongside showing there are more genes expressed in a particular group. In R, complexheatmap tool there is this function `anno_mark()` for this purpose. So looking for something similar. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:481,security,compl,complexheatmap,481,"Highlighting key genes in matrixplot/heatmap; Is there way to highlight key genes in the `sc.pl.heatmap` or `sc.pl.matrixplot` instead of producing overlapping tick labels when plotting a huge number of genes say 1000? Could we obtain the axes and set tick labels to invisible for specific index? I understand one way is to expand the figure size but what if only genes of interest could be highlighted alongside showing there are more genes expressed in a particular group. In R, complexheatmap tool there is this function `anno_mark()` for this purpose. So looking for something similar. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:299,testability,understand,understand,299,"Highlighting key genes in matrixplot/heatmap; Is there way to highlight key genes in the `sc.pl.heatmap` or `sc.pl.matrixplot` instead of producing overlapping tick labels when plotting a huge number of genes say 1000? Could we obtain the axes and set tick labels to invisible for specific index? I understand one way is to expand the figure size but what if only genes of interest could be highlighted alongside showing there are more genes expressed in a particular group. In R, complexheatmap tool there is this function `anno_mark()` for this purpose. So looking for something similar. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:496,usability,tool,tool,496,"Highlighting key genes in matrixplot/heatmap; Is there way to highlight key genes in the `sc.pl.heatmap` or `sc.pl.matrixplot` instead of producing overlapping tick labels when plotting a huge number of genes say 1000? Could we obtain the axes and set tick labels to invisible for specific index? I understand one way is to expand the figure size but what if only genes of interest could be highlighted alongside showing there are more genes expressed in a particular group. In R, complexheatmap tool there is this function `anno_mark()` for this purpose. So looking for something similar. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1237:342,deployability,updat,updated,342,"d = sce.tl.palantir(adata) returns ""None""; Hi,. Thanks for providing an amazing platform for single-cell data analysis. . I was trying to use palantir in scanpy and I just reran the example data. However, . d = sce.tl.palantir(adata) . always return None for any kind of data. Could you please comment on this? I am using scanpy 1.5 and have updated Palantir to 0.2.6. Thanks in advance,. Zeinab.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:80,interoperability,platform,platform,80,"d = sce.tl.palantir(adata) returns ""None""; Hi,. Thanks for providing an amazing platform for single-cell data analysis. . I was trying to use palantir in scanpy and I just reran the example data. However, . d = sce.tl.palantir(adata) . always return None for any kind of data. Could you please comment on this? I am using scanpy 1.5 and have updated Palantir to 0.2.6. Thanks in advance,. Zeinab.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:342,safety,updat,updated,342,"d = sce.tl.palantir(adata) returns ""None""; Hi,. Thanks for providing an amazing platform for single-cell data analysis. . I was trying to use palantir in scanpy and I just reran the example data. However, . d = sce.tl.palantir(adata) . always return None for any kind of data. Could you please comment on this? I am using scanpy 1.5 and have updated Palantir to 0.2.6. Thanks in advance,. Zeinab.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:342,security,updat,updated,342,"d = sce.tl.palantir(adata) returns ""None""; Hi,. Thanks for providing an amazing platform for single-cell data analysis. . I was trying to use palantir in scanpy and I just reran the example data. However, . d = sce.tl.palantir(adata) . always return None for any kind of data. Could you please comment on this? I am using scanpy 1.5 and have updated Palantir to 0.2.6. Thanks in advance,. Zeinab.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1238:295,availability,cluster,cluster,295,"sc.tl.rank_genes_groups to rank only top 200 genes?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi, I'm using sc.tl.rank_genes_groups to rank genes from one cluster, but I realized that it can show a maximum of 200 genes, can I change this default setting? Or I should use totally different code to get a gene list more than 200. . Thank you in advance! Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1238
https://github.com/scverse/scanpy/issues/1238:295,deployability,cluster,cluster,295,"sc.tl.rank_genes_groups to rank only top 200 genes?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi, I'm using sc.tl.rank_genes_groups to rank genes from one cluster, but I realized that it can show a maximum of 200 genes, can I change this default setting? Or I should use totally different code to get a gene list more than 200. . Thank you in advance! Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1238
https://github.com/scverse/scanpy/issues/1238:175,modifiability,design decis,design decisions,175,"sc.tl.rank_genes_groups to rank only top 200 genes?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi, I'm using sc.tl.rank_genes_groups to rank genes from one cluster, but I realized that it can show a maximum of 200 genes, can I change this default setting? Or I should use totally different code to get a gene list more than 200. . Thank you in advance! Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1238
https://github.com/scverse/scanpy/issues/1238:73,usability,help,help,73,"sc.tl.rank_genes_groups to rank only top 200 genes?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi, I'm using sc.tl.rank_genes_groups to rank genes from one cluster, but I realized that it can show a maximum of 200 genes, can I change this default setting? Or I should use totally different code to get a gene list more than 200. . Thank you in advance! Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1238
https://github.com/scverse/scanpy/issues/1239:902,availability,cluster,clusters,902,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:951,availability,cluster,clustering,951,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:207,deployability,VERSION,VERSION,207,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:502,deployability,VERSION,VERSION,502,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:793,deployability,VERSION,VERSIONS,793,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:902,deployability,cluster,clusters,902,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:951,deployability,cluster,clustering,951,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:985,deployability,Version,Versions,985,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:48,integrability,sub,subseted,48,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:88,integrability,sub,subpopulations,88,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:207,integrability,VERSION,VERSION,207,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:502,integrability,VERSION,VERSION,502,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:793,integrability,VERSION,VERSIONS,793,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:985,integrability,Version,Versions,985,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:207,modifiability,VERSION,VERSION,207,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:502,modifiability,VERSION,VERSION,502,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:793,modifiability,VERSION,VERSIONS,793,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:985,modifiability,Version,Versions,985,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:1092,usability,learn,learn,1092,"Can I make a deep copy of the scanpy object?; I subseted the scanpy object to view some subpopulations. But I was amazed that whether conducting deep copy yields different results. Here are the snippets: . #VERSION 1:. import copy. Tcells= copy.copy(adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] ). sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). #VERSION 2:. import copy. Tcells= adata[adata.obs[""Leiden0.7""].isin([""2"",""3"",""8"",""15""])] . sc.tl.pca(Tcells, svd_solver='arpack',n_comps=50). sc.pp.neighbors(Tcells, n_neighbors=10, n_pcs=40). sc.tl.umap(Tcells, min_dist=0.2, random_state=42). sc.pl.umap(Tcells,color=[""Leiden0.7""]). The two VERSIONS of snippet just give different umaps (even though I fixed the random seed), and different number of clusters (that's unacceptable, as far as I know, clustering is based on PCs). #### Versions:. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0. So should I make a deep copy of the scanpy object? It looks like deep copy ruined something in the object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/pull/1240:316,availability,slo,slow,316,"Fix pca on sparse data reproducibility; Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:316,reliability,slo,slow,316,"Fix pca on sparse data reproducibility; Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:158,safety,test,test,158,"Fix pca on sparse data reproducibility; Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:300,safety,test,tests,300,"Fix pca on sparse data reproducibility; Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:600,safety,test,test,600,"Fix pca on sparse data reproducibility; Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:653,safety,test,tests,653,"Fix pca on sparse data reproducibility; Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:158,testability,test,test,158,"Fix pca on sparse data reproducibility; Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:300,testability,test,tests,300,"Fix pca on sparse data reproducibility; Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:600,testability,test,test,600,"Fix pca on sparse data reproducibility; Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1240:653,testability,test,tests,653,"Fix pca on sparse data reproducibility; Bugfix for the sparse pca. It looks like we forgot to pass a random seed when this is used... But we also never had a test that checks if you run the function twice with the same random seed it returns the same result. This PR fixes both these issues. The new tests are a bit slow, but are definitely needed. I've also added a fixture for returning a copy of the pbmc3k dataset which has been normalized and had `highly_variable_genes` run on it. Preparation of the object should only happen once per run of the suite, but a new copy will be provided for each test that uses it. This was done to speed up the new tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1241:42,deployability,build,build,42,Ignore RandomState references so rtd will build docs; Per title,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/issues/1243:7,deployability,instal,install,7,leiden install instructions are wrong; leiden install via conda code is wrong in the current page. it should be:. ```. conda install -c conda-forge leidenalg . ```. _Originally posted by @YubinXie in https://github.com/theislab/scanpy/pull/1216#issuecomment-632506015_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:46,deployability,instal,install,46,leiden install instructions are wrong; leiden install via conda code is wrong in the current page. it should be:. ```. conda install -c conda-forge leidenalg . ```. _Originally posted by @YubinXie in https://github.com/theislab/scanpy/pull/1216#issuecomment-632506015_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:125,deployability,instal,install,125,leiden install instructions are wrong; leiden install via conda code is wrong in the current page. it should be:. ```. conda install -c conda-forge leidenalg . ```. _Originally posted by @YubinXie in https://github.com/theislab/scanpy/pull/1216#issuecomment-632506015_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:85,energy efficiency,current,current,85,leiden install instructions are wrong; leiden install via conda code is wrong in the current page. it should be:. ```. conda install -c conda-forge leidenalg . ```. _Originally posted by @YubinXie in https://github.com/theislab/scanpy/pull/1216#issuecomment-632506015_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1244:7,availability,error,error,7,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:22,deployability,version,version,22,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:41,deployability,instal,installed,41,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:64,deployability,version,version,64,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:145,deployability,instal,installed,145,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:399,deployability,modul,module,399,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:520,deployability,modul,module,520,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:553,deployability,log,logging,553,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:706,deployability,modul,module,706,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:862,deployability,modul,module,862,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:899,deployability,Modul,ModuleNotFoundError,899,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:923,deployability,modul,module,923,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1086,deployability,instal,installed,1086,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1132,deployability,stack,stackoverflow,1132,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1230,deployability,updat,update-jupyter-an,1230,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1275,deployability,version,version,1275,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:22,integrability,version,version,22,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:64,integrability,version,version,64,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1275,integrability,version,version,1275,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:22,modifiability,version,version,22,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:64,modifiability,version,version,64,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:399,modifiability,modul,module,399,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:477,modifiability,pac,packages,477,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:520,modifiability,modul,module,520,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:655,modifiability,pac,packages,655,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:706,modifiability,modul,module,706,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:810,modifiability,pac,packages,810,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:862,modifiability,modul,module,862,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:899,modifiability,Modul,ModuleNotFoundError,899,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:923,modifiability,modul,module,923,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1056,modifiability,extens,extension,1056,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1275,modifiability,version,version,1275,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:7,performance,error,error,7,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1066,reliability,doe,does,1066,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:7,safety,error,error,7,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:399,safety,modul,module,399,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:520,safety,modul,module,520,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:553,safety,log,logging,553,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:706,safety,modul,module,706,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:862,safety,modul,module,862,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:899,safety,Modul,ModuleNotFoundError,899,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:923,safety,modul,module,923,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1230,safety,updat,update-jupyter-an,1230,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:553,security,log,logging,553,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1230,security,updat,update-jupyter-an,1230,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:334,testability,Trace,Traceback,334,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:553,testability,log,logging,553,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:7,usability,error,error,7,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/issues/1244:1267,usability,minim,minimal,1267,"Import error when old version of tqdm is installed; When an old version of tqdm ([< 4.29.1](https://github.com/nteract/papermill/issues/287)) is installed, scanpy cannot be imported. . ```bash. conda create -n test_scanpy_tqdm scanpy=1.5.1 tqdm=4.19.4. conda activate test_scanpy_tqdm. python -c ""import scanpy as sc"" . ```. ```pytb. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/__init__.py"", line 39, in <module>. from . import datasets, logging, queries, external, get. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/__init__.py"", line 3, in <module>. from ._datasets import (. File ""/home/sturm/anaconda3/envs/test_scanpy_tqdm/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 8, in <module>. from tqdm.auto import tqdm. ModuleNotFoundError: No module named 'tqdm.auto'. ```. ### Suggested solution. Either . * merge #1130 (which has the additional benefit that the [ipywidgets extension does not have to be installed when running in jupyterlab](https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an)) or . * require a minimal version of `tqdm>=4.29.1`. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244
https://github.com/scverse/scanpy/pull/1245:0,deployability,Updat,Update,0,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:35,deployability,updat,updates,35,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:87,deployability,updat,updated,87,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:69,integrability,wrap,wrapper,69,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:69,interoperability,wrapper,wrapper,69,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:0,safety,Updat,Update,0,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:35,safety,updat,updates,35,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:87,safety,updat,updated,87,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:0,security,Updat,Update,0,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:35,security,updat,updates,35,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:87,security,updat,updated,87,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/pull/1245:64,usability,tool,tool,64,Update palantir external; Critical updates to Palantir external tool wrapper. Includes updated DocString.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1245
https://github.com/scverse/scanpy/issues/1246:666,availability,Error,Error,666,"sc.tl.pca() return TypeError: __init__() got an unexpected keyword argument 'rmatmat'; <!-- Please give a clear and concise description of what the bug is: -->. ... ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png). with adata like this:. ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:. ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:766,deployability,Version,Versions,766,"sc.tl.pca() return TypeError: __init__() got an unexpected keyword argument 'rmatmat'; <!-- Please give a clear and concise description of what the bug is: -->. ... ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png). with adata like this:. ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:. ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:799,deployability,log,logging,799,"sc.tl.pca() return TypeError: __init__() got an unexpected keyword argument 'rmatmat'; <!-- Please give a clear and concise description of what the bug is: -->. ... ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png). with adata like this:. ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:. ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:766,integrability,Version,Versions,766,"sc.tl.pca() return TypeError: __init__() got an unexpected keyword argument 'rmatmat'; <!-- Please give a clear and concise description of what the bug is: -->. ... ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png). with adata like this:. ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:. ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:766,modifiability,Version,Versions,766,"sc.tl.pca() return TypeError: __init__() got an unexpected keyword argument 'rmatmat'; <!-- Please give a clear and concise description of what the bug is: -->. ... ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png). with adata like this:. ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:. ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:666,performance,Error,Error,666,"sc.tl.pca() return TypeError: __init__() got an unexpected keyword argument 'rmatmat'; <!-- Please give a clear and concise description of what the bug is: -->. ... ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png). with adata like this:. ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:. ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:666,safety,Error,Error,666,"sc.tl.pca() return TypeError: __init__() got an unexpected keyword argument 'rmatmat'; <!-- Please give a clear and concise description of what the bug is: -->. ... ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png). with adata like this:. ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:. ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
