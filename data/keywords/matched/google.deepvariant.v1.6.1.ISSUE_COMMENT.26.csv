id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/670:90,deployability,pipelin,pipelines,90,oh~~~yeap.I have find the cause of this problem! . These samples did go through different pipelines where docker mounted to different containers. but it looks right except the sample name . Thanks very much.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/670
https://github.com/google/deepvariant/issues/670:134,deployability,contain,containers,134,oh~~~yeap.I have find the cause of this problem! . These samples did go through different pipelines where docker mounted to different containers. but it looks right except the sample name . Thanks very much.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/670
https://github.com/google/deepvariant/issues/670:90,integrability,pipelin,pipelines,90,oh~~~yeap.I have find the cause of this problem! . These samples did go through different pipelines where docker mounted to different containers. but it looks right except the sample name . Thanks very much.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/670
https://github.com/google/deepvariant/issues/670:165,safety,except,except,165,oh~~~yeap.I have find the cause of this problem! . These samples did go through different pipelines where docker mounted to different containers. but it looks right except the sample name . Thanks very much.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/670
https://github.com/google/deepvariant/issues/671:150,deployability,depend,depends,150,"Hi @geng-lee ,. DeepVariant's default should be good for achieving a good F1 metrics. Some of our users sometimes further filter the variants, but it depends on why you're doing it. Can you tell us why you want filter the SNPs?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:122,integrability,filter,filter,122,"Hi @geng-lee ,. DeepVariant's default should be good for achieving a good F1 metrics. Some of our users sometimes further filter the variants, but it depends on why you're doing it. Can you tell us why you want filter the SNPs?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:150,integrability,depend,depends,150,"Hi @geng-lee ,. DeepVariant's default should be good for achieving a good F1 metrics. Some of our users sometimes further filter the variants, but it depends on why you're doing it. Can you tell us why you want filter the SNPs?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:211,integrability,filter,filter,211,"Hi @geng-lee ,. DeepVariant's default should be good for achieving a good F1 metrics. Some of our users sometimes further filter the variants, but it depends on why you're doing it. Can you tell us why you want filter the SNPs?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:150,modifiability,depend,depends,150,"Hi @geng-lee ,. DeepVariant's default should be good for achieving a good F1 metrics. Some of our users sometimes further filter the variants, but it depends on why you're doing it. Can you tell us why you want filter the SNPs?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:150,safety,depend,depends,150,"Hi @geng-lee ,. DeepVariant's default should be good for achieving a good F1 metrics. Some of our users sometimes further filter the variants, but it depends on why you're doing it. Can you tell us why you want filter the SNPs?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:150,testability,depend,depends,150,"Hi @geng-lee ,. DeepVariant's default should be good for achieving a good F1 metrics. Some of our users sometimes further filter the variants, but it depends on why you're doing it. Can you tell us why you want filter the SNPs?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:98,usability,user,users,98,"Hi @geng-lee ,. DeepVariant's default should be good for achieving a good F1 metrics. Some of our users sometimes further filter the variants, but it depends on why you're doing it. Can you tell us why you want filter the SNPs?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:264,availability,Error,Error,264,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:292,availability,error,error,292,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:496,availability,error,error,496,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:242,deployability,scale,scaled,242,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:626,deployability,scale,scaled,626,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:1545,deployability,scale,scaled,1545," case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of number of F1 score, precision and recall. . More details are provided in the [Hap.py Manual](https://github.com/Illumina/hap.py/blob/master/doc/happy.md). Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:242,energy efficiency,scale,scaled,242,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:626,energy efficiency,scale,scaled,626,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:1159,energy efficiency,frequenc,frequency,1159,"$`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:1545,energy efficiency,scale,scaled,1545," case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of number of F1 score, precision and recall. . More details are provided in the [Hap.py Manual](https://github.com/Illumina/hap.py/blob/master/doc/happy.md). Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:759,integrability,filter,filtered,759,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:832,integrability,coupl,couple,832,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:1211,interoperability,specif,specific,1211,"is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:1946,interoperability,Format,Format,1946," case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of number of F1 score, precision and recall. . More details are provided in the [Hap.py Manual](https://github.com/Illumina/hap.py/blob/master/doc/happy.md). Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:2141,interoperability,standard,standard,2141," case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of number of F1 score, precision and recall. . More details are provided in the [Hap.py Manual](https://github.com/Illumina/hap.py/blob/master/doc/happy.md). Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:242,modifiability,scal,scaled,242,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:626,modifiability,scal,scaled,626,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:832,modifiability,coupl,couple,832,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:1545,modifiability,scal,scaled,1545," case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of number of F1 score, precision and recall. . More details are provided in the [Hap.py Manual](https://github.com/Illumina/hap.py/blob/master/doc/happy.md). Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:242,performance,scale,scaled,242,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:264,performance,Error,Error,264,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:292,performance,error,error,292,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:496,performance,error,error,496,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:626,performance,scale,scaled,626,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:1545,performance,scale,scaled,1545," case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of number of F1 score, precision and recall. . More details are provided in the [Hap.py Manual](https://github.com/Illumina/hap.py/blob/master/doc/happy.md). Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:264,safety,Error,Error,264,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:292,safety,error,error,292,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:496,safety,error,error,496,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:50,testability,understand,understand,50,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:832,testability,coupl,couple,832,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:1251,testability,coverag,coverage,1251,"log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of number of F1 score, precision and recall",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:264,usability,Error,Error,264,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:292,usability,error,error,292,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:496,usability,error,error,496,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:779,usability,support,support,779,"Hi @geng-lee,. Just to expand on a few things. To understand the impact of the information, you would need to look at each one individually, for example:. - $`GQ`$ $`(genotype`$ $`quality)`$: Tells you the genotype is incorrect using a Phred-scaled $`-10*log_{10}(Error)`$ value. So with low error you will get a higher score -- a higher score you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can us",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:1337,usability,close,close,1337,"ore you are confident the call is correct. In this case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of number of F1 score, precision and recall. . More details are provided in the [Hap.py Manual](https://github.com/Illumina/hap.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:2008,usability,tool,tool,2008," case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of number of F1 score, precision and recall. . More details are provided in the [Hap.py Manual](https://github.com/Illumina/hap.py/blob/master/doc/happy.md). Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:2378,usability,help,helps,2378," case your highest is 19, which is borderline for DeepVariant which has it at 20. A score of 20 means, an error of 0.01, so 99% probability that the call is correct. This has a relationship to the PL value, which gives normalized Phred-scaled scores per genotype, but in this case would be too low to call confidently. - $`DP`$ $`(read`$ $`depth)`$: This tells you the filtered reads that support the call. Here your depth is a bit low for a couple of them. For research purposes the cutoff is usually 10 or higher. For clinical 30 would be nice but anything higher than 18 can be good. You will see an AD value (which includes all reads at that position) as well, but that means you are including reads that could be problematic. . - $`VAF`$ $`(variant`$ $`allele`$ $`frequency)`$: This is the percentage of reads for a specific variant divided by the overall coverage at that locus. For heterozygous it would have a value of 50%, for homozygous close to 100% while matching the reference would be 0%. You will notice one is 75% and it denotes it as heterozygous, but the GQ and PL values are very low to call it confidently. - $`QUAL`$: These are Phred-scaled values that the probability the genotype is reference (0/0). For instance a QUAL score of 20 means that your are 99% confident there is a variant at that site, but as before with much lower values you would not be. You can read more about what these columns mean, and how to interpret them at the [following site](https://gatk.broadinstitute.org/hc/en-us/articles/360035531692-VCF-Variant-Call-Format). As @pichuan mention, other metrics you can use are a tool such as [Illumina's Hap.py](https://github.com/Illumina/hap.py/tree/master), with which you can benchmark your VCF against gold standard truth datasets, to see the confidence of these calls in terms of number of F1 score, precision and recall. . More details are provided in the [Hap.py Manual](https://github.com/Illumina/hap.py/blob/master/doc/happy.md). Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:218,integrability,filter,filter,218,"@pichuan @pgrosu. Thank you very much for your reply. Our work focuses on evaluating the off-target effect of base editors through WGS and RNAseq. The number of SNPS called by deepvariant is very large, so we need to filter the SNPS with low confidence to eliminate the noise. The above is very helpful to me. Thanks! Best,. Jamie.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:296,usability,help,helpful,296,"@pichuan @pgrosu. Thank you very much for your reply. Our work focuses on evaluating the off-target effect of base editors through WGS and RNAseq. The number of SNPS called by deepvariant is very large, so we need to filter the SNPS with low confidence to eliminate the noise. The above is very helpful to me. Thanks! Best,. Jamie.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:25,testability,context,context,25,Thanks @geng-lee for the context. It seems like you might have gotten enough pointers now. I'll close this issue. Feel free to open another issue if you have more questions.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/671:96,usability,close,close,96,Thanks @geng-lee for the context. It seems like you might have gotten enough pointers now. I'll close this issue. Feel free to open another issue if you have more questions.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/671
https://github.com/google/deepvariant/issues/672:28,availability,error,error,28,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:34,deployability,log,log,34,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:128,deployability,pipelin,pipeline,128,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:128,integrability,pipelin,pipeline,128,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:28,performance,error,error,28,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:67,reliability,doe,doesn,67,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:28,safety,error,error,28,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:34,safety,log,log,34,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:34,security,log,log,34,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:34,testability,log,log,34,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:28,usability,error,error,28,"Hi @crazysummerW , from the error log, it seems like your BAM file doesn't have base quality scores. Is that expected from your pipeline?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:305,integrability,sub,subreads,305,"Hi @crazysummerW , . in your first step, you mentioned ""pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@rg\tID:test1\tSM:test1'"". Can you explain to me what you're trying to do in this step? You also mentioned DeepConsensus. Are you planning to start from your own PacBio subreads BAM? Unless you're starting with subreads, you don't need to apply DeepConsensus. If you are starting with PacBio HiFi reads (which I think is most of the DeepVariant users), you should directly map your FASTQ files using pbmm2, which gives you a BAM file, then you apply DeepVariant on the BAM. However, if you are indeed starting from PacBio subreads, you will need to follow https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md to obtain the FASTQ file (which is the output that DeepConsensus gives you). Then, you map the FASTQ file, which gives you a BAM file, then you apply DeepVariant on the BAM. From your original question, it isn't quite clear to me what you're trying to do here. Can you elaborate?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:347,integrability,sub,subreads,347,"Hi @crazysummerW , . in your first step, you mentioned ""pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@rg\tID:test1\tSM:test1'"". Can you explain to me what you're trying to do in this step? You also mentioned DeepConsensus. Are you planning to start from your own PacBio subreads BAM? Unless you're starting with subreads, you don't need to apply DeepConsensus. If you are starting with PacBio HiFi reads (which I think is most of the DeepVariant users), you should directly map your FASTQ files using pbmm2, which gives you a BAM file, then you apply DeepVariant on the BAM. However, if you are indeed starting from PacBio subreads, you will need to follow https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md to obtain the FASTQ file (which is the output that DeepConsensus gives you). Then, you map the FASTQ file, which gives you a BAM file, then you apply DeepVariant on the BAM. From your original question, it isn't quite clear to me what you're trying to do here. Can you elaborate?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:658,integrability,sub,subreads,658,"Hi @crazysummerW , . in your first step, you mentioned ""pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@rg\tID:test1\tSM:test1'"". Can you explain to me what you're trying to do in this step? You also mentioned DeepConsensus. Are you planning to start from your own PacBio subreads BAM? Unless you're starting with subreads, you don't need to apply DeepConsensus. If you are starting with PacBio HiFi reads (which I think is most of the DeepVariant users), you should directly map your FASTQ files using pbmm2, which gives you a BAM file, then you apply DeepVariant on the BAM. However, if you are indeed starting from PacBio subreads, you will need to follow https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md to obtain the FASTQ file (which is the output that DeepConsensus gives you). Then, you map the FASTQ file, which gives you a BAM file, then you apply DeepVariant on the BAM. From your original question, it isn't quite clear to me what you're trying to do here. Can you elaborate?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:298,modifiability,Pac,PacBio,298,"Hi @crazysummerW , . in your first step, you mentioned ""pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@rg\tID:test1\tSM:test1'"". Can you explain to me what you're trying to do in this step? You also mentioned DeepConsensus. Are you planning to start from your own PacBio subreads BAM? Unless you're starting with subreads, you don't need to apply DeepConsensus. If you are starting with PacBio HiFi reads (which I think is most of the DeepVariant users), you should directly map your FASTQ files using pbmm2, which gives you a BAM file, then you apply DeepVariant on the BAM. However, if you are indeed starting from PacBio subreads, you will need to follow https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md to obtain the FASTQ file (which is the output that DeepConsensus gives you). Then, you map the FASTQ file, which gives you a BAM file, then you apply DeepVariant on the BAM. From your original question, it isn't quite clear to me what you're trying to do here. Can you elaborate?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:421,modifiability,Pac,PacBio,421,"Hi @crazysummerW , . in your first step, you mentioned ""pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@rg\tID:test1\tSM:test1'"". Can you explain to me what you're trying to do in this step? You also mentioned DeepConsensus. Are you planning to start from your own PacBio subreads BAM? Unless you're starting with subreads, you don't need to apply DeepConsensus. If you are starting with PacBio HiFi reads (which I think is most of the DeepVariant users), you should directly map your FASTQ files using pbmm2, which gives you a BAM file, then you apply DeepVariant on the BAM. However, if you are indeed starting from PacBio subreads, you will need to follow https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md to obtain the FASTQ file (which is the output that DeepConsensus gives you). Then, you map the FASTQ file, which gives you a BAM file, then you apply DeepVariant on the BAM. From your original question, it isn't quite clear to me what you're trying to do here. Can you elaborate?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:651,modifiability,Pac,PacBio,651,"Hi @crazysummerW , . in your first step, you mentioned ""pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@rg\tID:test1\tSM:test1'"". Can you explain to me what you're trying to do in this step? You also mentioned DeepConsensus. Are you planning to start from your own PacBio subreads BAM? Unless you're starting with subreads, you don't need to apply DeepConsensus. If you are starting with PacBio HiFi reads (which I think is most of the DeepVariant users), you should directly map your FASTQ files using pbmm2, which gives you a BAM file, then you apply DeepVariant on the BAM. However, if you are indeed starting from PacBio subreads, you will need to follow https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md to obtain the FASTQ file (which is the output that DeepConsensus gives you). Then, you map the FASTQ file, which gives you a BAM file, then you apply DeepVariant on the BAM. From your original question, it isn't quite clear to me what you're trying to do here. Can you elaborate?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:266,testability,plan,planning,266,"Hi @crazysummerW , . in your first step, you mentioned ""pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@rg\tID:test1\tSM:test1'"". Can you explain to me what you're trying to do in this step? You also mentioned DeepConsensus. Are you planning to start from your own PacBio subreads BAM? Unless you're starting with subreads, you don't need to apply DeepConsensus. If you are starting with PacBio HiFi reads (which I think is most of the DeepVariant users), you should directly map your FASTQ files using pbmm2, which gives you a BAM file, then you apply DeepVariant on the BAM. However, if you are indeed starting from PacBio subreads, you will need to follow https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md to obtain the FASTQ file (which is the output that DeepConsensus gives you). Then, you map the FASTQ file, which gives you a BAM file, then you apply DeepVariant on the BAM. From your original question, it isn't quite clear to me what you're trying to do here. Can you elaborate?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:481,usability,user,users,481,"Hi @crazysummerW , . in your first step, you mentioned ""pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@rg\tID:test1\tSM:test1'"". Can you explain to me what you're trying to do in this step? You also mentioned DeepConsensus. Are you planning to start from your own PacBio subreads BAM? Unless you're starting with subreads, you don't need to apply DeepConsensus. If you are starting with PacBio HiFi reads (which I think is most of the DeepVariant users), you should directly map your FASTQ files using pbmm2, which gives you a BAM file, then you apply DeepVariant on the BAM. However, if you are indeed starting from PacBio subreads, you will need to follow https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md to obtain the FASTQ file (which is the output that DeepConsensus gives you). Then, you map the FASTQ file, which gives you a BAM file, then you apply DeepVariant on the BAM. From your original question, it isn't quite clear to me what you're trying to do here. Can you elaborate?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:980,usability,clear,clear,980,"Hi @crazysummerW , . in your first step, you mentioned ""pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@rg\tID:test1\tSM:test1'"". Can you explain to me what you're trying to do in this step? You also mentioned DeepConsensus. Are you planning to start from your own PacBio subreads BAM? Unless you're starting with subreads, you don't need to apply DeepConsensus. If you are starting with PacBio HiFi reads (which I think is most of the DeepVariant users), you should directly map your FASTQ files using pbmm2, which gives you a BAM file, then you apply DeepVariant on the BAM. However, if you are indeed starting from PacBio subreads, you will need to follow https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md to obtain the FASTQ file (which is the output that DeepConsensus gives you). Then, you map the FASTQ file, which gives you a BAM file, then you apply DeepVariant on the BAM. From your original question, it isn't quite clear to me what you're trying to do here. Can you elaborate?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:214,deployability,pipelin,pipeline,214,"Hi @crazysummerW ,. I noticed in your title you mentioned ""Revio data"". If you're using Revio, DeepConsensus is already run. You don't need to run it again. So, please proceed with your usual mapping + DeepVariant pipeline, and you should be able to get your variant calls that way. If I'm not interpreting your use case correctly, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:214,integrability,pipelin,pipeline,214,"Hi @crazysummerW ,. I noticed in your title you mentioned ""Revio data"". If you're using Revio, DeepConsensus is already run. You don't need to run it again. So, please proceed with your usual mapping + DeepVariant pipeline, and you should be able to get your variant calls that way. If I'm not interpreting your use case correctly, please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:273,security,rotat,rotation,273,"Hi @crazysummerW ,. Given this is a question about DeepConsensus, can you repost your question (and give some context on what you're trying to do) in the DeepConsensus GitHub issue? And, because it is a 4-day weekend for us, please expect some delay for the next person on rotation to reply.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:110,testability,context,context,110,"Hi @crazysummerW ,. Given this is a question about DeepConsensus, can you repost your question (and give some context on what you're trying to do) in the DeepConsensus GitHub issue? And, because it is a 4-day weekend for us, please expect some delay for the next person on rotation to reply.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:263,usability,person,person,263,"Hi @crazysummerW ,. Given this is a question about DeepConsensus, can you repost your question (and give some context on what you're trying to do) in the DeepConsensus GitHub issue? And, because it is a 4-day weekend for us, please expect some delay for the next person on rotation to reply.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:990,availability,checkpoint,checkpoint,990,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:1007,availability,checkpoint,checkpoint,1007,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:265,deployability,deploy,deployed,265,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:259,energy efficiency,model,model,259,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:1001,energy efficiency,model,model,1001,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:851,interoperability,Specif,Specifically,851,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:663,modifiability,interm,intermediate,663,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:990,reliability,checkpoint,checkpoint,990,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:1007,reliability,checkpoint,checkpoint,1007,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:61,safety,test,tested,61,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:259,security,model,model,259,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:1001,security,model,model,1001,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:61,testability,test,tested,61,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:396,testability,context,context,396,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:536,testability,understand,understand,536,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:1155,usability,help,helps,1155,"Hi @crazysummerW ,. One more thought:. You mentioned ""I also tested the Revio Hifi data. It succeeded."" --> If that's the case, you don't need to re-run DeepConsensus before running DeepVariant, because DeepConsensus is already run on Revio, and in fact, the model deployed on Revio machine is the appropriate one to use. So, I am not sure why you need to re-run DeepConsensus. Maybe I miss some context here. That's why I encourage you to post directly on https://github.com/google/deepconsensus/issues instead of here. So that we can understand your use case of DeepConsensus. One more thing:. When running DeepConsensus, the code snippet you posted is only an intermediate step. You'll need to finish running through the steps to get to the FASTQ file here: https://github.com/google/deepconsensus/blob/r1.2/docs/quick_start.md#run-deepconsensus . Specifically this step:. ```. deepconsensus run \. --subreads_to_ccs=${shard_id}.subreads_to_ccs.bam \. --ccs_bam=${shard_id}.ccs.bam \. --checkpoint=model/checkpoint \. --output=${shard_id}.output.fastq. ```. is the one that generate the FASTQ you'll use for mapping and then variant calling. Hope this helps. For more DeepConsensus questions, please post on https://github.com/google/deepconsensus/issues and we can take it from there later next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:56,deployability,integr,integrated,56,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:56,integrability,integr,integrated,56,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:165,integrability,sub,subreads,165,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:627,integrability,sub,subreads,627,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:720,integrability,sub,subreads,720,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:56,interoperability,integr,integrated,56,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:56,modifiability,integr,integrated,56,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:56,reliability,integr,integrated,56,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:602,safety,input,input,602,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:56,security,integr,integrated,56,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:56,testability,integr,integrated,56,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:413,testability,coverag,coverage,413,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:602,usability,input,input,602,"@crazysummerW . As Pi-Chuan mentioned, DeepConsensus is integrated into the Revio system; so, you will get DeepConsensus reads directly from that system. The `n1000.subreads.bam` demo dataset being discussed here is from Sequel II. It is a small number of reads from the human genome. You should be able to push it through the mechanical steps of alignment and variant calling, but the results will be limited by coverage. To figure out which mechanical step is broken here, I would recommend to pass the FASTQ directly rather than through a `fofn` to be more explicit. The pbmm2 alignment should have input of HiFi reads, not subreads. So, a typical aligned file name would be `REF.hifi_reads.bam` without a mention of subreads. > pbmm2 align hs37d5.fasta ${shard_id}.output.fastq aligned.bam --sort",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:168,integrability,pub,public,168,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:212,integrability,sub,subreads,212,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:161,modifiability,Pac,PacBio,161,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:103,performance,perform,performed,103,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:117,safety,test,tests,117,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:281,safety,test,tested,281,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:117,testability,test,tests,117,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:281,testability,test,tested,281,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:92,usability,clear,clearly,92,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:103,usability,perform,performed,103,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:321,usability,help,help,321,"@pichuan @amwenger . Thank you very much for your response. Perhaps I didn't express myself clearly. I performed two tests. One is HiFi reads, which is from the PacBio public revio data set. Another one is n1000.subreads.bam, which is from DeepConsensus. . Both datasets have been tested successfully. Thank you for your help. Have a great weekend!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:283,availability,error,error,283,"Hi there! Thanks for the great work. I encountered the similar problem here. I have PacBio long-read scRNA-seq data, and I am trying to use DeepVariant on the pseudobulk level. However,`isoseq groupdedup` removed the quality scores in my bam files during preprocessing, which causes error . As you mentioned above, should I skip the deduplication step (but keep primer removal, tag, refine, barcode correction and sorting) and then align to reference genome using `pbmm2`? Or should I use another deduplication tool that keeps base quality score? Thanks for any help in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:84,modifiability,Pac,PacBio,84,"Hi there! Thanks for the great work. I encountered the similar problem here. I have PacBio long-read scRNA-seq data, and I am trying to use DeepVariant on the pseudobulk level. However,`isoseq groupdedup` removed the quality scores in my bam files during preprocessing, which causes error . As you mentioned above, should I skip the deduplication step (but keep primer removal, tag, refine, barcode correction and sorting) and then align to reference genome using `pbmm2`? Or should I use another deduplication tool that keeps base quality score? Thanks for any help in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:283,performance,error,error,283,"Hi there! Thanks for the great work. I encountered the similar problem here. I have PacBio long-read scRNA-seq data, and I am trying to use DeepVariant on the pseudobulk level. However,`isoseq groupdedup` removed the quality scores in my bam files during preprocessing, which causes error . As you mentioned above, should I skip the deduplication step (but keep primer removal, tag, refine, barcode correction and sorting) and then align to reference genome using `pbmm2`? Or should I use another deduplication tool that keeps base quality score? Thanks for any help in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:283,safety,error,error,283,"Hi there! Thanks for the great work. I encountered the similar problem here. I have PacBio long-read scRNA-seq data, and I am trying to use DeepVariant on the pseudobulk level. However,`isoseq groupdedup` removed the quality scores in my bam files during preprocessing, which causes error . As you mentioned above, should I skip the deduplication step (but keep primer removal, tag, refine, barcode correction and sorting) and then align to reference genome using `pbmm2`? Or should I use another deduplication tool that keeps base quality score? Thanks for any help in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:186,security,iso,isoseq,186,"Hi there! Thanks for the great work. I encountered the similar problem here. I have PacBio long-read scRNA-seq data, and I am trying to use DeepVariant on the pseudobulk level. However,`isoseq groupdedup` removed the quality scores in my bam files during preprocessing, which causes error . As you mentioned above, should I skip the deduplication step (but keep primer removal, tag, refine, barcode correction and sorting) and then align to reference genome using `pbmm2`? Or should I use another deduplication tool that keeps base quality score? Thanks for any help in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:283,usability,error,error,283,"Hi there! Thanks for the great work. I encountered the similar problem here. I have PacBio long-read scRNA-seq data, and I am trying to use DeepVariant on the pseudobulk level. However,`isoseq groupdedup` removed the quality scores in my bam files during preprocessing, which causes error . As you mentioned above, should I skip the deduplication step (but keep primer removal, tag, refine, barcode correction and sorting) and then align to reference genome using `pbmm2`? Or should I use another deduplication tool that keeps base quality score? Thanks for any help in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:511,usability,tool,tool,511,"Hi there! Thanks for the great work. I encountered the similar problem here. I have PacBio long-read scRNA-seq data, and I am trying to use DeepVariant on the pseudobulk level. However,`isoseq groupdedup` removed the quality scores in my bam files during preprocessing, which causes error . As you mentioned above, should I skip the deduplication step (but keep primer removal, tag, refine, barcode correction and sorting) and then align to reference genome using `pbmm2`? Or should I use another deduplication tool that keeps base quality score? Thanks for any help in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:562,usability,help,help,562,"Hi there! Thanks for the great work. I encountered the similar problem here. I have PacBio long-read scRNA-seq data, and I am trying to use DeepVariant on the pseudobulk level. However,`isoseq groupdedup` removed the quality scores in my bam files during preprocessing, which causes error . As you mentioned above, should I skip the deduplication step (but keep primer removal, tag, refine, barcode correction and sorting) and then align to reference genome using `pbmm2`? Or should I use another deduplication tool that keeps base quality score? Thanks for any help in advance!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:1,security,iso,isoseq,1,"`isoseq groupdedup` creates a consensus sequence per group without base qualities. It's not ""removing quality scores"". I recommend alignment of your FLNCs after `isoseq refine`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:162,security,iso,isoseq,162,"`isoseq groupdedup` creates a consensus sequence per group without base qualities. It's not ""removing quality scores"". I recommend alignment of your FLNCs after `isoseq refine`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:43,interoperability,specif,specific,43,"Hi @Jiayi-Wang-Joey , for the PacBio tools specific questions, it might be good to use their GitHub issues, so that other users there can benefit from the answer as well. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:30,modifiability,Pac,PacBio,30,"Hi @Jiayi-Wang-Joey , for the PacBio tools specific questions, it might be good to use their GitHub issues, so that other users there can benefit from the answer as well. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:37,usability,tool,tools,37,"Hi @Jiayi-Wang-Joey , for the PacBio tools specific questions, it might be good to use their GitHub issues, so that other users there can benefit from the answer as well. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:122,usability,user,users,122,"Hi @Jiayi-Wang-Joey , for the PacBio tools specific questions, it might be good to use their GitHub issues, so that other users there can benefit from the answer as well. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:113,availability,reliab,reliable,113,"Hi, sorry to bother again. I am wondering if I run DeepVariant on my non-deduplicated reads, will the results be reliable or make sense? Probably there will be artifactual mutations? In short, I should still run DeepVariant on deduplicated reads, right?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:160,deployability,artifact,artifactual,160,"Hi, sorry to bother again. I am wondering if I run DeepVariant on my non-deduplicated reads, will the results be reliable or make sense? Probably there will be artifactual mutations? In short, I should still run DeepVariant on deduplicated reads, right?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:113,reliability,reliab,reliable,113,"Hi, sorry to bother again. I am wondering if I run DeepVariant on my non-deduplicated reads, will the results be reliable or make sense? Probably there will be artifactual mutations? In short, I should still run DeepVariant on deduplicated reads, right?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/673:38,deployability,version,version,38,"@CWYuan08 , . Can you please see what version of Tensorflow you are using? Also can you try by binding the `/usr/bin/locale` in this following way:. ```. singularity exec -B /usr/lib/locale/:/usr/lib/locale/. ```. and see if that helps?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:38,integrability,version,version,38,"@CWYuan08 , . Can you please see what version of Tensorflow you are using? Also can you try by binding the `/usr/bin/locale` in this following way:. ```. singularity exec -B /usr/lib/locale/:/usr/lib/locale/. ```. and see if that helps?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:95,interoperability,bind,binding,95,"@CWYuan08 , . Can you please see what version of Tensorflow you are using? Also can you try by binding the `/usr/bin/locale` in this following way:. ```. singularity exec -B /usr/lib/locale/:/usr/lib/locale/. ```. and see if that helps?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:38,modifiability,version,version,38,"@CWYuan08 , . Can you please see what version of Tensorflow you are using? Also can you try by binding the `/usr/bin/locale` in this following way:. ```. singularity exec -B /usr/lib/locale/:/usr/lib/locale/. ```. and see if that helps?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:95,modifiability,bind,binding,95,"@CWYuan08 , . Can you please see what version of Tensorflow you are using? Also can you try by binding the `/usr/bin/locale` in this following way:. ```. singularity exec -B /usr/lib/locale/:/usr/lib/locale/. ```. and see if that helps?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:230,usability,help,helps,230,"@CWYuan08 , . Can you please see what version of Tensorflow you are using? Also can you try by binding the `/usr/bin/locale` in this following way:. ```. singularity exec -B /usr/lib/locale/:/usr/lib/locale/. ```. and see if that helps?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:388,availability,error,error,388,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:62,deployability,version,version,62,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:298,deployability,contain,container,298,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:62,integrability,version,version,62,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:62,modifiability,version,version,62,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:388,performance,error,error,388,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:388,safety,error,error,388,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:41,usability,help,help,41,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:310,usability,command,command,310,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:351,usability,command,command,351,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:388,usability,error,error,388,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:403,usability,command,command,403,"Dear @kishwarshafin . thank you for your help, the Tensorflow version is:. tensorflow 2.12.0 pypi_0 pypi. tensorflow-io-gcs-filesystem 0.32.0 pypi_0 pypi. I tried singularity exec -B /usr/lib/locale/:/usr/lib/locale/. it only gives:. Usage:. singularity [global options...] exec [exec options...] <container> <command>. and when I tried with the full command, it says FATAL Flags parsing error: Unknown command line flag 'B'. thanks again! Best,. CW",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:420,availability,error,error,420,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:26,deployability,version,version,26,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:65,deployability,version,version,65,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:279,deployability,version,version,279,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:45,energy efficiency,current,current,45,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:275,energy efficiency,cpu,cpu-version,275,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:26,integrability,version,version,26,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:65,integrability,version,version,65,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:279,integrability,version,version,279,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:26,modifiability,version,version,26,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:65,modifiability,version,version,65,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:279,modifiability,version,version,279,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:275,performance,cpu,cpu-version,275,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:420,performance,error,error,420,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:420,safety,error,error,420,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:322,usability,command,command,322,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:420,usability,error,error,420,"So yes, it's a tensorflow version issue. Our current [tensorflow version is 2.11](https://github.com/google/deepvariant/blob/r1.5/settings.sh#L72). Can you please try the [singulaity quickstart](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#cpu-version) to see if that works for you. The command actually is `singularity run -B` not `singularity exec -B` which maybe the reason for the error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:43,usability,help,help,43,"Dear @kishwarshafin,. many thanks for your help, it is working now! . I am also wondering if there is a model_type for Nanopore R9.4.1 chemistry? Best,. CW.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:128,testability,simpl,simplex,128,"@CWYuan08 , for Nanopore R9.4.1, we suggest using [PEPPER](https://github.com/kishwarshafin/pepper). DeepVariant supports R10.4 simplex and duplex modes. Thank you for confirming that it is working for you now. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:113,usability,support,supports,113,"@CWYuan08 , for Nanopore R9.4.1, we suggest using [PEPPER](https://github.com/kishwarshafin/pepper). DeepVariant supports R10.4 simplex and duplex modes. Thank you for confirming that it is working for you now. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:128,usability,simpl,simplex,128,"@CWYuan08 , for Nanopore R9.4.1, we suggest using [PEPPER](https://github.com/kishwarshafin/pepper). DeepVariant supports R10.4 simplex and duplex modes. Thank you for confirming that it is working for you now. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:168,usability,confirm,confirming,168,"@CWYuan08 , for Nanopore R9.4.1, we suggest using [PEPPER](https://github.com/kishwarshafin/pepper). DeepVariant supports R10.4 simplex and duplex modes. Thank you for confirming that it is working for you now. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:218,usability,close,close,218,"@CWYuan08 , for Nanopore R9.4.1, we suggest using [PEPPER](https://github.com/kishwarshafin/pepper). DeepVariant supports R10.4 simplex and duplex modes. Thank you for confirming that it is working for you now. I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/675:374,availability,avail,available,374,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:339,deployability,contain,container,339,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:444,modifiability,variab,variable,444,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:374,reliability,availab,available,374,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:683,reliability,doe,doesn,683,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:166,safety,input,input,166,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:211,safety,input,input,211,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:374,safety,avail,available,374,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:397,safety,compl,completes,397,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:782,safety,input,input,782,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:930,safety,input,input,930,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:978,safety,input,input,978,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:374,security,availab,available,374,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:397,security,compl,completes,397,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:24,usability,close,close,24,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:139,usability,command,command,139,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:166,usability,input,input,166,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:211,usability,input,input,211,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:675,usability,command,command,675,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:782,usability,input,input,782,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:930,usability,input,input,930,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:978,usability,input,input,978,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1126,usability,help,helps,1126,"@FraSilver You are very close. All you have to do is two things:. $`1)`$ First add the mapping of the output directory to the `docker run` command (below the one for input) as follows:. ```. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. ```. This basically makes the output directory visible from within the running Docker container, so that the results are available after Docker completes its run. $`2)`$ Next define the `FQ` variable, as it seems to be referenced as `$FQ`, but I'm not seeing it defined. If it is already defined previously, then that's fine. If you have multiple lines, you will need to also add the backslash `\` as follows, so that the command doesn't get started before the last line gets pasted:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/$FQ.align.sort.marked.bam \. --output_vcf=/output/$FQ.vcf.gz \. --output_gvcf=/output/$FQ.g.vcf.gz \. --num_shards=2 . ```. Let me know if it helps. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:324,energy efficiency,predict,prediction,324,"I have copy-n-paste the wrong script. . I have already written -v ""${OUTPUT_DIR}"":""/output"", declared my $FQ variable and used backslash. It doesn't work. In my ""/input"" directory I have .fasta file, .fasta.fai, bam and .bai file. I suppose I don't require nothing else. (maybe, also VCF tools if the aim is the vcf output ""prediction"". . Any suggestion? singularity run doesn't work as well. I get the ""deepvariant_1.5.0.sif "" image file after running singularity pull... Thanks in advance,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:109,modifiability,variab,variable,109,"I have copy-n-paste the wrong script. . I have already written -v ""${OUTPUT_DIR}"":""/output"", declared my $FQ variable and used backslash. It doesn't work. In my ""/input"" directory I have .fasta file, .fasta.fai, bam and .bai file. I suppose I don't require nothing else. (maybe, also VCF tools if the aim is the vcf output ""prediction"". . Any suggestion? singularity run doesn't work as well. I get the ""deepvariant_1.5.0.sif "" image file after running singularity pull... Thanks in advance,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:141,reliability,doe,doesn,141,"I have copy-n-paste the wrong script. . I have already written -v ""${OUTPUT_DIR}"":""/output"", declared my $FQ variable and used backslash. It doesn't work. In my ""/input"" directory I have .fasta file, .fasta.fai, bam and .bai file. I suppose I don't require nothing else. (maybe, also VCF tools if the aim is the vcf output ""prediction"". . Any suggestion? singularity run doesn't work as well. I get the ""deepvariant_1.5.0.sif "" image file after running singularity pull... Thanks in advance,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:371,reliability,doe,doesn,371,"I have copy-n-paste the wrong script. . I have already written -v ""${OUTPUT_DIR}"":""/output"", declared my $FQ variable and used backslash. It doesn't work. In my ""/input"" directory I have .fasta file, .fasta.fai, bam and .bai file. I suppose I don't require nothing else. (maybe, also VCF tools if the aim is the vcf output ""prediction"". . Any suggestion? singularity run doesn't work as well. I get the ""deepvariant_1.5.0.sif "" image file after running singularity pull... Thanks in advance,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:163,safety,input,input,163,"I have copy-n-paste the wrong script. . I have already written -v ""${OUTPUT_DIR}"":""/output"", declared my $FQ variable and used backslash. It doesn't work. In my ""/input"" directory I have .fasta file, .fasta.fai, bam and .bai file. I suppose I don't require nothing else. (maybe, also VCF tools if the aim is the vcf output ""prediction"". . Any suggestion? singularity run doesn't work as well. I get the ""deepvariant_1.5.0.sif "" image file after running singularity pull... Thanks in advance,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:324,safety,predict,prediction,324,"I have copy-n-paste the wrong script. . I have already written -v ""${OUTPUT_DIR}"":""/output"", declared my $FQ variable and used backslash. It doesn't work. In my ""/input"" directory I have .fasta file, .fasta.fai, bam and .bai file. I suppose I don't require nothing else. (maybe, also VCF tools if the aim is the vcf output ""prediction"". . Any suggestion? singularity run doesn't work as well. I get the ""deepvariant_1.5.0.sif "" image file after running singularity pull... Thanks in advance,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:163,usability,input,input,163,"I have copy-n-paste the wrong script. . I have already written -v ""${OUTPUT_DIR}"":""/output"", declared my $FQ variable and used backslash. It doesn't work. In my ""/input"" directory I have .fasta file, .fasta.fai, bam and .bai file. I suppose I don't require nothing else. (maybe, also VCF tools if the aim is the vcf output ""prediction"". . Any suggestion? singularity run doesn't work as well. I get the ""deepvariant_1.5.0.sif "" image file after running singularity pull... Thanks in advance,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:288,usability,tool,tools,288,"I have copy-n-paste the wrong script. . I have already written -v ""${OUTPUT_DIR}"":""/output"", declared my $FQ variable and used backslash. It doesn't work. In my ""/input"" directory I have .fasta file, .fasta.fai, bam and .bai file. I suppose I don't require nothing else. (maybe, also VCF tools if the aim is the vcf output ""prediction"". . Any suggestion? singularity run doesn't work as well. I get the ""deepvariant_1.5.0.sif "" image file after running singularity pull... Thanks in advance,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1645,availability,error,errors,1645,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1720,availability,avail,available,1720,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:54,deployability,fail,fails,54,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:110,deployability,stage,stage,110,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:257,interoperability,specif,specify,257,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:401,interoperability,specif,specifying,401,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:432,interoperability,format,format,432,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:2030,interoperability,share,share,2030,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:666,modifiability,variab,variables,666,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:342,performance,memor,memory,342,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:850,performance,perform,perform,850,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1074,performance,perform,perform,1074,"ndidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1280,performance,perform,perform,1280,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1645,performance,error,errors,1645,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1688,performance,memor,memory,1688,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1699,performance,disk,disk,1699,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:54,reliability,fail,fails,54,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1720,reliability,availab,available,1720,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1645,safety,error,errors,1645,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1663,safety,compl,completes,1663,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1720,safety,avail,available,1720,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:330,security,sign,significant,330,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1663,security,compl,completes,1663,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1720,security,availab,available,1720,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:342,usability,memor,memory,342,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:850,usability,perform,perform,850,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:898,usability,command,command,898,"Hi Fra,. So let me go through a few items:. $`1)`$ It fails to find variant candidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not neces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1074,usability,perform,perform,1074,"ndidates in the `make_examples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1142,usability,command,command,1142,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1280,usability,perform,perform,1280,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1541,usability,command,command,1541,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1645,usability,error,errors,1645,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1688,usability,memor,memory,1688,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1873,usability,tool,tools,1873,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1947,usability,tool,tools,1947,"mples` stage. Assuming the reads were generated from Illumina whole-exome sequencing (WES), this BAM file is fairly large. To troubleshoot, it is best to specify a smaller region you know candidates should be, as you will need significant memory for this to work for the the whole genome. The flag specifying a region is of this format, and adjust accordingly for your best candidate region of your study: . ```. --regions ""chr20:10,000,000-10,010,000"". ```. You can just use Docker as you are running using that already (via `docker run`), to keep the number of variables small. Before you run Docker again, please look at the next two items as well. $`2)`$ Assuming you used the same reference sequence file (`Homo_sapiens_assembly38.fasta`) to perform the alignment, please run the following command (also you don't need to mark duplicates with DeepVariant):. ``samtools view -H $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. $`3)`$ To perform a preliminary QC on your BAM file can you run the following command:. ``samtools flagstat $FQ.align.sort.marked.bam``. You can provide this via a gist or an attachment. If you have `fastQC` you can perform the following to generate the report, which you can attach a printed PDF file of the HTML output -- or you can attach the html with the accompanying zip file, if that is easier:. ` fastqc $FQ.align.sort.marked.bam`. $`4)`$ When you run the `docker run` command for `run_deepvariant` could you please provide the full output, to see where it gets stuck with errors, or how it completes. Also how much memory and disk space is freely available on the VM? I'm assuming the BAM file is several gigabytes. DeepVariant can read BAM files and will generate the VCF and GVCF, so no additional tools are required for it to work out of the box. We are just using a few tools to troubleshoot, but usually they are not necessary. Would you be willing to share the BAM file to get a better idea what is happening? Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:294,availability,Avail,Avail,294,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:54,performance,disk,disk,54,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:182,performance,disk,disk,182,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:187,performance,memor,memory,187,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:245,performance,memor,memory,245,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:435,performance,lock,lock,435,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:219,reliability,doe,does,219,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:294,safety,Avail,Avail,294,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:435,security,lock,lock,435,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:187,usability,memor,memory,187,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:245,usability,memor,memory,245,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:509,usability,user,user,509,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:524,usability,User,Users,524,"My BAM file is 300 MBytes. I have less than 100 Gb of disk space. I suppose is a lack of space. . But before I was able to create the output and the equivalent report, with the same disk memory. I don't know why now it does not process! This my memory on Ubuntu-VirtualM:. Filesystem Size Used Avail Use% Mounted on. tmpfs 794M 1.1M 793M 1% /run. /dev/sda1 126G 15G 112G 12% /. tmpfs 3.9G 0 3.9G 0% /dev/shm. tmpfs 5.0M 0 5.0M 0% /run/lock. /dev/sda15 105M 6.1M 99M 6% /boot/efi. tmpfs 794M 4.0K 794M 1% /run/user/1000. :C:/Users/frasi/OneDrive/Desktop/NEUROBLASTOMA/NEUROBLASTOMA/NEUROBLASTOMA 1000G 0 1000G 0% /mountpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:456,availability,monitor,monitored,456,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:456,deployability,monitor,monitored,456,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:638,deployability,resourc,resource,638,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:456,energy efficiency,monitor,monitored,456,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:638,energy efficiency,resourc,resource,638,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:995,integrability,sub,subregion,995,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:155,performance,disk,disk,155,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:199,performance,memor,memory-mapped,199,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:277,performance,memor,memory,277,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:287,performance,Memor,Memory,287,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:466,performance,memor,memory,466,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:638,performance,resourc,resource,638,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:456,reliability,monitor,monitored,456,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:456,safety,monitor,monitored,456,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:638,safety,resourc,resource,638,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:456,testability,monitor,monitored,456,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:638,testability,resourc,resource,638,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:199,usability,memor,memory-mapped,199,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:277,usability,memor,memory,277,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:287,usability,Memor,Memory,287,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:466,usability,memor,memory,466,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1048,usability,help,helps,1048,"Hi Fra,. That seems a bit small compared to other WES BAM files, which are between 5 - 10 GB:. https://ega-archive.org/datasets/EGAD00001005247/files. The disk space seems okay, though you have some memory-mapped file-systems, which should be okay if you have a good amount of memory. . Memory on Ubuntu can be checked with `cat /proc/meminfo` or (`top`). For example, when I ran the variant candidate selection, on just a small region of a chromosome and monitored memory usage, I saw the following trend:. ![image](https://github.com/google/deepvariant/assets/6555937/7e200851-3fde-4ad6-bf75-477ccefb9e32). You'll notice that it can be resource intensive. This is the reason I was opting we troubleshoot by first trying with a smaller region of a chromosome using `--regions`, ideally one you know variants should be present. A preliminary check with `samtools view -c BAM REGION` would ensure you have mapped reads there for DeepVariant to find, and with `samtools flagstat` to check on that subregion for the number of quality reads. . Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:20,safety,sanit,sanity,20,"Hi @FraSilver. As a sanity check, can you try running this quick start with no modifications at all? Try just copy-pasting it exactly as written without using your own files or making any other changes to the command:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:20,security,sanit,sanity,20,"Hi @FraSilver. As a sanity check, can you try running this quick start with no modifications at all? Try just copy-pasting it exactly as written without using your own files or making any other changes to the command:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:79,security,modif,modifications,79,"Hi @FraSilver. As a sanity check, can you try running this quick start with no modifications at all? Try just copy-pasting it exactly as written without using your own files or making any other changes to the command:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:209,usability,command,command,209,"Hi @FraSilver. As a sanity check, can you try running this quick start with no modifications at all? Try just copy-pasting it exactly as written without using your own files or making any other changes to the command:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:235,safety,test,testdata,235,"I' m using Ubuntu Virtual-Machine mount on Windows 11. Running ""cat ${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta"" it displays the fasta file, but after running:. sudo docker run...., it reports -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. Why?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:97,testability,unit,unittest,97,"I' m using Ubuntu Virtual-Machine mount on Windows 11. Running ""cat ${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta"" it displays the fasta file, but after running:. sudo docker run...., it reports -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. Why?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:235,testability,test,testdata,235,"I' m using Ubuntu Virtual-Machine mount on Windows 11. Running ""cat ${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta"" it displays the fasta file, but after running:. sudo docker run...., it reports -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. Why?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:260,testability,unit,unittest,260,"I' m using Ubuntu Virtual-Machine mount on Windows 11. Running ""cat ${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta"" it displays the fasta file, but after running:. sudo docker run...., it reports -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. Why?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:547,energy efficiency,core,cores,547,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:667,modifiability,paramet,parameters,667,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:811,safety,test,testdata,811,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:894,safety,test,testdata,894,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:435,testability,unit,unittest,435,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:811,testability,test,testdata,811,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:836,testability,unit,unittest,836,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:894,testability,test,testdata,894,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:919,testability,unit,unittest,919,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:602,usability,document,documentation,602,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:643,usability,clarit,clarity,643,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:737,usability,command,command,737,"Thank you Maria -- that's definitely a more elegant starting point. Hi Fra,. The reason why you are seeing that is because there are additional characters after some of the backslash characters (`\`) at the end of each line. So you need to make sure there are no spaces or characters after each backslash (i.e. it needs to be the last character on those lines) like this:. ```. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. ```. The strings that starts with ` **Replace this string...`, ` **Optional.` or ` **How many cores...` need to be removed, as they are there in the documentation only to provide additional clarity regarding those parameters. Otherwise Bash interprets the next line as a separate new command to run, like this:. ```. paul$ --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta. -bash: --ref=/mountpoint/fastQ/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory. paul$. ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:96,deployability,fail,failed,96,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:213,deployability,version,version,213,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:256,deployability,version,version,256,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:264,deployability,instal,installed,264,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:213,integrability,version,version,213,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:256,integrability,version,version,256,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:221,interoperability,incompatib,incompatible,221,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:213,modifiability,version,version,213,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:256,modifiability,version,version,256,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:77,performance,parallel,parallel,77,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:96,reliability,fail,failed,96,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:39,safety,input,input,39,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:39,usability,input,input,39,"ValueError: NOT_FOUND: Could not open /input/SAMPLE01.align.sort.marked.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples. I have a right bam file. . Can be that ""make examples"" require a python version incompatible with my python 3.10.x version installed on Unix-virtual machine?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:523,availability,error,error,523,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:768,availability,error,error,768,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:20,deployability,contain,container,20,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:52,deployability,version,version,52,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:52,integrability,version,version,52,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:292,interoperability,compatib,compatible,292,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:52,modifiability,version,version,52,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:414,modifiability,variab,variables,414,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:686,modifiability,variab,variable,686,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:523,performance,error,error,523,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:768,performance,error,error,768,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:164,safety,sanit,sanity,164,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:241,safety,compl,complete,241,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:523,safety,error,error,523,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:730,safety,compl,complete,730,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:768,safety,error,error,768,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:164,security,sanit,sanity,164,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:241,security,compl,complete,241,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:730,security,compl,complete,730,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:268,testability,context,context,268,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:546,testability,context,context,546,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:786,testability,context,context,786,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:374,usability,command,command,374,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:523,usability,error,error,523,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:568,usability,command,command,568,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:768,usability,error,error,768,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:822,usability,stop,stopped,822,"Hi Fra,. The Docker container has it's own internal version of Python so it becomes independent of any system it would be run on. . I have 4 questions:. 1) Did the sanity check Maria suggested work successfully for you? This is important to complete first as it gives context that your VM is compatible with a successful DeepVariant run. 2) Can you please provide the whole command that you just ran including any variables that were defined. Without both of these it becomes impossible to eliminate possible causes of the error, as they provide context as to how the command was set up. . 3) Please provide the `ls -l ${INPUT_DIR}` output to make sure it lists the BAM file using that variable definition. 4) Can you provide the complete output of the run, including error. This gives context as how far it ran before it stopped, which includes anything that worked. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:83,modifiability,variab,variable,83,"It works. Both with the tutorial data and my data. It doesn't read bam file with a variable previously declared. I've changed $FQ with SAMPLE01 and it works. Thanks. . Kind regard,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:54,reliability,doe,doesn,54,"It works. Both with the tutorial data and my data. It doesn't read bam file with a variable previously declared. I've changed $FQ with SAMPLE01 and it works. Thanks. . Kind regard,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:111,integrability,discover,discover,111,"Hi Fra,. That's great to hear! Hopefully you were able to detect some expected variant candidates, and ideally discover some novel and relevant ones as well. Glad this helped you out -- it was a fun team effort! Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:111,interoperability,discover,discover,111,"Hi Fra,. That's great to hear! Hopefully you were able to detect some expected variant candidates, and ideally discover some novel and relevant ones as well. Glad this helped you out -- it was a fun team effort! Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:58,safety,detect,detect,58,"Hi Fra,. That's great to hear! Hopefully you were able to detect some expected variant candidates, and ideally discover some novel and relevant ones as well. Glad this helped you out -- it was a fun team effort! Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:58,security,detect,detect,58,"Hi Fra,. That's great to hear! Hopefully you were able to detect some expected variant candidates, and ideally discover some novel and relevant ones as well. Glad this helped you out -- it was a fun team effort! Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:199,security,team,team,199,"Hi Fra,. That's great to hear! Hopefully you were able to detect some expected variant candidates, and ideally discover some novel and relevant ones as well. Glad this helped you out -- it was a fun team effort! Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:111,usability,discov,discover,111,"Hi Fra,. That's great to hear! Hopefully you were able to detect some expected variant candidates, and ideally discover some novel and relevant ones as well. Glad this helped you out -- it was a fun team effort! Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:168,usability,help,helped,168,"Hi Fra,. That's great to hear! Hopefully you were able to detect some expected variant candidates, and ideally discover some novel and relevant ones as well. Glad this helped you out -- it was a fun team effort! Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:514,safety,input,input,514,"Hi pgrosu, sorry again. It works using the quickstart tutorial but not with my BAM and fasta file. Running ls -l ${INPUT_DIR} it prints out: . Homo_sapiens_assembly38-3.sorted.bed.gz.tbi. Homo_sapiens_assembly38.fasta. Homo_sapiens_assembly38.fasta.fai. SAMPLE01.align.sort.marked.bai. SAMPLE01.align.sort.marked.bam. Code I run:. PWD=/mountpoint/fastQ. INPUT_DIR=""${PWD}/testdata_input"". mkdir -p ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/testdata_output"". mkdir -p ""${OUTPUT_DIR}"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/SAMPLE01.align.sort.marked.bam \. --output_vcf=/output/SAMPLE01.vcf.gz \. --output_gvcf=/output/SAMPLE01.g.vcf.gz \. --num_shards=2 . It displays: Task 0/2: 0 candidates. Otherwise, using quick-start.md tutorial it showed 6 candidates. How can I resolve? Thanks,. Fra.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:662,safety,input,input,662,"Hi pgrosu, sorry again. It works using the quickstart tutorial but not with my BAM and fasta file. Running ls -l ${INPUT_DIR} it prints out: . Homo_sapiens_assembly38-3.sorted.bed.gz.tbi. Homo_sapiens_assembly38.fasta. Homo_sapiens_assembly38.fasta.fai. SAMPLE01.align.sort.marked.bai. SAMPLE01.align.sort.marked.bam. Code I run:. PWD=/mountpoint/fastQ. INPUT_DIR=""${PWD}/testdata_input"". mkdir -p ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/testdata_output"". mkdir -p ""${OUTPUT_DIR}"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/SAMPLE01.align.sort.marked.bam \. --output_vcf=/output/SAMPLE01.vcf.gz \. --output_gvcf=/output/SAMPLE01.g.vcf.gz \. --num_shards=2 . It displays: Task 0/2: 0 candidates. Otherwise, using quick-start.md tutorial it showed 6 candidates. How can I resolve? Thanks,. Fra.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:710,safety,input,input,710,"Hi pgrosu, sorry again. It works using the quickstart tutorial but not with my BAM and fasta file. Running ls -l ${INPUT_DIR} it prints out: . Homo_sapiens_assembly38-3.sorted.bed.gz.tbi. Homo_sapiens_assembly38.fasta. Homo_sapiens_assembly38.fasta.fai. SAMPLE01.align.sort.marked.bai. SAMPLE01.align.sort.marked.bam. Code I run:. PWD=/mountpoint/fastQ. INPUT_DIR=""${PWD}/testdata_input"". mkdir -p ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/testdata_output"". mkdir -p ""${OUTPUT_DIR}"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/SAMPLE01.align.sort.marked.bam \. --output_vcf=/output/SAMPLE01.vcf.gz \. --output_gvcf=/output/SAMPLE01.g.vcf.gz \. --num_shards=2 . It displays: Task 0/2: 0 candidates. Otherwise, using quick-start.md tutorial it showed 6 candidates. How can I resolve? Thanks,. Fra.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:514,usability,input,input,514,"Hi pgrosu, sorry again. It works using the quickstart tutorial but not with my BAM and fasta file. Running ls -l ${INPUT_DIR} it prints out: . Homo_sapiens_assembly38-3.sorted.bed.gz.tbi. Homo_sapiens_assembly38.fasta. Homo_sapiens_assembly38.fasta.fai. SAMPLE01.align.sort.marked.bai. SAMPLE01.align.sort.marked.bam. Code I run:. PWD=/mountpoint/fastQ. INPUT_DIR=""${PWD}/testdata_input"". mkdir -p ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/testdata_output"". mkdir -p ""${OUTPUT_DIR}"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/SAMPLE01.align.sort.marked.bam \. --output_vcf=/output/SAMPLE01.vcf.gz \. --output_gvcf=/output/SAMPLE01.g.vcf.gz \. --num_shards=2 . It displays: Task 0/2: 0 candidates. Otherwise, using quick-start.md tutorial it showed 6 candidates. How can I resolve? Thanks,. Fra.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:662,usability,input,input,662,"Hi pgrosu, sorry again. It works using the quickstart tutorial but not with my BAM and fasta file. Running ls -l ${INPUT_DIR} it prints out: . Homo_sapiens_assembly38-3.sorted.bed.gz.tbi. Homo_sapiens_assembly38.fasta. Homo_sapiens_assembly38.fasta.fai. SAMPLE01.align.sort.marked.bai. SAMPLE01.align.sort.marked.bam. Code I run:. PWD=/mountpoint/fastQ. INPUT_DIR=""${PWD}/testdata_input"". mkdir -p ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/testdata_output"". mkdir -p ""${OUTPUT_DIR}"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/SAMPLE01.align.sort.marked.bam \. --output_vcf=/output/SAMPLE01.vcf.gz \. --output_gvcf=/output/SAMPLE01.g.vcf.gz \. --num_shards=2 . It displays: Task 0/2: 0 candidates. Otherwise, using quick-start.md tutorial it showed 6 candidates. How can I resolve? Thanks,. Fra.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:710,usability,input,input,710,"Hi pgrosu, sorry again. It works using the quickstart tutorial but not with my BAM and fasta file. Running ls -l ${INPUT_DIR} it prints out: . Homo_sapiens_assembly38-3.sorted.bed.gz.tbi. Homo_sapiens_assembly38.fasta. Homo_sapiens_assembly38.fasta.fai. SAMPLE01.align.sort.marked.bai. SAMPLE01.align.sort.marked.bam. Code I run:. PWD=/mountpoint/fastQ. INPUT_DIR=""${PWD}/testdata_input"". mkdir -p ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/testdata_output"". mkdir -p ""${OUTPUT_DIR}"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/Homo_sapiens_assembly38.fasta \. --reads=/input/SAMPLE01.align.sort.marked.bam \. --output_vcf=/output/SAMPLE01.vcf.gz \. --output_gvcf=/output/SAMPLE01.g.vcf.gz \. --num_shards=2 . It displays: Task 0/2: 0 candidates. Otherwise, using quick-start.md tutorial it showed 6 candidates. How can I resolve? Thanks,. Fra.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:79,deployability,stage,stage,79,"Hi Fra,. If it cannot find candidates, that happens during the `make_examples` stage. `make_examples` goes through an allele counter, and very sensitive variant caller to determine if there is enough read support for a candidate. Was the same genome (fasta) used for the alignment phase (from fastq) when generating the BAM files? When you load your BAM file in IGV to how many chromosomes and chromosomal regions does it show alignment for? . In the [quickstart tutorial](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) it uses the WGS model not the WES one (as indicated by `--model_type=WES` above). Also I believe your BAM file is only 300 Mb, which a bit small compared to other WES ones:. https://ega-archive.org/datasets/EGAD00001005247/files. Is your dataset a WES or WGS dataset? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:340,energy efficiency,load,load,340,"Hi Fra,. If it cannot find candidates, that happens during the `make_examples` stage. `make_examples` goes through an allele counter, and very sensitive variant caller to determine if there is enough read support for a candidate. Was the same genome (fasta) used for the alignment phase (from fastq) when generating the BAM files? When you load your BAM file in IGV to how many chromosomes and chromosomal regions does it show alignment for? . In the [quickstart tutorial](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) it uses the WGS model not the WES one (as indicated by `--model_type=WES` above). Also I believe your BAM file is only 300 Mb, which a bit small compared to other WES ones:. https://ega-archive.org/datasets/EGAD00001005247/files. Is your dataset a WES or WGS dataset? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:603,energy efficiency,model,model,603,"Hi Fra,. If it cannot find candidates, that happens during the `make_examples` stage. `make_examples` goes through an allele counter, and very sensitive variant caller to determine if there is enough read support for a candidate. Was the same genome (fasta) used for the alignment phase (from fastq) when generating the BAM files? When you load your BAM file in IGV to how many chromosomes and chromosomal regions does it show alignment for? . In the [quickstart tutorial](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) it uses the WGS model not the WES one (as indicated by `--model_type=WES` above). Also I believe your BAM file is only 300 Mb, which a bit small compared to other WES ones:. https://ega-archive.org/datasets/EGAD00001005247/files. Is your dataset a WES or WGS dataset? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:340,performance,load,load,340,"Hi Fra,. If it cannot find candidates, that happens during the `make_examples` stage. `make_examples` goes through an allele counter, and very sensitive variant caller to determine if there is enough read support for a candidate. Was the same genome (fasta) used for the alignment phase (from fastq) when generating the BAM files? When you load your BAM file in IGV to how many chromosomes and chromosomal regions does it show alignment for? . In the [quickstart tutorial](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) it uses the WGS model not the WES one (as indicated by `--model_type=WES` above). Also I believe your BAM file is only 300 Mb, which a bit small compared to other WES ones:. https://ega-archive.org/datasets/EGAD00001005247/files. Is your dataset a WES or WGS dataset? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:414,reliability,doe,does,414,"Hi Fra,. If it cannot find candidates, that happens during the `make_examples` stage. `make_examples` goes through an allele counter, and very sensitive variant caller to determine if there is enough read support for a candidate. Was the same genome (fasta) used for the alignment phase (from fastq) when generating the BAM files? When you load your BAM file in IGV to how many chromosomes and chromosomal regions does it show alignment for? . In the [quickstart tutorial](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) it uses the WGS model not the WES one (as indicated by `--model_type=WES` above). Also I believe your BAM file is only 300 Mb, which a bit small compared to other WES ones:. https://ega-archive.org/datasets/EGAD00001005247/files. Is your dataset a WES or WGS dataset? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:603,security,model,model,603,"Hi Fra,. If it cannot find candidates, that happens during the `make_examples` stage. `make_examples` goes through an allele counter, and very sensitive variant caller to determine if there is enough read support for a candidate. Was the same genome (fasta) used for the alignment phase (from fastq) when generating the BAM files? When you load your BAM file in IGV to how many chromosomes and chromosomal regions does it show alignment for? . In the [quickstart tutorial](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) it uses the WGS model not the WES one (as indicated by `--model_type=WES` above). Also I believe your BAM file is only 300 Mb, which a bit small compared to other WES ones:. https://ega-archive.org/datasets/EGAD00001005247/files. Is your dataset a WES or WGS dataset? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:205,usability,support,support,205,"Hi Fra,. If it cannot find candidates, that happens during the `make_examples` stage. `make_examples` goes through an allele counter, and very sensitive variant caller to determine if there is enough read support for a candidate. Was the same genome (fasta) used for the alignment phase (from fastq) when generating the BAM files? When you load your BAM file in IGV to how many chromosomes and chromosomal regions does it show alignment for? . In the [quickstart tutorial](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) it uses the WGS model not the WES one (as indicated by `--model_type=WES` above). Also I believe your BAM file is only 300 Mb, which a bit small compared to other WES ones:. https://ega-archive.org/datasets/EGAD00001005247/files. Is your dataset a WES or WGS dataset? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:578,usability,command,command,578,"Hi Fra,. If it cannot find candidates, that happens during the `make_examples` stage. `make_examples` goes through an allele counter, and very sensitive variant caller to determine if there is enough read support for a candidate. Was the same genome (fasta) used for the alignment phase (from fastq) when generating the BAM files? When you load your BAM file in IGV to how many chromosomes and chromosomal regions does it show alignment for? . In the [quickstart tutorial](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) it uses the WGS model not the WES one (as indicated by `--model_type=WES` above). Also I believe your BAM file is only 300 Mb, which a bit small compared to other WES ones:. https://ega-archive.org/datasets/EGAD00001005247/files. Is your dataset a WES or WGS dataset? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:629,usability,indicat,indicated,629,"Hi Fra,. If it cannot find candidates, that happens during the `make_examples` stage. `make_examples` goes through an allele counter, and very sensitive variant caller to determine if there is enough read support for a candidate. Was the same genome (fasta) used for the alignment phase (from fastq) when generating the BAM files? When you load your BAM file in IGV to how many chromosomes and chromosomal regions does it show alignment for? . In the [quickstart tutorial](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) it uses the WGS model not the WES one (as indicated by `--model_type=WES` above). Also I believe your BAM file is only 300 Mb, which a bit small compared to other WES ones:. https://ega-archive.org/datasets/EGAD00001005247/files. Is your dataset a WES or WGS dataset? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:12,integrability,sub,subset,12,"It's just a subset: Chromosome 8 of WES dataset. Might work by running the code using the whole WES or WGS? Thanks,. Fra.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:202,deployability,Integr,Integrative,202,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:466,deployability,depend,dependent,466,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:659,energy efficiency,model,model,659,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:202,integrability,Integr,Integrative,202,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:466,integrability,depend,dependent,466,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:843,integrability,sub,subsequent,843,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:202,interoperability,Integr,Integrative,202,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:202,modifiability,Integr,Integrative,202,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:466,modifiability,depend,dependent,466,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:202,reliability,Integr,Integrative,202,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:466,safety,depend,dependent,466,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:712,safety,valid,valid,712,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:202,security,Integr,Integrative,202,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:659,security,model,model,659,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:202,testability,Integr,Integrative,202,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:466,testability,depend,dependent,466,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:343,usability,confirm,confirm,343,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:502,usability,support,support,502,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:734,usability,help,help,734,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:920,usability,help,helps,920,"Hi Fra,. As far as I can infer, there is something in the BAM and reference files that the variant caller is unable to call variants for. Can you please take a look in the chromosome 8 region with the [Integrative Genomics Viewer (IGV)](https://software.broadinstitute.org/software/igv/) using your BAM aligned to the same exact reference, to confirm that you see some variation and proper alignment. I am looking at the call variant code, and the allele counts are dependent on the reference and read support by position. You should also limit your analysis with the `--regions` flag so it is quicker as well. If your data is WES then you should use the WES model, in order for the results to be scientifically valid. Maybe it might help if you realign your FASTQ files to the reference used by DeepVariant to regenerate the BAM file and the subsequent BAI file, just to be sure nothing happened along the way. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:13,reliability,doe,doesn,13,"Hi Paul,. it doesn't work. I have confirmed the presence of variants in my BAM file with IGV software and used --regions flag to be faster. I do not think realign is the solution to the problem, unfortunately. Thanks you all the same,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:34,usability,confirm,confirmed,34,"Hi Paul,. it doesn't work. I have confirmed the presence of variants in my BAM file with IGV software and used --regions flag to be faster. I do not think realign is the solution to the problem, unfortunately. Thanks you all the same,. Fra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:276,integrability,filter,filter,276,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:97,interoperability,share,share,97,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:998,interoperability,specif,specific-variant-in-my-data,998,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:407,modifiability,paramet,parameters,407,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:870,modifiability,paramet,parameters,870,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:970,reliability,doe,does-deepvariant-not-call-a-specific-variant-in-my-data,970,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1401,reliability,doe,does,1401,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:181,safety,reme,remember,181,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1329,security,command-lin,command-line,1329,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:169,usability,behavi,behavior,169,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:426,usability,prefer,preference,426,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1253,usability,behavi,behavior,1253,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1329,usability,command,command-line,1329,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1357,usability,command,command,1357,"Hi Fra,. That is very interesting -- let me ask a few questions:. $`1)`$ Would you be willing to share the data? $`2)`$ Do other BAM files that you have exhibit similar behavior? I remember you mentioning that the quickstart tutorial worked for you. $`3)`$ If you want to not filter out possible candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference:. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. $`4)`$ Have you tried to see if other variant callers such as [freebayes](https://github.com/freebayes/freebayes) exhibit similar behavior with your dataset? $`5)`$ If you type on your Linux terminal (Bash command-line) the following command:. ```. cat /proc/meminfo. ```. What does it report back? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/676:129,deployability,updat,update,129,Thanks for bringing this to our attention! I'm running our tests with `nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04` now and will update here when I have confirmed whether it's working.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/676:59,safety,test,tests,59,Thanks for bringing this to our attention! I'm running our tests with `nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04` now and will update here when I have confirmed whether it's working.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/676:129,safety,updat,update,129,Thanks for bringing this to our attention! I'm running our tests with `nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04` now and will update here when I have confirmed whether it's working.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/676:129,security,updat,update,129,Thanks for bringing this to our attention! I'm running our tests with `nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04` now and will update here when I have confirmed whether it's working.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/676:59,testability,test,tests,59,Thanks for bringing this to our attention! I'm running our tests with `nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04` now and will update here when I have confirmed whether it's working.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/676:153,usability,confirm,confirmed,153,Thanks for bringing this to our attention! I'm running our tests with `nvidia/cuda:12.1.1-cudnn8-devel-ubuntu20.04` now and will update here when I have confirmed whether it's working.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/676:38,safety,test,tested,38,"The 12.1.1 base image did NOT work. I tested `nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04` instead, which did work correctly. . # Please use `nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/676:38,testability,test,tested,38,"The 12.1.1 base image did NOT work. I tested `nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04` instead, which did work correctly. . # Please use `nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/677:77,deployability,version,version,77,"Hi @Sami-St ,. This is usually something to do with some underlying software version not matching. . A few suggestions you can try:. * https://github.com/google/deepvariant/issues/580#issuecomment-1304902858. * https://github.com/google/deepvariant/issues/559#issuecomment-1230609842. And, Docker would be usually easier than Singularity. But if you can't use Docker, maybe consider trying udocker. I haven't personally tried it, but here is some information:. * https://github.com/google/deepvariant/issues/669#issuecomment-1603444351. If none of these work, let us know and we can ask a few questions to check your environment a bit more (and see how we can reproduce the issue to debug)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:77,integrability,version,version,77,"Hi @Sami-St ,. This is usually something to do with some underlying software version not matching. . A few suggestions you can try:. * https://github.com/google/deepvariant/issues/580#issuecomment-1304902858. * https://github.com/google/deepvariant/issues/559#issuecomment-1230609842. And, Docker would be usually easier than Singularity. But if you can't use Docker, maybe consider trying udocker. I haven't personally tried it, but here is some information:. * https://github.com/google/deepvariant/issues/669#issuecomment-1603444351. If none of these work, let us know and we can ask a few questions to check your environment a bit more (and see how we can reproduce the issue to debug)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:77,modifiability,version,version,77,"Hi @Sami-St ,. This is usually something to do with some underlying software version not matching. . A few suggestions you can try:. * https://github.com/google/deepvariant/issues/580#issuecomment-1304902858. * https://github.com/google/deepvariant/issues/559#issuecomment-1230609842. And, Docker would be usually easier than Singularity. But if you can't use Docker, maybe consider trying udocker. I haven't personally tried it, but here is some information:. * https://github.com/google/deepvariant/issues/669#issuecomment-1603444351. If none of these work, let us know and we can ask a few questions to check your environment a bit more (and see how we can reproduce the issue to debug)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:409,usability,person,personally,409,"Hi @Sami-St ,. This is usually something to do with some underlying software version not matching. . A few suggestions you can try:. * https://github.com/google/deepvariant/issues/580#issuecomment-1304902858. * https://github.com/google/deepvariant/issues/559#issuecomment-1230609842. And, Docker would be usually easier than Singularity. But if you can't use Docker, maybe consider trying udocker. I haven't personally tried it, but here is some information:. * https://github.com/google/deepvariant/issues/669#issuecomment-1603444351. If none of these work, let us know and we can ask a few questions to check your environment a bit more (and see how we can reproduce the issue to debug)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:267,deployability,updat,updated,267,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:100,performance,time,time,100,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:541,reliability,Doe,Does,541,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:225,safety,input,input,225,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:267,safety,updat,updated,267,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:343,safety,input,input,343,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:352,safety,input,input,352,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:506,safety,test,test,506,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:267,security,updat,updated,267,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:506,testability,test,test,506,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:47,usability,help,helpful,47,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:225,usability,input,input,225,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:343,usability,input,input,343,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:352,usability,input,input,352,"Hi @Sami-St,. What @pichuan wrote is also very helpful to try -- I guess we were typing at the same time :) . So it works for me if I replace the beginning of the `shell` field of the Snakemake file with the following -- the input and output mapping would need to be updated based on your directory setup:. ```. docker run \. -v ""/input_files/input"":""/input"" \. -v ""/output_files/output"":""/output"" \. google/deepvariant:1.5.0 \. /opt/deepvariant/bin/make_examples \. ... ```. This would be a first step to test before generalizing the file. Does this also work for you? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:324,deployability,contain,container,324,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:292,interoperability,bind,bind,292,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:298,interoperability,share,shared,298,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:396,interoperability,bind,bind,396,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:292,modifiability,bind,bind,292,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:396,modifiability,bind,bind,396,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:599,performance,perform,performs,599,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:236,security,command-lin,command-line,236,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:236,usability,command,command-line,236,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:599,usability,perform,performs,599,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:642,usability,help,helps,642,"Hi @Sami-St,. If you're really keen on using Singularity, then you can add the following two lines to your `Snakefile`:. ```. threads: 1. singularity: ""/location_of_your_sif_file/deepvariant_1.5.0.sif"". ```. And then launch it from the command-line with the following to ensure that you map (bind) shared folders within the container:. ```. snakemake -c 1 --use-singularity --singularity-args ""--bind /folder_to_share_with_singularity"". ```. It might be better if you use `/opt/deepvariant/bin/run_deepvariant` instead of `make_examples` $`-`$ unless you really know what your are doing $`-`$ as it performs the proper setup for you. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:454,deployability,updat,update,454,"Hey @pichuan, @pgrosu . thx for the quick reply's :) i tested your first idea paul still had the same issue sadly, but the solution from issue 559 seems to be working (i dont understand why so but thats another problem) since the workflow is still running so i cant say for sure but it makes the tfrecords what didnt happend the last few time. ![image](https://github.com/google/deepvariant/assets/138118818/14c3b254-ec78-468c-9a2f-301443bc3a5b). I will update when the Workflow is done . Best regards . Sami",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:338,performance,time,time,338,"Hey @pichuan, @pgrosu . thx for the quick reply's :) i tested your first idea paul still had the same issue sadly, but the solution from issue 559 seems to be working (i dont understand why so but thats another problem) since the workflow is still running so i cant say for sure but it makes the tfrecords what didnt happend the last few time. ![image](https://github.com/google/deepvariant/assets/138118818/14c3b254-ec78-468c-9a2f-301443bc3a5b). I will update when the Workflow is done . Best regards . Sami",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:55,safety,test,tested,55,"Hey @pichuan, @pgrosu . thx for the quick reply's :) i tested your first idea paul still had the same issue sadly, but the solution from issue 559 seems to be working (i dont understand why so but thats another problem) since the workflow is still running so i cant say for sure but it makes the tfrecords what didnt happend the last few time. ![image](https://github.com/google/deepvariant/assets/138118818/14c3b254-ec78-468c-9a2f-301443bc3a5b). I will update when the Workflow is done . Best regards . Sami",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:454,safety,updat,update,454,"Hey @pichuan, @pgrosu . thx for the quick reply's :) i tested your first idea paul still had the same issue sadly, but the solution from issue 559 seems to be working (i dont understand why so but thats another problem) since the workflow is still running so i cant say for sure but it makes the tfrecords what didnt happend the last few time. ![image](https://github.com/google/deepvariant/assets/138118818/14c3b254-ec78-468c-9a2f-301443bc3a5b). I will update when the Workflow is done . Best regards . Sami",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:454,security,updat,update,454,"Hey @pichuan, @pgrosu . thx for the quick reply's :) i tested your first idea paul still had the same issue sadly, but the solution from issue 559 seems to be working (i dont understand why so but thats another problem) since the workflow is still running so i cant say for sure but it makes the tfrecords what didnt happend the last few time. ![image](https://github.com/google/deepvariant/assets/138118818/14c3b254-ec78-468c-9a2f-301443bc3a5b). I will update when the Workflow is done . Best regards . Sami",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:55,testability,test,tested,55,"Hey @pichuan, @pgrosu . thx for the quick reply's :) i tested your first idea paul still had the same issue sadly, but the solution from issue 559 seems to be working (i dont understand why so but thats another problem) since the workflow is still running so i cant say for sure but it makes the tfrecords what didnt happend the last few time. ![image](https://github.com/google/deepvariant/assets/138118818/14c3b254-ec78-468c-9a2f-301443bc3a5b). I will update when the Workflow is done . Best regards . Sami",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:175,testability,understand,understand,175,"Hey @pichuan, @pgrosu . thx for the quick reply's :) i tested your first idea paul still had the same issue sadly, but the solution from issue 559 seems to be working (i dont understand why so but thats another problem) since the workflow is still running so i cant say for sure but it makes the tfrecords what didnt happend the last few time. ![image](https://github.com/google/deepvariant/assets/138118818/14c3b254-ec78-468c-9a2f-301443bc3a5b). I will update when the Workflow is done . Best regards . Sami",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:230,usability,workflow,workflow,230,"Hey @pichuan, @pgrosu . thx for the quick reply's :) i tested your first idea paul still had the same issue sadly, but the solution from issue 559 seems to be working (i dont understand why so but thats another problem) since the workflow is still running so i cant say for sure but it makes the tfrecords what didnt happend the last few time. ![image](https://github.com/google/deepvariant/assets/138118818/14c3b254-ec78-468c-9a2f-301443bc3a5b). I will update when the Workflow is done . Best regards . Sami",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:470,usability,Workflow,Workflow,470,"Hey @pichuan, @pgrosu . thx for the quick reply's :) i tested your first idea paul still had the same issue sadly, but the solution from issue 559 seems to be working (i dont understand why so but thats another problem) since the workflow is still running so i cant say for sure but it makes the tfrecords what didnt happend the last few time. ![image](https://github.com/google/deepvariant/assets/138118818/14c3b254-ec78-468c-9a2f-301443bc3a5b). I will update when the Workflow is done . Best regards . Sami",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:494,availability,down,down,494,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:766,deployability,configurat,configurations,766,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:590,energy efficiency,model,models,590,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:637,energy efficiency,optim,optimized,637,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:927,energy efficiency,model,models,927,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1038,energy efficiency,model,model,1038,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1116,energy efficiency,optim,optimized,1116,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:766,integrability,configur,configurations,766,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:652,interoperability,specif,specific,652,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:465,modifiability,Pac,PacBio,465,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:661,modifiability,paramet,parameters,661,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:766,modifiability,configur,configurations,766,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:868,modifiability,paramet,parameters,868,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:637,performance,optimiz,optimized,637,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:941,performance,time,times,941,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1116,performance,optimiz,optimized,1116,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:950,reliability,resilien,resilient,950,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:950,safety,resilien,resilient,950,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:207,security,team,team,207,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:590,security,model,models,590,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:766,security,configur,configurations,766,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:927,security,model,models,927,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1038,security,model,model,1038,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:245,testability,Understand,Understanding,245,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:562,testability,understand,understand,562,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1161,usability,help,helps,1161,"Hi Sami,. That's great news! Yes, example tfrecords is what you want -- this creates the variant candidates with the accompanying images. Whatever gets you to the right result is a good solution, and it's a team effort to quickly get you there. Understanding what exactly is being -- or not being created -- and why is just as important, so you have full insight of the steps of the experiment. Just from your setup I can infer you are probably running data from a PacBio sequencer. You can go down some nice rabbit holes with DeepVariant, if you really want to understand the process. The models for different types of sequencers where optimized with specific parameters in mind -- some more flexible than others. The `make_examples` step generates the right image configurations for those, or you can rely on `run_deepvariant` to do that for you -- ideally all your parameters were properly interpreted in Python. Though the models can at times be resilient under some data conditions, you want to provide the right data to the correct model to be sure your results are properly interpreted as they were naturally optimized under those conditions :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:42,usability,close,close,42,Glad to hear the problem was solved. I'll close this issue now. Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/678:35,deployability,updat,update,35,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:356,deployability,contain,container,356,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:88,interoperability,bind,binds,88,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:98,interoperability,bind,bind,98,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:118,interoperability,bind,bind,118,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:212,interoperability,bind,bind,212,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:232,interoperability,bind,bind,232,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:88,modifiability,bind,binds,88,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:98,modifiability,bind,bind,98,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:118,modifiability,bind,bind,118,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:212,modifiability,bind,bind,212,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:232,modifiability,bind,bind,232,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:35,safety,updat,update,35,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:35,security,updat,update,35,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:334,security,access,accessible,334,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:23,usability,close,close,23,"@tzcoolman You're very close. Just update your `singularity run` with the following two binds (`--bind ${INPUT_DIR} --bind ${OUTPUT_DIR}`), like this:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} docker://google/deepvariant:""${BIN_VERSION}"" ... ```. This makes those directories accessible within the container. The rest can stay the same. Let me know if there is anything else. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/679:579,availability,error,error,579,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:178,deployability,contain,container,178,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:490,deployability,contain,containall,490,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:71,interoperability,bind,bind,71,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:71,modifiability,bind,bind,71,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:242,modifiability,interm,intermediate,242,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:342,modifiability,interm,intermediate,342,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:579,performance,error,error,579,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:579,safety,error,error,579,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:49,security,command-lin,command-line,49,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:49,usability,command,command-line,49,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:579,usability,error,error,579,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:600,usability,progress,progress,600,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:638,usability,help,helped,638,"Hi Bo,. First remove the following two from your command-line:. ```. --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp. --intermediate_results_dir=/tmp. ```. The Singularity container already has its own `/tmp` folder, and if you want an intermediate results folder you would want it be a different (unused) path name. You don't need the intermediate results folder to run DeepVariant. If you want to use stuff from your home folder (or other auto-mounted ones), then you don't need `--containall` either. Let me know if that fixes things, otherwise we can see what the next error you get and we progress like that. Let me know if it helped. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:92,availability,operat,operation,92,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:178,availability,error,error,178,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2615,availability,error,error,2615,"tion ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3863,availability,Error,Error,3863,"4, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3958,availability,Error,Error,3958,"/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6320,availability,Error,Error,6320,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:220,deployability,contain,containall,220,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:331,deployability,contain,containall,331,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2152,deployability,modul,module,2152,"ing --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2635,deployability,Continu,Continue,2635,"ing_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. Fil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3094,deployability,modul,module,3094,"iant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3627,deployability,modul,module,3627,"l?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:5834,deployability,fail,failed,5834,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:5978,deployability,instal,installed,5978,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6092,deployability,fail,failed,6092,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6236,deployability,instal,installed,6236,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:561,integrability,translat,translatome,561,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1102,integrability,buffer,buffer,1102,"emes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1330,integrability,translat,translatome,1330,"inall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3909,integrability,buffer,buffer,3909,"de, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpez",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4448,integrability,translat,translatome,4448,"globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:5013,integrability,buffer,buffer,5013,"ning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warnin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:5241,integrability,translat,translatome,5241,"/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed o",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:277,interoperability,share,share,277,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:347,interoperability,bind,bind,347,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:391,interoperability,bind,bind,391,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:417,interoperability,bind,bind,417,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:451,interoperability,bind,bind,451,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:475,interoperability,bind,bind,475,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:507,interoperability,bind,bind,507,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:561,interoperability,translat,translatome,561,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1330,interoperability,translat,translatome,1330,"inall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4180,interoperability,share,share,4180,"sertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4234,interoperability,bind,bind,4234,"s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhangh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4278,interoperability,bind,bind,4278,"iant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4304,interoperability,bind,bind,4304,"le not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4338,interoperability,bind,bind,4338,"nt call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4362,interoperability,bind,bind,4362,"sr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4394,interoperability,bind,bind,4394," 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4448,interoperability,translat,translatome,4448,"globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:5241,interoperability,translat,translatome,5241,"/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed o",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6039,interoperability,standard,standard,6039,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6297,interoperability,standard,standard,6297,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:240,modifiability,paramet,parameter,240,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:347,modifiability,bind,bind,347,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:391,modifiability,bind,bind,391,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:417,modifiability,bind,bind,417,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:451,modifiability,bind,bind,451,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:475,modifiability,bind,bind,475,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:507,modifiability,bind,bind,507,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:580,modifiability,Pac,PacBio,580,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:781,modifiability,PAC,PACBIO,781,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:951,modifiability,Interm,Intermediate,951,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1225,modifiability,Pac,PacBio,1225,"ll; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1349,modifiability,Pac,PacBio,1349,"/usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_exam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2152,modifiability,modul,module,2152,"ing --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3094,modifiability,modul,module,3094,"iant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3627,modifiability,modul,module,3627,"l?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4234,modifiability,bind,bind,4234,"s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhangh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4278,modifiability,bind,bind,4278,"iant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4304,modifiability,bind,bind,4304,"le not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4338,modifiability,bind,bind,4338,"nt call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4362,modifiability,bind,bind,4362,"sr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4394,modifiability,bind,bind,4394," 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4467,modifiability,Pac,PacBio,4467,"File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4668,modifiability,PAC,PACBIO,4668,"mples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4838,modifiability,Interm,Intermediate,4838,"t found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. pe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:5136,modifiability,Pac,PacBio,5136," sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:5260,modifiability,Pac,PacBio,5260,"b/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:178,performance,error,error,178,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1058,performance,time,time,1058," the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1074,performance,parallel,parallel,1074," command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2615,performance,error,error,2615,"tion ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2622,performance,disk,disk,2622,"600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3853,performance,parallel,parallel,3853,", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate result",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3863,performance,Error,Error,3863,"4, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3937,performance,disk,disk,3937,"le ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3948,performance,parallel,parallel,3948,"python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3958,performance,Error,Error,3958,"/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4969,performance,time,time,4969," $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are support",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4985,performance,parallel,parallel,4985,"pdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed o",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6320,performance,Error,Error,6320,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6564,performance,parallel,parallel,6564,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:5834,reliability,fail,failed,5834,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6092,reliability,fail,failed,6092,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6537,reliability,doe,does,6537,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:54,safety,test,tested,54,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:178,safety,error,error,178,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2152,safety,modul,module,2152,"ing --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2615,safety,error,error,2615,"tion ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3094,safety,modul,module,3094,"iant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3627,safety,modul,module,3627,"l?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3863,safety,Error,Error,3863,"4, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3958,safety,Error,Error,3958,"/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6320,safety,Error,Error,6320,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:79,security,command-lin,command-line,79,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:254,security,command-lin,command-line,254,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4157,security,command-lin,command-line,4157,"ine 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapien",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:54,testability,test,tested,54,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:267,testability,plan,plan,267,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1845,testability,Trace,Traceback,1845,"1.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/ru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2239,testability,Assert,AssertionError,2239,"sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2787,testability,Trace,Traceback,2787,"ef_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_googl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3181,testability,Assert,AssertionError,3181,"make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3320,testability,Trace,Traceback,3320,"riant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3714,testability,Assert,AssertionError,3714,"f/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/out",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4170,testability,plan,plan,4170,"in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:79,usability,command,command-line,79,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:178,usability,error,error,178,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:254,usability,command,command-line,254,"Dear Paul:. Thank you so much for the speedy reply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1043,usability,command,command,1043,"ply. I tested the following two command-line operation schemes separately, and encountered some problems. I feel that the previous error report is not a problem with the (--containall; tmpDir) parameter. ## command-line plan A:. /share/app/singularity/3.8.1/bin/singularity exec \. --containall \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/tmp8_1neaqr in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/R202302180101/R202302180101.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/tmp8_1neaqr/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/tmp8_1neaqr/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2615,usability,error,error,2615,"tion ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_nwff5xo0/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. warning: /tmp/Bazel.runfiles_4ji1hg9j/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so: write error (disk full?). Continue? (y/n/^C) . warning: /tmp/Bazel.runfiles__5bs6aw8/runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so is probably truncated. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3863,usability,Error,Error,3863,"4, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3958,usability,Error,Error,3958,"/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4032,usability,close,close,4032,"pvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4125,usability,user,user,4125,"in/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/R",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4157,usability,command,command-line,4157,"ine 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_i3h8s325/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. Traceback (most recent call last):. File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main. return _run_code(code, main_globals, None,. File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code. exec(code, run_globals). File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 392, in <module>. File ""/opt/deepvariant/bin/make_examples.zip/__main__.py"", line 326, in Main. AssertionError: Cannot exec() '/tmp/Bazel.runfiles_8twzrz82/runfiles/com_google_deepvariant/deepvariant/make_examples.py': file not found. parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapien",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:4954,usability,command,command,4954,"Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. real 0m2.302s. user 0m1.215s. sys 0m0.687s. ## command-line plan B:. /share/app/singularity/3.8.1/bin/singularity exec \. --bind /usr/lib/locale/:/usr/lib/locale/ \. --bind $ccsbam:$ccsbam \. --bind $ccsbam.bai:$ccsbam.bai \. --bind $fasta:$fasta \. --bind $fasta.fai:$fasta.fai \. --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output \. /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:5964,usability,support,supported,5964,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6222,usability,support,supported,6222,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6320,usability,Error,Error,6320,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6599,usability,user,user,6599,"riant/bin/run_deepvariant \. --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20. ***** Intermediate results will be written to /tmp/6178902.1.st_supermem.q/tmpezd79ese in docker. ****. ***** Running the command:*****. time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/Reference/PacBio/minimap2/Homo_sapiens_assembly38.fasta"" --reads ""/hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v4/T202302180201/T202302180201.pbmm2.CCS.alignment.sort.bam"" --examples ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""/tmp/6178902.1.st_supermem.q/tmpezd79ese/gvcf.tfrecord@20.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Error in tempfile() using template /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/parXXXXX.par: Parent directory (/hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/) does not exist at /usr/bin/parallel line 3889. real 0m2.813s. user 0m0.258s. sys 0m0.406s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:107,deployability,contain,container,107,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:218,deployability,contain,containall,218,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:167,interoperability,share,share,167,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:231,interoperability,bind,bind,231,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:400,interoperability,bind,bind,400,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:412,interoperability,bind,bind,412,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:440,interoperability,bind,bind,440,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:231,modifiability,bind,bind,231,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:400,modifiability,bind,bind,400,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:412,modifiability,bind,bind,412,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:440,modifiability,bind,bind,440,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:852,reliability,Doe,Does,852,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:147,safety,permiss,permissions,147,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:34,usability,command,command,34,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:903,usability,command,command,903,"Hi Bo,. If you type the following command, what do you get for an output -- just trying to check that your container has a /tmp folder with proper permissions:. ```. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /usr/lib/locale/:/usr/lib/locale/ /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif ls -l /. ```. By the way, when you `--bind` don't bind individual files, just bind the folder, and then just reference the bam or reference file from that folder, like in the following doc:. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md#notes-on-singularity. Also on the second approach, if you create the following directory via the following, and re-run it:. ```. mkdir -p /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/temporary_internet_files/. ```. Does this make the second approach work? The above command creates the missing `temporary_internet_files` folder. Thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:112,usability,command,command,112,"Dear Paul:. Thank you for your reply! Although I dont know why, I can suddenly run successfully using the same command line as before.. Best Regards! Bo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:101,availability,consist,consistent,101,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:243,availability,cluster,cluster,243,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:303,availability,avail,available,303,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:243,deployability,cluster,cluster,243,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:288,deployability,resourc,resources,288,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:288,energy efficiency,resourc,resources,288,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:69,interoperability,distribut,distributed,69,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:124,performance,workload,workloads,124,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:224,performance,time,timeslot,224,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:288,performance,resourc,resources,288,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:303,reliability,availab,available,303,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:288,safety,resourc,resources,288,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:303,safety,avail,available,303,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:303,security,availab,available,303,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:288,testability,resourc,resources,288,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:101,usability,consist,consistent,101,"Dear Bo,. That's really awesome to hear! Yeah, sometimes how quickly distributed file systems become consistent under heavy workloads is something that has the rare possibility of happening. Today you might have hit a sweet timeslot where the cluster was not being hit very hard, so more resources were available to match (or exceed) the requirements of your run. Glad to hear it all worked out,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:19,usability,help,help,19,"Thank you for your help @pgrosu . Good to know the issue has been resolved. I will close this now. @Zhanghaibo777 , please feel free to reopen if the issue persists.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:83,usability,close,close,83,"Thank you for your help @pgrosu . Good to know the issue has been resolved. I will close this now. @Zhanghaibo777 , please feel free to reopen if the issue persists.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/680:111,reliability,doe,does,111,"Hi @egnarora,. Your initial approach is the correct one. Since you have multiple samples, and DeepVariant only does single sample calling, it would not be advisable to merge your BAM files into a single sample BAM file. Regarding having a multi-sample BAM file, that would not work with DeepVariant as it only accepts one sample. If in fact the whole group are the same sample, then yes you can merge, otherwise no. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:424,usability,help,helps,424,"Hi @egnarora,. Your initial approach is the correct one. Since you have multiple samples, and DeepVariant only does single sample calling, it would not be advisable to merge your BAM files into a single sample BAM file. Regarding having a multi-sample BAM file, that would not work with DeepVariant as it only accepts one sample. If in fact the whole group are the same sample, then yes you can merge, otherwise no. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:225,integrability,sub,subsequent,225,"Dear Paul. Thank you very much for your answer, but I still have a small question to ask you, is there a big difference between the result of this combination and the result of gatk group call? Will it have any impact on my subsequent analysis? For example, some individual missing SNPS will not exist in the merged vcf? With best wishes. Cheng.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:462,availability,sli,slightly,462,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:1409,availability,servic,service,1409,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:1941,availability,down,downstream,1941,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:1409,deployability,servic,service,1409,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:82,energy efficiency,optim,optimization,82,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:320,energy efficiency,optim,optimization,320,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:1409,integrability,servic,service,1409,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:171,modifiability,scal,scalable,171,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:310,modifiability,paramet,parameter-optimization,310,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:1409,modifiability,servic,service,1409,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:82,performance,optimiz,optimization,82,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:171,performance,scalab,scalable,171,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:320,performance,optimiz,optimization,320,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:2041,performance,parallel,parallel,2041,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:462,reliability,sli,slightly,462,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:1000,reliability,pra,practices,1000,"Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:1513,safety,input,input,1513,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:2060,safety,valid,validate,2060,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:435,security,auth,authors,435,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:2060,security,validat,validate,2060,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:1565,testability,coverag,coverage,1565,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:1783,testability,assert,assertion,1783,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:353,usability,minim,minimum,353,"Dear Cheng,. Yes, there can be some differences between DeepVariant-GLNexus (with optimization) and GATK-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:1513,usability,input,input,1513,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:2091,usability,help,helps,2091,"-Joint genotyping. If you look at the following paper:. [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8023681/pdf/btaa1081.pdf). Using parameter-optimization of GLNexus (such as minimum quality thresholds, among others listed under Supplementary Table 4), the authors were able to get a slightly different number of SNPs than via GATK-Joint:. ![image](https://github.com/google/deepvariant/assets/6555937/da3459b6-cb09-45b8-8fd9-9bbcdb0d12a7) . This is from Supplementary Figure 11 (A) found under Supplementary data, listed as [a link on this page](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). So merging with GLNexus for DeepVariant gVCF output files $`-`$ as @AndrewCarroll mentioned in a [previous post](https://github.com/google/deepvariant/issues/83#issuecomment-553660314) $`-`$ by using [Best practices for multi-sample variant calling with DeepVariant](https://github.com/google/deepvariant/blob/r1.5/docs/trio-merge-case-study.md), it was found to be more accurate than using those gVCFs with GATK GenotypeGVCFs. Regarding missing SNPs in individual samples, their genotype might get a no call (`./.`) as noted in [this line of the GLNexus code](https://github.com/dnanexus-rnd/GLnexus/blob/main/src/service.cc#L206):. ```. Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele. ```. Though it probably could also get called as homozygous reference, if all the QC pass. Regarding impact on downstream analysis, probably the best bet is to try both approaches (DV-GLN-OPT and GATK-Joint) in parallel, and then validate both results. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:651,availability,recov,recovered,651,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:651,deployability,recov,recovered,651,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:362,integrability,discover,discovering,362,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:362,interoperability,discover,discovering,362,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:297,modifiability,extens,extensive,297,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:673,modifiability,extens,extensive,673,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:249,performance,performed analys,performed analysis,249,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:423,performance,perform,performing,423,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:651,reliability,recov,recovered,651,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:651,safety,recov,recovered,651,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:651,security,recov,recovered,651,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:249,usability,perform,performed,249,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:362,usability,discov,discovering,362,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:423,usability,perform,performing,423,"Hi @egnarora . The way you are running DeepVariant (run on individual samples then genotype jointly with GLnexus) is correct and what we recommend. Thank you @pgrosu which is in agreement with the recommendation. @egnarora some external groups have performed analysis on strategies which use more extensive joint calling processes with DeepVariant (for example, discovering all variants in a cohort and then experimentally performing force calling on candidate positions). Regeneron is one example of a group that has conducted this analysis. Their conclusion is that there are not variant calls which are missed in the individual process that can be recovered by the more extensive joint calling, and their conclusion was that the recommendation to use GLnexus will not result in missed variants that another approach would capture. Hopefully this answers your question. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:204,performance,time,time,204,"Hi Andrew,. Thank you for the nice words, and it's great to hear of the independent empirical confirmation! It was fun going through the paper again, as the ideas became even better reinforced the second time around :). Thank you,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:94,usability,confirm,confirmation,94,"Hi Andrew,. Thank you for the nice words, and it's great to hear of the independent empirical confirmation! It was fun going through the paper again, as the ideas became even better reinforced the second time around :). Thank you,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:253,availability,avail,available,253,"The Honourable Andrew and Paul. Thank you both very much for your kind answers and advice, it will be very helpful for me in my next endeavours, Deepvariant is a very efficient and useful piece of software, thank you for all your hard work in making it available to us. I will follow your advice and read some other people's research papers. Sincere thanks again. Cheng.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:253,reliability,availab,available,253,"The Honourable Andrew and Paul. Thank you both very much for your kind answers and advice, it will be very helpful for me in my next endeavours, Deepvariant is a very efficient and useful piece of software, thank you for all your hard work in making it available to us. I will follow your advice and read some other people's research papers. Sincere thanks again. Cheng.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:253,safety,avail,available,253,"The Honourable Andrew and Paul. Thank you both very much for your kind answers and advice, it will be very helpful for me in my next endeavours, Deepvariant is a very efficient and useful piece of software, thank you for all your hard work in making it available to us. I will follow your advice and read some other people's research papers. Sincere thanks again. Cheng.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:253,security,availab,available,253,"The Honourable Andrew and Paul. Thank you both very much for your kind answers and advice, it will be very helpful for me in my next endeavours, Deepvariant is a very efficient and useful piece of software, thank you for all your hard work in making it available to us. I will follow your advice and read some other people's research papers. Sincere thanks again. Cheng.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:107,usability,help,helpful,107,"The Honourable Andrew and Paul. Thank you both very much for your kind answers and advice, it will be very helpful for me in my next endeavours, Deepvariant is a very efficient and useful piece of software, thank you for all your hard work in making it available to us. I will follow your advice and read some other people's research papers. Sincere thanks again. Cheng.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:167,usability,efficien,efficient,167,"The Honourable Andrew and Paul. Thank you both very much for your kind answers and advice, it will be very helpful for me in my next endeavours, Deepvariant is a very efficient and useful piece of software, thank you for all your hard work in making it available to us. I will follow your advice and read some other people's research papers. Sincere thanks again. Cheng.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:110,security,team,team,110,"Hi Cheng,. Thank you for the kind words, and I am happy to hear it was helpful for you! It was fun collective team effort :). Feel free to drop by anytime if there is anything you need help with DeepVariant in the future. Best of luck in your forthcoming analysis! Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:71,usability,help,helpful,71,"Hi Cheng,. Thank you for the kind words, and I am happy to hear it was helpful for you! It was fun collective team effort :). Feel free to drop by anytime if there is anything you need help with DeepVariant in the future. Best of luck in your forthcoming analysis! Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/680:185,usability,help,help,185,"Hi Cheng,. Thank you for the kind words, and I am happy to hear it was helpful for you! It was fun collective team effort :). Feel free to drop by anytime if there is anything you need help with DeepVariant in the future. Best of luck in your forthcoming analysis! Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/680
https://github.com/google/deepvariant/issues/681:491,availability,avail,available,491,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:564,availability,cluster,cluster,564,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:564,deployability,cluster,cluster,564,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:594,deployability,resourc,resource-intensive,594,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:411,energy efficiency,CPU,CPU,411,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:415,energy efficiency,core,cores,415,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:477,energy efficiency,GPU,GPUs,477,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:594,energy efficiency,resourc,resource-intensive,594,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:338,performance,memor,memory,338,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:375,performance,disk,disk,375,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:411,performance,CPU,CPU,411,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:477,performance,GPU,GPUs,477,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:594,performance,resourc,resource-intensive,594,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:491,reliability,availab,available,491,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:282,safety,compl,completes,282,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:491,safety,avail,available,491,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:594,safety,resourc,resource-intensive,594,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:282,security,compl,completes,282,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:491,security,availab,available,491,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:594,testability,resourc,resource-intensive,594,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:39,usability,experien,experiencing,39,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:338,usability,memor,memory,338,"Hi Taghrid,. I'm sorry to hear you are experiencing this. I just have a few questions:. 1) Have you tried first going through [DeepVariant Quick Start](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md) in order to check that a smaller DeepVariant run completes successfully on your system? 2) How much free memory do you have? 3) How much free disk space do you have? 4) How many CPU cores do you have and how occupied are they? 5) Do you NVIDIA GPUs that are available to you on your system? I am assuming you are running this on a cluster as DeepVariant can be resource-intensive. . Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:278,deployability,version,version,278,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:524,deployability,version,version,524,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:396,energy efficiency,current,currently,396,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:278,integrability,version,version,278,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:524,integrability,version,version,524,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:278,modifiability,version,version,278,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:524,modifiability,version,version,524,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:105,safety,input,input,105,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:421,testability,simpl,simplex,421,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:44,usability,help,helpful,44,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:105,usability,input,input,105,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:406,usability,support,supports,406,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:421,usability,simpl,simplex,421,"Thanks @pgrosu. Knowing these would be very helpful. Besides compute, this can also be an issue with the input data. @Taghrid-M ,. Can you please tell a little more about the data in `HG004-hg38.ont.mm2.bam`:. 1) What chemistry is this data R9 or R10? 2) What is the basecaller version you used for basecalling this data? 3) What is the average read length of the reads? Please note, DeepVariant currently supports R10.4 simplex and duplex variant calling for nanopore. If your data is from previous chemistry or basecaller version, please use [PEPPER](https://github.com/kishwarshafin/pepper) to call variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:601,deployability,resourc,resources,601,"That's a good point @kishwarshafin! I think @Taghrid-M is probably using GIAB data based on the following -- as that's the only Nanopore I see for the HG004 sample -- and then probably using minimap2 to align:. https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG004_NA24143_mother/UCSC_Ultralong_OxfordNanopore_Promethion/. @Taghrid-M is probably using the following documentation (as it seems to match his run):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-ont-r104-duplex-case-study.md. In any case, it would still be a huge BAM file requiring significant resources, but I'll let @Taghrid-M fill in the gaps. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:601,energy efficiency,resourc,resources,601,"That's a good point @kishwarshafin! I think @Taghrid-M is probably using GIAB data based on the following -- as that's the only Nanopore I see for the HG004 sample -- and then probably using minimap2 to align:. https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG004_NA24143_mother/UCSC_Ultralong_OxfordNanopore_Promethion/. @Taghrid-M is probably using the following documentation (as it seems to match his run):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-ont-r104-duplex-case-study.md. In any case, it would still be a huge BAM file requiring significant resources, but I'll let @Taghrid-M fill in the gaps. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:601,performance,resourc,resources,601,"That's a good point @kishwarshafin! I think @Taghrid-M is probably using GIAB data based on the following -- as that's the only Nanopore I see for the HG004 sample -- and then probably using minimap2 to align:. https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG004_NA24143_mother/UCSC_Ultralong_OxfordNanopore_Promethion/. @Taghrid-M is probably using the following documentation (as it seems to match his run):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-ont-r104-duplex-case-study.md. In any case, it would still be a huge BAM file requiring significant resources, but I'll let @Taghrid-M fill in the gaps. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:601,safety,resourc,resources,601,"That's a good point @kishwarshafin! I think @Taghrid-M is probably using GIAB data based on the following -- as that's the only Nanopore I see for the HG004 sample -- and then probably using minimap2 to align:. https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG004_NA24143_mother/UCSC_Ultralong_OxfordNanopore_Promethion/. @Taghrid-M is probably using the following documentation (as it seems to match his run):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-ont-r104-duplex-case-study.md. In any case, it would still be a huge BAM file requiring significant resources, but I'll let @Taghrid-M fill in the gaps. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:589,security,sign,significant,589,"That's a good point @kishwarshafin! I think @Taghrid-M is probably using GIAB data based on the following -- as that's the only Nanopore I see for the HG004 sample -- and then probably using minimap2 to align:. https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG004_NA24143_mother/UCSC_Ultralong_OxfordNanopore_Promethion/. @Taghrid-M is probably using the following documentation (as it seems to match his run):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-ont-r104-duplex-case-study.md. In any case, it would still be a huge BAM file requiring significant resources, but I'll let @Taghrid-M fill in the gaps. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:601,testability,resourc,resources,601,"That's a good point @kishwarshafin! I think @Taghrid-M is probably using GIAB data based on the following -- as that's the only Nanopore I see for the HG004 sample -- and then probably using minimap2 to align:. https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG004_NA24143_mother/UCSC_Ultralong_OxfordNanopore_Promethion/. @Taghrid-M is probably using the following documentation (as it seems to match his run):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-ont-r104-duplex-case-study.md. In any case, it would still be a huge BAM file requiring significant resources, but I'll let @Taghrid-M fill in the gaps. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:389,usability,document,documentation,389,"That's a good point @kishwarshafin! I think @Taghrid-M is probably using GIAB data based on the following -- as that's the only Nanopore I see for the HG004 sample -- and then probably using minimap2 to align:. https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG004_NA24143_mother/UCSC_Ultralong_OxfordNanopore_Promethion/. @Taghrid-M is probably using the following documentation (as it seems to match his run):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-ont-r104-duplex-case-study.md. In any case, it would still be a huge BAM file requiring significant resources, but I'll let @Taghrid-M fill in the gaps. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:80,availability,cluster,cluster,80,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:901,availability,avail,available,901,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:80,deployability,cluster,cluster,80,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:301,deployability,version,version,301,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:398,deployability,Version,Version,398,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:796,energy efficiency,CPU,CPU,796,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:800,energy efficiency,core,cores,800,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:860,energy efficiency,CPU,CPU,860,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:864,energy efficiency,core,cores,864,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:896,energy efficiency,GPU,GPUs,896,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:301,integrability,version,version,301,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:398,integrability,Version,Version,398,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:301,modifiability,version,version,301,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:398,modifiability,Version,Version,398,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:376,performance,perform,performed,376,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:667,performance,memor,memory,667,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:713,performance,disk,disk,713,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:773,performance,disk,disk,773,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:796,performance,CPU,CPU,796,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:860,performance,CPU,CPU,860,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:896,performance,GPU,GPUs,896,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:901,reliability,availab,available,901,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:576,safety,compl,completes,576,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:901,safety,avail,available,901,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:152,security,nist,nist,152,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:576,security,compl,completes,576,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:901,security,availab,available,901,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:376,usability,perform,performed,376,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:532,usability,guid,guide,532,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:667,usability,memor,memory,667,"Thanks @pgrosu @kishwarshafin, I appreciate your swift reply! Yes, I am using a cluster, and the data have been obtained from precisionFDA https://data.nist.gov/od/id/mds2-2336. **What chemistry is this data? Is it R9 or R10?**. This data was generated using R9.4 flow cells. **What is the basecaller version you used for basecalling this data?**. The basecalling process was performed using Guppy Version 3.6. **What is the average read length of the reads?**. 85X. **Have you tried first going through the DeepVariant Quick Start guide to check if a smaller DeepVariant run completes successfully on your system?**. Yes, I have successfully run it. **How much free memory do you have?**. 1.3T . **How much free disk space do you have?**. I have approximately 14T of free disk space. **How many CPU cores do you have, and what is their occupancy level?**. 16 CPU cores. **Do you have any NVIDIA GPUs available on your system?**. No.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:254,availability,error,error,254,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:643,deployability,version,version,643,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:862,deployability,version,version,862,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:889,deployability,contain,container,889,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1245,deployability,version,version,1245,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1389,deployability,contain,container,1389,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1564,deployability,version,version,1564,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1591,deployability,contain,container,1591,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:495,energy efficiency,model,model,495,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:832,energy efficiency,model,model,832,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1269,energy efficiency,model,model,1269,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:104,integrability,pub,publication,104,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:643,integrability,version,version,643,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:862,integrability,version,version,862,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1245,integrability,version,version,1245,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1564,integrability,version,version,1564,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1148,interoperability,registr,registry,1148,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:643,modifiability,version,version,643,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:680,modifiability,layer,layers,680,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:862,modifiability,version,version,862,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:923,modifiability,layer,layers,923,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1245,modifiability,version,version,1245,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1364,modifiability,paramet,parameter,1364,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1423,modifiability,layer,layers,1423,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1564,modifiability,version,version,1564,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1625,modifiability,layer,layers,1625,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:254,performance,error,error,254,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1922,performance,bottleneck,bottleneck,1922,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:254,safety,error,error,254,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:291,security,sign,signals,291,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:495,security,model,model,495,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:832,security,model,model,832,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1269,security,model,model,1269,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:799,testability,context,context,799,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1042,testability,context,context,1042," I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1542,testability,context,context,1542,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1744,testability,context,context,1744,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:254,usability,error,error,254,"Hi @Taghrid-M,. This is good! One small thing, I think the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what woul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1852,usability,command,commands,1852,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:1983,usability,confirm,confirm,1983,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:2014,usability,effectiv,effective,2014,"hink the average read length is 48,060 based on [this publication](. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9205427/pdf/main.pdf). The thing is that Guppy 3.6.0 is a bit old, and will have a higher error rate when processing the FAST5 signals from the R9 nanopore through the bidirectional RNN to generate the FASTQ file, [as shown in the following post](https://github.com/kishwarshafin/pepper/issues/90). . So that the proper SNP Pepper model gets selected internally, you can use the `--ont_r9_guppy4_hac` argument with `run_pepper_margin_deepvariant call_variants`, though not sure [version r0.8](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore) has the Guppy 4 model. Otherwise you can use [version r0.4 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.4/images/sha256-0a609f60aa45620b1949c0ffa06299554248d77e23f4186aaa1c3306a95f20a2?context=explore). . Ideally maybe you can get the FAST5 files from the [following Amazon S3 page](https://registry.opendata.aws/ont-open-data/) and reprocess them with Guppy 5 $`-`$ as that's the latest version that the Pepper model seems to be trained against $`-`$ so that you can then utilize the `--ont_r9_guppy5_sup` parameter with the [r0.8 container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.8/images/sha256-70908591ad67e8567a6e4551119b2cfc33d957ad39701c8af51b36b516214645?context=explore), or [version r0.5 of the Docker container](https://hub.docker.com/layers/kishwars/pepper_deepvariant/r0.5/images/sha256-13906107b84849590400074e84ce12aba051447a8118c84f31f2b20540fbd807?context=explore). Regarding troubleshooting maybe you can run it with `--dry` so you can get the individual commands, so you can run each one individually to determine where the bottleneck is stemming from. I'll wait for @kishwarshafin to confirm what would be the most effective approach. Thank you,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:161,usability,support,supporting,161,"Hi @pgrosu thank you for finding the detailed sources! Yes you are exactly right. @Taghrid-M as @pgrosu said, Guppy 3.6 HAC mode is very old and the only caller supporting that would be PEPPER r0.4. There are several sources of new data for HG002. One of those is the human-pangenome project. For example you can find guppy 6 SUP data from [here](https://s3-us-west-2.amazonaws.com/human-pangenomics/index.html?prefix=T2T/scratch/HG002/sequencing/ont/). Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:464,usability,help,helps,464,"Hi @pgrosu thank you for finding the detailed sources! Yes you are exactly right. @Taghrid-M as @pgrosu said, Guppy 3.6 HAC mode is very old and the only caller supporting that would be PEPPER r0.4. There are several sources of new data for HG002. One of those is the human-pangenome project. For example you can find guppy 6 SUP data from [here](https://s3-us-west-2.amazonaws.com/human-pangenomics/index.html?prefix=T2T/scratch/HG002/sequencing/ont/). Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:26,energy efficiency,cool,cool,26,"Hi @kishwarshafin, . Very cool -- absolutely happy to help out and many thanks! . ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:54,usability,help,help,54,"Hi @kishwarshafin, . Very cool -- absolutely happy to help out and many thanks! . ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/681:175,usability,help,help,175,"@pgrosu @kishwarshafin . I'm deeply grateful for your thorough explanation and assistance. I'll attempt to utilize HG002 from the human pangenome, following your advice. Your help is greatly appreciated.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/681
https://github.com/google/deepvariant/issues/682:41,energy efficiency,model,model,41,"Hi @Axze-rgb,. I don't believe so as the model was trained with a specific type of variation $`-`$ and I'll let others chime in $`-`$ but in the meantime you can read the following:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#can-i-use-deepvariant-for-somatic-non-germline-calling. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:66,interoperability,specif,specific,66,"Hi @Axze-rgb,. I don't believe so as the model was trained with a specific type of variation $`-`$ and I'll let others chime in $`-`$ but in the meantime you can read the following:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#can-i-use-deepvariant-for-somatic-non-germline-calling. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:41,security,model,model,41,"Hi @Axze-rgb,. I don't believe so as the model was trained with a specific type of variation $`-`$ and I'll let others chime in $`-`$ but in the meantime you can read the following:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#can-i-use-deepvariant-for-somatic-non-germline-calling. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:307,usability,help,helps,307,"Hi @Axze-rgb,. I don't believe so as the model was trained with a specific type of variation $`-`$ and I'll let others chime in $`-`$ but in the meantime you can read the following:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#can-i-use-deepvariant-for-somatic-non-germline-calling. Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:177,energy efficiency,frequenc,frequencies,177,"Hi @Axze-rgb . May I ask a few questions about this organism to understand how to respond? Is your organism haploid, diploid, or polyploid? . Do you have some rough idea of the frequencies for MAF you would want to be able to cover? . Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:64,testability,understand,understand,64,"Hi @Axze-rgb . May I ask a few questions about this organism to understand how to respond? Is your organism haploid, diploid, or polyploid? . Do you have some rough idea of the frequencies for MAF you would want to be able to cover? . Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:308,availability,cluster,clusters,308,"He Andrew. It's a diploid organism with an ancient tetraploid structure. That's ancient enough it should avoid any mapping issue.. so, diploid it is. . Yes ... What we saw in the experimental evolution results, is that some independent lines get the same SNP. It doesn't seem random, like there were genetic clusters in the clonal ""or so we thought"" amcestral population. Still, du the mode of reproduction and very ""obbious signal"" I would not expect anything less than 10% of all alleles to be relevant. Does this answer your question? . For this question to be complete: I forgot to link the answer of Clair3 authors https://github.com/HKU-BAL/Clair3/issues/210#issuecomment-1642527205. I don't favour one over the other nor am I trying to start a conflict ^^ but I think it's an interesting technical discussion! . Thank you ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:308,deployability,cluster,clusters,308,"He Andrew. It's a diploid organism with an ancient tetraploid structure. That's ancient enough it should avoid any mapping issue.. so, diploid it is. . Yes ... What we saw in the experimental evolution results, is that some independent lines get the same SNP. It doesn't seem random, like there were genetic clusters in the clonal ""or so we thought"" amcestral population. Still, du the mode of reproduction and very ""obbious signal"" I would not expect anything less than 10% of all alleles to be relevant. Does this answer your question? . For this question to be complete: I forgot to link the answer of Clair3 authors https://github.com/HKU-BAL/Clair3/issues/210#issuecomment-1642527205. I don't favour one over the other nor am I trying to start a conflict ^^ but I think it's an interesting technical discussion! . Thank you ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:751,interoperability,conflict,conflict,751,"He Andrew. It's a diploid organism with an ancient tetraploid structure. That's ancient enough it should avoid any mapping issue.. so, diploid it is. . Yes ... What we saw in the experimental evolution results, is that some independent lines get the same SNP. It doesn't seem random, like there were genetic clusters in the clonal ""or so we thought"" amcestral population. Still, du the mode of reproduction and very ""obbious signal"" I would not expect anything less than 10% of all alleles to be relevant. Does this answer your question? . For this question to be complete: I forgot to link the answer of Clair3 authors https://github.com/HKU-BAL/Clair3/issues/210#issuecomment-1642527205. I don't favour one over the other nor am I trying to start a conflict ^^ but I think it's an interesting technical discussion! . Thank you ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:263,reliability,doe,doesn,263,"He Andrew. It's a diploid organism with an ancient tetraploid structure. That's ancient enough it should avoid any mapping issue.. so, diploid it is. . Yes ... What we saw in the experimental evolution results, is that some independent lines get the same SNP. It doesn't seem random, like there were genetic clusters in the clonal ""or so we thought"" amcestral population. Still, du the mode of reproduction and very ""obbious signal"" I would not expect anything less than 10% of all alleles to be relevant. Does this answer your question? . For this question to be complete: I forgot to link the answer of Clair3 authors https://github.com/HKU-BAL/Clair3/issues/210#issuecomment-1642527205. I don't favour one over the other nor am I trying to start a conflict ^^ but I think it's an interesting technical discussion! . Thank you ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:506,reliability,Doe,Does,506,"He Andrew. It's a diploid organism with an ancient tetraploid structure. That's ancient enough it should avoid any mapping issue.. so, diploid it is. . Yes ... What we saw in the experimental evolution results, is that some independent lines get the same SNP. It doesn't seem random, like there were genetic clusters in the clonal ""or so we thought"" amcestral population. Still, du the mode of reproduction and very ""obbious signal"" I would not expect anything less than 10% of all alleles to be relevant. Does this answer your question? . For this question to be complete: I forgot to link the answer of Clair3 authors https://github.com/HKU-BAL/Clair3/issues/210#issuecomment-1642527205. I don't favour one over the other nor am I trying to start a conflict ^^ but I think it's an interesting technical discussion! . Thank you ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:105,safety,avoid,avoid,105,"He Andrew. It's a diploid organism with an ancient tetraploid structure. That's ancient enough it should avoid any mapping issue.. so, diploid it is. . Yes ... What we saw in the experimental evolution results, is that some independent lines get the same SNP. It doesn't seem random, like there were genetic clusters in the clonal ""or so we thought"" amcestral population. Still, du the mode of reproduction and very ""obbious signal"" I would not expect anything less than 10% of all alleles to be relevant. Does this answer your question? . For this question to be complete: I forgot to link the answer of Clair3 authors https://github.com/HKU-BAL/Clair3/issues/210#issuecomment-1642527205. I don't favour one over the other nor am I trying to start a conflict ^^ but I think it's an interesting technical discussion! . Thank you ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:564,safety,compl,complete,564,"He Andrew. It's a diploid organism with an ancient tetraploid structure. That's ancient enough it should avoid any mapping issue.. so, diploid it is. . Yes ... What we saw in the experimental evolution results, is that some independent lines get the same SNP. It doesn't seem random, like there were genetic clusters in the clonal ""or so we thought"" amcestral population. Still, du the mode of reproduction and very ""obbious signal"" I would not expect anything less than 10% of all alleles to be relevant. Does this answer your question? . For this question to be complete: I forgot to link the answer of Clair3 authors https://github.com/HKU-BAL/Clair3/issues/210#issuecomment-1642527205. I don't favour one over the other nor am I trying to start a conflict ^^ but I think it's an interesting technical discussion! . Thank you ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:425,security,sign,signal,425,"He Andrew. It's a diploid organism with an ancient tetraploid structure. That's ancient enough it should avoid any mapping issue.. so, diploid it is. . Yes ... What we saw in the experimental evolution results, is that some independent lines get the same SNP. It doesn't seem random, like there were genetic clusters in the clonal ""or so we thought"" amcestral population. Still, du the mode of reproduction and very ""obbious signal"" I would not expect anything less than 10% of all alleles to be relevant. Does this answer your question? . For this question to be complete: I forgot to link the answer of Clair3 authors https://github.com/HKU-BAL/Clair3/issues/210#issuecomment-1642527205. I don't favour one over the other nor am I trying to start a conflict ^^ but I think it's an interesting technical discussion! . Thank you ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:564,security,compl,complete,564,"He Andrew. It's a diploid organism with an ancient tetraploid structure. That's ancient enough it should avoid any mapping issue.. so, diploid it is. . Yes ... What we saw in the experimental evolution results, is that some independent lines get the same SNP. It doesn't seem random, like there were genetic clusters in the clonal ""or so we thought"" amcestral population. Still, du the mode of reproduction and very ""obbious signal"" I would not expect anything less than 10% of all alleles to be relevant. Does this answer your question? . For this question to be complete: I forgot to link the answer of Clair3 authors https://github.com/HKU-BAL/Clair3/issues/210#issuecomment-1642527205. I don't favour one over the other nor am I trying to start a conflict ^^ but I think it's an interesting technical discussion! . Thank you ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:612,security,auth,authors,612,"He Andrew. It's a diploid organism with an ancient tetraploid structure. That's ancient enough it should avoid any mapping issue.. so, diploid it is. . Yes ... What we saw in the experimental evolution results, is that some independent lines get the same SNP. It doesn't seem random, like there were genetic clusters in the clonal ""or so we thought"" amcestral population. Still, du the mode of reproduction and very ""obbious signal"" I would not expect anything less than 10% of all alleles to be relevant. Does this answer your question? . For this question to be complete: I forgot to link the answer of Clair3 authors https://github.com/HKU-BAL/Clair3/issues/210#issuecomment-1642527205. I don't favour one over the other nor am I trying to start a conflict ^^ but I think it's an interesting technical discussion! . Thank you ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:451,availability,error,error,451,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:828,availability,error,errors,828,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:221,energy efficiency,model,models,221,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1183,energy efficiency,frequenc,frequency,1183,"ut it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported VAF, and looking at pileups yourself. If this is a direction you are curious to go in, I would be interested in anything you find.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1543,energy efficiency,estimat,estimate,1543,"ut it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported VAF, and looking at pileups yourself. If this is a direction you are curious to go in, I would be interested in anything you find.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:285,integrability,sub,subclonal,285,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:541,integrability,Sub,Subclonal,541,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:755,integrability,sub,subclonal,755,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1878,integrability,sub,subclonal,1878,"ut it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported VAF, and looking at pileups yourself. If this is a direction you are curious to go in, I would be interested in anything you find.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1758,interoperability,distribut,distributions,1758,"ut it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported VAF, and looking at pileups yourself. If this is a direction you are curious to go in, I would be interested in anything you find.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1218,modifiability,paramet,parameters,1218,"ut it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported VAF, and looking at pileups yourself. If this is a direction you are curious to go in, I would be interested in anything you find.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:451,performance,error,error,451,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:828,performance,error,errors,828,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:451,safety,error,error,451,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:828,safety,error,errors,828,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:189,security,assess,assess,189,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:221,security,model,models,221,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:583,security,sign,signature,583,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:797,security,sign,signature,797,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1833,security,ident,identify,1833,"ut it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported VAF, and looking at pileups yourself. If this is a direction you are curious to go in, I would be interested in anything you find.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:451,usability,error,error,451,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:828,usability,error,errors,828,"Hi @Axze-rgb . Anything recommended is going to require some investigation on your part. It might send you on a fruitless chase, but it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1292,usability,command,command,1292,"ut it could also be interesting. DeepVariant is trained to assess probabilities of diploid models, and its training data is diploid with some likely minor subclonal acquired variants. We've found that for diploid genomes, the output probabilities (represented as GQ values) are very well calibrated against the empirical error probability, and so are highly informative with respect to the quality of a call. . Subclonal variants will not look like the signature of true germline variants in a diploid organism, and so will not be likely to be assigned a high probability of a variant call. However, it is also the case that subclonal variants will not look like the signature of the noise-derived errors typical for rejected calls. As a result, it could be the case that the probabilities for the genotype classes for REF (0/0) or No-Call (./.) are informative in a manner you could use. DeepVariant will nominate candidates and write output for any SNP site that has the following properties: At least 2 non-variant alleles of a given candidate and a frequency of 0.12 or higher. These parameters can be changed by adding the following line to the DeepVariant command:. `--make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12`. Replacing 2 and 0.12 with the values you want. Keep in mind that decreasing these can increase runtime, so you'll likely want to experiment on running a region to estimate the proportion of candidates you create. Given that HiFi reads area are already very accurate and SNP calling on them is much easier than with other technologies, it may be the case that if you plot the GQ distributions of the REF (0/0) and No-call (./.) lines, you may be able to identify a group that looks like they may be subclonal variants. For this, you would need to do a reasonable amount of plotting, stratification by GQ and the reported VAF, and looking at pileups yourself. If this is a direction you are curious to go in, I would be interested in anything you find.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:160,deployability,updat,updated,160,"Hey @AndrewCarroll . This is a very interesting idea that I am going to try asap :) This whole study is taking much more time than planned, but I will keep you updated on the results! . Thanks a lot for your commitment",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:121,performance,time,time,121,"Hey @AndrewCarroll . This is a very interesting idea that I am going to try asap :) This whole study is taking much more time than planned, but I will keep you updated on the results! . Thanks a lot for your commitment",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:160,safety,updat,updated,160,"Hey @AndrewCarroll . This is a very interesting idea that I am going to try asap :) This whole study is taking much more time than planned, but I will keep you updated on the results! . Thanks a lot for your commitment",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:160,security,updat,updated,160,"Hey @AndrewCarroll . This is a very interesting idea that I am going to try asap :) This whole study is taking much more time than planned, but I will keep you updated on the results! . Thanks a lot for your commitment",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:131,testability,plan,planned,131,"Hey @AndrewCarroll . This is a very interesting idea that I am going to try asap :) This whole study is taking much more time than planned, but I will keep you updated on the results! . Thanks a lot for your commitment",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:337,usability,Clear,Clearly,337,"Hello @AndrewCarroll I launched DeepVariant as suggested, and then plotted the GQ distrubution. Here is a Gaussian kernel I fitted on it to better see (some people saw 2 peaks, others 4). So, here is what Gau would see . . ![density_gaussian](https://github.com/google/deepvariant/assets/81575666/eeb28721-204b-47b6-9ea0-750aca1ba21f). Clearly 4 peaks (github horribly compresses the plot, actually here it's hard to see the 2 peaks on the right end)... now I am gonna investigate in relation to the AF. I already had a quick look at the data themselves, that's gonna be fun ... some AF are so small. . I will keep you posted. Don't hesitate to comment. EDIT: I changed the plot type, it's much better now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:133,safety,valid,validate,133,"Hi @Axze-rgb,. That's good, and that just tells you that there might be high GQ regions of possible correct calls, which you need to validate. Now what you want is to determine the stationary areas of variation, which would not fall within noise signatures. As Andrew mentioned, you want to look at GQ regions with their VAF, and begin to stratify confidence regions backed up by good alignment of reads (IGV, or your favorite browser). Then you want to determine what regions of high-confidence with stable high GQ (correct call) mean in terms of VAF genotype regions, which might look like this (but not exactly):. ![image](https://github.com/google/deepvariant/assets/6555937/0847f683-8d69-4bb6-a6d4-eddd7e166993). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:133,security,validat,validate,133,"Hi @Axze-rgb,. That's good, and that just tells you that there might be high GQ regions of possible correct calls, which you need to validate. Now what you want is to determine the stationary areas of variation, which would not fall within noise signatures. As Andrew mentioned, you want to look at GQ regions with their VAF, and begin to stratify confidence regions backed up by good alignment of reads (IGV, or your favorite browser). Then you want to determine what regions of high-confidence with stable high GQ (correct call) mean in terms of VAF genotype regions, which might look like this (but not exactly):. ![image](https://github.com/google/deepvariant/assets/6555937/0847f683-8d69-4bb6-a6d4-eddd7e166993). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:246,security,sign,signatures,246,"Hi @Axze-rgb,. That's good, and that just tells you that there might be high GQ regions of possible correct calls, which you need to validate. Now what you want is to determine the stationary areas of variation, which would not fall within noise signatures. As Andrew mentioned, you want to look at GQ regions with their VAF, and begin to stratify confidence regions backed up by good alignment of reads (IGV, or your favorite browser). Then you want to determine what regions of high-confidence with stable high GQ (correct call) mean in terms of VAF genotype regions, which might look like this (but not exactly):. ![image](https://github.com/google/deepvariant/assets/6555937/0847f683-8d69-4bb6-a6d4-eddd7e166993). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:726,usability,help,helps,726,"Hi @Axze-rgb,. That's good, and that just tells you that there might be high GQ regions of possible correct calls, which you need to validate. Now what you want is to determine the stationary areas of variation, which would not fall within noise signatures. As Andrew mentioned, you want to look at GQ regions with their VAF, and begin to stratify confidence regions backed up by good alignment of reads (IGV, or your favorite browser). Then you want to determine what regions of high-confidence with stable high GQ (correct call) mean in terms of VAF genotype regions, which might look like this (but not exactly):. ![image](https://github.com/google/deepvariant/assets/6555937/0847f683-8d69-4bb6-a6d4-eddd7e166993). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:262,integrability,sub,subclonal,262,"Hi @Axze-rgb . Thank you for the plot. Are you looking at all variants here or just 0/0 and ./. variants. I think for this analysis, you probably want to exclude 1/1 and 0/1 variants (although I am a bit less certain about 0/1 as these might get calls which are subclonal too). . Seeing if there is a second peak in the 0/0 and ./. variants in the absence of what I assume are a peak of 0/1 calls at GQ 30 are could be interesting. Thank you for doing the analysis. If you're able to share a VCF I would be curious to take a look too. If you like, you could email a file link to awcarroll@google.com (no obligation to do so, of course).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:484,interoperability,share,share,484,"Hi @Axze-rgb . Thank you for the plot. Are you looking at all variants here or just 0/0 and ./. variants. I think for this analysis, you probably want to exclude 1/1 and 0/1 variants (although I am a bit less certain about 0/1 as these might get calls which are subclonal too). . Seeing if there is a second peak in the 0/0 and ./. variants in the absence of what I assume are a peak of 0/1 calls at GQ 30 are could be interesting. Thank you for doing the analysis. If you're able to share a VCF I would be curious to take a look too. If you like, you could email a file link to awcarroll@google.com (no obligation to do so, of course).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:106,integrability,FILTER,FILTER,106,"It's all the variants that have been called RefCall, actually, see the command:. ```. bcftools query -f ""%FILTER\t[ %GQ]\n"" OUTPUT_VCF|awk '$1==""RefCall""' > RefCall_all_GQ. ```. So 1/1 and 0/1 should be excluded, unless Deepvariant consider 1/1 as a RefCall. . I am asking around about if I am allowed to share the data, they don't ""belong' to me (though we could talk days about what it means to own scientific data). I am doing my best to get a ""yes"" answer. cheers. PS: precisely, at the moment I wanted to make a kind of hexbin plot of VAF vs GQ, however I am encountering a problem with sites like those: . Chrom_3 7095984 . A ACGAACGTTTTGCGATAGTATTTAACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTCGAGGAACGAAACTAATCGAAATCGAATCTTGATCACAATTTTCTGCATCTTGTTTCAATTTTTGACTTAAAGAT,ATGAACGTTTTGCGATAGTATTTCACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTGGAGGAACGAAACTAATTGAAATCGAATCTTGATCACAATTTTGTGCATCTTGTTTCAATTTTTCACTTAAAGAT 4.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:2:217:3,47,64:0.21659,0.294931:0,12,3,12,2,3. Clearly DeepVariant thinks there are 3 potential alleles, but that in the end it can't determine ... . While most of the time I have 35 (GQ) against whatever, but a single value. . This is causing my code to plot complete nonsense with negative GQ showing up in the plot. At the moment I don't know if I should find a way to replace the 2 values by a single one, or find a way to deal with the complexity in my plot. I would appreciate if you have an idea ^^' .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:305,interoperability,share,share,305,"It's all the variants that have been called RefCall, actually, see the command:. ```. bcftools query -f ""%FILTER\t[ %GQ]\n"" OUTPUT_VCF|awk '$1==""RefCall""' > RefCall_all_GQ. ```. So 1/1 and 0/1 should be excluded, unless Deepvariant consider 1/1 as a RefCall. . I am asking around about if I am allowed to share the data, they don't ""belong' to me (though we could talk days about what it means to own scientific data). I am doing my best to get a ""yes"" answer. cheers. PS: precisely, at the moment I wanted to make a kind of hexbin plot of VAF vs GQ, however I am encountering a problem with sites like those: . Chrom_3 7095984 . A ACGAACGTTTTGCGATAGTATTTAACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTCGAGGAACGAAACTAATCGAAATCGAATCTTGATCACAATTTTCTGCATCTTGTTTCAATTTTTGACTTAAAGAT,ATGAACGTTTTGCGATAGTATTTCACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTGGAGGAACGAAACTAATTGAAATCGAATCTTGATCACAATTTTGTGCATCTTGTTTCAATTTTTCACTTAAAGAT 4.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:2:217:3,47,64:0.21659,0.294931:0,12,3,12,2,3. Clearly DeepVariant thinks there are 3 potential alleles, but that in the end it can't determine ... . While most of the time I have 35 (GQ) against whatever, but a single value. . This is causing my code to plot complete nonsense with negative GQ showing up in the plot. At the moment I don't know if I should find a way to replace the 2 values by a single one, or find a way to deal with the complexity in my plot. I would appreciate if you have an idea ^^' .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1276,performance,time,time,1276,"It's all the variants that have been called RefCall, actually, see the command:. ```. bcftools query -f ""%FILTER\t[ %GQ]\n"" OUTPUT_VCF|awk '$1==""RefCall""' > RefCall_all_GQ. ```. So 1/1 and 0/1 should be excluded, unless Deepvariant consider 1/1 as a RefCall. . I am asking around about if I am allowed to share the data, they don't ""belong' to me (though we could talk days about what it means to own scientific data). I am doing my best to get a ""yes"" answer. cheers. PS: precisely, at the moment I wanted to make a kind of hexbin plot of VAF vs GQ, however I am encountering a problem with sites like those: . Chrom_3 7095984 . A ACGAACGTTTTGCGATAGTATTTAACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTCGAGGAACGAAACTAATCGAAATCGAATCTTGATCACAATTTTCTGCATCTTGTTTCAATTTTTGACTTAAAGAT,ATGAACGTTTTGCGATAGTATTTCACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTGGAGGAACGAAACTAATTGAAATCGAATCTTGATCACAATTTTGTGCATCTTGTTTCAATTTTTCACTTAAAGAT 4.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:2:217:3,47,64:0.21659,0.294931:0,12,3,12,2,3. Clearly DeepVariant thinks there are 3 potential alleles, but that in the end it can't determine ... . While most of the time I have 35 (GQ) against whatever, but a single value. . This is causing my code to plot complete nonsense with negative GQ showing up in the plot. At the moment I don't know if I should find a way to replace the 2 values by a single one, or find a way to deal with the complexity in my plot. I would appreciate if you have an idea ^^' .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1368,safety,compl,complete,1368,"It's all the variants that have been called RefCall, actually, see the command:. ```. bcftools query -f ""%FILTER\t[ %GQ]\n"" OUTPUT_VCF|awk '$1==""RefCall""' > RefCall_all_GQ. ```. So 1/1 and 0/1 should be excluded, unless Deepvariant consider 1/1 as a RefCall. . I am asking around about if I am allowed to share the data, they don't ""belong' to me (though we could talk days about what it means to own scientific data). I am doing my best to get a ""yes"" answer. cheers. PS: precisely, at the moment I wanted to make a kind of hexbin plot of VAF vs GQ, however I am encountering a problem with sites like those: . Chrom_3 7095984 . A ACGAACGTTTTGCGATAGTATTTAACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTCGAGGAACGAAACTAATCGAAATCGAATCTTGATCACAATTTTCTGCATCTTGTTTCAATTTTTGACTTAAAGAT,ATGAACGTTTTGCGATAGTATTTCACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTGGAGGAACGAAACTAATTGAAATCGAATCTTGATCACAATTTTGTGCATCTTGTTTCAATTTTTCACTTAAAGAT 4.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:2:217:3,47,64:0.21659,0.294931:0,12,3,12,2,3. Clearly DeepVariant thinks there are 3 potential alleles, but that in the end it can't determine ... . While most of the time I have 35 (GQ) against whatever, but a single value. . This is causing my code to plot complete nonsense with negative GQ showing up in the plot. At the moment I don't know if I should find a way to replace the 2 values by a single one, or find a way to deal with the complexity in my plot. I would appreciate if you have an idea ^^' .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1549,safety,compl,complexity,1549,"It's all the variants that have been called RefCall, actually, see the command:. ```. bcftools query -f ""%FILTER\t[ %GQ]\n"" OUTPUT_VCF|awk '$1==""RefCall""' > RefCall_all_GQ. ```. So 1/1 and 0/1 should be excluded, unless Deepvariant consider 1/1 as a RefCall. . I am asking around about if I am allowed to share the data, they don't ""belong' to me (though we could talk days about what it means to own scientific data). I am doing my best to get a ""yes"" answer. cheers. PS: precisely, at the moment I wanted to make a kind of hexbin plot of VAF vs GQ, however I am encountering a problem with sites like those: . Chrom_3 7095984 . A ACGAACGTTTTGCGATAGTATTTAACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTCGAGGAACGAAACTAATCGAAATCGAATCTTGATCACAATTTTCTGCATCTTGTTTCAATTTTTGACTTAAAGAT,ATGAACGTTTTGCGATAGTATTTCACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTGGAGGAACGAAACTAATTGAAATCGAATCTTGATCACAATTTTGTGCATCTTGTTTCAATTTTTCACTTAAAGAT 4.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:2:217:3,47,64:0.21659,0.294931:0,12,3,12,2,3. Clearly DeepVariant thinks there are 3 potential alleles, but that in the end it can't determine ... . While most of the time I have 35 (GQ) against whatever, but a single value. . This is causing my code to plot complete nonsense with negative GQ showing up in the plot. At the moment I don't know if I should find a way to replace the 2 values by a single one, or find a way to deal with the complexity in my plot. I would appreciate if you have an idea ^^' .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1368,security,compl,complete,1368,"It's all the variants that have been called RefCall, actually, see the command:. ```. bcftools query -f ""%FILTER\t[ %GQ]\n"" OUTPUT_VCF|awk '$1==""RefCall""' > RefCall_all_GQ. ```. So 1/1 and 0/1 should be excluded, unless Deepvariant consider 1/1 as a RefCall. . I am asking around about if I am allowed to share the data, they don't ""belong' to me (though we could talk days about what it means to own scientific data). I am doing my best to get a ""yes"" answer. cheers. PS: precisely, at the moment I wanted to make a kind of hexbin plot of VAF vs GQ, however I am encountering a problem with sites like those: . Chrom_3 7095984 . A ACGAACGTTTTGCGATAGTATTTAACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTCGAGGAACGAAACTAATCGAAATCGAATCTTGATCACAATTTTCTGCATCTTGTTTCAATTTTTGACTTAAAGAT,ATGAACGTTTTGCGATAGTATTTCACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTGGAGGAACGAAACTAATTGAAATCGAATCTTGATCACAATTTTGTGCATCTTGTTTCAATTTTTCACTTAAAGAT 4.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:2:217:3,47,64:0.21659,0.294931:0,12,3,12,2,3. Clearly DeepVariant thinks there are 3 potential alleles, but that in the end it can't determine ... . While most of the time I have 35 (GQ) against whatever, but a single value. . This is causing my code to plot complete nonsense with negative GQ showing up in the plot. At the moment I don't know if I should find a way to replace the 2 values by a single one, or find a way to deal with the complexity in my plot. I would appreciate if you have an idea ^^' .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1549,security,compl,complexity,1549,"It's all the variants that have been called RefCall, actually, see the command:. ```. bcftools query -f ""%FILTER\t[ %GQ]\n"" OUTPUT_VCF|awk '$1==""RefCall""' > RefCall_all_GQ. ```. So 1/1 and 0/1 should be excluded, unless Deepvariant consider 1/1 as a RefCall. . I am asking around about if I am allowed to share the data, they don't ""belong' to me (though we could talk days about what it means to own scientific data). I am doing my best to get a ""yes"" answer. cheers. PS: precisely, at the moment I wanted to make a kind of hexbin plot of VAF vs GQ, however I am encountering a problem with sites like those: . Chrom_3 7095984 . A ACGAACGTTTTGCGATAGTATTTAACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTCGAGGAACGAAACTAATCGAAATCGAATCTTGATCACAATTTTCTGCATCTTGTTTCAATTTTTGACTTAAAGAT,ATGAACGTTTTGCGATAGTATTTCACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTGGAGGAACGAAACTAATTGAAATCGAATCTTGATCACAATTTTGTGCATCTTGTTTCAATTTTTCACTTAAAGAT 4.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:2:217:3,47,64:0.21659,0.294931:0,12,3,12,2,3. Clearly DeepVariant thinks there are 3 potential alleles, but that in the end it can't determine ... . While most of the time I have 35 (GQ) against whatever, but a single value. . This is causing my code to plot complete nonsense with negative GQ showing up in the plot. At the moment I don't know if I should find a way to replace the 2 values by a single one, or find a way to deal with the complexity in my plot. I would appreciate if you have an idea ^^' .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:71,usability,command,command,71,"It's all the variants that have been called RefCall, actually, see the command:. ```. bcftools query -f ""%FILTER\t[ %GQ]\n"" OUTPUT_VCF|awk '$1==""RefCall""' > RefCall_all_GQ. ```. So 1/1 and 0/1 should be excluded, unless Deepvariant consider 1/1 as a RefCall. . I am asking around about if I am allowed to share the data, they don't ""belong' to me (though we could talk days about what it means to own scientific data). I am doing my best to get a ""yes"" answer. cheers. PS: precisely, at the moment I wanted to make a kind of hexbin plot of VAF vs GQ, however I am encountering a problem with sites like those: . Chrom_3 7095984 . A ACGAACGTTTTGCGATAGTATTTAACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTCGAGGAACGAAACTAATCGAAATCGAATCTTGATCACAATTTTCTGCATCTTGTTTCAATTTTTGACTTAAAGAT,ATGAACGTTTTGCGATAGTATTTCACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTGGAGGAACGAAACTAATTGAAATCGAATCTTGATCACAATTTTGTGCATCTTGTTTCAATTTTTCACTTAAAGAT 4.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:2:217:3,47,64:0.21659,0.294931:0,12,3,12,2,3. Clearly DeepVariant thinks there are 3 potential alleles, but that in the end it can't determine ... . While most of the time I have 35 (GQ) against whatever, but a single value. . This is causing my code to plot complete nonsense with negative GQ showing up in the plot. At the moment I don't know if I should find a way to replace the 2 values by a single one, or find a way to deal with the complexity in my plot. I would appreciate if you have an idea ^^' .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1155,usability,Clear,Clearly,1155,"It's all the variants that have been called RefCall, actually, see the command:. ```. bcftools query -f ""%FILTER\t[ %GQ]\n"" OUTPUT_VCF|awk '$1==""RefCall""' > RefCall_all_GQ. ```. So 1/1 and 0/1 should be excluded, unless Deepvariant consider 1/1 as a RefCall. . I am asking around about if I am allowed to share the data, they don't ""belong' to me (though we could talk days about what it means to own scientific data). I am doing my best to get a ""yes"" answer. cheers. PS: precisely, at the moment I wanted to make a kind of hexbin plot of VAF vs GQ, however I am encountering a problem with sites like those: . Chrom_3 7095984 . A ACGAACGTTTTGCGATAGTATTTAACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTCGAGGAACGAAACTAATCGAAATCGAATCTTGATCACAATTTTCTGCATCTTGTTTCAATTTTTGACTTAAAGAT,ATGAACGTTTTGCGATAGTATTTCACAAAATATGTTATATGTTTTTCATTGAAATCAATCTTTAATAGAATTTCTTTTAGTATTTGTGTATACATAAATGTTGGATCTAAATGATCGATATTTTCGACGGATTTTTTGTTACTTGGAGGAACGAAACTAATTGAAATCGAATCTTGATCACAATTTTGTGCATCTTGTTTCAATTTTTCACTTAAAGAT 4.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:2:217:3,47,64:0.21659,0.294931:0,12,3,12,2,3. Clearly DeepVariant thinks there are 3 potential alleles, but that in the end it can't determine ... . While most of the time I have 35 (GQ) against whatever, but a single value. . This is causing my code to plot complete nonsense with negative GQ showing up in the plot. At the moment I don't know if I should find a way to replace the 2 values by a single one, or find a way to deal with the complexity in my plot. I would appreciate if you have an idea ^^' .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1458,availability,error,error,1458,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:248,energy efficiency,model,model,248,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:357,energy efficiency,optim,optimizes,357,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:371,energy efficiency,model,model,371,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:561,energy efficiency,optim,optimal,561,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:583,energy efficiency,model,model,583,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:815,energy efficiency,model,model,815,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:860,energy efficiency,model,model,860,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1378,energy efficiency,load,load,1378,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1464,energy efficiency,model,modeling,1464,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:89,integrability,sub,subclonal,89,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:804,integrability,event,eventually,804,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:273,interoperability,specif,specific,273,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:853,modifiability,Pac,PacBio,853,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:357,performance,optimiz,optimizes,357,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1378,performance,load,load,1378,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1458,performance,error,error,1458,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:689,reliability,stabil,stability,689,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:791,safety,test,test,791,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1458,safety,error,error,1458,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:248,security,model,model,248,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:340,security,loss,loss,340,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:371,security,model,model,371,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:583,security,model,model,583,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:665,security,sign,significant,665,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:815,security,model,model,815,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:860,security,model,model,860,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1464,security,model,modeling,1464,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:791,testability,test,test,791,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:325,usability,minim,minimizing,325,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1458,usability,error,error,1458,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1579,usability,help,helps,1579,"Hi @Axze-rgb,. Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types $`-`$ that's the basic hypothesis here. So here's a quick way you can fix the multiallelic issue above:. $`1)`$ First split the multiallelic sites into biallelic records like this:. ```. bcftools norm -m - multi_allelic.vcf > biallelic.vcf. ```. $`2)`$ Then parse for the `0/0` and `./.` genotypes $`-`$ I'm assuming your genotypes are not phased:. ```. bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. ```. Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:123,energy efficiency,model,model,123,"Hello @pgrosu . Thanks for the bcftools suggestion, exactly what's needed. I will try to digest your comment about how the model was trained. Thank you for explaining! I will report back. . @AndrewCarroll I am gonna send you the vcf file, from a protonmail address (the proton domain is sometimes blocked by servers). . Thanks everyone for the great disussion, I hav learned a lot.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:123,security,model,model,123,"Hello @pgrosu . Thanks for the bcftools suggestion, exactly what's needed. I will try to digest your comment about how the model was trained. Thank you for explaining! I will report back. . @AndrewCarroll I am gonna send you the vcf file, from a protonmail address (the proton domain is sometimes blocked by servers). . Thanks everyone for the great disussion, I hav learned a lot.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:367,usability,learn,learned,367,"Hello @pgrosu . Thanks for the bcftools suggestion, exactly what's needed. I will try to digest your comment about how the model was trained. Thank you for explaining! I will report back. . @AndrewCarroll I am gonna send you the vcf file, from a protonmail address (the proton domain is sometimes blocked by servers). . Thanks everyone for the great disussion, I hav learned a lot.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:501,performance,perform,perform,501,"Hello, here is a VAF vs GQ plot. English is not my native language so I am not sure how to say it appropriately but what the? It seems GQ is not correlated with VAF. ![histogram2d](https://github.com/google/deepvariant/assets/81575666/9dc535f1-8337-4d51-b82b-7d58ddeec006). I am not sure what to expect since we selected for RefCall in the end, maybe it's actually correct. I am gonna redo the call with Clair3 and see if it gives results as weird as those ones. . EDIT: side note, does make_examples perform any kind of realignment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:482,reliability,doe,does,482,"Hello, here is a VAF vs GQ plot. English is not my native language so I am not sure how to say it appropriately but what the? It seems GQ is not correlated with VAF. ![histogram2d](https://github.com/google/deepvariant/assets/81575666/9dc535f1-8337-4d51-b82b-7d58ddeec006). I am not sure what to expect since we selected for RefCall in the end, maybe it's actually correct. I am gonna redo the call with Clair3 and see if it gives results as weird as those ones. . EDIT: side note, does make_examples perform any kind of realignment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:501,usability,perform,perform,501,"Hello, here is a VAF vs GQ plot. English is not my native language so I am not sure how to say it appropriately but what the? It seems GQ is not correlated with VAF. ![histogram2d](https://github.com/google/deepvariant/assets/81575666/9dc535f1-8337-4d51-b82b-7d58ddeec006). I am not sure what to expect since we selected for RefCall in the end, maybe it's actually correct. I am gonna redo the call with Clair3 and see if it gives results as weird as those ones. . EDIT: side note, does make_examples perform any kind of realignment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:45,availability,replic,replicates,45,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:249,availability,cluster,clusters,249,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:770,availability,error,errors,770,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1143,availability,replic,replicates,1143,"y genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1330,availability,consist,consistent,1330,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1754,availability,cluster,clusters,1754,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:249,deployability,cluster,clusters,249,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:747,deployability,artifact,artifacts,747,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1754,deployability,cluster,clusters,1754,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1782,deployability,observ,observe,1782,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:673,energy efficiency,frequenc,frequency,673,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1658,energy efficiency,frequenc,frequency,1658,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1725,energy efficiency,frequenc,frequency,1725,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:550,integrability,sub,sub-populations,550,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:576,integrability,event,events,576,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:914,integrability,event,events,914,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1191,integrability,event,events,1191,"ly not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1264,integrability,event,events,1264,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1348,interoperability,specif,specific,1348,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1365,interoperability,distribut,distribution,1365,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1404,interoperability,heterogen,heterogeneity,1404,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1848,interoperability,heterogen,heterogeneity,1848,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:71,modifiability,inherit,inheritance,71,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1045,modifiability,evolv,evolve,1045,"licates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure the",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1994,modifiability,inherit,inheritance,1994,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:770,performance,error,errors,770,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:770,safety,error,errors,770,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1093,safety,valid,validate,1093," mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the dr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1222,safety,valid,validate,1222,"ay you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1953,safety,isol,isolate,1953,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2007,safety,valid,validated,2007,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:204,security,lineag,lineages,204,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1093,security,validat,validate,1093," mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the dr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1222,security,validat,validate,1222,"ay you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1953,security,iso,isolate,1953,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2007,security,validat,validated,2007,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1240,testability,coverag,coverage,1240,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1782,testability,observ,observe,1782,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1953,testability,isol,isolate,1953,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2026,testability,coverag,coverage,2026,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:653,usability,support,support,653,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:770,usability,error,errors,770,"Hi @Axze-rgb,. So we know that this organism replicates through clonal inheritance to transfer of mutations to daughter cells that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1121,usability,support,supported,1121,"that would be driven by genetic drift or selection forces, and usually not by lineages. Though you say you noticed genetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and tr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1330,usability,consist,consistent,1330,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1396,usability,minim,minimal,1396,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2230,usability,help,helps,2230,"enetic clusters forming stemming from the ancestor population. So if the mutations are more localized and are still diploid, that means it would not behave in the way true germline diploid genomes would transfer their genotypes. This means you would have more alterations -- that might be real, or stem from sub-populations of clonal events affecting your sample purity -- and thus you cannot rely on ploidy to support your allele frequency (as illustrated by your plot above). This is of course assuming artifacts of sequencer errors, and others are removed. So instead you would need to do something like ""panel of clonals"" to compare against, to compare between clonal events. Then among these you would denoise for the common variants, so you can construct a phylogenetic analysis how the mutations evolve. All these alterations you would need to validate through your reads supported by multiple replicates. Though you are fighting your clonal events here, and would need to validate that the coverage of the labeled events (samples) in your cohort study are individually relatively consistent in the specific variant distribution (i.e. you want no/minimal heterogeneity of samples contaminating each individual labeled sample). This way your samples are comparable. Based on the above, hope it makes sense why the `./.` and `0/0` make sense to analyze. Given that you cannot rely on the ploidy for your allele frequency, this can also be illustrated by the diversity in allele frequency, instead of unique clusters you would normally observe in a true germline variant. Given that, there probably is heterogeneity in the sample purity of variants, which would lead to a spread of the VAF. Now you need to isolate the variants and determine their inheritance, validated by large coverage to ensure they are true variants. This will provide you the drivers of the mutations and transmissions -- some of which might be more stable than others given different selection forces. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:478,interoperability,compatib,compatible,478,"Hi @pgrosu . This is a fascinating perspective on how to use variant callers here... actually, we don't ""know"" they reproduce through clonal inheritance. No one has ever seen a male or male organ in 2 centuries. And in the labs, when we see the pattern we have here, we tend to believe indeed they reproduce through clonal inheritance. . But. there are (solid) data and papers that show that when you go outside of the lab do some population genetics, the results are perfectly compatible with sexual reproduction. That doesn't mean it's happening here, of course. But we actually can't assume they are clonal. Or, we can, but we must keep in mind it's absolutely not guaranteed. . Do you think it makes sense to compare with Clair3?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:141,modifiability,inherit,inheritance,141,"Hi @pgrosu . This is a fascinating perspective on how to use variant callers here... actually, we don't ""know"" they reproduce through clonal inheritance. No one has ever seen a male or male organ in 2 centuries. And in the labs, when we see the pattern we have here, we tend to believe indeed they reproduce through clonal inheritance. . But. there are (solid) data and papers that show that when you go outside of the lab do some population genetics, the results are perfectly compatible with sexual reproduction. That doesn't mean it's happening here, of course. But we actually can't assume they are clonal. Or, we can, but we must keep in mind it's absolutely not guaranteed. . Do you think it makes sense to compare with Clair3?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:323,modifiability,inherit,inheritance,323,"Hi @pgrosu . This is a fascinating perspective on how to use variant callers here... actually, we don't ""know"" they reproduce through clonal inheritance. No one has ever seen a male or male organ in 2 centuries. And in the labs, when we see the pattern we have here, we tend to believe indeed they reproduce through clonal inheritance. . But. there are (solid) data and papers that show that when you go outside of the lab do some population genetics, the results are perfectly compatible with sexual reproduction. That doesn't mean it's happening here, of course. But we actually can't assume they are clonal. Or, we can, but we must keep in mind it's absolutely not guaranteed. . Do you think it makes sense to compare with Clair3?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:520,reliability,doe,doesn,520,"Hi @pgrosu . This is a fascinating perspective on how to use variant callers here... actually, we don't ""know"" they reproduce through clonal inheritance. No one has ever seen a male or male organ in 2 centuries. And in the labs, when we see the pattern we have here, we tend to believe indeed they reproduce through clonal inheritance. . But. there are (solid) data and papers that show that when you go outside of the lab do some population genetics, the results are perfectly compatible with sexual reproduction. That doesn't mean it's happening here, of course. But we actually can't assume they are clonal. Or, we can, but we must keep in mind it's absolutely not guaranteed. . Do you think it makes sense to compare with Clair3?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:733,availability,state,states,733,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1362,availability,operat,operates,1362," going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly an",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3495,availability,replic,replicates,3495,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3814,availability,reliab,reliably,3814,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3900,availability,down,downstream,3900,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:710,deployability,depend,dependencies,710,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2416,deployability,fail,fail,2416,"our read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for know",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2570,deployability,scale,scale,2570,"). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of anal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:959,energy efficiency,predict,predict,959,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1627,energy efficiency,adapt,adapts,1627," the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1695,energy efficiency,model,models,1695,"y long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for varia",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1906,energy efficiency,adapt,adapt,1906,"iven sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2225,energy efficiency,model,model,2225,"mid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2541,energy efficiency,model,models,2541,"`insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2570,energy efficiency,scale,scale,2570,"). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of anal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2736,energy efficiency,model,model,2736,"ve semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2778,energy efficiency,model,model,2778," have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adju",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2854,energy efficiency,model,models,2854,"ariability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse datase",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3003,energy efficiency,model,model,3003,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3823,energy efficiency,predict,predictable,3823,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:325,integrability,event,events,325,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:710,integrability,depend,dependencies,710,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:733,integrability,state,states,733,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1627,integrability,adapt,adapts,1627," the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1906,integrability,adapt,adapt,1906,"iven sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2793,integrability,sub,subtype,2793,"ed with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1627,interoperability,adapt,adapts,1627," the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1906,interoperability,adapt,adapt,1906,"iven sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2286,interoperability,specif,specific,2286,"is still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3757,interoperability,specif,specific,3757,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:710,modifiability,depend,dependencies,710,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1250,modifiability,variab,variable,1250,"t a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the wei",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1627,modifiability,adapt,adapts,1627," the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1856,modifiability,variab,variability,1856,"on known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1884,modifiability,exten,extent,1884,"ions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1906,modifiability,adapt,adapt,1906,"iven sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2570,modifiability,scal,scale,2570,"). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of anal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2693,modifiability,variab,variable,2693,"dels -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3138,modifiability,variab,variability,3138,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3766,modifiability,paramet,parameters,3766,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:188,performance,network,network,188,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:219,performance,network,network,219,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:275,performance,network,network,275,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:291,performance,memor,memory,291,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:592,performance,time,time-series-like,592,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:765,performance,memor,memory,765,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1322,performance,network,network,1322,"vents without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and the",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2008,performance,network,network,2008,"e it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model wou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2570,performance,scale,scale,2570,"). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of anal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3454,performance,time,time,3454,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1581,reliability,doe,does,1581,"ugh in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2416,reliability,fail,fail,2416,"our read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for know",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3814,reliability,reliab,reliably,3814,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:311,safety,reme,remember,311,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:385,safety,input,input,385,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:540,safety,input,input,540,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:635,safety,input,input,635,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:677,safety,reme,remembering,677,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:710,safety,depend,dependencies,710,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:959,safety,predict,predict,959,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1155,safety,input,input,1155,"ir3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1753,safety,input,input,1753,"s fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that mea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1829,safety,input,input,1829,"the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2106,safety,input,input,2106,"ction by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2150,safety,input,input,2150,"f input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2312,safety,input,input,2312,"neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multialleli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2343,safety,input,inputs,2343,"iases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2655,safety,valid,validated,2655,"nal environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3202,safety,isol,isolates,3202,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3346,safety,isol,isolate,3346,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3401,safety,valid,validate,3401,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3823,safety,predict,predictable,3823,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:188,security,network,network,188,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:219,security,network,network,219,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:275,security,network,network,275,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1322,security,network,network,1322,"vents without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and the",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1634,security,sign,significantly,1634,"data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they wer",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1695,security,model,models,1695,"y long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for varia",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1915,security,sign,significant,1915,"e of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2008,security,network,network,2008,"e it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model wou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2225,security,model,model,2225,"mid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2332,security,modif,modify,2332,"ights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2350,security,sign,significantly,2350,"till operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. Yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2541,security,model,models,2541,"`insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2655,security,validat,validated,2655,"nal environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2736,security,model,model,2736,"ve semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2778,security,model,model,2778," have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adju",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2854,security,model,models,2854,"ariability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse datase",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3003,security,model,model,3003,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3126,security,control,control,3126,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3202,security,iso,isolates,3202,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3346,security,iso,isolate,3346,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3401,security,validat,validate,3401,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3481,security,modif,modify,3481,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:710,testability,depend,dependencies,710,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1259,testability,coverag,coverage,1259,"rent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2026,testability,simpl,simplified,2026,"nts. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confid",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2199,testability,simpl,simple,2199,"ng). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2206,testability,regress,regression,2206," use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3126,testability,control,control,3126,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3202,testability,isol,isolates,3202,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3346,testability,isol,isolate,3346,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3613,testability,understand,understand,3613,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:20,usability,clear,clearly,20,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:291,usability,memor,memory,291,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:298,usability,efficien,efficient,298,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:385,usability,input,input,385,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:540,usability,input,input,540,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:568,usability,progress,progresses,568,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:635,usability,input,input,635,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:765,usability,memor,memory,765,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:772,usability,efficien,efficient,772,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:853,usability,progress,progression,853,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:879,usability,progress,progressions,879,"Hi @Axze-rgb,. This clearly tells me that your organism is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1050,usability,help,helpful,1050,"m is highly sensitive under selective pressure. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_ou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1094,usability,shortcut,shortcut,1094,"re. So let's think what might happen if you used Clair3. Clair3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alph",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1155,usability,input,input,1155,"ir3 has both a full-alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1175,usability,learn,learn,1175,"alignment network (ResNet), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1196,usability,learn,learning,1196,"Net), and a pileup network (Bi-LSTM). . Bi-LSTM is just a recurrent neural network that is memory efficient to remember past events without gradient instabilities, by going through the input forward and in reverse while getting output information from the previous step. All this means is that it has a bunch of weights and biases that the input (and previous output) progresses through in a time-series-like pattern -- traversing the input data both forward and in reverse -- remembering internally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1686,usability,learn,learning,1686,"nternally long-term dependencies stored as states. This means it is fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1753,usability,input,input,1753,"s fairly memory efficient and fairly fast. In terms of sequence it captures the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that mea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1829,usability,input,input,1829,"the variants given a progression known by past progressions. As an analogy, given sequence of historical stock prices, can you predict the future stock price. Instead of stock price it produces variants. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2026,usability,simpl,simplified,2026,"nts. The ResNet is helpful to train faster as it is uses skip (shortcut) connection by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confid",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2106,usability,input,input,2106,"ction by utilizing the residual difference of input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2150,usability,input,input,2150,"f input and output to learn from (residual learning). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2199,usability,simpl,simple,2199,"ng). They use spatial pyramid pooling (SPP) for variable coverage of full-alignments. This still a convolutional neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2312,usability,input,input,2312,"neural network of weights and biases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multialleli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2343,usability,input,inputs,2343,"iases. It still operates like DeepVariant on channels constructed from your read information (`reference_base`, `alternative_base`, `mapping_quality`, `base_quality`, `strand_info`, `variant_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2532,usability,learn,learning,2532,"_type`, `insert_base`, `phasing_info`). What does this mean for you? We know your organism adapts significantly to the external environment. The deep learning models -- either DeepVariant or Clair3 -- have semi-fixed input assumptions. Sure they have been trained with some flexibility in the input data to capture some variability, but not to the extent that they will adapt to significant allele, or possible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3929,usability,help,helps,3929,"sible structural variation. I mean think of a convolutional neural network like this simplified example:. $`y\_output = weights_\gamma \cdot ( (weights_\alpha \cdot input + bias_\alpha) + (weights_\beta \cdot input + bias_\beta) ) + bias_\gamma`$. This is a simple regression (linear model). If you adjust the weights and bias terms for produce specific output given the input, and then you modify the inputs significantly and hope to get the same results, it will naturally fail. The same with DeepVariant and Clair3, they are bounded and determined by their weights and biases. These deep learning models were meant to work at scale under relatively normal data conditions (data conditions they were trained and validated for). The way to adjust for variable datasets is to create an ensemble model. What that means is that you have a model for each subtype of your organism. Then your run your data across all models to see which ones respond with high confidence. In your case, you don't have that and have to adjust for the data you have; as training a new model would require a confident variant truth set. So what is the known starting point is the biology of your organism. To control for variability, the first step is probably to ensure you have good isolates of your organism that you can get sequence data from -- you've seen that in your case it was multiallelic so it probably is not a pure isolate. You probably don't need to arrest them if you validate for known markers and sequenced at the same time to ensure they do not modify. These replicates would form your panels. Then there is probably a whole slew of analysis, and experiments you would need to understand these variants. Part of that can be to see how you can confidence-label the variants generated by DeepVariant and Clair3 given their specific parameters adjusted accordingly. If they become reliably predictable under a diverse dataset, then you can probably use them for your downstream analysis. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:134,energy efficiency,green,green,134,"Hello, very great answer. I have other data including from an artificial evolution experiment. But I can't tell you more here without green light from my PIs. But definitely this thread is one of the most useful ever. Again, thank you so much all. I really really appreciate it. @AndrewCarroll did you get the file?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:218,energy efficiency,model,model,218,"If you are interested, we can plan a talk, I would explain the experiment to you, and compare the results from DeepVariant/Clair3 with those of bcftools (I was hoping Octopus but it seems they have problems with their model file, several in the community have proposed our help, we will see). . MEanwhile today I am gonna analyse the Clair3 output.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:218,security,model,model,218,"If you are interested, we can plan a talk, I would explain the experiment to you, and compare the results from DeepVariant/Clair3 with those of bcftools (I was hoping Octopus but it seems they have problems with their model file, several in the community have proposed our help, we will see). . MEanwhile today I am gonna analyse the Clair3 output.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:30,testability,plan,plan,30,"If you are interested, we can plan a talk, I would explain the experiment to you, and compare the results from DeepVariant/Clair3 with those of bcftools (I was hoping Octopus but it seems they have problems with their model file, several in the community have proposed our help, we will see). . MEanwhile today I am gonna analyse the Clair3 output.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:273,usability,help,help,273,"If you are interested, we can plan a talk, I would explain the experiment to you, and compare the results from DeepVariant/Clair3 with those of bcftools (I was hoping Octopus but it seems they have problems with their model file, several in the community have proposed our help, we will see). . MEanwhile today I am gonna analyse the Clair3 output.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1494,availability,error,error,1494,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1730,deployability,depend,depends,1730,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:256,energy efficiency,model,model,256,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:365,energy efficiency,optim,optimizes,365,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:379,energy efficiency,model,model,379,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:569,energy efficiency,optim,optimal,569,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:591,energy efficiency,model,model,591,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:823,energy efficiency,model,model,823,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:868,energy efficiency,model,model,868,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1414,energy efficiency,load,load,1414,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1500,energy efficiency,model,modeling,1500,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:97,integrability,sub,subclonal,97,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:812,integrability,event,eventually,812,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1730,integrability,depend,depends,1730,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:281,interoperability,specif,specific,281,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:861,modifiability,Pac,PacBio,861,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1730,modifiability,depend,depends,1730,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:365,performance,optimiz,optimizes,365,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1414,performance,load,load,1414,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1494,performance,error,error,1494,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1944,performance,memor,memory,1944,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:697,reliability,stabil,stability,697,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:799,safety,test,test,799,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1494,safety,error,error,1494,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1730,safety,depend,depends,1730,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:256,security,model,model,256,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:348,security,loss,loss,348,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:379,security,model,model,379,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:591,security,model,model,591,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:673,security,sign,significant,673,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:823,security,model,model,823,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:868,security,model,model,868,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1500,security,model,modeling,1500,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:799,testability,test,test,799,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1730,testability,depend,depends,1730,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:333,usability,minim,minimizing,333,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1494,usability,error,error,1494,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1621,usability,help,helps,1621,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1944,usability,memor,memory,1944,"> Hi @Axze-rgb,. > . > Yes, you want to only look at your `./.` and `0/0` genotypes, because the subclonal variants will likely not look like true germline ones, and probably fall into the category of not being called or a reference call. Keep in mind the model was created with a specific type of variation in the dataset as it was minimizing the loss function to optimizes the model's weights, in order to have the variant caller's GQ values correlate maximally with the GQ scores derived empirically from GIAB ground truth. So your tensor images might not look like optimal ones that the model would recognize as a true germline variant, but that discrepancy might have significant statistical stability above the noise region, of which you can take advantage of. That is what your are trying to test for and eventually model, with the hope to show that the PacBio model can be generalized for more dataset types  that's the basic hypothesis here. > . > So here's a quick way you can fix the multiallelic issue above:. > . > 1) First split the multiallelic sites into biallelic records like this:. > . > ```. > bcftools norm -m - multi_allelic.vcf > biallelic.vcf. > ```. > . > 2) Then parse for the `0/0` and `./.` genotypes  I'm assuming your genotypes are not phased:. > . > ```. > bcftools query -f '[%GT,%GQ,%VAF]' biallelic.vcf | grep '\./\.\|0/0' | cut -f2,3 -d',' > gq_vaf.csv. > ```. > . > Then just load it up in R with `read.csv(""gq_vaf.csv"")`, and plot it. There is a lot more error modeling you will need to do to generate the confidence intervals, which would probably require more data. > . > Hope it helps, ~p. For the record there is an issue with your second code, only the first is generated by cut, or it depends on the unix system. . It's easy to fix by asking bcftools itself to make the new line. > bcftools query -f '[%GT,%GQ,%VAF\n]' biallelic.vcf | grep '\./\.\|0/0' > gq_vaf.csv. I know you probably did it from memory, but in case someone else finds the thread ;) .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:221,integrability,sub,subclonal,221,@Axze-rgb . Just catching up with some of your posts and plots now. The most interesting thing in your plot is the larger number of counts at the VAF ~0.15 GQ 30. Those would be your most likely candidates to look at for subclonal variants. I wonder what this looks like for a human VCF (whether you see a similar higher density). For example: . gs://brain-genomics-public/research/sequencing/grch38/vcf/pacbio_hifi/HG006.pacbio-hifi.29x.deepvariant-v1.0.grch38.vcf.gz.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:366,integrability,pub,public,366,@Axze-rgb . Just catching up with some of your posts and plots now. The most interesting thing in your plot is the larger number of counts at the VAF ~0.15 GQ 30. Those would be your most likely candidates to look at for subclonal variants. I wonder what this looks like for a human VCF (whether you see a similar higher density). For example: . gs://brain-genomics-public/research/sequencing/grch38/vcf/pacbio_hifi/HG006.pacbio-hifi.29x.deepvariant-v1.0.grch38.vcf.gz.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:422,modifiability,pac,pacbio-hifi,422,@Axze-rgb . Just catching up with some of your posts and plots now. The most interesting thing in your plot is the larger number of counts at the VAF ~0.15 GQ 30. Those would be your most likely candidates to look at for subclonal variants. I wonder what this looks like for a human VCF (whether you see a similar higher density). For example: . gs://brain-genomics-public/research/sequencing/grch38/vcf/pacbio_hifi/HG006.pacbio-hifi.29x.deepvariant-v1.0.grch38.vcf.gz.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:77,availability,slo,slow,77,"Hi @Axze-rgb and Andrew,. Good catch on the newline character  its hard to slow down at times when things are fun :) . Before having a presentation -- as my bandwidth is a bit tight these days (though I usually love presentations) -- I would be curious to see what you first get from Clair3 and Andrew's candidate region, as well as any additional insight Andrew might get from the VCF. I have this funny feeling of what the outcome might be  and we can have the presentation later among the three of us (and anyone else that's interested) as things emerge more clearly. Thank you,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:82,availability,down,down,82,"Hi @Axze-rgb and Andrew,. Good catch on the newline character  its hard to slow down at times when things are fun :) . Before having a presentation -- as my bandwidth is a bit tight these days (though I usually love presentations) -- I would be curious to see what you first get from Clair3 and Andrew's candidate region, as well as any additional insight Andrew might get from the VCF. I have this funny feeling of what the outcome might be  and we can have the presentation later among the three of us (and anyone else that's interested) as things emerge more clearly. Thank you,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:90,performance,time,times,90,"Hi @Axze-rgb and Andrew,. Good catch on the newline character  its hard to slow down at times when things are fun :) . Before having a presentation -- as my bandwidth is a bit tight these days (though I usually love presentations) -- I would be curious to see what you first get from Clair3 and Andrew's candidate region, as well as any additional insight Andrew might get from the VCF. I have this funny feeling of what the outcome might be  and we can have the presentation later among the three of us (and anyone else that's interested) as things emerge more clearly. Thank you,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:77,reliability,slo,slow,77,"Hi @Axze-rgb and Andrew,. Good catch on the newline character  its hard to slow down at times when things are fun :) . Before having a presentation -- as my bandwidth is a bit tight these days (though I usually love presentations) -- I would be curious to see what you first get from Clair3 and Andrew's candidate region, as well as any additional insight Andrew might get from the VCF. I have this funny feeling of what the outcome might be  and we can have the presentation later among the three of us (and anyone else that's interested) as things emerge more clearly. Thank you,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:565,usability,clear,clearly,565,"Hi @Axze-rgb and Andrew,. Good catch on the newline character  its hard to slow down at times when things are fun :) . Before having a presentation -- as my bandwidth is a bit tight these days (though I usually love presentations) -- I would be curious to see what you first get from Clair3 and Andrew's candidate region, as well as any additional insight Andrew might get from the VCF. I have this funny feeling of what the outcome might be  and we can have the presentation later among the three of us (and anyone else that's interested) as things emerge more clearly. Thank you,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:106,energy efficiency,frequenc,frequency,106,"The comparison with Clair3 is not trivial, as it seems at least per default it doesn't register those low frequency RefCall variants. I asked Aquaskyline about it. . Meanwhile here is a hexbin plot of the deepvariant results, some people seem to find them more fashionable (when I am a bit anxious about thins, I make plots). ![QG vs VQF DeepVariant](https://github.com/google/deepvariant/assets/81575666/b7259c28-a919-49c4-b1fa-a3e3507000f5).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:79,reliability,doe,doesn,79,"The comparison with Clair3 is not trivial, as it seems at least per default it doesn't register those low frequency RefCall variants. I asked Aquaskyline about it. . Meanwhile here is a hexbin plot of the deepvariant results, some people seem to find them more fashionable (when I am a bit anxious about thins, I make plots). ![QG vs VQF DeepVariant](https://github.com/google/deepvariant/assets/81575666/b7259c28-a919-49c4-b1fa-a3e3507000f5).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:250,availability,state,state,250,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:315,availability,error,error,315,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:48,energy efficiency,cool,cool,48,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:878,energy efficiency,predict,predictable,878,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:140,integrability,event,events,140,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:250,integrability,state,state,250,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:265,integrability,event,events,265,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:524,integrability,event,events,524,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:315,performance,error,error,315,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:275,safety,compl,complete,275,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:315,safety,error,error,315,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:878,safety,predict,predictable,878,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:275,security,compl,complete,275,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:447,security,sign,signals,447,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:679,security,sign,significant,679,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:862,security,sign,significant,862,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:307,usability,minim,minimal,307,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:315,usability,error,error,315,"This is impressive work! Though it looks pretty cool, let's ask ourselves what is happening here. The biological system went through clonal events (let's suppose under some non-random selective conditions), where the sequencer hopefully captured the state of those events as complete as possible (i.e. with minimal error). Then we pass those through two processes (DeepVariant and Clair3), which respond with areas of variation mirroring previous signals it was trained with to maximally respond upon. The key is, are these events biologically meaningful? So if you look in the literature or known databases -- for your organism -- would these changes be reflective of something significant within exomic (gene) regions, or pathways that might be activated? If so why, and what might be those non-random selective conditions that make these genomic changes both significant and predictable?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:273,availability,repair,repair,273,"Well, why do you want those events to be non random? . In nature they seem to do this. https://www.nature.com/articles/s41467-020-19614-y. In lab we see them do that . https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9710870/. Random breaks during their meiosis and subsequent repair might have generated sublonces in the petri dish.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:28,integrability,event,events,28,"Well, why do you want those events to be non random? . In nature they seem to do this. https://www.nature.com/articles/s41467-020-19614-y. In lab we see them do that . https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9710870/. Random breaks during their meiosis and subsequent repair might have generated sublonces in the petri dish.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:262,integrability,sub,subsequent,262,"Well, why do you want those events to be non random? . In nature they seem to do this. https://www.nature.com/articles/s41467-020-19614-y. In lab we see them do that . https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9710870/. Random breaks during their meiosis and subsequent repair might have generated sublonces in the petri dish.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:301,integrability,sub,sublonces,301,"Well, why do you want those events to be non random? . In nature they seem to do this. https://www.nature.com/articles/s41467-020-19614-y. In lab we see them do that . https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9710870/. Random breaks during their meiosis and subsequent repair might have generated sublonces in the petri dish.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:273,reliability,repair,repair,273,"Well, why do you want those events to be non random? . In nature they seem to do this. https://www.nature.com/articles/s41467-020-19614-y. In lab we see them do that . https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9710870/. Random breaks during their meiosis and subsequent repair might have generated sublonces in the petri dish.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:271,availability,repair,repair,271,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:399,availability,repair,repair,399,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:597,availability,repair,repair,597,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:653,availability,repair,repair,653,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1174,availability,repair,repair,1174,"in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1819,availability,repair,repair,1819,"ic regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within no",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:143,deployability,observ,observed,143,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2625,deployability,continu,continues,2625,"tifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in your daughter cells is functionally divergent, or is actually just preserved as compared to the parent. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:694,energy efficiency,model,model,694,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2607,energy efficiency,model,model,2607,"tifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in your daughter cells is functionally divergent, or is actually just preserved as compared to the parent. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:260,integrability,sub,subsequent,260,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:816,interoperability,specif,specific,816,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:968,interoperability,convers,conversion,968,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2295,interoperability,specif,specific,2295,"tifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in your daughter cells is functionally divergent, or is actually just preserved as compared to the parent. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1136,modifiability,maintain,maintained,1136,"u observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1642,performance,content,content,1642,"er DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight en",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:271,reliability,repair,repair,271,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:399,reliability,repair,repair,399,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:597,reliability,repair,repair,597,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:653,reliability,repair,repair,653,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1174,reliability,repair,repair,1174,"in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1819,reliability,repair,repair,1819,"ic regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within no",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1136,safety,maintain,maintained,1136,"u observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1184,safety,safe,safeguard,1184,"nt lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1487,safety,accid,accidental,1487,"; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/go",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1766,safety,compl,complete,1766," of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:674,security,sign,significant,674,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:694,security,model,model,694,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:760,security,sign,signatures,760,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1766,security,compl,complete,1766," of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1980,security,auth,authors,1980,"take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2254,security,lineag,lineages,2254,"tifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in your daughter cells is functionally divergent, or is actually just preserved as compared to the parent. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2451,security,lineag,lineages,2451,"tifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in your daughter cells is functionally divergent, or is actually just preserved as compared to the parent. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2607,security,model,model,2607,"tifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in your daughter cells is functionally divergent, or is actually just preserved as compared to the parent. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2743,security,lineag,lineages,2743,"tifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in your daughter cells is functionally divergent, or is actually just preserved as compared to the parent. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:143,testability,observ,observed,143,"Perfectly reasonable question, and thank you for the references. I mentioned non-random selective conditions that should be present, since you observed the preservation of SNPs in independent lines. Sure random breaks and other DNA damage can occur with their subsequent repair, though the papers have very different goals. If you want to be able to compare them from the point of view of damage-to-repair, it will be a bit difficult. Let me explain why through the papers:. $`\underline{In \; the \; Lab \; (from \; the \; paper)}`$. - This paper showed how the preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1556,usability,efficien,efficiently,1556," preservation of viability through repair via homologs (preserving consensus) or other DNA repair mechanisms is significant to this model organism. Below are a few excerpts denoting this:. - _*""The signatures of IHR [interhomolog recombination] found in specific regions of A. vaga genome (14) or in natural A. vaga populations (8) thus likely result from mechanisms such as crossing over (CO) and/or gene conversion that take place during the meiotic pairing of homologs (Fig. 4B).""*_. - _*""[T]he nonreductional meiotic process in bdelloid rotifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2238,usability,progress,progress,2238,"tifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in your daughter cells is functionally divergent, or is actually just preserved as compared to the parent. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2569,usability,experien,experience,2569,"tifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in your daughter cells is functionally divergent, or is actually just preserved as compared to the parent. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3093,usability,help,helps,3093,"tifers was likely evolutionary maintained to serve primarily for DNA repair to safeguard the genetic information of the species, especially when thriving in semiterrestrial environments where DNA DSBs [double-strand breaks] do accumulate during prolonged periods of desiccation.""*_. - _*""Regardless of the origin of DNA DSBs (programmed DSBs during the meiotic-derived oogenesis or accidental DSBs due to genotoxic stresses), IHR in the germ line can efficiently and accurately reconstruct broken chromosomes while shuffling the allelic content and creating offspring that are genetically diverse from their mother.""*_. - This shows preservation of function by complete correction through homologs, or through DNA repair pathways reconstituting viable function. $`\underline{In \; Nature \; (from \; the \; paper \; and \; supplementary \; materials)}`$. - In this paper the authors were trying to show the randomization of variation. This is a very different goal than trying to show the preservation of gene function under variation. Their focus was more on the linkage between SNPs, and chose to carefully look at how differences progress across lineages. If you look at one of the gene specific analysis was done for the COX1 gene as a phylogenetic tree -- presented in the Supplementary Materials -- it illustrated high similarity among the lineages:. ![image](https://github.com/google/deepvariant/assets/6555937/a119536e-cdc4-4ea3-a06a-fbf32b2f3d8e). In my experience when nature finds a strong model, it usually continues to fight entropy to preserve itself. To show that, one would have to explore the functional analysis of the lineages, showing that the variation (SNPs) was either synonymous, or within non-coding regions. Therefore in your analysis, if you want to just show variation, that is fine. The more interesting question is how much of that variation in your daughter cells is functionally divergent, or is actually just preserved as compared to the parent. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:63,integrability,filter,filter,63,"There is something very fishy, look at this line from the vcf, filter on GQ=32 and VAF<=0.2. `Chrom_3	8414	.	T	G	0	RefCall	.	GT:GQ:DP:AD:VAF:PL	0/0:32:90:75,15:0.166667:0,32,43. `. But that doesn't seem to correspond at all at IGV (exporting details). ```. <hr>Total count: 194. A : 0. C : 0. G : 87 (45%, 45+, 42- ). T : 106 (55%, 56+, 50- ). N : 1 (1%, 1+, 0- ). ```. It's almost 50-50; we are far from the 16 percent of the vcf. Now, I know DeepVariant sometimes realign and what we see is not necessarily what it saw. . But then, how do I interpret this? @AndrewCarroll did you have a chance to check? I am afraid this goes beyond my skills here. Any suggestion is welcome. . the feeling is a bit desperate on my side, to be honest. . EDIT/ might be me... but Deepvariant does not consider all ""T"" mapped on the same location as equivalent, right? It will take into account the mapping score of the read? Which might explain in Tablet we see more of the alternate allele that is reported in the vcf? ![image](https://github.com/google/deepvariant/assets/81575666/f75cba09-c552-4eb0-92ae-c548012b3913). high quality is darker shade, so we see here that a lot of the T are of low mapping quality. Which might have caused the call 0/0. There are very few instances that seem to show a good mapping quality to support the T. . ![image](https://github.com/google/deepvariant/assets/81575666/ddec44d9-d65c-4b5b-bd9d-8e6bad6baf53). The gray shading of IGV is a nightmare for me, I don't know if it's my eyes. But it's very difficult to distinguish",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:190,reliability,doe,doesn,190,"There is something very fishy, look at this line from the vcf, filter on GQ=32 and VAF<=0.2. `Chrom_3	8414	.	T	G	0	RefCall	.	GT:GQ:DP:AD:VAF:PL	0/0:32:90:75,15:0.166667:0,32,43. `. But that doesn't seem to correspond at all at IGV (exporting details). ```. <hr>Total count: 194. A : 0. C : 0. G : 87 (45%, 45+, 42- ). T : 106 (55%, 56+, 50- ). N : 1 (1%, 1+, 0- ). ```. It's almost 50-50; we are far from the 16 percent of the vcf. Now, I know DeepVariant sometimes realign and what we see is not necessarily what it saw. . But then, how do I interpret this? @AndrewCarroll did you have a chance to check? I am afraid this goes beyond my skills here. Any suggestion is welcome. . the feeling is a bit desperate on my side, to be honest. . EDIT/ might be me... but Deepvariant does not consider all ""T"" mapped on the same location as equivalent, right? It will take into account the mapping score of the read? Which might explain in Tablet we see more of the alternate allele that is reported in the vcf? ![image](https://github.com/google/deepvariant/assets/81575666/f75cba09-c552-4eb0-92ae-c548012b3913). high quality is darker shade, so we see here that a lot of the T are of low mapping quality. Which might have caused the call 0/0. There are very few instances that seem to show a good mapping quality to support the T. . ![image](https://github.com/google/deepvariant/assets/81575666/ddec44d9-d65c-4b5b-bd9d-8e6bad6baf53). The gray shading of IGV is a nightmare for me, I don't know if it's my eyes. But it's very difficult to distinguish",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:776,reliability,doe,does,776,"There is something very fishy, look at this line from the vcf, filter on GQ=32 and VAF<=0.2. `Chrom_3	8414	.	T	G	0	RefCall	.	GT:GQ:DP:AD:VAF:PL	0/0:32:90:75,15:0.166667:0,32,43. `. But that doesn't seem to correspond at all at IGV (exporting details). ```. <hr>Total count: 194. A : 0. C : 0. G : 87 (45%, 45+, 42- ). T : 106 (55%, 56+, 50- ). N : 1 (1%, 1+, 0- ). ```. It's almost 50-50; we are far from the 16 percent of the vcf. Now, I know DeepVariant sometimes realign and what we see is not necessarily what it saw. . But then, how do I interpret this? @AndrewCarroll did you have a chance to check? I am afraid this goes beyond my skills here. Any suggestion is welcome. . the feeling is a bit desperate on my side, to be honest. . EDIT/ might be me... but Deepvariant does not consider all ""T"" mapped on the same location as equivalent, right? It will take into account the mapping score of the read? Which might explain in Tablet we see more of the alternate allele that is reported in the vcf? ![image](https://github.com/google/deepvariant/assets/81575666/f75cba09-c552-4eb0-92ae-c548012b3913). high quality is darker shade, so we see here that a lot of the T are of low mapping quality. Which might have caused the call 0/0. There are very few instances that seem to show a good mapping quality to support the T. . ![image](https://github.com/google/deepvariant/assets/81575666/ddec44d9-d65c-4b5b-bd9d-8e6bad6baf53). The gray shading of IGV is a nightmare for me, I don't know if it's my eyes. But it's very difficult to distinguish",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1310,usability,support,support,1310,"There is something very fishy, look at this line from the vcf, filter on GQ=32 and VAF<=0.2. `Chrom_3	8414	.	T	G	0	RefCall	.	GT:GQ:DP:AD:VAF:PL	0/0:32:90:75,15:0.166667:0,32,43. `. But that doesn't seem to correspond at all at IGV (exporting details). ```. <hr>Total count: 194. A : 0. C : 0. G : 87 (45%, 45+, 42- ). T : 106 (55%, 56+, 50- ). N : 1 (1%, 1+, 0- ). ```. It's almost 50-50; we are far from the 16 percent of the vcf. Now, I know DeepVariant sometimes realign and what we see is not necessarily what it saw. . But then, how do I interpret this? @AndrewCarroll did you have a chance to check? I am afraid this goes beyond my skills here. Any suggestion is welcome. . the feeling is a bit desperate on my side, to be honest. . EDIT/ might be me... but Deepvariant does not consider all ""T"" mapped on the same location as equivalent, right? It will take into account the mapping score of the read? Which might explain in Tablet we see more of the alternate allele that is reported in the vcf? ![image](https://github.com/google/deepvariant/assets/81575666/f75cba09-c552-4eb0-92ae-c548012b3913). high quality is darker shade, so we see here that a lot of the T are of low mapping quality. Which might have caused the call 0/0. There are very few instances that seem to show a good mapping quality to support the T. . ![image](https://github.com/google/deepvariant/assets/81575666/ddec44d9-d65c-4b5b-bd9d-8e6bad6baf53). The gray shading of IGV is a nightmare for me, I don't know if it's my eyes. But it's very difficult to distinguish",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:321,availability,error,error,321,"@Axze-rgb That's correct, you have to use AD (allele depth), which counts only informative reads out of the total reads (that IGV shows):. VAF = 15/(75+15) = 0.166667. AD refers to the reference and alternate alleles (in comma-separated order) that pass the filters, IGV shows all of them. The GQ is good with a 0.0631 % error the call is incorrect, or 93.96 % the call is correct. Does that help? Thanks,. `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:258,integrability,filter,filters,258,"@Axze-rgb That's correct, you have to use AD (allele depth), which counts only informative reads out of the total reads (that IGV shows):. VAF = 15/(75+15) = 0.166667. AD refers to the reference and alternate alleles (in comma-separated order) that pass the filters, IGV shows all of them. The GQ is good with a 0.0631 % error the call is incorrect, or 93.96 % the call is correct. Does that help? Thanks,. `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:321,performance,error,error,321,"@Axze-rgb That's correct, you have to use AD (allele depth), which counts only informative reads out of the total reads (that IGV shows):. VAF = 15/(75+15) = 0.166667. AD refers to the reference and alternate alleles (in comma-separated order) that pass the filters, IGV shows all of them. The GQ is good with a 0.0631 % error the call is incorrect, or 93.96 % the call is correct. Does that help? Thanks,. `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:382,reliability,Doe,Does,382,"@Axze-rgb That's correct, you have to use AD (allele depth), which counts only informative reads out of the total reads (that IGV shows):. VAF = 15/(75+15) = 0.166667. AD refers to the reference and alternate alleles (in comma-separated order) that pass the filters, IGV shows all of them. The GQ is good with a 0.0631 % error the call is incorrect, or 93.96 % the call is correct. Does that help? Thanks,. `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:321,safety,error,error,321,"@Axze-rgb That's correct, you have to use AD (allele depth), which counts only informative reads out of the total reads (that IGV shows):. VAF = 15/(75+15) = 0.166667. AD refers to the reference and alternate alleles (in comma-separated order) that pass the filters, IGV shows all of them. The GQ is good with a 0.0631 % error the call is incorrect, or 93.96 % the call is correct. Does that help? Thanks,. `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:321,usability,error,error,321,"@Axze-rgb That's correct, you have to use AD (allele depth), which counts only informative reads out of the total reads (that IGV shows):. VAF = 15/(75+15) = 0.166667. AD refers to the reference and alternate alleles (in comma-separated order) that pass the filters, IGV shows all of them. The GQ is good with a 0.0631 % error the call is incorrect, or 93.96 % the call is correct. Does that help? Thanks,. `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:392,usability,help,help,392,"@Axze-rgb That's correct, you have to use AD (allele depth), which counts only informative reads out of the total reads (that IGV shows):. VAF = 15/(75+15) = 0.166667. AD refers to the reference and alternate alleles (in comma-separated order) that pass the filters, IGV shows all of them. The GQ is good with a 0.0631 % error the call is incorrect, or 93.96 % the call is correct. Does that help? Thanks,. `p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:9,reliability,doe,doesn,9,"And that doesn't bother you? We interpret this as low clonal presence, while we have actually massive bad mapping of the T at the same place? Coincidence? Or are the few ""good"" Ts an artefact? . My advisor once told me if I stopped asking such question I probably would have a PhD already, but ... I am warry of coincidence.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:224,usability,stop,stopped,224,"And that doesn't bother you? We interpret this as low clonal presence, while we have actually massive bad mapping of the T at the same place? Coincidence? Or are the few ""good"" Ts an artefact? . My advisor once told me if I stopped asking such question I probably would have a PhD already, but ... I am warry of coincidence.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:908,integrability,sub,subscribed,908,"Hi sorry to jump on this thread but how sure are you of genomic stability. in your organism? Just thinking about, mutation rates, did you amplify the pacbio sample,. have you checked for methylation? Joe. On Mon, 31 Jul 2023, 17:17 Axze-rgb, ***@***.***> wrote:. > And that doesn't bother you? We interpret this as low clonal presence,. > while we have actually massive bad mapping of the T at the same place? > Coincidence? Or are the few ""good"" Ts an artefact? >. > My advisor once told me if I stopped asking such question I probably would. > have a PhD already, but ... I am warry of coincidence. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658710664>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2UURSWJPUBSPQQJU3LXS7LBBANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you are subscribed to this thread.Message. > ID: ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:934,integrability,Messag,Message,934,"Hi sorry to jump on this thread but how sure are you of genomic stability. in your organism? Just thinking about, mutation rates, did you amplify the pacbio sample,. have you checked for methylation? Joe. On Mon, 31 Jul 2023, 17:17 Axze-rgb, ***@***.***> wrote:. > And that doesn't bother you? We interpret this as low clonal presence,. > while we have actually massive bad mapping of the T at the same place? > Coincidence? Or are the few ""good"" Ts an artefact? >. > My advisor once told me if I stopped asking such question I probably would. > have a PhD already, but ... I am warry of coincidence. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658710664>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2UURSWJPUBSPQQJU3LXS7LBBANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you are subscribed to this thread.Message. > ID: ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:934,interoperability,Messag,Message,934,"Hi sorry to jump on this thread but how sure are you of genomic stability. in your organism? Just thinking about, mutation rates, did you amplify the pacbio sample,. have you checked for methylation? Joe. On Mon, 31 Jul 2023, 17:17 Axze-rgb, ***@***.***> wrote:. > And that doesn't bother you? We interpret this as low clonal presence,. > while we have actually massive bad mapping of the T at the same place? > Coincidence? Or are the few ""good"" Ts an artefact? >. > My advisor once told me if I stopped asking such question I probably would. > have a PhD already, but ... I am warry of coincidence. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658710664>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2UURSWJPUBSPQQJU3LXS7LBBANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you are subscribed to this thread.Message. > ID: ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:150,modifiability,pac,pacbio,150,"Hi sorry to jump on this thread but how sure are you of genomic stability. in your organism? Just thinking about, mutation rates, did you amplify the pacbio sample,. have you checked for methylation? Joe. On Mon, 31 Jul 2023, 17:17 Axze-rgb, ***@***.***> wrote:. > And that doesn't bother you? We interpret this as low clonal presence,. > while we have actually massive bad mapping of the T at the same place? > Coincidence? Or are the few ""good"" Ts an artefact? >. > My advisor once told me if I stopped asking such question I probably would. > have a PhD already, but ... I am warry of coincidence. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658710664>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2UURSWJPUBSPQQJU3LXS7LBBANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you are subscribed to this thread.Message. > ID: ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:64,reliability,stabil,stability,64,"Hi sorry to jump on this thread but how sure are you of genomic stability. in your organism? Just thinking about, mutation rates, did you amplify the pacbio sample,. have you checked for methylation? Joe. On Mon, 31 Jul 2023, 17:17 Axze-rgb, ***@***.***> wrote:. > And that doesn't bother you? We interpret this as low clonal presence,. > while we have actually massive bad mapping of the T at the same place? > Coincidence? Or are the few ""good"" Ts an artefact? >. > My advisor once told me if I stopped asking such question I probably would. > have a PhD already, but ... I am warry of coincidence. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658710664>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2UURSWJPUBSPQQJU3LXS7LBBANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you are subscribed to this thread.Message. > ID: ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:274,reliability,doe,doesn,274,"Hi sorry to jump on this thread but how sure are you of genomic stability. in your organism? Just thinking about, mutation rates, did you amplify the pacbio sample,. have you checked for methylation? Joe. On Mon, 31 Jul 2023, 17:17 Axze-rgb, ***@***.***> wrote:. > And that doesn't bother you? We interpret this as low clonal presence,. > while we have actually massive bad mapping of the T at the same place? > Coincidence? Or are the few ""good"" Ts an artefact? >. > My advisor once told me if I stopped asking such question I probably would. > have a PhD already, but ... I am warry of coincidence. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658710664>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2UURSWJPUBSPQQJU3LXS7LBBANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you are subscribed to this thread.Message. > ID: ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:805,security,auth,auth,805,"Hi sorry to jump on this thread but how sure are you of genomic stability. in your organism? Just thinking about, mutation rates, did you amplify the pacbio sample,. have you checked for methylation? Joe. On Mon, 31 Jul 2023, 17:17 Axze-rgb, ***@***.***> wrote:. > And that doesn't bother you? We interpret this as low clonal presence,. > while we have actually massive bad mapping of the T at the same place? > Coincidence? Or are the few ""good"" Ts an artefact? >. > My advisor once told me if I stopped asking such question I probably would. > have a PhD already, but ... I am warry of coincidence. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658710664>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2UURSWJPUBSPQQJU3LXS7LBBANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you are subscribed to this thread.Message. > ID: ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:497,usability,stop,stopped,497,"Hi sorry to jump on this thread but how sure are you of genomic stability. in your organism? Just thinking about, mutation rates, did you amplify the pacbio sample,. have you checked for methylation? Joe. On Mon, 31 Jul 2023, 17:17 Axze-rgb, ***@***.***> wrote:. > And that doesn't bother you? We interpret this as low clonal presence,. > while we have actually massive bad mapping of the T at the same place? > Coincidence? Or are the few ""good"" Ts an artefact? >. > My advisor once told me if I stopped asking such question I probably would. > have a PhD already, but ... I am warry of coincidence. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658710664>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2UURSWJPUBSPQQJU3LXS7LBBANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you are subscribed to this thread.Message. > ID: ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:638,integrability,Messag,Message,638,"No problem, your variant of interest isn't a genomic region that may be. hyper variable ie a simple sequence repeat (they can occur in coding. regions) or something else that may lead to the variability your seeing? Joe. On Mon, 31 Jul 2023, 17:30 Axze-rgb, ***@***.***> wrote:. > nothing is amplified no, it's all PCR free. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658733075>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2X446P2BMPITLE5763XS7MRXANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:638,interoperability,Messag,Message,638,"No problem, your variant of interest isn't a genomic region that may be. hyper variable ie a simple sequence repeat (they can occur in coding. regions) or something else that may lead to the variability your seeing? Joe. On Mon, 31 Jul 2023, 17:30 Axze-rgb, ***@***.***> wrote:. > nothing is amplified no, it's all PCR free. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658733075>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2X446P2BMPITLE5763XS7MRXANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:79,modifiability,variab,variable,79,"No problem, your variant of interest isn't a genomic region that may be. hyper variable ie a simple sequence repeat (they can occur in coding. regions) or something else that may lead to the variability your seeing? Joe. On Mon, 31 Jul 2023, 17:30 Axze-rgb, ***@***.***> wrote:. > nothing is amplified no, it's all PCR free. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658733075>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2X446P2BMPITLE5763XS7MRXANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:191,modifiability,variab,variability,191,"No problem, your variant of interest isn't a genomic region that may be. hyper variable ie a simple sequence repeat (they can occur in coding. regions) or something else that may lead to the variability your seeing? Joe. On Mon, 31 Jul 2023, 17:30 Axze-rgb, ***@***.***> wrote:. > nothing is amplified no, it's all PCR free. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658733075>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2X446P2BMPITLE5763XS7MRXANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:529,security,auth,auth,529,"No problem, your variant of interest isn't a genomic region that may be. hyper variable ie a simple sequence repeat (they can occur in coding. regions) or something else that may lead to the variability your seeing? Joe. On Mon, 31 Jul 2023, 17:30 Axze-rgb, ***@***.***> wrote:. > nothing is amplified no, it's all PCR free. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658733075>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2X446P2BMPITLE5763XS7MRXANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:93,testability,simpl,simple,93,"No problem, your variant of interest isn't a genomic region that may be. hyper variable ie a simple sequence repeat (they can occur in coding. regions) or something else that may lead to the variability your seeing? Joe. On Mon, 31 Jul 2023, 17:30 Axze-rgb, ***@***.***> wrote:. > nothing is amplified no, it's all PCR free. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658733075>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2X446P2BMPITLE5763XS7MRXANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:93,usability,simpl,simple,93,"No problem, your variant of interest isn't a genomic region that may be. hyper variable ie a simple sequence repeat (they can occur in coding. regions) or something else that may lead to the variability your seeing? Joe. On Mon, 31 Jul 2023, 17:30 Axze-rgb, ***@***.***> wrote:. > nothing is amplified no, it's all PCR free. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658733075>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2X446P2BMPITLE5763XS7MRXANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:500,integrability,Messag,Message,500,"Sorry but simple sequence repeats are mutable in prokaryotes too.... On Mon, 31 Jul 2023, 17:45 Axze-rgb, ***@***.***> wrote:. > that's not a feature of this genome we are not in humans. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658755258>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2V75T2P2ATODR6Z6QDXS7OLHANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:500,interoperability,Messag,Message,500,"Sorry but simple sequence repeats are mutable in prokaryotes too.... On Mon, 31 Jul 2023, 17:45 Axze-rgb, ***@***.***> wrote:. > that's not a feature of this genome we are not in humans. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658755258>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2V75T2P2ATODR6Z6QDXS7OLHANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:391,security,auth,auth,391,"Sorry but simple sequence repeats are mutable in prokaryotes too.... On Mon, 31 Jul 2023, 17:45 Axze-rgb, ***@***.***> wrote:. > that's not a feature of this genome we are not in humans. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658755258>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2V75T2P2ATODR6Z6QDXS7OLHANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:10,testability,simpl,simple,10,"Sorry but simple sequence repeats are mutable in prokaryotes too.... On Mon, 31 Jul 2023, 17:45 Axze-rgb, ***@***.***> wrote:. > that's not a feature of this genome we are not in humans. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658755258>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2V75T2P2ATODR6Z6QDXS7OLHANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:10,usability,simpl,simple,10,"Sorry but simple sequence repeats are mutable in prokaryotes too.... On Mon, 31 Jul 2023, 17:45 Axze-rgb, ***@***.***> wrote:. > that's not a feature of this genome we are not in humans. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658755258>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2V75T2P2ATODR6Z6QDXS7OLHANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:115,interoperability,convers,conversations,115,"Ok so you have no idea what we are talking about, this is not a prokaryote. I would suggest you avoid hopping into conversations for making completely ignorant comments, not even bothering to check about what organisms we are dealing with. I find this kind of behaviour extremely irritating, especially since the answer to your questions are deducible from reading the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:96,safety,avoid,avoid,96,"Ok so you have no idea what we are talking about, this is not a prokaryote. I would suggest you avoid hopping into conversations for making completely ignorant comments, not even bothering to check about what organisms we are dealing with. I find this kind of behaviour extremely irritating, especially since the answer to your questions are deducible from reading the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:140,safety,compl,completely,140,"Ok so you have no idea what we are talking about, this is not a prokaryote. I would suggest you avoid hopping into conversations for making completely ignorant comments, not even bothering to check about what organisms we are dealing with. I find this kind of behaviour extremely irritating, especially since the answer to your questions are deducible from reading the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:140,security,compl,completely,140,"Ok so you have no idea what we are talking about, this is not a prokaryote. I would suggest you avoid hopping into conversations for making completely ignorant comments, not even bothering to check about what organisms we are dealing with. I find this kind of behaviour extremely irritating, especially since the answer to your questions are deducible from reading the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:260,usability,behavi,behaviour,260,"Ok so you have no idea what we are talking about, this is not a prokaryote. I would suggest you avoid hopping into conversations for making completely ignorant comments, not even bothering to check about what organisms we are dealing with. I find this kind of behaviour extremely irritating, especially since the answer to your questions are deducible from reading the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:880,integrability,Messag,Message,880,"You said it was random clonal organism, il have a look when the reads are. on the sra database, was just trying to help,. And yes I don't care about SNPs sorry. (Google people) I'll be here to offer random advice to other people if I'm. still allowed,. Joe. On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. > Ok so you have no idea what we are talking about, this is not a. > prokaryote. I would suggest you avoid hopping into conversations for making. > completely ignorant comments, not even bothering to check about what. > organisms we are dealing with. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:436,interoperability,convers,conversations,436,"You said it was random clonal organism, il have a look when the reads are. on the sra database, was just trying to help,. And yes I don't care about SNPs sorry. (Google people) I'll be here to offer random advice to other people if I'm. still allowed,. Joe. On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. > Ok so you have no idea what we are talking about, this is not a. > prokaryote. I would suggest you avoid hopping into conversations for making. > completely ignorant comments, not even bothering to check about what. > organisms we are dealing with. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:880,interoperability,Messag,Message,880,"You said it was random clonal organism, il have a look when the reads are. on the sra database, was just trying to help,. And yes I don't care about SNPs sorry. (Google people) I'll be here to offer random advice to other people if I'm. still allowed,. Joe. On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. > Ok so you have no idea what we are talking about, this is not a. > prokaryote. I would suggest you avoid hopping into conversations for making. > completely ignorant comments, not even bothering to check about what. > organisms we are dealing with. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:417,safety,avoid,avoid,417,"You said it was random clonal organism, il have a look when the reads are. on the sra database, was just trying to help,. And yes I don't care about SNPs sorry. (Google people) I'll be here to offer random advice to other people if I'm. still allowed,. Joe. On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. > Ok so you have no idea what we are talking about, this is not a. > prokaryote. I would suggest you avoid hopping into conversations for making. > completely ignorant comments, not even bothering to check about what. > organisms we are dealing with. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:464,safety,compl,completely,464,"You said it was random clonal organism, il have a look when the reads are. on the sra database, was just trying to help,. And yes I don't care about SNPs sorry. (Google people) I'll be here to offer random advice to other people if I'm. still allowed,. Joe. On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. > Ok so you have no idea what we are talking about, this is not a. > prokaryote. I would suggest you avoid hopping into conversations for making. > completely ignorant comments, not even bothering to check about what. > organisms we are dealing with. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:464,security,compl,completely,464,"You said it was random clonal organism, il have a look when the reads are. on the sra database, was just trying to help,. And yes I don't care about SNPs sorry. (Google people) I'll be here to offer random advice to other people if I'm. still allowed,. Joe. On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. > Ok so you have no idea what we are talking about, this is not a. > prokaryote. I would suggest you avoid hopping into conversations for making. > completely ignorant comments, not even bothering to check about what. > organisms we are dealing with. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:771,security,auth,auth,771,"You said it was random clonal organism, il have a look when the reads are. on the sra database, was just trying to help,. And yes I don't care about SNPs sorry. (Google people) I'll be here to offer random advice to other people if I'm. still allowed,. Joe. On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. > Ok so you have no idea what we are talking about, this is not a. > prokaryote. I would suggest you avoid hopping into conversations for making. > completely ignorant comments, not even bothering to check about what. > organisms we are dealing with. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:115,usability,help,help,115,"You said it was random clonal organism, il have a look when the reads are. on the sra database, was just trying to help,. And yes I don't care about SNPs sorry. (Google people) I'll be here to offer random advice to other people if I'm. still allowed,. Joe. On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. > Ok so you have no idea what we are talking about, this is not a. > prokaryote. I would suggest you avoid hopping into conversations for making. > completely ignorant comments, not even bothering to check about what. > organisms we are dealing with. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1018,integrability,Messag,Message,1018,"And there's bacteria with 4 chromosomes.... On Mon, 31 Jul 2023, 17:50 Joe, ***@***.***> wrote:. > You said it was random clonal organism, il have a look when the reads are. > on the sra database, was just trying to help,. >. > And yes I don't care about SNPs sorry. >. > (Google people) I'll be here to offer random advice to other people if I'm. > still allowed,. >. > Joe. >. > On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. >. >> Ok so you have no idea what we are talking about, this is not a. >> prokaryote. I would suggest you avoid hopping into conversations for making. >> completely ignorant comments, not even bothering to check about what. >> organisms we are dealing with. >>. >> . >> Reply to this email directly, view it on GitHub. >> <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. >> or unsubscribe. >> <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. >> . >> You are receiving this because you commented.Message ID:. >> ***@***.***>. >>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:564,interoperability,convers,conversations,564,"And there's bacteria with 4 chromosomes.... On Mon, 31 Jul 2023, 17:50 Joe, ***@***.***> wrote:. > You said it was random clonal organism, il have a look when the reads are. > on the sra database, was just trying to help,. >. > And yes I don't care about SNPs sorry. >. > (Google people) I'll be here to offer random advice to other people if I'm. > still allowed,. >. > Joe. >. > On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. >. >> Ok so you have no idea what we are talking about, this is not a. >> prokaryote. I would suggest you avoid hopping into conversations for making. >> completely ignorant comments, not even bothering to check about what. >> organisms we are dealing with. >>. >> . >> Reply to this email directly, view it on GitHub. >> <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. >> or unsubscribe. >> <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. >> . >> You are receiving this because you commented.Message ID:. >> ***@***.***>. >>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1018,interoperability,Messag,Message,1018,"And there's bacteria with 4 chromosomes.... On Mon, 31 Jul 2023, 17:50 Joe, ***@***.***> wrote:. > You said it was random clonal organism, il have a look when the reads are. > on the sra database, was just trying to help,. >. > And yes I don't care about SNPs sorry. >. > (Google people) I'll be here to offer random advice to other people if I'm. > still allowed,. >. > Joe. >. > On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. >. >> Ok so you have no idea what we are talking about, this is not a. >> prokaryote. I would suggest you avoid hopping into conversations for making. >> completely ignorant comments, not even bothering to check about what. >> organisms we are dealing with. >>. >> . >> Reply to this email directly, view it on GitHub. >> <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. >> or unsubscribe. >> <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. >> . >> You are receiving this because you commented.Message ID:. >> ***@***.***>. >>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:545,safety,avoid,avoid,545,"And there's bacteria with 4 chromosomes.... On Mon, 31 Jul 2023, 17:50 Joe, ***@***.***> wrote:. > You said it was random clonal organism, il have a look when the reads are. > on the sra database, was just trying to help,. >. > And yes I don't care about SNPs sorry. >. > (Google people) I'll be here to offer random advice to other people if I'm. > still allowed,. >. > Joe. >. > On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. >. >> Ok so you have no idea what we are talking about, this is not a. >> prokaryote. I would suggest you avoid hopping into conversations for making. >> completely ignorant comments, not even bothering to check about what. >> organisms we are dealing with. >>. >> . >> Reply to this email directly, view it on GitHub. >> <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. >> or unsubscribe. >> <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. >> . >> You are receiving this because you commented.Message ID:. >> ***@***.***>. >>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:593,safety,compl,completely,593,"And there's bacteria with 4 chromosomes.... On Mon, 31 Jul 2023, 17:50 Joe, ***@***.***> wrote:. > You said it was random clonal organism, il have a look when the reads are. > on the sra database, was just trying to help,. >. > And yes I don't care about SNPs sorry. >. > (Google people) I'll be here to offer random advice to other people if I'm. > still allowed,. >. > Joe. >. > On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. >. >> Ok so you have no idea what we are talking about, this is not a. >> prokaryote. I would suggest you avoid hopping into conversations for making. >> completely ignorant comments, not even bothering to check about what. >> organisms we are dealing with. >>. >> . >> Reply to this email directly, view it on GitHub. >> <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. >> or unsubscribe. >> <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. >> . >> You are receiving this because you commented.Message ID:. >> ***@***.***>. >>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:593,security,compl,completely,593,"And there's bacteria with 4 chromosomes.... On Mon, 31 Jul 2023, 17:50 Joe, ***@***.***> wrote:. > You said it was random clonal organism, il have a look when the reads are. > on the sra database, was just trying to help,. >. > And yes I don't care about SNPs sorry. >. > (Google people) I'll be here to offer random advice to other people if I'm. > still allowed,. >. > Joe. >. > On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. >. >> Ok so you have no idea what we are talking about, this is not a. >> prokaryote. I would suggest you avoid hopping into conversations for making. >> completely ignorant comments, not even bothering to check about what. >> organisms we are dealing with. >>. >> . >> Reply to this email directly, view it on GitHub. >> <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. >> or unsubscribe. >> <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. >> . >> You are receiving this because you commented.Message ID:. >> ***@***.***>. >>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:907,security,auth,auth,907,"And there's bacteria with 4 chromosomes.... On Mon, 31 Jul 2023, 17:50 Joe, ***@***.***> wrote:. > You said it was random clonal organism, il have a look when the reads are. > on the sra database, was just trying to help,. >. > And yes I don't care about SNPs sorry. >. > (Google people) I'll be here to offer random advice to other people if I'm. > still allowed,. >. > Joe. >. > On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. >. >> Ok so you have no idea what we are talking about, this is not a. >> prokaryote. I would suggest you avoid hopping into conversations for making. >> completely ignorant comments, not even bothering to check about what. >> organisms we are dealing with. >>. >> . >> Reply to this email directly, view it on GitHub. >> <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. >> or unsubscribe. >> <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. >> . >> You are receiving this because you commented.Message ID:. >> ***@***.***>. >>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:216,usability,help,help,216,"And there's bacteria with 4 chromosomes.... On Mon, 31 Jul 2023, 17:50 Joe, ***@***.***> wrote:. > You said it was random clonal organism, il have a look when the reads are. > on the sra database, was just trying to help,. >. > And yes I don't care about SNPs sorry. >. > (Google people) I'll be here to offer random advice to other people if I'm. > still allowed,. >. > Joe. >. > On Mon, 31 Jul 2023, 17:48 Axze-rgb, ***@***.***> wrote:. >. >> Ok so you have no idea what we are talking about, this is not a. >> prokaryote. I would suggest you avoid hopping into conversations for making. >> completely ignorant comments, not even bothering to check about what. >> organisms we are dealing with. >>. >> . >> Reply to this email directly, view it on GitHub. >> <https://github.com/google/deepvariant/issues/682#issuecomment-1658759224>,. >> or unsubscribe. >> <https://github.com/notifications/unsubscribe-auth/BAYQV2TF5UCMO6WOF6KVCJ3XS7OWLANCNFSM6AAAAAA2QKAKXQ>. >> . >> You are receiving this because you commented.Message ID:. >> ***@***.***>. >>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:220,performance,time,time,220,"The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:50,performance,time,time,50,"Closing the thread, because I am not wasting more time with this stupid nonsense",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1834,availability,error,errors,1834,"ACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always prac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1913,availability,consist,consistency,1913,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1958,availability,error,error,1958,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2038,availability,error,error,2038,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2649,availability,down,down,2649,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2728,availability,down,down,2728,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:73,deployability,scale,scaled,73,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2441,deployability,depend,depends,2441,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:73,energy efficiency,scale,scaled,73,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1964,energy efficiency,model,models,1964,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2044,energy efficiency,model,model,2044,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2423,energy efficiency,model,model,2423,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2441,integrability,depend,depends,2441,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1611,interoperability,format,format,1611,"matics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems an",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1650,interoperability,format,format,1650,". A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:73,modifiability,scal,scaled,73,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:144,modifiability,inherit,inherited,144,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1142,modifiability,deco,decode,1142,"nherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2441,modifiability,depend,depends,2441,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:73,performance,scale,scaled,73,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:594,performance,Content,Content,594,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1834,performance,error,errors,1834,"ACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always prac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1958,performance,error,error,1958,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2038,performance,error,error,2038,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2347,performance,time,time,2347,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2461,performance,time,time,2461,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2833,reliability,pra,practice,2833,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:44,safety,detect,detecting,44,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1834,safety,error,errors,1834,"ACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always prac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1958,safety,error,error,1958,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2038,safety,error,error,2038,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2395,safety,compl,complete,2395,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2441,safety,depend,depends,2441,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:44,security,detect,detecting,44,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:455,security,encrypt,encrypted,455,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1964,security,model,models,1964,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2044,security,model,model,2044,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2395,security,compl,complete,2395,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2423,security,model,model,2423,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2655,security,defend,defending,2655,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1781,testability,coverag,coverage,1781,"AACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone tha",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2306,testability,Understand,Understanding,2306,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2404,testability,understand,understanding,2404,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2441,testability,depend,depends,2441,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:547,usability,support,support,547,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:568,usability,help,help,568,"@Axze-rgb This has to do with you sequencer detecting the Q-Score (Phred-scaled) read quality, that gets stored in the FASTQ files that and get inherited in converted BAM file when you align the reads. So a SAM/BAM file have read quality scores per base following the sequence, like this:. ```. CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# . ```. The score is a ASCII encrypted score + the value 33. You can read the Phred value here per ASCII value:. https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm. A full line in a SAM/BAM file would look like this:. ```. readID43GYAX15:7:1:1202:19894/1 256 contig87 540849 1 65M * 0 0 CCTGCACGAACGAAATCCGCATGCGTCTGGTCGTTGTACGGAACGGCGGTTGTGTGACGAACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1834,usability,error,errors,1834,"ACGGC EDDEEDEE=EE?DE??DDDBADEBEFFFDBEFFEBCBC=?BEEEE@=:?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always prac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1913,usability,consist,consistency,1913,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1958,usability,error,error,1958,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2038,usability,error,error,2038,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2282,usability,confirm,confirm,2282,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2509,usability,learn,learning,2509,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2880,usability,help,helps,2880,":?::?7?:8-6?7?@??# AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:65 YT:Z:UU. ```. The columns of this tab-delimited line are usually the following:. QNAME FLAG RNAME POS MAPQ CIGAR RNEXT PNEXT TLEN SEQ QUAL TAGS. 1) Read Name. 2) SAM flag[ --> decode](http://www.google.com/url?q=http%3A%2F%2Fbroadinstitute.github.io%2Fpicard%2Fexplain-flags.html&sa=D&sntz=1&usg=AOvVaw0FjgFbRCGf0ogpCecZqsJX). 3) contig name or * for unmapped. 4) mapped position of base 1 of a read on the reference sequence. 5) MAPQ mapping quality. 6) CIGAR string describing insertions and deletions. 7) Name of mate. 8) Position of mate. 9) Template length. 10) Read Sequence. 11) Read Quality. 12) Additional information in TAG:TYPE:VALUE format. You can read about the SAM/BAM format at the following link:. https://samtools.github.io/hts-specs/SAMv1.pdf. So to answer the last two questions. So having good coverage (read depth) lets you get around sequencing errors -- meaning you might have to repeat the experiment as well for ensuring consistency in the results. Some labs create error models with different known repeated read lengths to generate a sequencer error model -- you don't need to do that, as that cost a lot of money to do properly. You can probably do it with known samples and compare it to golden truth datasets, but again that will cost. The other way to do it is to try other assays to confirm your results. . Understanding all the moving parts takes time. Sure it is very rewarding once you have a complete understanding of a model, but it all depends on how much time is reasonable for you. You can always keep learning after getting the PhD, as that just teaches you how to independently think about big problems and how to systematically break them down (defending your approach). Once you confidently have that thought process down, you're virtually unbeatable and don't need hone that skill as it already is innate. You can always practice that during your postdoc :) . Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:260,availability,down,downloaded,260,"Could be the stupidest advice in the universe but are you looking at your. vcf file :). Literally just thought talking through the problem might help, fellow. human, and no I didn't check the organism, you could have told me and I. would gkne the ncbi datanae downloaded the genomes aligned them checked. your region if interest don't worry if I see your name on the email thread. on this public github repository I won't reply and I'll loom forward your. paper on bioarvix hopefully,. Honestly all the best,. And if you don't care about prokaryotes then fair enough,. Joe. On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote:. > The name of the organism has been said in this thread, that you are unable. > to find it, and believe we deal with a prokaryote is pathetic, really. Why. > would we bother with your stupid advice when you didn't even take the time. > to read the thread? >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:389,integrability,pub,public,389,"Could be the stupidest advice in the universe but are you looking at your. vcf file :). Literally just thought talking through the problem might help, fellow. human, and no I didn't check the organism, you could have told me and I. would gkne the ncbi datanae downloaded the genomes aligned them checked. your region if interest don't worry if I see your name on the email thread. on this public github repository I won't reply and I'll loom forward your. paper on bioarvix hopefully,. Honestly all the best,. And if you don't care about prokaryotes then fair enough,. Joe. On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote:. > The name of the organism has been said in this thread, that you are unable. > to find it, and believe we deal with a prokaryote is pathetic, really. Why. > would we bother with your stupid advice when you didn't even take the time. > to read the thread? >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:403,integrability,repositor,repository,403,"Could be the stupidest advice in the universe but are you looking at your. vcf file :). Literally just thought talking through the problem might help, fellow. human, and no I didn't check the organism, you could have told me and I. would gkne the ncbi datanae downloaded the genomes aligned them checked. your region if interest don't worry if I see your name on the email thread. on this public github repository I won't reply and I'll loom forward your. paper on bioarvix hopefully,. Honestly all the best,. And if you don't care about prokaryotes then fair enough,. Joe. On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote:. > The name of the organism has been said in this thread, that you are unable. > to find it, and believe we deal with a prokaryote is pathetic, really. Why. > would we bother with your stupid advice when you didn't even take the time. > to read the thread? >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1201,integrability,Messag,Message,1201,"Could be the stupidest advice in the universe but are you looking at your. vcf file :). Literally just thought talking through the problem might help, fellow. human, and no I didn't check the organism, you could have told me and I. would gkne the ncbi datanae downloaded the genomes aligned them checked. your region if interest don't worry if I see your name on the email thread. on this public github repository I won't reply and I'll loom forward your. paper on bioarvix hopefully,. Honestly all the best,. And if you don't care about prokaryotes then fair enough,. Joe. On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote:. > The name of the organism has been said in this thread, that you are unable. > to find it, and believe we deal with a prokaryote is pathetic, really. Why. > would we bother with your stupid advice when you didn't even take the time. > to read the thread? >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:403,interoperability,repositor,repository,403,"Could be the stupidest advice in the universe but are you looking at your. vcf file :). Literally just thought talking through the problem might help, fellow. human, and no I didn't check the organism, you could have told me and I. would gkne the ncbi datanae downloaded the genomes aligned them checked. your region if interest don't worry if I see your name on the email thread. on this public github repository I won't reply and I'll loom forward your. paper on bioarvix hopefully,. Honestly all the best,. And if you don't care about prokaryotes then fair enough,. Joe. On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote:. > The name of the organism has been said in this thread, that you are unable. > to find it, and believe we deal with a prokaryote is pathetic, really. Why. > would we bother with your stupid advice when you didn't even take the time. > to read the thread? >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1201,interoperability,Messag,Message,1201,"Could be the stupidest advice in the universe but are you looking at your. vcf file :). Literally just thought talking through the problem might help, fellow. human, and no I didn't check the organism, you could have told me and I. would gkne the ncbi datanae downloaded the genomes aligned them checked. your region if interest don't worry if I see your name on the email thread. on this public github repository I won't reply and I'll loom forward your. paper on bioarvix hopefully,. Honestly all the best,. And if you don't care about prokaryotes then fair enough,. Joe. On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote:. > The name of the organism has been said in this thread, that you are unable. > to find it, and believe we deal with a prokaryote is pathetic, really. Why. > would we bother with your stupid advice when you didn't even take the time. > to read the thread? >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:860,performance,time,time,860,"Could be the stupidest advice in the universe but are you looking at your. vcf file :). Literally just thought talking through the problem might help, fellow. human, and no I didn't check the organism, you could have told me and I. would gkne the ncbi datanae downloaded the genomes aligned them checked. your region if interest don't worry if I see your name on the email thread. on this public github repository I won't reply and I'll loom forward your. paper on bioarvix hopefully,. Honestly all the best,. And if you don't care about prokaryotes then fair enough,. Joe. On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote:. > The name of the organism has been said in this thread, that you are unable. > to find it, and believe we deal with a prokaryote is pathetic, really. Why. > would we bother with your stupid advice when you didn't even take the time. > to read the thread? >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1092,security,auth,auth,1092,"Could be the stupidest advice in the universe but are you looking at your. vcf file :). Literally just thought talking through the problem might help, fellow. human, and no I didn't check the organism, you could have told me and I. would gkne the ncbi datanae downloaded the genomes aligned them checked. your region if interest don't worry if I see your name on the email thread. on this public github repository I won't reply and I'll loom forward your. paper on bioarvix hopefully,. Honestly all the best,. And if you don't care about prokaryotes then fair enough,. Joe. On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote:. > The name of the organism has been said in this thread, that you are unable. > to find it, and believe we deal with a prokaryote is pathetic, really. Why. > would we bother with your stupid advice when you didn't even take the time. > to read the thread? >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:145,usability,help,help,145,"Could be the stupidest advice in the universe but are you looking at your. vcf file :). Literally just thought talking through the problem might help, fellow. human, and no I didn't check the organism, you could have told me and I. would gkne the ncbi datanae downloaded the genomes aligned them checked. your region if interest don't worry if I see your name on the email thread. on this public github repository I won't reply and I'll loom forward your. paper on bioarvix hopefully,. Honestly all the best,. And if you don't care about prokaryotes then fair enough,. Joe. On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote:. > The name of the organism has been said in this thread, that you are unable. > to find it, and believe we deal with a prokaryote is pathetic, really. Why. > would we bother with your stupid advice when you didn't even take the time. > to read the thread? >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:198,availability,state,state,198,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:662,availability,error,errors,662,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:644,energy efficiency,model,model,644,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:957,energy efficiency,frequenc,frequency,957,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:198,integrability,state,state,198,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:95,interoperability,format,format,95,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:450,interoperability,distribut,distributed,450,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:662,performance,error,errors,662,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:662,safety,error,errors,662,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:644,security,model,model,644,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:888,security,trust,trust,888,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1045,security,trust,trust,1045,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:738,testability,plan,plan,738,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:389,usability,tool,tools,389,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:662,usability,error,errors,662,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:877,usability,person,personally,877,"Is there a way to ban trolls on github? It is extremely irritating. . @pgrosu I know about sam format (reasonably well) but my point is that I have seen that pop up a lot in my experiment, the same state of character called with high confidence in parts of the reads, and with low confidence in other parts of the reads. There might (might) be something in this genome that throws off the tools we have. My guess is that it's the high heterozygosity distributed all across the chromosomes. It's somehow disappointing to see the problem reappears here with HiFi reads, I was hoping to get rid of it when ditching Illumina, and using the HiFi to model the calling errors of the Illumina (which in itself is immensely ambitious). . I have a plan B, which is assembling genomes de novo, we have good results. Will it have the accuracy needed? That's the big question. EDIT: do you personally trust, based on the evidence presented here, there is a clone of low frequency? I know it's probably not enough data, but to get a feel of to what point you trust the scoring system ;)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:308,availability,down,downloaded,308,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:435,integrability,pub,public,435,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:449,integrability,repositor,repository,449,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1239,integrability,Messag,Message,1239,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1429,integrability,messag,messages,1429,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1448,integrability,messag,message,1448,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1519,integrability,pub,public,1519,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:449,interoperability,repositor,repository,449,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1239,interoperability,Messag,Message,1239,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1429,interoperability,messag,messages,1429,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1448,interoperability,messag,message,1448,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:905,performance,time,time,905,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1731,performance,memor,memory,1731,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1135,security,auth,auth,1135,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:195,usability,help,help,195,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1731,usability,memor,memory,1731,"> Could be the stupidest advice in the universe but she you looking st your vcf file.or thinking if the necwr comment to send back to me, Literally just thought talking through the problem might help, fellow human, and no I didn't check the organism, you could have told me and I would gkne the ncbi datanae downloaded the genomes aligned them checked your region if interest don't worry if I see your name on the email thread on this public github repository I won't reply and I'll loom forward your paper on bioarvix hopefully, Honestly all the best, And if you don't care about prokaryotes then fair enough, Joe. > [](#). > On Mon, 31 Jul 2023, 17:54 Axze-rgb, ***@***.***> wrote: The name of the organism has been said in this thread, that you are unable to find it, and believe we deal with a prokaryote is pathetic, really. Why would we bother with your stupid advice when you didn't even take the time to read the thread?  Reply to this email directly, view it on GitHub <[#682 (comment)](https://github.com/google/deepvariant/issues/682#issuecomment-1658768123)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ> . You are receiving this because you commented.Message ID: ***@***.***>. There are so many trolls it's difficult to know when someone is just clumsy. I am willing to give you the benefit of the doubt. Buit really you could have read the messages above, or message me to know what we are talking about? If this discussion is in public, it's indeed to attract interest of others. But just read 2 minutes without suggesting the first spontaneous idea you have. Which is not idiot in itself but that's something we though of if ... 2014 in my memory serves me well ^^. Allez, useless to have petty fight and it's not a good look. I might have overreacted to a genuine sympathetic comment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:711,availability,down,downloaded,711,"No worries, but like I have studied quite a lot of dna and rna sequence. data. But i may also be missing the obvious answer. By the way hybrid assembly using both long and short reads can make for a. more complete assembly. On a comletely separate note, you check for methylation in your organism? Id be happy to do it for you! Joe. On Mon, 31 Jul 2023, 18:10 Axze-rgb, ***@***.***> wrote:. > Could be the stupidest advice in the universe but she you looking st your. > vcf file.or thinking if the necwr comment to send back to me, Literally. > just thought talking through the problem might help, fellow human, and no I. > didn't check the organism, you could have told me and I would gkne the ncbi. > datanae downloaded the genomes aligned them checked your region if interest. > don't worry if I see your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:841,integrability,pub,public,841,"No worries, but like I have studied quite a lot of dna and rna sequence. data. But i may also be missing the obvious answer. By the way hybrid assembly using both long and short reads can make for a. more complete assembly. On a comletely separate note, you check for methylation in your organism? Id be happy to do it for you! Joe. On Mon, 31 Jul 2023, 18:10 Axze-rgb, ***@***.***> wrote:. > Could be the stupidest advice in the universe but she you looking st your. > vcf file.or thinking if the necwr comment to send back to me, Literally. > just thought talking through the problem might help, fellow human, and no I. > didn't check the organism, you could have told me and I would gkne the ncbi. > datanae downloaded the genomes aligned them checked your region if interest. > don't worry if I see your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:858,integrability,repositor,repository,858,"No worries, but like I have studied quite a lot of dna and rna sequence. data. But i may also be missing the obvious answer. By the way hybrid assembly using both long and short reads can make for a. more complete assembly. On a comletely separate note, you check for methylation in your organism? Id be happy to do it for you! Joe. On Mon, 31 Jul 2023, 18:10 Axze-rgb, ***@***.***> wrote:. > Could be the stupidest advice in the universe but she you looking st your. > vcf file.or thinking if the necwr comment to send back to me, Literally. > just thought talking through the problem might help, fellow human, and no I. > didn't check the organism, you could have told me and I would gkne the ncbi. > datanae downloaded the genomes aligned them checked your region if interest. > don't worry if I see your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1797,integrability,Messag,Message,1797,"e your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1990,integrability,messag,messages,1990," your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2009,integrability,messag,message,2009," your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2083,integrability,pub,public,2083," your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2771,integrability,Messag,Message,2771," your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:858,interoperability,repositor,repository,858,"No worries, but like I have studied quite a lot of dna and rna sequence. data. But i may also be missing the obvious answer. By the way hybrid assembly using both long and short reads can make for a. more complete assembly. On a comletely separate note, you check for methylation in your organism? Id be happy to do it for you! Joe. On Mon, 31 Jul 2023, 18:10 Axze-rgb, ***@***.***> wrote:. > Could be the stupidest advice in the universe but she you looking st your. > vcf file.or thinking if the necwr comment to send back to me, Literally. > just thought talking through the problem might help, fellow human, and no I. > didn't check the organism, you could have told me and I would gkne the ncbi. > datanae downloaded the genomes aligned them checked your region if interest. > don't worry if I see your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1797,interoperability,Messag,Message,1797,"e your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1990,interoperability,messag,messages,1990," your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2009,interoperability,messag,message,2009," your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2771,interoperability,Messag,Message,2771," your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1345,performance,time,time,1345," 2023, 18:10 Axze-rgb, ***@***.***> wrote:. > Could be the stupidest advice in the universe but she you looking st your. > vcf file.or thinking if the necwr comment to send back to me, Literally. > just thought talking through the problem might help, fellow human, and no I. > didn't check the organism, you could have told me and I would gkne the ncbi. > datanae downloaded the genomes aligned them checked your region if interest. > don't worry if I see your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, usele",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2304,performance,memor,memory,2304," your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:205,safety,compl,complete,205,"No worries, but like I have studied quite a lot of dna and rna sequence. data. But i may also be missing the obvious answer. By the way hybrid assembly using both long and short reads can make for a. more complete assembly. On a comletely separate note, you check for methylation in your organism? Id be happy to do it for you! Joe. On Mon, 31 Jul 2023, 18:10 Axze-rgb, ***@***.***> wrote:. > Could be the stupidest advice in the universe but she you looking st your. > vcf file.or thinking if the necwr comment to send back to me, Literally. > just thought talking through the problem might help, fellow human, and no I. > didn't check the organism, you could have told me and I would gkne the ncbi. > datanae downloaded the genomes aligned them checked your region if interest. > don't worry if I see your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:205,security,compl,complete,205,"No worries, but like I have studied quite a lot of dna and rna sequence. data. But i may also be missing the obvious answer. By the way hybrid assembly using both long and short reads can make for a. more complete assembly. On a comletely separate note, you check for methylation in your organism? Id be happy to do it for you! Joe. On Mon, 31 Jul 2023, 18:10 Axze-rgb, ***@***.***> wrote:. > Could be the stupidest advice in the universe but she you looking st your. > vcf file.or thinking if the necwr comment to send back to me, Literally. > just thought talking through the problem might help, fellow human, and no I. > didn't check the organism, you could have told me and I would gkne the ncbi. > datanae downloaded the genomes aligned them checked your region if interest. > don't worry if I see your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1585,security,auth,auth,1585,"ight help, fellow human, and no I. > didn't check the organism, you could have told me and I would gkne the ncbi. > datanae downloaded the genomes aligned them checked your region if interest. > don't worry if I see your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-16587",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1690,security,auth,auth,1690,"he ncbi. > datanae downloaded the genomes aligned them checked your region if interest. > don't worry if I see your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2662,security,auth,auth,2662," your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:592,usability,help,help,592,"No worries, but like I have studied quite a lot of dna and rna sequence. data. But i may also be missing the obvious answer. By the way hybrid assembly using both long and short reads can make for a. more complete assembly. On a comletely separate note, you check for methylation in your organism? Id be happy to do it for you! Joe. On Mon, 31 Jul 2023, 18:10 Axze-rgb, ***@***.***> wrote:. > Could be the stupidest advice in the universe but she you looking st your. > vcf file.or thinking if the necwr comment to send back to me, Literally. > just thought talking through the problem might help, fellow human, and no I. > didn't check the organism, you could have told me and I would gkne the ncbi. > datanae downloaded the genomes aligned them checked your region if interest. > don't worry if I see your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2304,usability,memor,memory,2304," your name on the email thread on this public github. > repository I won't reply and I'll loom forward your paper on bioarvix. > hopefully, Honestly all the best, And if you don't care about prokaryotes. > then fair enough, Joe. >  <#m_-2096600892735742938_>. > On Mon, 31 Jul 2023, 17:54 Axze-rgb, *@*.*> wrote: The name of the. > organism has been said in this thread, that you are unable to find it, and. > believe we deal with a prokaryote is pathetic, really. Why would we bother. > with your stupid advice when you didn't even take the time to read the. > thread?  Reply to this email directly, view it on GitHub <#682 (comment). > <https://github.com/google/deepvariant/issues/682#issuecomment-1658768123>>,. > or unsubscribe. > https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ. > <https://github.com/notifications/unsubscribe-auth/BAYQV2XLSQBKI475IIY3253XS7PMTANCNFSM6AAAAAA2QKAKXQ>. > . You are receiving this because you commented.Message ID: @.*>. >. > There are so many trolls it's difficult to know when someone is just. > clumsy. I am willing to give you the benefit of the doubt. Buit really you. > could have read the messages above, or message me to know what we are. > talking about? If this discussion is in public, it's indeed to attract. > interest of others. But just read 2 minutes without suggesting the first. > spontaneous idea you have. Which is not idiot in itself but that's. > something we though of in ... 2014 in my memory serves me well ^^. >. > Allez, useless to have petty fight and it's not a good look. I might have. > overreacted to a genuine sympathetic comment. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658794438>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2WSPRXKHQH7UQOXNVTXS7RHRANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:190,availability,error,errors,190,"We have done those approaches, except for methylation maybe (not sure about that one). The main issue if we have a diploid genome, with a high heterozygosity, which leads to mapping scoring errors, as well as some callers totally losing their minds.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:190,performance,error,errors,190,"We have done those approaches, except for methylation maybe (not sure about that one). The main issue if we have a diploid genome, with a high heterozygosity, which leads to mapping scoring errors, as well as some callers totally losing their minds.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:31,safety,except,except,31,"We have done those approaches, except for methylation maybe (not sure about that one). The main issue if we have a diploid genome, with a high heterozygosity, which leads to mapping scoring errors, as well as some callers totally losing their minds.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:190,safety,error,errors,190,"We have done those approaches, except for methylation maybe (not sure about that one). The main issue if we have a diploid genome, with a high heterozygosity, which leads to mapping scoring errors, as well as some callers totally losing their minds.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:190,usability,error,errors,190,"We have done those approaches, except for methylation maybe (not sure about that one). The main issue if we have a diploid genome, with a high heterozygosity, which leads to mapping scoring errors, as well as some callers totally losing their minds.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:648,integrability,topic,topics,648,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:44,security,team,team,44,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:202,security,team,team,202,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:332,security,team,team,332,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:685,security,team,team,685,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:255,testability,context,context,255,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:167,usability,help,help,167,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:295,usability,help,help,295,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:459,usability,help,help,459,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:522,usability,help,helpful,522,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:694,usability,support,support,694,"Hi everyone on this thread:. We (the Google team that works on DeepVariant) have really appreciated our GitHub community where people post questions, discussions, and help each other out. Even when our team answer questions, we don't always have the full context. We really appreciate community help and discussion from outside the team as well. For people who post on our GitHub issues, please be respectful to each other, and know that people are trying to help out, even when you might not feel like the answers are as helpful. @Axze-rgb we'll take another look at this thread and see what answer we can provide. It is possible that some of the topics here might be beyond what our team can support, but we'll try our best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:541,availability,down,down,541,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:657,availability,error,error,657,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:607,integrability,sub,subclonal,607,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:823,integrability,event,events,823,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:866,integrability,filter,filter,866,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:91,performance,time,time,91,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:657,performance,error,error,657,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1075,reliability,pra,practice,1075,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:171,safety,reme,remember,171,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:657,safety,error,error,657,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:754,safety,compl,complexities,754,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:754,security,compl,complexities,754,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:594,usability,clear,clearly,594,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:631,usability,clear,clear,631,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:657,usability,error,error,657,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1112,usability,indicat,indicate,1112,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1123,usability,clear,clear,1123,"Hi All,. I appreciate that all of you are contributing scientific insights and taking your time to add thoughts on the DeepVariant GitHub issues. as @pichuan said, please remember that we are all scientists trying to work with each other and be respectful of each other. @Axze-rgb I haven't had a chance to look into the data (with what I have I would be looking at the effect in human data just to get a feel for how unusual it is). However, from your results, I'm not sure that this approach is promising and I am sorry I may have led you down a bad path. I was hoping to see sites that look clearly like subclonal SNPs (so look clear on other sources of error). From your pileups posted, it looks like many of the GQ30 VAF 0.15 population are mapping complexities. . It might be possible to further separate out mapping events, for example by increasing the MapQ filter, or excluding sites that are within a short distance of other variants, but I am not sure the approach will be worthwhile. My apologies, I think that in principle this is an interesting concept, but in practice, I am not sure your results indicate a clear win with the approach.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:86,availability,failur,failure,86,"I am actually happy we at least can rule something out. Those rotifers have led us to failure on this for years now, there is something that we miss. That we all miss.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:86,deployability,fail,failure,86,"I am actually happy we at least can rule something out. Those rotifers have led us to failure on this for years now, there is something that we miss. That we all miss.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:86,performance,failur,failure,86,"I am actually happy we at least can rule something out. Those rotifers have led us to failure on this for years now, there is something that we miss. That we all miss.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:86,reliability,fail,failure,86,"I am actually happy we at least can rule something out. Those rotifers have led us to failure on this for years now, there is something that we miss. That we all miss.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:389,energy efficiency,frequenc,frequency,389,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:284,integrability,messag,message,284,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1261,integrability,topic,topics,1261,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1656,integrability,Messag,Message,1656,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:146,interoperability,share,share,146,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:284,interoperability,messag,message,284,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1656,interoperability,Messag,Message,1656,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:594,security,team,team,594,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:760,security,team,team,760,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:896,security,team,team,896,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1298,security,team,team,1298,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1547,security,auth,auth,1547,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:816,testability,context,context,816,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:720,usability,help,help,720,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:856,usability,help,help,856,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1028,usability,help,help,1028,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1094,usability,help,helpful,1094,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1307,usability,support,support,1307,"No problem, I just wanted to say I did ask google bard some questions I. thought might be important,. You can have a look here: https://g.co/bard/share/4013d7eb8290. Or start a thread of your own :). And I'll hop out of this thread now as I think I'm cluttering it up, but. drop me a message if you ever want to chat. Also I know some clonal organisms that can change there entire allele. frequency and linkage in less than 5 minutes! Not trying to distact you, all the best,. Joe. On Mon, 31 Jul 2023, 18:34 Pi-Chuan Chang, ***@***.***> wrote:. > Hi everyone on this thread:. > We (the Google team that works on DeepVariant) have really appreciated our. > GitHub community where people post questions, discussions, and help each. > other out. > Even when our team answer questions, we don't always have the full. > context. We really appreciate community help and discussion from outside. > the team as well. > For people who post on our GitHub issues, please be respectful to each. > other, and know that people are trying to help out, even when you might not. > feel like the answers are as helpful. >. > @Axze-rgb <https://github.com/Axze-rgb> we'll take another look at this. > thread and see what answer we can provide. It is possible that some of the. > topics here might be beyond what our team can support, but we'll try our. > best. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/682#issuecomment-1658849274>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/BAYQV2U67RCHYD4ET3E22ALXS7UA7ANCNFSM6AAAAAA2QKAKXQ>. > . > You are receiving this because you commented.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:654,availability,operat,operates,654,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1298,availability,down,down,1298,"e do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2410,availability,operat,operates,2410,"arding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- poss",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2597,availability,state,state,2597," even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3961,deployability,log,login,3961,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:635,energy efficiency,model,model,635,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:725,energy efficiency,model,model,725,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1157,energy efficiency,frequenc,frequency,1157," have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-8814206",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1366,energy efficiency,frequenc,frequency,1366,"first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test wh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1613,energy efficiency,frequenc,frequency,1613,"chanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2387,energy efficiency,model,model,2387," terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2750,energy efficiency,model,model,2750," [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of pol",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3096,energy efficiency,model,model,3096,"ogle/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3737,energy efficiency,profil,profiling,3737,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3866,energy efficiency,profil,profiling,3866,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3979,energy efficiency,Measur,Measuring,3979,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2597,integrability,state,state,2597," even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1073,interoperability,specif,specific,1073,"eels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1952,interoperability,distribut,distribution,1952,"ng with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1218,modifiability,variab,variables,1218,"appy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increas",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:100,performance,time,time-crunch,100,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:297,performance,time,time,297,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2578,performance,time,time,2578,"atch -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3737,performance,profil,profiling,3737,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3866,performance,profil,profiling,3866,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:4262,performance,content,content,4262,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1357,reliability,doe,does,1357,"driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypothese",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:177,safety,compl,complete,177,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:716,safety,test,test,716,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1468,safety,valid,validate,1468,"w you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2056,safety,valid,validated,2056,"or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the me",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2364,safety,test,test,2364,"frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional exp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2630,safety,compl,complexities,2630," mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/Align",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3379,safety,valid,validating,3379,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3521,safety,compl,complete,3521,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3961,safety,log,login,3961,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:177,security,compl,complete,177,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:635,security,model,model,635,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:725,security,model,model,725,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1145,security,trust,trust,1145,"ese:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1468,security,validat,validate,1468,"w you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2056,security,validat,validated,2056,"or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the me",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2387,security,model,model,2387," terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2431,security,trust,trust,2431,"'s behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2630,security,compl,complexities,2630," mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/Align",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2750,security,model,model,2750," [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of pol",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3096,security,model,model,3096,"ogle/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3379,security,validat,validating,3379,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3521,security,compl,complete,3521,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3961,security,log,login,3961,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:716,testability,test,test,716,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1331,testability,simpl,simpler,1331,"iven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1514,testability,verif,verified,1514,"second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2023,testability,coverag,coverage,2023," which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment mi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2364,testability,test,test,2364,"frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional exp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3961,testability,log,login,3961,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:968,usability,close,closer,968,"@Axze-rgb A lot of what I'm gonna say I'm sure you already know well. As it feels you might be in a time-crunch, you're a better judge than me on these:. - Do you have a fairly complete story that you and your advisor are happy with? - If you want to pursue a deeper the story, what proportion of time do you want to make it science-driven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1331,usability,simpl,simpler,1331,"iven versus engineering-driven? The first question you don't have to answer, and is more obvious to you than me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1437,usability,behavi,behavior,1437,"an me -- and it would affect how you pursue the second -- so I'll tackle the second one :) The science-driven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1543,usability,confirm,confirm,1543,"ven one is not so much goal-driven, but rather trying to uncover the mechanism that the model the organism operates through. This can be a rabbit hole as you hypothesis-test the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/represen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1718,usability,tool,tools,1718,"the model's response through different experiments. So if you want to pursue de-novo assembly, ask yourself why you got good results previously? That's why I mentioned the ""panel of clonals"", which has the same basic idea. You are starting with a closer variant in its molecular evolution, than a reference which might be quite distant and/or mixed in specific loci or contigs as compared to your clone. . Regarding would I trust a low frequency region given the evidence? When there are multiple variables that start to accumulate with an experiment, I usually start breaking down towards the root cause with simpler experiments. What does low frequency region mean in terms of sequencing regarding your organism's behavior? For example, you can validate known regions in your clone you have verified via other assays to confirm that the sequencing results match -- it might not even be low frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assum",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2609,usability,hint,hints,2609," frequency. Next, as you mentioned, you check for heterozygous k-mer pairs, which you can investigate via tools GenomeScope and Smudgeplot as [presented in the following paper](https://www.nature.com/articles/s41467-020-14998-3). For example, if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitut",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2849,usability,behavi,behavior,2849,", if you look at the figure of the k-mer spectra of diploid Arabidopsis thaliana, it has a similar distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:2947,usability,confirm,confirming,2947,"distribution as your original GQ plot (assuming correlation of GQ with coverage, which would need to be validated):. ![image](https://github.com/google/deepvariant/assets/6555937/6e225f54-b836-4c0d-a4af-88142066bace). They mentioned that _*""for a diploid species, increasing heterozygosity will result in a higher first peak and a lower second peak"",*_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:3654,usability,help,helps,3654,"_ which makes sense. Then from there, you form hypotheses to test what might be the model of your organism operates by. So do I trust the reads, usually yes from HiFi, but maybe a better question is what exactly are the reads inferring/representing here regarding a point in time of a clone(s) state? This hints at the mapping complexities that Andrew was suggesting. Regarding the engineering approach, here you assume to have a well-established model you rely upon -- or at least backed up thoroughly by prior experiments -- of your organism's behavior under different conditions. It is more goal-driven, as you have stronger expectations of confirming new hypotheses. Given that, you use it to infer how the experiment might behave, or in your case the meaning behind your results. If your model is not well-established for your organism, your organism might respond in a unexpected ways given an experimental setup. I get the feeling we're trying to mix the engineering with the science-based approach, which might cause us to require designing additional experiments for validating previous results -- possibly becoming circular. On another note, I'm sure your already know this regarding IGV colors, you can get complete breakdown of their meaning at the following site: . https://software.broadinstitute.org/software/igv/AlignmentData. Hope it helps,. ~p. #### References. 1. [GenomeScope 2.0 and Smudgeplot for reference-free profiling of polyploid genomes](https://www.nature.com/articles/s41467-020-14998-3). 2. [GenomeScope: fast reference-free genome profiling from short reads](https://academic.oup.com/bioinformatics/article/33/14/2202/3089939?login=false). 3. [Measuring Genome Sizes Using Read-Depth, k-mers, and Flow Cytometry: Methodological Comparisons in Beetles (Coleoptera)](https://academic.oup.com/g3journal/article/10/9/3047/6060154). 4. [Kmer2SNP: reference-free SNP calling from raw reads based on matching](https://www.biorxiv.org/content/10.1101/2020.05.17.100305v1.full)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:242,performance,time,time,242,"@pgrosu . You have perfectly summed it up, we are at a point where established techniques don't seem to work well. This is the crucial element ... . you have asked 2 very deep questions that I should discuss with them openly. . Regarding the time I have, well, I don't have any scholarship any more. So I have all the time I want, except I have to dedicate some of it to get money for food. . Thanks for Kmer2SNP we have tried it, but unfortunately, it's absolutely unusable: it is impossible to have a rotifer-only culture in lab, you always get bacteria and fungi along. Therefore, they show up in kmer2SNP, and you compare the evolution of the rotifers + the rest. . We do have other plans, fortunately I am not yet at the end of the story.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:318,performance,time,time,318,"@pgrosu . You have perfectly summed it up, we are at a point where established techniques don't seem to work well. This is the crucial element ... . you have asked 2 very deep questions that I should discuss with them openly. . Regarding the time I have, well, I don't have any scholarship any more. So I have all the time I want, except I have to dedicate some of it to get money for food. . Thanks for Kmer2SNP we have tried it, but unfortunately, it's absolutely unusable: it is impossible to have a rotifer-only culture in lab, you always get bacteria and fungi along. Therefore, they show up in kmer2SNP, and you compare the evolution of the rotifers + the rest. . We do have other plans, fortunately I am not yet at the end of the story.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:331,safety,except,except,331,"@pgrosu . You have perfectly summed it up, we are at a point where established techniques don't seem to work well. This is the crucial element ... . you have asked 2 very deep questions that I should discuss with them openly. . Regarding the time I have, well, I don't have any scholarship any more. So I have all the time I want, except I have to dedicate some of it to get money for food. . Thanks for Kmer2SNP we have tried it, but unfortunately, it's absolutely unusable: it is impossible to have a rotifer-only culture in lab, you always get bacteria and fungi along. Therefore, they show up in kmer2SNP, and you compare the evolution of the rotifers + the rest. . We do have other plans, fortunately I am not yet at the end of the story.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:687,testability,plan,plans,687,"@pgrosu . You have perfectly summed it up, we are at a point where established techniques don't seem to work well. This is the crucial element ... . you have asked 2 very deep questions that I should discuss with them openly. . Regarding the time I have, well, I don't have any scholarship any more. So I have all the time I want, except I have to dedicate some of it to get money for food. . Thanks for Kmer2SNP we have tried it, but unfortunately, it's absolutely unusable: it is impossible to have a rotifer-only culture in lab, you always get bacteria and fungi along. Therefore, they show up in kmer2SNP, and you compare the evolution of the rotifers + the rest. . We do have other plans, fortunately I am not yet at the end of the story.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:71,safety,compl,complete,71,"@Axze-rgb Alas, the unfortunate pains of grad school. Trust me, if you complete the story it will become a joyous reminder of its intrinsic elegance (from the point-of-view of understanding the problem fully), as well as a rewarding reminder of the required rigor during future difficult uncharted waters you might face scientifically. Good luck, though I'm sure you'll do great! ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:54,security,Trust,Trust,54,"@Axze-rgb Alas, the unfortunate pains of grad school. Trust me, if you complete the story it will become a joyous reminder of its intrinsic elegance (from the point-of-view of understanding the problem fully), as well as a rewarding reminder of the required rigor during future difficult uncharted waters you might face scientifically. Good luck, though I'm sure you'll do great! ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:71,security,compl,complete,71,"@Axze-rgb Alas, the unfortunate pains of grad school. Trust me, if you complete the story it will become a joyous reminder of its intrinsic elegance (from the point-of-view of understanding the problem fully), as well as a rewarding reminder of the required rigor during future difficult uncharted waters you might face scientifically. Good luck, though I'm sure you'll do great! ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:176,testability,understand,understanding,176,"@Axze-rgb Alas, the unfortunate pains of grad school. Trust me, if you complete the story it will become a joyous reminder of its intrinsic elegance (from the point-of-view of understanding the problem fully), as well as a rewarding reminder of the required rigor during future difficult uncharted waters you might face scientifically. Good luck, though I'm sure you'll do great! ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:192,energy efficiency,power,power,192,"Now I have filtered the HiFi reads based on mapq, to check if we see the same patter of strange peak of GQ 30 and VAF 0,17. I wanted to do the other things as well but we are out of computing power",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:11,integrability,filter,filtered,11,"Now I have filtered the HiFi reads based on mapq, to check if we see the same patter of strange peak of GQ 30 and VAF 0,17. I wanted to do the other things as well but we are out of computing power",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:76,deployability,updat,updates,76,"Hi @Axze-rgb ,. I'll close this issue now. Please feel free to give further updates to this thread. If you have more questions that the DeepVariant team can help support, please feel free to open another issue. I'm closing this so that it's easier for our people on rotation to track active issues for support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:76,safety,updat,updates,76,"Hi @Axze-rgb ,. I'll close this issue now. Please feel free to give further updates to this thread. If you have more questions that the DeepVariant team can help support, please feel free to open another issue. I'm closing this so that it's easier for our people on rotation to track active issues for support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:76,security,updat,updates,76,"Hi @Axze-rgb ,. I'll close this issue now. Please feel free to give further updates to this thread. If you have more questions that the DeepVariant team can help support, please feel free to open another issue. I'm closing this so that it's easier for our people on rotation to track active issues for support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:148,security,team,team,148,"Hi @Axze-rgb ,. I'll close this issue now. Please feel free to give further updates to this thread. If you have more questions that the DeepVariant team can help support, please feel free to open another issue. I'm closing this so that it's easier for our people on rotation to track active issues for support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:266,security,rotat,rotation,266,"Hi @Axze-rgb ,. I'll close this issue now. Please feel free to give further updates to this thread. If you have more questions that the DeepVariant team can help support, please feel free to open another issue. I'm closing this so that it's easier for our people on rotation to track active issues for support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:21,usability,close,close,21,"Hi @Axze-rgb ,. I'll close this issue now. Please feel free to give further updates to this thread. If you have more questions that the DeepVariant team can help support, please feel free to open another issue. I'm closing this so that it's easier for our people on rotation to track active issues for support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:157,usability,help,help,157,"Hi @Axze-rgb ,. I'll close this issue now. Please feel free to give further updates to this thread. If you have more questions that the DeepVariant team can help support, please feel free to open another issue. I'm closing this so that it's easier for our people on rotation to track active issues for support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:162,usability,support,support,162,"Hi @Axze-rgb ,. I'll close this issue now. Please feel free to give further updates to this thread. If you have more questions that the DeepVariant team can help support, please feel free to open another issue. I'm closing this so that it's easier for our people on rotation to track active issues for support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:302,usability,support,support,302,"Hi @Axze-rgb ,. I'll close this issue now. Please feel free to give further updates to this thread. If you have more questions that the DeepVariant team can help support, please feel free to open another issue. I'm closing this so that it's easier for our people on rotation to track active issues for support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:62,usability,help,help,62,"I just would like to thanks everyone here for their patience, help and comments. . Cheers. I will definitely tell you when I have the results I am looking for.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:465,deployability,manag,manage,465,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:465,energy efficiency,manag,manage,465,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:747,performance,Network,Network,747,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:816,performance,time,time,816,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:465,safety,manag,manage,465,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:747,security,Network,Network,747,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:289,testability,coverag,coverage,289,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:576,testability,plan,plan,576,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:722,testability,understand,understand,722,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:884,testability,understand,understand,884,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:110,usability,person,person,110,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:182,usability,person,person,182,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:518,usability,help,helpful,518,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:761,usability,learn,learn,761,"Hello, . I write here again to say 2 things. - first I apologize for having be somewhat agressive towards the person who came in the discussion, it seems to me it was just a curious person after all and not a troll. So sorry about that. I apologize @Joe-r-code . - We are going to do high coverage ONT sequencing, which should allow for a better SNP calling. If it works well, would you be interested to train DeepVariant on my data set? That would make it able to manage high heterozygous genomes. You have been very helpful and I really appreciated it. So, I think we could plan to collaborate on training deepvariant on a highly heterozygous genome with many paralogs? I also ask this, because honestly I would love to understand better Neural Network and I learn better by doing. . The sequencing will take some time though. Cheers. . EDIT: by ""curious"" I mean someone wanting to understand, I don't mean weird. In French curious can mean weird, so I don't know if this is the case in English.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:391,energy efficiency,model,model,391,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:525,energy efficiency,model,model,525,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1291,energy efficiency,model,model,1291,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1634,integrability,event,eventually,1634,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:145,performance,time,time,145,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:747,performance,time,time,747,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1358,performance,network,networks,1358,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1518,performance,Network,Networks,1518,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:371,reliability,pra,practice,371,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1410,reliability,pra,practice,1410,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1037,safety,compl,complexities,1037,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:391,security,model,model,391,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:525,security,model,model,525,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1037,security,compl,complexities,1037,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1291,security,model,model,1291,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1358,security,network,networks,1358,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1518,security,Network,Networks,1518,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1152,testability,simpl,simple,1152,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1491,testability,understand,understand,1491,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:282,usability,prefer,prefer,282,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:305,usability,guidanc,guidance,305,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:792,usability,behavi,behavior,792,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1152,usability,simpl,simple,1152,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1314,usability,learn,learning,1314,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1337,usability,learn,learning,1337,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1445,usability,learn,learning,1445,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1718,usability,learn,learning,1718,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:1810,usability,help,helps,1810,"@Axze-rgb Great to hear from you! How have you been? I only want to hear good news :) Thank you kindly for the opportunity, but unfortunately my time is a bit dominated by a few things these days. A collaboration is a big commitment in order for me to assist properly, so for now I prefer to just provide guidance as necessary. Before you sequence too much, it's best to practice training a model with some data on your own to get a feel for what's happening. You have a great tutorial (including the data) on how to train a model [at the following link](https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md). Again it has germline diploid assumptions built into it. If your data varies a lot, it will take some time for the weights to shift to your data's behavior in order to achieve good accuracy (when possible). Regarding paralogs, you might need to align to a pangenome graph via giraffe, like in [the following paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9365333/). Again you are adding complexities that require careful mastery of nuances you need to recognize when issues come up. Start playing with simple things first to get a good grasp of what's going on. So my humble recommendation is to take baby steps. Try to play with training a model first. Regarding learning about machine learning/deep neural networks (DNNs), find a book/youtube videos you can practice from - which matches your learning style and makes you code - to better understand how Deep Neural Networks work. Ideally sit in a class, so you are forced to do the homework, and begin with the fundamentals before eventually reaching DNNs (which have a prerequisite of some fundamentals of machine learning concepts as background). Most importantly, have fun and keep us posted :). Hope it helps,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:62,interoperability,specif,specifications,62,"Hi @Axze-rgb,. Would you kindly open a new issue with the ONT specifications? As in the chemistry, cell line etc. Would be interested to know what exactly your experimental setup is and if there's any way we can help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:212,usability,help,help,212,"Hi @Axze-rgb,. Would you kindly open a new issue with the ONT specifications? As in the chemistry, cell line etc. Would be interested to know what exactly your experimental setup is and if there's any way we can help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/683:920,availability,operat,operating,920,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:225,deployability,stage,stages,225,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1015,deployability,resourc,resource,1015,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1024,deployability,manag,managing,1024,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:879,energy efficiency,CPU,CPU,879,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:883,energy efficiency,core,core,883,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:910,energy efficiency,CPU,CPUs,910,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1015,energy efficiency,resourc,resource,1015,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1024,energy efficiency,manag,managing,1024,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1097,energy efficiency,cloud,cloud,1097,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1400,energy efficiency,CPU,CPU,1400,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1404,energy efficiency,core,cores,1404,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1556,energy efficiency,CPU,CPU,1556,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:388,integrability,sub,sub-regions,388,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:264,interoperability,distribut,distribution,264,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:148,modifiability,pac,pacbio-hifi,148,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1239,modifiability,paramet,parameter,1239,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1363,modifiability,paramet,parameters,1363,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1774,modifiability,paramet,parameters,1774,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:62,performance,time,time,62,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:252,performance,parallel,parallelism,252,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:879,performance,CPU,CPU,879,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:899,performance,workload,workloads,899,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:910,performance,CPU,CPUs,910,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1010,performance,time,time,1010,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1015,performance,resourc,resource,1015,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1160,performance,perform,performance,1160,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1379,performance,parallel,parallel,1379,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1400,performance,CPU,CPU,1400,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1483,performance,parallel,parallel,1483,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1556,performance,CPU,CPU,1556,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1789,performance,parallel,parallel,1789,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1866,performance,parallel,parallel,1866,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1015,safety,resourc,resource,1015,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1024,safety,manag,managing,1024,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1671,safety,test,test,1671,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:971,testability,context,context,971,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1015,testability,resourc,resource,1015,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1103,testability,understand,understanding-context-switching-and-its-impact-on-system-performance,1103,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1671,testability,test,test,1671,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1160,usability,perform,performance,1160,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1286,usability,command,commands,1286,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1464,usability,prefer,preferred,1464,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1891,usability,help,helps,1891,"Hi @tzcoolman,. A few things:. $`1)`$ Yes, it can take a long time, as shown here:. https://github.com/google/deepvariant/blob/r1.5/docs/metrics.md#pacbio-hifi. $`2)`$ Yes, `make_examples` is single-threaded and has multiple stages. You can adjust the parallelism distribution indirectly through the number of shards, which can either match the number of chromosomes (or if more then the sub-regions):. https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-details.md#make_examples. https://github.com/google/deepvariant/blob/r1.5/docs/runtime-by-region.md. $`3)`$ Be careful when adjusting the `vsc_min_*` values $`-`$ yes, higher values will make it faster $`-`$ but the reason those were adjusted in post #578 is because the reference was also lower quality, and you might miss some candidates doing so. $`4)`$ One way to make things faster would be to balance the CPU core and thread workloads. CPUs with operating systems have limits at how much they can context switch, before they spend more time resource managing these threads, which is called [thrashing](https://blog.netdata.cloud/understanding-context-switching-and-its-impact-on-system-performance/). A trick you could do is to run DeepVariant with the `--dry_run` parameter, in order to retrieve the individual commands being run. Then you can run the `make_examples` step, adjusting the parameters for `parallel` for either CPU cores or threads, as now the number of jobslots (-j) is its preferred method. `parallel` loves threads and the jobslot (`-j`) argument tries to balance CPU/threads, but the key word here is $`tries`$. In fact, you can force it one way or anther, but you will have to test that empirically in order to see what gets you the best results for your machine. The list of the parameters for parallel are shown on the following page:. https://man.linuxreviews.org/man1/parallel.1.html. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/684:97,deployability,stage,stage,97,"Hi Amy,. Basically, this all happens when the candidates are selected during the `make_examples` stage:. $`1)`$ DP (read depth) is set from the total allele counts [in this line](https://github.com/google/deepvariant/blob/r1.5/deepvariant/variant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:391,deployability,stage,stage,391,"Hi Amy,. Basically, this all happens when the candidates are selected during the `make_examples` stage:. $`1)`$ DP (read depth) is set from the total allele counts [in this line](https://github.com/google/deepvariant/blob/r1.5/deepvariant/variant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:565,deployability,updat,updated,565,"Hi Amy,. Basically, this all happens when the candidates are selected during the `make_examples` stage:. $`1)`$ DP (read depth) is set from the total allele counts [in this line](https://github.com/google/deepvariant/blob/r1.5/deepvariant/variant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:830,deployability,stage,stage,830,"Hi Amy,. Basically, this all happens when the candidates are selected during the `make_examples` stage:. $`1)`$ DP (read depth) is set from the total allele counts [in this line](https://github.com/google/deepvariant/blob/r1.5/deepvariant/variant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:791,energy efficiency,model,model,791,"Hi Amy,. Basically, this all happens when the candidates are selected during the `make_examples` stage:. $`1)`$ DP (read depth) is set from the total allele counts [in this line](https://github.com/google/deepvariant/blob/r1.5/deepvariant/variant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:1245,integrability,FILTER,FILTER,1245,"ant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:1299,integrability,filter,filter,1299,"ant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:2098,interoperability,specif,specific-variant-in-my-data,2098,"ant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:1437,modifiability,paramet,parameters,1437,"ant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:1970,modifiability,paramet,parameters,1970,"ant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:2070,reliability,doe,does-deepvariant-not-call-a-specific-variant-in-my-data,2070,"ant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:565,safety,updat,updated,565,"Hi Amy,. Basically, this all happens when the candidates are selected during the `make_examples` stage:. $`1)`$ DP (read depth) is set from the total allele counts [in this line](https://github.com/google/deepvariant/blob/r1.5/deepvariant/variant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:565,security,updat,updated,565,"Hi Amy,. Basically, this all happens when the candidates are selected during the `make_examples` stage:. $`1)`$ DP (read depth) is set from the total allele counts [in this line](https://github.com/google/deepvariant/blob/r1.5/deepvariant/variant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:791,security,model,model,791,"Hi Amy,. Basically, this all happens when the candidates are selected during the `make_examples` stage:. $`1)`$ DP (read depth) is set from the total allele counts [in this line](https://github.com/google/deepvariant/blob/r1.5/deepvariant/variant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:1456,usability,prefer,preference,1456,"ant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:2231,usability,help,helps,2231,"ant_calling.cc#L307):. ```Python. nucleus::SetInfoField(kDPFormatField, TotalAlleleCounts(allele_count), call);. ```. $`2)`$ In the `make_examples` stage, a tensor image (set of matrices) representing information about your reads gets created. That tensor is usually preinitialized with zeros (0), and then the values get updated with the read information for the rows. The first 5 rows are the reference representation anyway, before it gets populated with your read representation starting with row 6. Then this tensor gets processed through the model $`-`$ during the `call_variants` stage $`-`$ generating the genotype probabilities for: homozygous ref, het, and homozygous alt. $`3)`$ Then in `postprocess_variants` $`-`$ based on the most likely genotype (having the maximum genotype probability) from step $`2`$ $`-`$ the [`compute_filter_fields()`](https://github.com/google/deepvariant/blob/r1.5/deepvariant/postprocess_variants.py#L170-L190) function assigns the `PASS` or `RefCall` for the `FILTER` column of the VCF file. $`4)`$ If you want to filter out these low depth candidates, you can adjust this via the `--make_examples_extra_args=`, by setting some or all of the following parameters to your preference (notice the the default count is already 2, which you are obvserving):. * vsc_min_count_snps (the default is 2). * vsc_min_count_indels (the default is 2). * vsc_min_fraction_snps (the default is 0.12). * vsc_min_fraction_indels (the default is 0.06). * vsc_min_fraction_multiplier (the default is 1.0). Here is an example:. ```. --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_count_indels=3,vsc_min_fraction_snps=0.12,vsc_min_fraction_indels=0.06'. ```. You can read more details about these parameters at the following links:. https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. https://github.com/google/deepvariant/blob/r1.5/deepvariant/make_examples_options.py#L178-L202. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:75,testability,understand,understand,75,"Hi Paul,. Thank you so much for your detailed reply, that really helped me understand it! . BW,. Amy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:65,usability,help,helped,65,"Hi Paul,. Thank you so much for your detailed reply, that really helped me understand it! . BW,. Amy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:23,usability,help,helped,23,"Thank you Amy, glad it helped. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:371,availability,down,downsampled,371,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:513,availability,robust,robust,513,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:221,energy efficiency,predict,prediction,221,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:400,energy efficiency,model,model,400,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:431,modifiability,variab,variability,431,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:762,modifiability,maintain,maintain,762,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:213,performance,network,network,213,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:513,reliability,robust,robust,513,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:221,safety,predict,prediction,221,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:513,safety,robust,robust,513,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:762,safety,maintain,maintain,762,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:213,security,network,network,213,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:400,security,model,model,400,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:383,testability,coverag,coverages,383,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:422,testability,coverag,coverage,422,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:533,testability,coverag,coverages,533,"Thank you very much @pgrosu for such detailed answer! You are absolutely right. So, @amy-houseman, in summary, if a candidate variant passes all of the VSC's (very sensitive caller) thresholds and then the neural network prediction is confident on the genotype, `post_processing` will assign a PASS to the variant. One more thing to note, we train DeepVariant at several downsampled coverages so the model can capture the coverage variability of regions and different sequencing runs. This also makes DeepVariant robust to different coverages. Hopefully that answers your question. . @pgrosu, again thank you for such detailed and excellent answer. This Q/A is an excellent candidate for our FAQ (https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md). We maintain this as a hub for all common answers. Let us know if it would be OK if we link to your response here in our FAQ.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:188,usability,help,help,188,"Hi Kishwar (@kishwarshafin),. Thank you for the nice surprise! Of course I would be more than happy if it becomes part of the FAQ. Feel free to link it, or however you feel is the best to help everyone. It is a wonderful way to grow the community. Many thanks,. Paul.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/684:5,usability,close,close,5,I'll close this bug now. Thanks all!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/684
https://github.com/google/deepvariant/issues/685:104,availability,echo,echo,104,"Hi @Axze-rgb ,. instead of setting INPUT_DIR=""${PWD}"" please provide the absolute path. You can also do echo $INPUT_DIR to make sure the variable is set correctly. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:137,modifiability,variab,variable,137,"Hi @Axze-rgb ,. instead of setting INPUT_DIR=""${PWD}"" please provide the absolute path. You can also do echo $INPUT_DIR to make sure the variable is set correctly. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:174,usability,help,helps,174,"Hi @Axze-rgb ,. instead of setting INPUT_DIR=""${PWD}"" please provide the absolute path. You can also do echo $INPUT_DIR to make sure the variable is set correctly. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:110,modifiability,paramet,parameters,110,Also it seems like you are saying your bam files name is BAM? Please make sure your files name matches the parameters you are setting. Generally the BAM file would be somename.bam.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:112,modifiability,paramet,parameters,112,"> Also it seems like you are saying your bam files name is BAM? Please make sure your files name matches the parameters you are setting. Generally the BAM file would be somename.bam. Sorry, I don't understand, I declare a variable BAM=mysorted.bam"" isn't it how it should work? I will try with providing the absolute path then. . Still puzzled why the dry run works.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:227,modifiability,variab,variable,227,"> Also it seems like you are saying your bam files name is BAM? Please make sure your files name matches the parameters you are setting. Generally the BAM file would be somename.bam. Sorry, I don't understand, I declare a variable BAM=mysorted.bam"" isn't it how it should work? I will try with providing the absolute path then. . Still puzzled why the dry run works.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:203,testability,understand,understand,203,"> Also it seems like you are saying your bam files name is BAM? Please make sure your files name matches the parameters you are setting. Generally the BAM file would be somename.bam. Sorry, I don't understand, I declare a variable BAM=mysorted.bam"" isn't it how it should work? I will try with providing the absolute path then. . Still puzzled why the dry run works.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:345,availability,error,error,345,"Ok that seems to be working with absolute path (at least it's making the examples right now). Also, the index of the bam was corrupted! it seems that you declare the BAM but then deepvariant goes to the index. Which makes sense of course, but maybe it would be a good idea to say somewhere in the doc to pay attention to the index? Or return an error like ""index not found"" rather than ""bam not found""? and why dry run didn't catch this? . Anyway, thank you .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:345,performance,error,error,345,"Ok that seems to be working with absolute path (at least it's making the examples right now). Also, the index of the bam was corrupted! it seems that you declare the BAM but then deepvariant goes to the index. Which makes sense of course, but maybe it would be a good idea to say somewhere in the doc to pay attention to the index? Or return an error like ""index not found"" rather than ""bam not found""? and why dry run didn't catch this? . Anyway, thank you .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
