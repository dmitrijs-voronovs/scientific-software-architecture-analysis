id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/pull/1753:469,safety,error,error-case-sensitive-drives-supported,469,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:776,safety,updat,update,776,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1393,safety,modul,modules,1393,"important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> exa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1781,safety,manag,managed,1781,"em. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2641,safety,modul,modules,2641,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:3243,safety,modul,module,3243,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:103,security,modif,modification,103,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:776,security,updat,update,776,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1707,testability,simpl,simplifies,1707,"t warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:435,usability,help,helpx,435,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:469,usability,error,error-case-sensitive-drives-supported,469,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:533,usability,support,support,533,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:855,usability,navigat,navigate,855,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1354,usability,learn,learn,1354," you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often qui",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1376,usability,learn,learn,1376,"tive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <detai",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1707,usability,simpl,simplifies,1707,"t warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2124,usability,visual,visual,2124,"e while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-define",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2456,usability,user,user-images,2456,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2687,usability,user,user,2687,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2692,usability,guid,guide,2692,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2735,usability,document,documentation,2735,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2840,usability,user,user,2840,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2845,usability,guid,guide,2845,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:3026,usability,guid,guide,3026,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:3116,usability,user,user-defined-redirects,3116,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/issues/1756:15,deployability,Fail,Failed,15,LoweringError: Failed in nopython mode pipeline (step: nopython mode backend);,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756
https://github.com/scverse/scanpy/issues/1756:39,deployability,pipelin,pipeline,39,LoweringError: Failed in nopython mode pipeline (step: nopython mode backend);,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756
https://github.com/scverse/scanpy/issues/1756:39,integrability,pipelin,pipeline,39,LoweringError: Failed in nopython mode pipeline (step: nopython mode backend);,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756
https://github.com/scverse/scanpy/issues/1756:15,reliability,Fail,Failed,15,LoweringError: Failed in nopython mode pipeline (step: nopython mode backend);,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756
https://github.com/scverse/scanpy/issues/1757:744,availability,heal,healthy,744,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1259,deployability,scale,scaled,1259,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1545,deployability,log,log-scaling,1545,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1259,energy efficiency,scale,scaled,1259,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:347,integrability,standardiz,standardize,347,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:432,integrability,sub,subtract,432,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:588,integrability,sub,subtraction,588,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:627,integrability,sub,subtraction,627,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1309,integrability,sub,subtracting,1309,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:347,interoperability,standard,standardize,347,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1069,interoperability,specif,specific,1069,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1808,interoperability,specif,specify,1808,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:47,modifiability,scal,scaling,47,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:413,modifiability,variab,variable,413,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1259,modifiability,scal,scaled,1259,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1549,modifiability,scal,scaling,1549,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:549,performance,time,time,549,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1259,performance,scale,scaled,1259,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1545,safety,log,log-scaling,1545,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1545,security,log,log-scaling,1545,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1545,testability,log,log-scaling,1545,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:238,usability,document,documentation,238,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:445,usability,minim,minimum,445,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:607,usability,minim,minimum,607,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:654,usability,minim,minimum,654,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:884,usability,close,close,884,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1137,usability,user,user-images,1137,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1371,usability,user,user-images,1371,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1506,usability,close,closer,1506,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1800,usability,user,user,1800,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1818,usability,custom,custom,1818,"sc.pl.dotplot() `standard_scale='var'`: should scaling be changed?; This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as . ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data! A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------. ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------. ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:. 1. delete the above line 185 (and the other places it shows up...). 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1758:202,deployability,version,version,202,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:325,deployability,log,logfoldchanges,325,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:615,deployability,modul,module,615,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:698,deployability,log,logfoldchanges,698,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1453,deployability,log,log,1453,"`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, ti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1977,deployability,log,log,1977,""""""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2414,deployability,log,log,2414,"(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I mi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2825,deployability,log,log,2825,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:202,integrability,version,version,202,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:202,modifiability,version,version,202,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:615,modifiability,modul,module,615,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1697,modifiability,layer,layer,1697,"gfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2105,modifiability,layer,layer,2105,"s/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2542,modifiability,layer,layer,2542,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2846,modifiability,layer,layer,2846,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:3015,modifiability,layer,layer,3015,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:3021,modifiability,layer,layer,3021,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:3146,modifiability,layer,layer,3146,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:408,reliability,doe,doesn,408,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:325,safety,log,logfoldchanges,325,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:588,safety,input,input-,588,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:615,safety,modul,module,615,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:698,safety,log,logfoldchanges,698,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1453,safety,log,log,1453,"`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, ti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1977,safety,log,log,1977,""""""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2414,safety,log,log,2414,"(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I mi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2825,safety,log,log,2825,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:67,security,Team,Team,67,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:325,security,log,logfoldchanges,325,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:698,security,log,logfoldchanges,698,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1453,security,log,log,1453,"`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, ti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1977,security,log,log,1977,""""""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2414,security,log,log,2414,"(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I mi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2825,security,log,log,2825,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:325,testability,log,logfoldchanges,325,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:544,testability,Trace,Traceback,544,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:698,testability,log,logfoldchanges,698,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1453,testability,log,log,1453,"`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, ti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1977,testability,log,log,1977,""""""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2414,testability,log,log,2414,"(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I mi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2825,testability,log,log,2825,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds). 130 **kwds,. 131 ):. --> 132 BasePlot.__init__(. 133 self,. 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds). 109 self._update_var_groups(). 110 . --> 111 self.categories, self.obs_tidy = _prepare_dataframe(. 112 adata,. 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1864 groupby.remove(groupby_index). 1865 keys = list(groupby) + list(np.unique(var_names)). -> 1866 obs_tidy = get.obs_df(. 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols. 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`."". ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:588,usability,input,input-,588,"pl.rank_gene_groups using gene_symbols key word not working; Hello Team,. ```. sc.__version__. '1.7.0rc2.dev6+g5fc12f4a'. ```. I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot . `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-43-4ca50e495f54> in <module>. ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 656 """""". 657 . --> 658 return _rank_genes_groups_plot(. 659 adata,. 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds). 435 from .._dotplot import dotplot. 436 . --> 437 _pl = dotplot(. 438 adata,. 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds). 940 del kwds['color_map']. 941 . --> 942 dp = DotPlot(. 943 adata,. 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1759:1030,energy efficiency,load,load,1030,"between sc.tl.tsne and scikit-learn.TSNE; from the doc of sc.tl.tsne, I knew it was implemented by scikit, but I can't get the same result between sc.tl.tsne and scikit.TSNE，my test code is below. ```. #!/usr/bin/env python3. # -*- coding: utf-8 -*-. """""". from sklearn import datasets. import scanpy as sc. import numpy as np. import random. import matplotlib.pyplot as plt. from sklearn.manifold import TSNE. np.random.seed(1). random.seed(1). iris = datasets.load_iris(). X = iris.data. label=iris.target. adata=sc.AnnData(X). adata.obs[""celltype""]=label.astype(int).astype(str). sc.tl.tsne(adata,random_state=0,use_fast_tsne=False). axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False). sc_tsne=adata.obsm[""X_tsne""]. #print(ax). print(np.min(sc_tsne[:,0])). print(np.max(sc_tsne[:,0])). print(np.min(sc_tsne[:,1])). print(np.max(sc_tsne[:,1])). print(""====================""). # import pickle. # #with open(). # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'). # tsne2=pickle.load(file). target=label. tsne = TSNE(learning_rate=1000,init='random', random_state=0). X_transformed = tsne.fit_transform(X). fig=plt.figure(). for label in np.unique(target):. plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label). plt.legend(loc=""upper left""). plt.show(). #print(X_transformed). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). print(""==================""). params_sklearn = dict(. perplexity=30,. random_state=0,. verbose=False,. early_exaggeration=12,. learning_rate=1000,. ). from sklearn.manifold import TSNE. # unfortunately, sklearn does not allow to set a minimum number. # of iterations for barnes-hut tSNE. tsne3 = TSNE(**params_sklearn). X_transformed=tsne3.fit_transform(X). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). ```. I get the result. ![image](",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1759:1030,performance,load,load,1030,"between sc.tl.tsne and scikit-learn.TSNE; from the doc of sc.tl.tsne, I knew it was implemented by scikit, but I can't get the same result between sc.tl.tsne and scikit.TSNE，my test code is below. ```. #!/usr/bin/env python3. # -*- coding: utf-8 -*-. """""". from sklearn import datasets. import scanpy as sc. import numpy as np. import random. import matplotlib.pyplot as plt. from sklearn.manifold import TSNE. np.random.seed(1). random.seed(1). iris = datasets.load_iris(). X = iris.data. label=iris.target. adata=sc.AnnData(X). adata.obs[""celltype""]=label.astype(int).astype(str). sc.tl.tsne(adata,random_state=0,use_fast_tsne=False). axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False). sc_tsne=adata.obsm[""X_tsne""]. #print(ax). print(np.min(sc_tsne[:,0])). print(np.max(sc_tsne[:,0])). print(np.min(sc_tsne[:,1])). print(np.max(sc_tsne[:,1])). print(""====================""). # import pickle. # #with open(). # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'). # tsne2=pickle.load(file). target=label. tsne = TSNE(learning_rate=1000,init='random', random_state=0). X_transformed = tsne.fit_transform(X). fig=plt.figure(). for label in np.unique(target):. plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label). plt.legend(loc=""upper left""). plt.show(). #print(X_transformed). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). print(""==================""). params_sklearn = dict(. perplexity=30,. random_state=0,. verbose=False,. early_exaggeration=12,. learning_rate=1000,. ). from sklearn.manifold import TSNE. # unfortunately, sklearn does not allow to set a minimum number. # of iterations for barnes-hut tSNE. tsne3 = TSNE(**params_sklearn). X_transformed=tsne3.fit_transform(X). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). ```. I get the result. ![image](",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1759:1713,reliability,doe,does,1713,"it.TSNE，my test code is below. ```. #!/usr/bin/env python3. # -*- coding: utf-8 -*-. """""". from sklearn import datasets. import scanpy as sc. import numpy as np. import random. import matplotlib.pyplot as plt. from sklearn.manifold import TSNE. np.random.seed(1). random.seed(1). iris = datasets.load_iris(). X = iris.data. label=iris.target. adata=sc.AnnData(X). adata.obs[""celltype""]=label.astype(int).astype(str). sc.tl.tsne(adata,random_state=0,use_fast_tsne=False). axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False). sc_tsne=adata.obsm[""X_tsne""]. #print(ax). print(np.min(sc_tsne[:,0])). print(np.max(sc_tsne[:,0])). print(np.min(sc_tsne[:,1])). print(np.max(sc_tsne[:,1])). print(""====================""). # import pickle. # #with open(). # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'). # tsne2=pickle.load(file). target=label. tsne = TSNE(learning_rate=1000,init='random', random_state=0). X_transformed = tsne.fit_transform(X). fig=plt.figure(). for label in np.unique(target):. plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label). plt.legend(loc=""upper left""). plt.show(). #print(X_transformed). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). print(""==================""). params_sklearn = dict(. perplexity=30,. random_state=0,. verbose=False,. early_exaggeration=12,. learning_rate=1000,. ). from sklearn.manifold import TSNE. # unfortunately, sklearn does not allow to set a minimum number. # of iterations for barnes-hut tSNE. tsne3 = TSNE(**params_sklearn). X_transformed=tsne3.fit_transform(X). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). ```. I get the result. ![image](https://user-images.githubusercontent.com/59059267/112352805-0fd6fd00-8d06-11eb-9627-5a4708d706de.png). I can't figure it out why this happen. Thank you for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1759:209,safety,test,test,209,"can't reproduce the same result between sc.tl.tsne and scikit-learn.TSNE; from the doc of sc.tl.tsne, I knew it was implemented by scikit, but I can't get the same result between sc.tl.tsne and scikit.TSNE，my test code is below. ```. #!/usr/bin/env python3. # -*- coding: utf-8 -*-. """""". from sklearn import datasets. import scanpy as sc. import numpy as np. import random. import matplotlib.pyplot as plt. from sklearn.manifold import TSNE. np.random.seed(1). random.seed(1). iris = datasets.load_iris(). X = iris.data. label=iris.target. adata=sc.AnnData(X). adata.obs[""celltype""]=label.astype(int).astype(str). sc.tl.tsne(adata,random_state=0,use_fast_tsne=False). axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False). sc_tsne=adata.obsm[""X_tsne""]. #print(ax). print(np.min(sc_tsne[:,0])). print(np.max(sc_tsne[:,0])). print(np.min(sc_tsne[:,1])). print(np.max(sc_tsne[:,1])). print(""====================""). # import pickle. # #with open(). # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'). # tsne2=pickle.load(file). target=label. tsne = TSNE(learning_rate=1000,init='random', random_state=0). X_transformed = tsne.fit_transform(X). fig=plt.figure(). for label in np.unique(target):. plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label). plt.legend(loc=""upper left""). plt.show(). #print(X_transformed). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). print(""==================""). params_sklearn = dict(. perplexity=30,. random_state=0,. verbose=False,. early_exaggeration=12,. learning_rate=1000,. ). from sklearn.manifold import TSNE. # unfortunately, sklearn does not allow to set a minimum number. # of iterations for barnes-hut tSNE. tsne3 = TSNE(**params_sklearn). X_transformed=tsne3.fit_transform(X). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1759:209,testability,test,test,209,"can't reproduce the same result between sc.tl.tsne and scikit-learn.TSNE; from the doc of sc.tl.tsne, I knew it was implemented by scikit, but I can't get the same result between sc.tl.tsne and scikit.TSNE，my test code is below. ```. #!/usr/bin/env python3. # -*- coding: utf-8 -*-. """""". from sklearn import datasets. import scanpy as sc. import numpy as np. import random. import matplotlib.pyplot as plt. from sklearn.manifold import TSNE. np.random.seed(1). random.seed(1). iris = datasets.load_iris(). X = iris.data. label=iris.target. adata=sc.AnnData(X). adata.obs[""celltype""]=label.astype(int).astype(str). sc.tl.tsne(adata,random_state=0,use_fast_tsne=False). axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False). sc_tsne=adata.obsm[""X_tsne""]. #print(ax). print(np.min(sc_tsne[:,0])). print(np.max(sc_tsne[:,0])). print(np.min(sc_tsne[:,1])). print(np.max(sc_tsne[:,1])). print(""====================""). # import pickle. # #with open(). # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'). # tsne2=pickle.load(file). target=label. tsne = TSNE(learning_rate=1000,init='random', random_state=0). X_transformed = tsne.fit_transform(X). fig=plt.figure(). for label in np.unique(target):. plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label). plt.legend(loc=""upper left""). plt.show(). #print(X_transformed). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). print(""==================""). params_sklearn = dict(. perplexity=30,. random_state=0,. verbose=False,. early_exaggeration=12,. learning_rate=1000,. ). from sklearn.manifold import TSNE. # unfortunately, sklearn does not allow to set a minimum number. # of iterations for barnes-hut tSNE. tsne3 = TSNE(**params_sklearn). X_transformed=tsne3.fit_transform(X). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1759:62,usability,learn,learn,62,"can't reproduce the same result between sc.tl.tsne and scikit-learn.TSNE; from the doc of sc.tl.tsne, I knew it was implemented by scikit, but I can't get the same result between sc.tl.tsne and scikit.TSNE，my test code is below. ```. #!/usr/bin/env python3. # -*- coding: utf-8 -*-. """""". from sklearn import datasets. import scanpy as sc. import numpy as np. import random. import matplotlib.pyplot as plt. from sklearn.manifold import TSNE. np.random.seed(1). random.seed(1). iris = datasets.load_iris(). X = iris.data. label=iris.target. adata=sc.AnnData(X). adata.obs[""celltype""]=label.astype(int).astype(str). sc.tl.tsne(adata,random_state=0,use_fast_tsne=False). axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False). sc_tsne=adata.obsm[""X_tsne""]. #print(ax). print(np.min(sc_tsne[:,0])). print(np.max(sc_tsne[:,0])). print(np.min(sc_tsne[:,1])). print(np.max(sc_tsne[:,1])). print(""====================""). # import pickle. # #with open(). # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'). # tsne2=pickle.load(file). target=label. tsne = TSNE(learning_rate=1000,init='random', random_state=0). X_transformed = tsne.fit_transform(X). fig=plt.figure(). for label in np.unique(target):. plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label). plt.legend(loc=""upper left""). plt.show(). #print(X_transformed). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). print(""==================""). params_sklearn = dict(. perplexity=30,. random_state=0,. verbose=False,. early_exaggeration=12,. learning_rate=1000,. ). from sklearn.manifold import TSNE. # unfortunately, sklearn does not allow to set a minimum number. # of iterations for barnes-hut tSNE. tsne3 = TSNE(**params_sklearn). X_transformed=tsne3.fit_transform(X). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1759:969,usability,User,Users,969,"can't reproduce the same result between sc.tl.tsne and scikit-learn.TSNE; from the doc of sc.tl.tsne, I knew it was implemented by scikit, but I can't get the same result between sc.tl.tsne and scikit.TSNE，my test code is below. ```. #!/usr/bin/env python3. # -*- coding: utf-8 -*-. """""". from sklearn import datasets. import scanpy as sc. import numpy as np. import random. import matplotlib.pyplot as plt. from sklearn.manifold import TSNE. np.random.seed(1). random.seed(1). iris = datasets.load_iris(). X = iris.data. label=iris.target. adata=sc.AnnData(X). adata.obs[""celltype""]=label.astype(int).astype(str). sc.tl.tsne(adata,random_state=0,use_fast_tsne=False). axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False). sc_tsne=adata.obsm[""X_tsne""]. #print(ax). print(np.min(sc_tsne[:,0])). print(np.max(sc_tsne[:,0])). print(np.min(sc_tsne[:,1])). print(np.max(sc_tsne[:,1])). print(""====================""). # import pickle. # #with open(). # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'). # tsne2=pickle.load(file). target=label. tsne = TSNE(learning_rate=1000,init='random', random_state=0). X_transformed = tsne.fit_transform(X). fig=plt.figure(). for label in np.unique(target):. plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label). plt.legend(loc=""upper left""). plt.show(). #print(X_transformed). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). print(""==================""). params_sklearn = dict(. perplexity=30,. random_state=0,. verbose=False,. early_exaggeration=12,. learning_rate=1000,. ). from sklearn.manifold import TSNE. # unfortunately, sklearn does not allow to set a minimum number. # of iterations for barnes-hut tSNE. tsne3 = TSNE(**params_sklearn). X_transformed=tsne3.fit_transform(X). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1759:1737,usability,minim,minimum,1737,"it.TSNE，my test code is below. ```. #!/usr/bin/env python3. # -*- coding: utf-8 -*-. """""". from sklearn import datasets. import scanpy as sc. import numpy as np. import random. import matplotlib.pyplot as plt. from sklearn.manifold import TSNE. np.random.seed(1). random.seed(1). iris = datasets.load_iris(). X = iris.data. label=iris.target. adata=sc.AnnData(X). adata.obs[""celltype""]=label.astype(int).astype(str). sc.tl.tsne(adata,random_state=0,use_fast_tsne=False). axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False). sc_tsne=adata.obsm[""X_tsne""]. #print(ax). print(np.min(sc_tsne[:,0])). print(np.max(sc_tsne[:,0])). print(np.min(sc_tsne[:,1])). print(np.max(sc_tsne[:,1])). print(""====================""). # import pickle. # #with open(). # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'). # tsne2=pickle.load(file). target=label. tsne = TSNE(learning_rate=1000,init='random', random_state=0). X_transformed = tsne.fit_transform(X). fig=plt.figure(). for label in np.unique(target):. plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label). plt.legend(loc=""upper left""). plt.show(). #print(X_transformed). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). print(""==================""). params_sklearn = dict(. perplexity=30,. random_state=0,. verbose=False,. early_exaggeration=12,. learning_rate=1000,. ). from sklearn.manifold import TSNE. # unfortunately, sklearn does not allow to set a minimum number. # of iterations for barnes-hut tSNE. tsne3 = TSNE(**params_sklearn). X_transformed=tsne3.fit_transform(X). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). ```. I get the result. ![image](https://user-images.githubusercontent.com/59059267/112352805-0fd6fd00-8d06-11eb-9627-5a4708d706de.png). I can't figure it out why this happen. Thank you for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1759:2040,usability,user,user-images,2040,"it.TSNE，my test code is below. ```. #!/usr/bin/env python3. # -*- coding: utf-8 -*-. """""". from sklearn import datasets. import scanpy as sc. import numpy as np. import random. import matplotlib.pyplot as plt. from sklearn.manifold import TSNE. np.random.seed(1). random.seed(1). iris = datasets.load_iris(). X = iris.data. label=iris.target. adata=sc.AnnData(X). adata.obs[""celltype""]=label.astype(int).astype(str). sc.tl.tsne(adata,random_state=0,use_fast_tsne=False). axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False). sc_tsne=adata.obsm[""X_tsne""]. #print(ax). print(np.min(sc_tsne[:,0])). print(np.max(sc_tsne[:,0])). print(np.min(sc_tsne[:,1])). print(np.max(sc_tsne[:,1])). print(""====================""). # import pickle. # #with open(). # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'). # tsne2=pickle.load(file). target=label. tsne = TSNE(learning_rate=1000,init='random', random_state=0). X_transformed = tsne.fit_transform(X). fig=plt.figure(). for label in np.unique(target):. plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label). plt.legend(loc=""upper left""). plt.show(). #print(X_transformed). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). print(""==================""). params_sklearn = dict(. perplexity=30,. random_state=0,. verbose=False,. early_exaggeration=12,. learning_rate=1000,. ). from sklearn.manifold import TSNE. # unfortunately, sklearn does not allow to set a minimum number. # of iterations for barnes-hut tSNE. tsne3 = TSNE(**params_sklearn). X_transformed=tsne3.fit_transform(X). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). ```. I get the result. ![image](https://user-images.githubusercontent.com/59059267/112352805-0fd6fd00-8d06-11eb-9627-5a4708d706de.png). I can't figure it out why this happen. Thank you for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1759:2194,usability,help,help,2194,"it.TSNE，my test code is below. ```. #!/usr/bin/env python3. # -*- coding: utf-8 -*-. """""". from sklearn import datasets. import scanpy as sc. import numpy as np. import random. import matplotlib.pyplot as plt. from sklearn.manifold import TSNE. np.random.seed(1). random.seed(1). iris = datasets.load_iris(). X = iris.data. label=iris.target. adata=sc.AnnData(X). adata.obs[""celltype""]=label.astype(int).astype(str). sc.tl.tsne(adata,random_state=0,use_fast_tsne=False). axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False). sc_tsne=adata.obsm[""X_tsne""]. #print(ax). print(np.min(sc_tsne[:,0])). print(np.max(sc_tsne[:,0])). print(np.min(sc_tsne[:,1])). print(np.max(sc_tsne[:,1])). print(""====================""). # import pickle. # #with open(). # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'). # tsne2=pickle.load(file). target=label. tsne = TSNE(learning_rate=1000,init='random', random_state=0). X_transformed = tsne.fit_transform(X). fig=plt.figure(). for label in np.unique(target):. plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label). plt.legend(loc=""upper left""). plt.show(). #print(X_transformed). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). print(""==================""). params_sklearn = dict(. perplexity=30,. random_state=0,. verbose=False,. early_exaggeration=12,. learning_rate=1000,. ). from sklearn.manifold import TSNE. # unfortunately, sklearn does not allow to set a minimum number. # of iterations for barnes-hut tSNE. tsne3 = TSNE(**params_sklearn). X_transformed=tsne3.fit_transform(X). print(np.min(X_transformed[:,0])). print(np.max(X_transformed[:,0])). print(np.min(X_transformed[:,1])). print(np.max(X_transformed[:,1])). ```. I get the result. ![image](https://user-images.githubusercontent.com/59059267/112352805-0fd6fd00-8d06-11eb-9627-5a4708d706de.png). I can't figure it out why this happen. Thank you for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1760:123,modifiability,paramet,parameters,123,"correlation between two adata objects; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. How to use sc.pl.correlation_matrix to compute correlation between two different anndata? I want to compare urine""data1"" with biopsy cells""data2"". ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1760
https://github.com/scverse/scanpy/issues/1760:400,modifiability,pac,package,400,"correlation between two adata objects; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. How to use sc.pl.correlation_matrix to compute correlation between two different anndata? I want to compare urine""data1"" with biopsy cells""data2"". ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1760
https://github.com/scverse/scanpy/issues/1760:205,testability,simpl,simple,205,"correlation between two adata objects; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. How to use sc.pl.correlation_matrix to compute correlation between two different anndata? I want to compare urine""data1"" with biopsy cells""data2"". ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1760
https://github.com/scverse/scanpy/issues/1760:197,usability,tool,tool,197,"correlation between two adata objects; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. How to use sc.pl.correlation_matrix to compute correlation between two different anndata? I want to compare urine""data1"" with biopsy cells""data2"". ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1760
https://github.com/scverse/scanpy/issues/1760:205,usability,simpl,simple,205,"correlation between two adata objects; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. How to use sc.pl.correlation_matrix to compute correlation between two different anndata? I want to compare urine""data1"" with biopsy cells""data2"". ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1760
https://github.com/scverse/scanpy/issues/1760:221,usability,tool,tool,221,"correlation between two adata objects; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. How to use sc.pl.correlation_matrix to compute correlation between two different anndata? I want to compare urine""data1"" with biopsy cells""data2"". ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1760
https://github.com/scverse/scanpy/issues/1760:269,usability,tool,tools,269,"correlation between two adata objects; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. How to use sc.pl.correlation_matrix to compute correlation between two different anndata? I want to compare urine""data1"" with biopsy cells""data2"". ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1760
https://github.com/scverse/scanpy/issues/1760:369,usability,tool,tools,369,"correlation between two adata objects; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. How to use sc.pl.correlation_matrix to compute correlation between two different anndata? I want to compare urine""data1"" with biopsy cells""data2"". ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1760
https://github.com/scverse/scanpy/issues/1761:124,availability,down,downloads,124,"read_mtx obs and var mixed; Hi,. I was reading some mtx file from here: . https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-4/downloads. `adata = sc.read_mtx(""./data/mtx/E-HCAD-4.aggregated_filtered_counts.mtx"")`. `AnnData object with n_obs × n_vars = 25052 × 606606. ` . `sc.__version__`. `'1.7.1'`. when loading the mtx file the obs and vars are mixed up. . That happened with another mtx file before. I was wondering if already a fix exists to specify the obs and vars (or switch them if necessary). . Thanks . </details>. ![image](https://user-images.githubusercontent.com/7283790/112545551-a19f4280-8db8-11eb-8e0d-7d56ee0443b5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1761
https://github.com/scverse/scanpy/issues/1761:304,energy efficiency,load,loading,304,"read_mtx obs and var mixed; Hi,. I was reading some mtx file from here: . https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-4/downloads. `adata = sc.read_mtx(""./data/mtx/E-HCAD-4.aggregated_filtered_counts.mtx"")`. `AnnData object with n_obs × n_vars = 25052 × 606606. ` . `sc.__version__`. `'1.7.1'`. when loading the mtx file the obs and vars are mixed up. . That happened with another mtx file before. I was wondering if already a fix exists to specify the obs and vars (or switch them if necessary). . Thanks . </details>. ![image](https://user-images.githubusercontent.com/7283790/112545551-a19f4280-8db8-11eb-8e0d-7d56ee0443b5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1761
https://github.com/scverse/scanpy/issues/1761:445,interoperability,specif,specify,445,"read_mtx obs and var mixed; Hi,. I was reading some mtx file from here: . https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-4/downloads. `adata = sc.read_mtx(""./data/mtx/E-HCAD-4.aggregated_filtered_counts.mtx"")`. `AnnData object with n_obs × n_vars = 25052 × 606606. ` . `sc.__version__`. `'1.7.1'`. when loading the mtx file the obs and vars are mixed up. . That happened with another mtx file before. I was wondering if already a fix exists to specify the obs and vars (or switch them if necessary). . Thanks . </details>. ![image](https://user-images.githubusercontent.com/7283790/112545551-a19f4280-8db8-11eb-8e0d-7d56ee0443b5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1761
https://github.com/scverse/scanpy/issues/1761:304,performance,load,loading,304,"read_mtx obs and var mixed; Hi,. I was reading some mtx file from here: . https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-4/downloads. `adata = sc.read_mtx(""./data/mtx/E-HCAD-4.aggregated_filtered_counts.mtx"")`. `AnnData object with n_obs × n_vars = 25052 × 606606. ` . `sc.__version__`. `'1.7.1'`. when loading the mtx file the obs and vars are mixed up. . That happened with another mtx file before. I was wondering if already a fix exists to specify the obs and vars (or switch them if necessary). . Thanks . </details>. ![image](https://user-images.githubusercontent.com/7283790/112545551-a19f4280-8db8-11eb-8e0d-7d56ee0443b5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1761
https://github.com/scverse/scanpy/issues/1761:541,usability,user,user-images,541,"read_mtx obs and var mixed; Hi,. I was reading some mtx file from here: . https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-4/downloads. `adata = sc.read_mtx(""./data/mtx/E-HCAD-4.aggregated_filtered_counts.mtx"")`. `AnnData object with n_obs × n_vars = 25052 × 606606. ` . `sc.__version__`. `'1.7.1'`. when loading the mtx file the obs and vars are mixed up. . That happened with another mtx file before. I was wondering if already a fix exists to specify the obs and vars (or switch them if necessary). . Thanks . </details>. ![image](https://user-images.githubusercontent.com/7283790/112545551-a19f4280-8db8-11eb-8e0d-7d56ee0443b5.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1761
https://github.com/scverse/scanpy/issues/1762:37,deployability,contain,contain,37,sc.datasets.pbmc68k_reduced() didn't contain all the genes in .raw; I'm using Scanpy 1.5.0. sc.datasets.pbmc68k_reduced() gave me a really small object. I was trying to retrieve the full transcriptome by using .raw but it only stored 700 genes. Is there any chance for Scanpy to add the raw data back in that object?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1762
https://github.com/scverse/scanpy/pull/1763:323,performance,time,time,323,"Making var_group_rotation work when swap_axes is True; It'd be great if `var_group_rotation` option works also when `swap_axes` is True (right now rotation 270 is hard-coded). I tried to modify the code but I am not sure how to solve it properly (e.g. if labels are too long etc). Please have a look whenever you guys have time and feel free to modify the PR. ```python. import scanpy as sc. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.tl.rank_genes_groups(ad, 'paul15_clusters'). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). ```. Output:. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549850-d4374400-8d94-11eb-8a43-c975b70bc4fd.png"">. <img width=""437"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549869-d9948e80-8d94-11eb-91d1-695f50c53aba.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1763
https://github.com/scverse/scanpy/pull/1763:147,security,rotat,rotation,147,"Making var_group_rotation work when swap_axes is True; It'd be great if `var_group_rotation` option works also when `swap_axes` is True (right now rotation 270 is hard-coded). I tried to modify the code but I am not sure how to solve it properly (e.g. if labels are too long etc). Please have a look whenever you guys have time and feel free to modify the PR. ```python. import scanpy as sc. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.tl.rank_genes_groups(ad, 'paul15_clusters'). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). ```. Output:. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549850-d4374400-8d94-11eb-8a43-c975b70bc4fd.png"">. <img width=""437"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549869-d9948e80-8d94-11eb-91d1-695f50c53aba.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1763
https://github.com/scverse/scanpy/pull/1763:187,security,modif,modify,187,"Making var_group_rotation work when swap_axes is True; It'd be great if `var_group_rotation` option works also when `swap_axes` is True (right now rotation 270 is hard-coded). I tried to modify the code but I am not sure how to solve it properly (e.g. if labels are too long etc). Please have a look whenever you guys have time and feel free to modify the PR. ```python. import scanpy as sc. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.tl.rank_genes_groups(ad, 'paul15_clusters'). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). ```. Output:. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549850-d4374400-8d94-11eb-8a43-c975b70bc4fd.png"">. <img width=""437"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549869-d9948e80-8d94-11eb-91d1-695f50c53aba.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1763
https://github.com/scverse/scanpy/pull/1763:345,security,modif,modify,345,"Making var_group_rotation work when swap_axes is True; It'd be great if `var_group_rotation` option works also when `swap_axes` is True (right now rotation 270 is hard-coded). I tried to modify the code but I am not sure how to solve it properly (e.g. if labels are too long etc). Please have a look whenever you guys have time and feel free to modify the PR. ```python. import scanpy as sc. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.tl.rank_genes_groups(ad, 'paul15_clusters'). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). ```. Output:. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549850-d4374400-8d94-11eb-8a43-c975b70bc4fd.png"">. <img width=""437"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549869-d9948e80-8d94-11eb-91d1-695f50c53aba.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1763
https://github.com/scverse/scanpy/pull/1763:1058,usability,user,user-images,1058,"Making var_group_rotation work when swap_axes is True; It'd be great if `var_group_rotation` option works also when `swap_axes` is True (right now rotation 270 is hard-coded). I tried to modify the code but I am not sure how to solve it properly (e.g. if labels are too long etc). Please have a look whenever you guys have time and feel free to modify the PR. ```python. import scanpy as sc. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.tl.rank_genes_groups(ad, 'paul15_clusters'). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). ```. Output:. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549850-d4374400-8d94-11eb-8a43-c975b70bc4fd.png"">. <img width=""437"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549869-d9948e80-8d94-11eb-91d1-695f50c53aba.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1763
https://github.com/scverse/scanpy/pull/1763:1196,usability,user,user-images,1196,"Making var_group_rotation work when swap_axes is True; It'd be great if `var_group_rotation` option works also when `swap_axes` is True (right now rotation 270 is hard-coded). I tried to modify the code but I am not sure how to solve it properly (e.g. if labels are too long etc). Please have a look whenever you guys have time and feel free to modify the PR. ```python. import scanpy as sc. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.tl.rank_genes_groups(ad, 'paul15_clusters'). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=0, groups=['1Ery', '2Ery', '3Ery']). sc.pl.rank_genes_groups_dotplot(ad, n_genes=3, dendrogram=False, swap_axes=True, var_group_rotation=90, groups=['1Ery', '2Ery', '3Ery']). ```. Output:. <img width=""423"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549850-d4374400-8d94-11eb-8a43-c975b70bc4fd.png"">. <img width=""437"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/112549869-d9948e80-8d94-11eb-91d1-695f50c53aba.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1763
https://github.com/scverse/scanpy/issues/1764:85,performance,perform,performance,85,"small datasets; Hi,. Scanpy are designed to handle big datasets, while how about the performance on small datasets ? (such as as few as 50 cells from early embryo)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1764
https://github.com/scverse/scanpy/issues/1764:85,usability,perform,performance,85,"small datasets; Hi,. Scanpy are designed to handle big datasets, while how about the performance on small datasets ? (such as as few as 50 cells from early embryo)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1764
https://github.com/scverse/scanpy/pull/1765:190,energy efficiency,measur,measure,190,"highly deviant genes implementation; An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:. - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house. - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/pull/1765:361,modifiability,paramet,parameters,361,"highly deviant genes implementation; An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:. - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house. - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/pull/1765:520,modifiability,variab,variable,520,"highly deviant genes implementation; An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:. - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house. - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/pull/1765:227,safety,test,testing,227,"highly deviant genes implementation; An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:. - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house. - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/pull/1765:562,safety,test,tests,562,"highly deviant genes implementation; An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:. - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house. - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/pull/1765:78,security,ident,identification,78,"highly deviant genes implementation; An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:. - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house. - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/pull/1765:214,security,sign,significance,214,"highly deviant genes implementation; An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:. - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house. - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/pull/1765:227,testability,test,testing,227,"highly deviant genes implementation; An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:. - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house. - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/pull/1765:562,testability,test,tests,562,"highly deviant genes implementation; An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:. - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house. - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/issues/1766:464,availability,error,error,464,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:772,deployability,version,version,772,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:772,integrability,version,version,772,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:403,modifiability,paramet,parameters,403,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:772,modifiability,version,version,772,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:464,performance,error,error,464,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:464,safety,error,error,464,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:348,security,modif,modify,348,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:84,usability,tool,tool,84,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:246,usability,user,user-images,246,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:464,usability,error,error,464,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:872,usability,learn,learn,872,"The axis-y limits of sc.pl.rank_genes_groups_violin(); Hi. Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:. ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png). Can I modify the y axis limits? I'm sorry I haven't find the parameters yet. And when I try to use `use_raw=False`, I got error:. `ValueError: Data must be 1-dimensional`. `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`. And my code:. `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`. and my version:. `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer! Best,. Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/pull/1767:244,safety,review,review,244,Added dorothea/progeny; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Added links to dorothea/progeny in the ecosystem documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1767
https://github.com/scverse/scanpy/pull/1767:244,testability,review,review,244,Added dorothea/progeny; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Added links to dorothea/progeny in the ecosystem documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1767
https://github.com/scverse/scanpy/pull/1767:95,usability,guid,guidelines,95,Added dorothea/progeny; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Added links to dorothea/progeny in the ecosystem documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1767
https://github.com/scverse/scanpy/pull/1767:126,usability,guid,guide,126,Added dorothea/progeny; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Added links to dorothea/progeny in the ecosystem documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1767
https://github.com/scverse/scanpy/pull/1767:222,usability,workflow,workflow,222,Added dorothea/progeny; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Added links to dorothea/progeny in the ecosystem documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1767
https://github.com/scverse/scanpy/pull/1767:306,usability,document,documentation,306,Added dorothea/progeny; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Added links to dorothea/progeny in the ecosystem documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1767
https://github.com/scverse/scanpy/pull/1768:265,availability,sli,slim,265,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:270,availability,down,down,270,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:386,availability,error,error,386,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:34,deployability,version,version,34,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:115,deployability,version,version,115,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:202,deployability,artifact,artifact,202,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:408,deployability,version,version,408,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:540,deployability,version,version,540,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:34,integrability,version,version,34,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:115,integrability,version,version,115,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:408,integrability,version,version,408,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:540,integrability,version,version,540,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:34,modifiability,version,version,34,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:115,modifiability,version,version,115,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:408,modifiability,version,version,408,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:540,modifiability,version,version,540,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:386,performance,error,error,386,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:265,reliability,sli,slim,265,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:21,safety,test,test,21,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:386,safety,error,error,386,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:21,testability,test,test,21,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:386,usability,error,error,386,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:441,usability,user,user-images,441,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:573,usability,user,user-images,573,"Fix correlation plot test for new version of matplotlib; The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1769:34,deployability,version,version,34,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:113,deployability,Updat,Update,113,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:34,integrability,version,version,34,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:205,interoperability,conflict,conflict,205,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:34,modifiability,version,version,34,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:21,safety,test,test,21,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:113,safety,Updat,Update,113,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:120,safety,test,test,120,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:179,safety,test,test,179,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:113,security,Updat,Update,113,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:21,testability,test,test,21,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:120,testability,test,test,120,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:179,testability,test,test,179,Fix correlation plot test for new version of matplotlib (#1768); * Minor kwarg fixes in pl.correlation_matrix. * Update test correlation image. * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/issues/1770:581,availability,state,statement,581,"sc.pl.dotplot() does not use `smallest_dot` correctly; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I recently realized that the `smallest_dot` argument is no longer working correctly in `sc.pl.dotplot()`, and I think I've identified a small typo in the codebase. https://github.com/theislab/scanpy/blob/3fb1463a64e91a87854d19e06bcf4efedd0fad66/scanpy/plotting/_dotplot.py#L340. along with the `if` statement on the line above it. I believe these lines should read. ```python. if smallest_dot != self.smallest_dot:. self.smallest_dot = smallest_dot. ```. Using different values for `smallest_dot` produces the same output, and I think this is why. I will write a quick PR for this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1770
https://github.com/scverse/scanpy/issues/1770:176,deployability,version,version,176,"sc.pl.dotplot() does not use `smallest_dot` correctly; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I recently realized that the `smallest_dot` argument is no longer working correctly in `sc.pl.dotplot()`, and I think I've identified a small typo in the codebase. https://github.com/theislab/scanpy/blob/3fb1463a64e91a87854d19e06bcf4efedd0fad66/scanpy/plotting/_dotplot.py#L340. along with the `if` statement on the line above it. I believe these lines should read. ```python. if smallest_dot != self.smallest_dot:. self.smallest_dot = smallest_dot. ```. Using different values for `smallest_dot` produces the same output, and I think this is why. I will write a quick PR for this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1770
https://github.com/scverse/scanpy/issues/1770:176,integrability,version,version,176,"sc.pl.dotplot() does not use `smallest_dot` correctly; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I recently realized that the `smallest_dot` argument is no longer working correctly in `sc.pl.dotplot()`, and I think I've identified a small typo in the codebase. https://github.com/theislab/scanpy/blob/3fb1463a64e91a87854d19e06bcf4efedd0fad66/scanpy/plotting/_dotplot.py#L340. along with the `if` statement on the line above it. I believe these lines should read. ```python. if smallest_dot != self.smallest_dot:. self.smallest_dot = smallest_dot. ```. Using different values for `smallest_dot` produces the same output, and I think this is why. I will write a quick PR for this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1770
https://github.com/scverse/scanpy/issues/1770:581,integrability,state,statement,581,"sc.pl.dotplot() does not use `smallest_dot` correctly; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I recently realized that the `smallest_dot` argument is no longer working correctly in `sc.pl.dotplot()`, and I think I've identified a small typo in the codebase. https://github.com/theislab/scanpy/blob/3fb1463a64e91a87854d19e06bcf4efedd0fad66/scanpy/plotting/_dotplot.py#L340. along with the `if` statement on the line above it. I believe these lines should read. ```python. if smallest_dot != self.smallest_dot:. self.smallest_dot = smallest_dot. ```. Using different values for `smallest_dot` produces the same output, and I think this is why. I will write a quick PR for this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1770
https://github.com/scverse/scanpy/issues/1770:176,modifiability,version,version,176,"sc.pl.dotplot() does not use `smallest_dot` correctly; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I recently realized that the `smallest_dot` argument is no longer working correctly in `sc.pl.dotplot()`, and I think I've identified a small typo in the codebase. https://github.com/theislab/scanpy/blob/3fb1463a64e91a87854d19e06bcf4efedd0fad66/scanpy/plotting/_dotplot.py#L340. along with the `if` statement on the line above it. I believe these lines should read. ```python. if smallest_dot != self.smallest_dot:. self.smallest_dot = smallest_dot. ```. Using different values for `smallest_dot` produces the same output, and I think this is why. I will write a quick PR for this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1770
https://github.com/scverse/scanpy/issues/1770:16,reliability,doe,does,16,"sc.pl.dotplot() does not use `smallest_dot` correctly; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I recently realized that the `smallest_dot` argument is no longer working correctly in `sc.pl.dotplot()`, and I think I've identified a small typo in the codebase. https://github.com/theislab/scanpy/blob/3fb1463a64e91a87854d19e06bcf4efedd0fad66/scanpy/plotting/_dotplot.py#L340. along with the `if` statement on the line above it. I believe these lines should read. ```python. if smallest_dot != self.smallest_dot:. self.smallest_dot = smallest_dot. ```. Using different values for `smallest_dot` produces the same output, and I think this is why. I will write a quick PR for this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1770
https://github.com/scverse/scanpy/issues/1770:405,security,ident,identified,405,"sc.pl.dotplot() does not use `smallest_dot` correctly; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I recently realized that the `smallest_dot` argument is no longer working correctly in `sc.pl.dotplot()`, and I think I've identified a small typo in the codebase. https://github.com/theislab/scanpy/blob/3fb1463a64e91a87854d19e06bcf4efedd0fad66/scanpy/plotting/_dotplot.py#L340. along with the `if` statement on the line above it. I believe these lines should read. ```python. if smallest_dot != self.smallest_dot:. self.smallest_dot = smallest_dot. ```. Using different values for `smallest_dot` produces the same output, and I think this is why. I will write a quick PR for this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1770
https://github.com/scverse/scanpy/issues/1770:136,usability,confirm,confirmed,136,"sc.pl.dotplot() does not use `smallest_dot` correctly; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I recently realized that the `smallest_dot` argument is no longer working correctly in `sc.pl.dotplot()`, and I think I've identified a small typo in the codebase. https://github.com/theislab/scanpy/blob/3fb1463a64e91a87854d19e06bcf4efedd0fad66/scanpy/plotting/_dotplot.py#L340. along with the `if` statement on the line above it. I believe these lines should read. ```python. if smallest_dot != self.smallest_dot:. self.smallest_dot = smallest_dot. ```. Using different values for `smallest_dot` produces the same output, and I think this is why. I will write a quick PR for this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1770
https://github.com/scverse/scanpy/issues/1770:219,usability,confirm,confirmed,219,"sc.pl.dotplot() does not use `smallest_dot` correctly; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I recently realized that the `smallest_dot` argument is no longer working correctly in `sc.pl.dotplot()`, and I think I've identified a small typo in the codebase. https://github.com/theislab/scanpy/blob/3fb1463a64e91a87854d19e06bcf4efedd0fad66/scanpy/plotting/_dotplot.py#L340. along with the `if` statement on the line above it. I believe these lines should read. ```python. if smallest_dot != self.smallest_dot:. self.smallest_dot = smallest_dot. ```. Using different values for `smallest_dot` produces the same output, and I think this is why. I will write a quick PR for this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1770
https://github.com/scverse/scanpy/pull/1772:151,deployability,version,version,151,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:500,deployability,fail,failed-diff,500,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:639,deployability,fail,failed,639,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1381,deployability,Updat,Update,1381,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1866,deployability,fail,failing,1866,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1931,deployability,fail,fails,1931,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:2145,deployability,api,api,2145,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:207,energy efficiency,Current,Currently,207,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:151,integrability,version,version,151,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:2145,integrability,api,api,2145,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1048,interoperability,Share,Shared,1048," reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:2145,interoperability,api,api,2145,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:151,modifiability,version,version,151,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:2227,performance,time,time,2227,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:500,reliability,fail,failed-diff,500,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:639,reliability,fail,failed,639,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1866,reliability,fail,failing,1866,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1931,reliability,fail,fails,1931,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:20,safety,test,test,20,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:82,safety,test,tests,82,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:101,safety,test,test,101,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:285,safety,test,tests,285,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:301,safety,Test,Tests,301,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:384,safety,test,tests,384,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:646,safety,test,test,646,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:958,safety,test,tests,958,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:988,safety,test,tests,988,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1381,safety,Updat,Update,1381,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1389,safety,Test,Tested,1389,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1773,safety,test,test,1773,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1992,safety,test,tests,1992,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:2061,safety,test,test,2061,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:2237,safety,test,test,2237,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1381,security,Updat,Update,1381,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:20,testability,test,test,20,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:82,testability,test,tests,82,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:101,testability,test,test,101,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:285,testability,test,tests,285,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:301,testability,Test,Tests,301,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:384,testability,test,tests,384,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:646,testability,test,test,646,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:958,testability,test,tests,958,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:988,testability,test,tests,988,"Reorganize plotting test outputs; We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1389,testability,Test,Tested,1389,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1773,testability,test,test,1773,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1969,testability,simpl,simple,1969,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1992,testability,test,tests,1992,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:2061,testability,test,test,2061,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:2237,testability,test,test,2237,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1125,usability,user,user-images,1125," plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Deci",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1495,usability,user,user-images,1495,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1969,usability,simpl,simple,1969,"ide a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```. scanpy/tests/_images/pca.png. scanpy/tests/figures/pca.png. ```. which one is the reference? ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`. * Naming conventions are obvious. * Per test, each file has a unique name. ## TODO. - [x] Dev docs. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1773:5,deployability,fail,failing,5,Test failing plot; Branch of #1772 to check that CI reporting is made better. Makes some reference based plotting tests fail.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773
https://github.com/scverse/scanpy/pull/1773:120,deployability,fail,fail,120,Test failing plot; Branch of #1772 to check that CI reporting is made better. Makes some reference based plotting tests fail.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773
https://github.com/scverse/scanpy/pull/1773:5,reliability,fail,failing,5,Test failing plot; Branch of #1772 to check that CI reporting is made better. Makes some reference based plotting tests fail.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773
https://github.com/scverse/scanpy/pull/1773:120,reliability,fail,fail,120,Test failing plot; Branch of #1772 to check that CI reporting is made better. Makes some reference based plotting tests fail.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773
https://github.com/scverse/scanpy/pull/1773:0,safety,Test,Test,0,Test failing plot; Branch of #1772 to check that CI reporting is made better. Makes some reference based plotting tests fail.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773
https://github.com/scverse/scanpy/pull/1773:114,safety,test,tests,114,Test failing plot; Branch of #1772 to check that CI reporting is made better. Makes some reference based plotting tests fail.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773
https://github.com/scverse/scanpy/pull/1773:0,testability,Test,Test,0,Test failing plot; Branch of #1772 to check that CI reporting is made better. Makes some reference based plotting tests fail.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773
https://github.com/scverse/scanpy/pull/1773:114,testability,test,tests,114,Test failing plot; Branch of #1772 to check that CI reporting is made better. Makes some reference based plotting tests fail.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773
https://github.com/scverse/scanpy/pull/1775:208,deployability,API,API,208,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:559,deployability,build,building,559,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:110,energy efficiency,model,model,110,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:208,integrability,API,API,208,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:326,integrability,wrap,wrapper,326,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:208,interoperability,API,API,208,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:256,interoperability,compatib,compatible,256,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:326,interoperability,wrapper,wrapper,326,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:350,safety,test,test,350,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:359,safety,test,tests,359,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:86,security,ident,identity,86,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:110,security,model,model,110,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:317,testability,simpl,simply,317,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:350,testability,test,test,350,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:359,testability,test,tests,359,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:25,usability,tool,tool,25,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:164,usability,tool,tool,164,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:317,usability,simpl,simply,317,"Add scNym as an external tool `sce.tl.scnym`; Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper. I also added a test in `tests/external/test_scnym.py` that passes. Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see. Thanks for building a great ecosystem! Best,. Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/issues/1776:23,deployability,Updat,Update,23,"PEP 621/ 631 Metadata; Update `pyproject.toml` to use [PEP-621](https://www.python.org/dev/peps/pep-0621/) and [PEP-631](https://www.python.org/dev/peps/pep-0631/) metadata. Basically, simplify by removing most of the `tool.flit` stuff. @flying-sheep, would you like to do this/ do you foresee any blockers?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1776
https://github.com/scverse/scanpy/issues/1776:23,safety,Updat,Update,23,"PEP 621/ 631 Metadata; Update `pyproject.toml` to use [PEP-621](https://www.python.org/dev/peps/pep-0621/) and [PEP-631](https://www.python.org/dev/peps/pep-0631/) metadata. Basically, simplify by removing most of the `tool.flit` stuff. @flying-sheep, would you like to do this/ do you foresee any blockers?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1776
https://github.com/scverse/scanpy/issues/1776:23,security,Updat,Update,23,"PEP 621/ 631 Metadata; Update `pyproject.toml` to use [PEP-621](https://www.python.org/dev/peps/pep-0621/) and [PEP-631](https://www.python.org/dev/peps/pep-0631/) metadata. Basically, simplify by removing most of the `tool.flit` stuff. @flying-sheep, would you like to do this/ do you foresee any blockers?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1776
https://github.com/scverse/scanpy/issues/1776:185,testability,simpl,simplify,185,"PEP 621/ 631 Metadata; Update `pyproject.toml` to use [PEP-621](https://www.python.org/dev/peps/pep-0621/) and [PEP-631](https://www.python.org/dev/peps/pep-0631/) metadata. Basically, simplify by removing most of the `tool.flit` stuff. @flying-sheep, would you like to do this/ do you foresee any blockers?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1776
https://github.com/scverse/scanpy/issues/1776:185,usability,simpl,simplify,185,"PEP 621/ 631 Metadata; Update `pyproject.toml` to use [PEP-621](https://www.python.org/dev/peps/pep-0621/) and [PEP-631](https://www.python.org/dev/peps/pep-0631/) metadata. Basically, simplify by removing most of the `tool.flit` stuff. @flying-sheep, would you like to do this/ do you foresee any blockers?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1776
https://github.com/scverse/scanpy/issues/1776:219,usability,tool,tool,219,"PEP 621/ 631 Metadata; Update `pyproject.toml` to use [PEP-621](https://www.python.org/dev/peps/pep-0621/) and [PEP-631](https://www.python.org/dev/peps/pep-0631/) metadata. Basically, simplify by removing most of the `tool.flit` stuff. @flying-sheep, would you like to do this/ do you foresee any blockers?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1776
https://github.com/scverse/scanpy/issues/1777:298,availability,cluster,clusters,298,"What does Y-axis signify in this differential gene expression plot?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. Hello,. I had to do differential gene expression for the clusters in my data, and I got the genes. However, I am not able to get what the numbers in the y-axis on right hand side signify? Can you please confirm the same. I will be grateful for your help. I have attached the image screenshot. ![image](https://user-images.githubusercontent.com/60312173/113270478-20cfd180-92f7-11eb-84ac-6d3d6f32856a.png). Thank you. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1777
https://github.com/scverse/scanpy/issues/1777:298,deployability,cluster,clusters,298,"What does Y-axis signify in this differential gene expression plot?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. Hello,. I had to do differential gene expression for the clusters in my data, and I got the genes. However, I am not able to get what the numbers in the y-axis on right hand side signify? Can you please confirm the same. I will be grateful for your help. I have attached the image screenshot. ![image](https://user-images.githubusercontent.com/60312173/113270478-20cfd180-92f7-11eb-84ac-6d3d6f32856a.png). Thank you. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1777
https://github.com/scverse/scanpy/issues/1777:191,modifiability,design decis,design decisions,191,"What does Y-axis signify in this differential gene expression plot?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. Hello,. I had to do differential gene expression for the clusters in my data, and I got the genes. However, I am not able to get what the numbers in the y-axis on right hand side signify? Can you please confirm the same. I will be grateful for your help. I have attached the image screenshot. ![image](https://user-images.githubusercontent.com/60312173/113270478-20cfd180-92f7-11eb-84ac-6d3d6f32856a.png). Thank you. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1777
https://github.com/scverse/scanpy/issues/1777:5,reliability,doe,does,5,"What does Y-axis signify in this differential gene expression plot?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. Hello,. I had to do differential gene expression for the clusters in my data, and I got the genes. However, I am not able to get what the numbers in the y-axis on right hand side signify? Can you please confirm the same. I will be grateful for your help. I have attached the image screenshot. ![image](https://user-images.githubusercontent.com/60312173/113270478-20cfd180-92f7-11eb-84ac-6d3d6f32856a.png). Thank you. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1777
https://github.com/scverse/scanpy/issues/1777:17,security,sign,signify,17,"What does Y-axis signify in this differential gene expression plot?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. Hello,. I had to do differential gene expression for the clusters in my data, and I got the genes. However, I am not able to get what the numbers in the y-axis on right hand side signify? Can you please confirm the same. I will be grateful for your help. I have attached the image screenshot. ![image](https://user-images.githubusercontent.com/60312173/113270478-20cfd180-92f7-11eb-84ac-6d3d6f32856a.png). Thank you. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1777
https://github.com/scverse/scanpy/issues/1777:420,security,sign,signify,420,"What does Y-axis signify in this differential gene expression plot?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. Hello,. I had to do differential gene expression for the clusters in my data, and I got the genes. However, I am not able to get what the numbers in the y-axis on right hand side signify? Can you please confirm the same. I will be grateful for your help. I have attached the image screenshot. ![image](https://user-images.githubusercontent.com/60312173/113270478-20cfd180-92f7-11eb-84ac-6d3d6f32856a.png). Thank you. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1777
https://github.com/scverse/scanpy/issues/1777:89,usability,help,help,89,"What does Y-axis signify in this differential gene expression plot?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. Hello,. I had to do differential gene expression for the clusters in my data, and I got the genes. However, I am not able to get what the numbers in the y-axis on right hand side signify? Can you please confirm the same. I will be grateful for your help. I have attached the image screenshot. ![image](https://user-images.githubusercontent.com/60312173/113270478-20cfd180-92f7-11eb-84ac-6d3d6f32856a.png). Thank you. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1777
https://github.com/scverse/scanpy/issues/1777:444,usability,confirm,confirm,444,"What does Y-axis signify in this differential gene expression plot?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. Hello,. I had to do differential gene expression for the clusters in my data, and I got the genes. However, I am not able to get what the numbers in the y-axis on right hand side signify? Can you please confirm the same. I will be grateful for your help. I have attached the image screenshot. ![image](https://user-images.githubusercontent.com/60312173/113270478-20cfd180-92f7-11eb-84ac-6d3d6f32856a.png). Thank you. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1777
https://github.com/scverse/scanpy/issues/1777:490,usability,help,help,490,"What does Y-axis signify in this differential gene expression plot?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. Hello,. I had to do differential gene expression for the clusters in my data, and I got the genes. However, I am not able to get what the numbers in the y-axis on right hand side signify? Can you please confirm the same. I will be grateful for your help. I have attached the image screenshot. ![image](https://user-images.githubusercontent.com/60312173/113270478-20cfd180-92f7-11eb-84ac-6d3d6f32856a.png). Thank you. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1777
https://github.com/scverse/scanpy/issues/1777:551,usability,user,user-images,551,"What does Y-axis signify in this differential gene expression plot?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. Hello,. I had to do differential gene expression for the clusters in my data, and I got the genes. However, I am not able to get what the numbers in the y-axis on right hand side signify? Can you please confirm the same. I will be grateful for your help. I have attached the image screenshot. ![image](https://user-images.githubusercontent.com/60312173/113270478-20cfd180-92f7-11eb-84ac-6d3d6f32856a.png). Thank you. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1777
https://github.com/scverse/scanpy/issues/1778:123,availability,cluster,clusters,123,"What does y-axis in differential gene expression plot signify?; Hello,. I wanted to do differential gene expression on the clusters of my data. When I plotted them, I obtained the expressed genes. However, I wanted to know the significance of the number in y-axis on the right hand side. . I am attaching the screenshot of the image. . ![image](https://user-images.githubusercontent.com/58388074/113273888-b4ef6800-92fa-11eb-9509-4f4a4f6f3770.png). Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1778
https://github.com/scverse/scanpy/issues/1778:123,deployability,cluster,clusters,123,"What does y-axis in differential gene expression plot signify?; Hello,. I wanted to do differential gene expression on the clusters of my data. When I plotted them, I obtained the expressed genes. However, I wanted to know the significance of the number in y-axis on the right hand side. . I am attaching the screenshot of the image. . ![image](https://user-images.githubusercontent.com/58388074/113273888-b4ef6800-92fa-11eb-9509-4f4a4f6f3770.png). Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1778
https://github.com/scverse/scanpy/issues/1778:5,reliability,doe,does,5,"What does y-axis in differential gene expression plot signify?; Hello,. I wanted to do differential gene expression on the clusters of my data. When I plotted them, I obtained the expressed genes. However, I wanted to know the significance of the number in y-axis on the right hand side. . I am attaching the screenshot of the image. . ![image](https://user-images.githubusercontent.com/58388074/113273888-b4ef6800-92fa-11eb-9509-4f4a4f6f3770.png). Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1778
https://github.com/scverse/scanpy/issues/1778:54,security,sign,signify,54,"What does y-axis in differential gene expression plot signify?; Hello,. I wanted to do differential gene expression on the clusters of my data. When I plotted them, I obtained the expressed genes. However, I wanted to know the significance of the number in y-axis on the right hand side. . I am attaching the screenshot of the image. . ![image](https://user-images.githubusercontent.com/58388074/113273888-b4ef6800-92fa-11eb-9509-4f4a4f6f3770.png). Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1778
https://github.com/scverse/scanpy/issues/1778:227,security,sign,significance,227,"What does y-axis in differential gene expression plot signify?; Hello,. I wanted to do differential gene expression on the clusters of my data. When I plotted them, I obtained the expressed genes. However, I wanted to know the significance of the number in y-axis on the right hand side. . I am attaching the screenshot of the image. . ![image](https://user-images.githubusercontent.com/58388074/113273888-b4ef6800-92fa-11eb-9509-4f4a4f6f3770.png). Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1778
https://github.com/scverse/scanpy/issues/1778:353,usability,user,user-images,353,"What does y-axis in differential gene expression plot signify?; Hello,. I wanted to do differential gene expression on the clusters of my data. When I plotted them, I obtained the expressed genes. However, I wanted to know the significance of the number in y-axis on the right hand side. . I am attaching the screenshot of the image. . ![image](https://user-images.githubusercontent.com/58388074/113273888-b4ef6800-92fa-11eb-9509-4f4a4f6f3770.png). Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1778
https://github.com/scverse/scanpy/issues/1779:36,availability,stead,stead,36,"Stacked_violin color map to mean in stead of median; <!-- What kind of feature would you like to request? -->. - [X ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Be default, median values are mapped to the violin color using a color map. Is it possible to map the mean to the color? Or just provide a color matrix for each position for StackedViolin as a public function? Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1779
https://github.com/scverse/scanpy/issues/1779:412,deployability,Stack,StackedViolin,412,"Stacked_violin color map to mean in stead of median; <!-- What kind of feature would you like to request? -->. - [X ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Be default, median values are mapped to the violin color using a color map. Is it possible to map the mean to the color? Or just provide a color matrix for each position for StackedViolin as a public function? Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1779
https://github.com/scverse/scanpy/issues/1779:431,integrability,pub,public,431,"Stacked_violin color map to mean in stead of median; <!-- What kind of feature would you like to request? -->. - [X ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Be default, median values are mapped to the violin color using a color map. Is it possible to map the mean to the color? Or just provide a color matrix for each position for StackedViolin as a public function? Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1779
https://github.com/scverse/scanpy/issues/1779:138,modifiability,paramet,parameters,138,"Stacked_violin color map to mean in stead of median; <!-- What kind of feature would you like to request? -->. - [X ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Be default, median values are mapped to the violin color using a color map. Is it possible to map the mean to the color? Or just provide a color matrix for each position for StackedViolin as a public function? Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1779
https://github.com/scverse/scanpy/pull/1780:205,availability,operat,operates,205,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:480,availability,cluster,clusters,480,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:489,availability,down,downstream,489,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:32,deployability,Integr,Integrated,32,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:156,deployability,API,API,156,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:480,deployability,cluster,clusters,480,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:586,deployability,instal,installed,586,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:637,deployability,integr,integrate,637,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:666,deployability,API,API,666,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:12,integrability,Compon,Component,12,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:32,integrability,Integr,Integrated,32,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:52,integrability,Compon,Component,52,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:156,integrability,API,API,156,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:512,integrability,repositor,repository,512,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:637,integrability,integr,integrate,637,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:666,integrability,API,API,666,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:12,interoperability,Compon,Component,12,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:32,interoperability,Integr,Integrated,32,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:52,interoperability,Compon,Component,52,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:156,interoperability,API,API,156,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:512,interoperability,repositor,repository,512,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:637,interoperability,integr,integrate,637,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:666,interoperability,API,API,666,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:12,modifiability,Compon,Component,12,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:32,modifiability,Integr,Integrated,32,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:52,modifiability,Compon,Component,52,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:296,modifiability,layer,layer,296,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:637,modifiability,integr,integrate,637,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:96,performance,content,content,96,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:32,reliability,Integr,Integrated,32,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:637,reliability,integr,integrate,637,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:32,security,Integr,Integrated,32,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:637,security,integr,integrate,637,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:32,testability,Integr,Integrated,32,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:637,testability,integr,integrate,637,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:171,usability,document,documentation,171,"Add Shannon Component Analysis; Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/issues/1781:40,deployability,modul,module,40,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:183,deployability,version,version,183,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:568,deployability,modul,module,568,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:907,deployability,Modul,ModuleNotFoundError,907,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:931,deployability,modul,module,931,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1133,deployability,modul,module,1133,"I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1357,deployability,instal,install,1357,"2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1427,deployability,Version,Versions,1427," information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1448,deployability,log,logging,1448,"o reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2361,deployability,log,logical,2361,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2415,deployability,updat,updated,2415,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:5,energy efficiency,model,models,5,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:493,energy efficiency,model,models,493,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:881,energy efficiency,model,models,881,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:950,energy efficiency,model,models,950,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2369,energy efficiency,CPU,CPU,2369,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2373,energy efficiency,core,cores,2373,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:183,integrability,version,version,183,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:736,integrability,batch,batch,736,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1196,integrability,batch,batch,1196,"y. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. ya",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1427,integrability,Version,Versions,1427," information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:40,modifiability,modul,module,40,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:183,modifiability,version,version,183,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:568,modifiability,modul,module,568,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:813,modifiability,pac,packages,813,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:907,modifiability,Modul,ModuleNotFoundError,907,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:931,modifiability,modul,module,931,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1133,modifiability,modul,module,1133,"I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1259,modifiability,pac,packages,1259,"er branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [G",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1370,modifiability,pac,package,1370,"nimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1427,modifiability,Version,Versions,1427," information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1934,modifiability,pac,packaging,1934,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:736,performance,batch,batch,736,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1196,performance,batch,batch,1196,"y. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. ya",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2369,performance,CPU,CPU,2369,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:479,reliability,doe,does,479,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:40,safety,modul,module,40,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:568,safety,modul,module,568,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:907,safety,Modul,ModuleNotFoundError,907,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:931,safety,modul,module,931,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:988,safety,except,exception,988,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1007,safety,except,exception,1007,"needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1133,safety,modul,module,1133,"I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1448,safety,log,logging,1448,"o reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2361,safety,log,logical,2361,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2415,safety,updat,updated,2415,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:5,security,model,models,5,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:493,security,model,models,493,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:517,security,access,access,517,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:881,security,model,models,881,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:950,security,model,models,950,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1448,security,log,logging,1448,"o reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2361,security,log,logical,2361,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2395,security,Session,Session,2395,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2415,security,updat,updated,2415,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1028,testability,Trace,Traceback,1028,"o scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1448,testability,log,logging,1448,"o reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2361,testability,log,logical,2361,"eproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.1. scipy 1.6.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]. Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17. 56 logical CPU cores, x86_64. -----. Session information updated at 2021-04-06 12:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:143,usability,confirm,confirmed,143,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:226,usability,confirm,confirmed,226,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:317,usability,guid,guide,317,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:372,usability,minim,minimal-bug-reports,372,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:580,usability,Minim,Minimal,580,"scvi.models needs to be changed to scvi.module in _scvi.py; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). ```. ```pytb. File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi. from scvi.models import VAE, LDVAE. ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>. sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'). File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi. raise ImportError(. ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions. >>> scanpy.logging.print_versions() . WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 3.2.1. igraph 0.9.1. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.36.0. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.20.2. packaging 20.9. pandas 1.2.3. pkg_resources NA. pyexpat NA. pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1782:365,availability,error,error,365,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1488,availability,error,error,1488," ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:222,deployability,version,version,222,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1588,deployability,modul,module,1588," zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `fla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2747,deployability,Version,Versions,2747,"vor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. rpy2 3.3.6. scanpy 1.6.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:433,energy efficiency,load,loaded,433,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2642,energy efficiency,load,loading,2642,"00, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2705,energy efficiency,load,loaded,2705,"> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2959,energy efficiency,cloud,cloudpickle,2959," n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. rpy2 3.3.6. scanpy 1.6.0. scipy 1.5.4. seaborn 0.11.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:222,integrability,version,version,222,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1982,integrability,sub,subset,1982,"550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. coloram",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2299,integrability,sub,subset,2299,"). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2747,integrability,Version,Versions,2747,"vor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. rpy2 3.3.6. scanpy 1.6.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:222,modifiability,version,version,222,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1588,modifiability,modul,module,1588," zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `fla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1812,modifiability,pac,packages,1812,"r[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1900,modifiability,layer,layer,1900,"""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2114,modifiability,layer,layer,2114,"ene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2120,modifiability,layer,layer,2120,"me', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2163,modifiability,pac,packages,2163,"= zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2262,modifiability,layer,layer,2262,"t_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2330,modifiability,layer,layers,2330,"nes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2337,modifiability,layer,layer,2337,"counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2347,modifiability,layer,layer,2347,"500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2747,modifiability,Version,Versions,2747,"vor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. rpy2 3.3.6. scanpy 1.6.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:3076,modifiability,deco,decorator,3076,"enes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. rpy2 3.3.6. scanpy 1.6.0. scipy 1.5.4. seaborn 0.11.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. wcwidth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:3481,modifiability,pac,packaging,3481,"riable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. rpy2 3.3.6. scanpy 1.6.0. scipy 1.5.4. seaborn 0.11.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:365,performance,error,error,365,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:433,performance,load,loaded,433,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1488,performance,error,error,1488," ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2642,performance,load,loading,2642,"00, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2705,performance,load,loaded,2705,"> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2928,performance,bottleneck,bottleneck,2928,"_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. rpy2 3.3.6. scanpy 1.6.0. scipy 1.5.4. seaborn 0.11.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:365,safety,error,error,365,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1488,safety,error,error,1488," ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1560,safety,input,input-,1560,"d""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.high",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1588,safety,modul,module,1588," zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `fla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1516,testability,Trace,Traceback,1516,"ython. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:182,usability,confirm,confirmed,182,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:365,usability,error,error,365,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:496,usability,Minim,Minimal,496,"After reading in .h5ad: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1488,usability,error,error,1488," ### Minimal code sample. ```python. zf_48 = anndata.read_h5ad(""data.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1560,usability,input,input-,1560,"d""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(). sc.pp.filter_cells(zf_48, min_genes=550). sc.pp.filter_genes(zf_48, min_cells=10). zf_48. #AnnData object with n_obs × n_vars = 887 × 13180. # obs: 'n_genes'. # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') . sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ```. Here is the error:. ```pytb. ValueError Traceback (most recent call last). <ipython-input-170-37cd37b7326e> in <module>. 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]. 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]. ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.high",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:3996,usability,tool,toolz,3996,"riable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 59 X = adata.layers[layer] if layer is not None else adata.X. 60 if check_nonnegative_integers(X) is False:. ---> 61 raise ValueError(. 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects "". 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data. ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. PyObjCTools NA. anndata 0.7.5. anndata2ri 1.0.5. appnope 0.1.2. attr 20.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2020.12.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.4.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. jsonschema 3.2.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.8. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. rpy2 3.3.6. scanpy 1.6.0. scipy 1.5.4. seaborn 0.11.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/pull/1784:36,deployability,releas,release,36,Move paga path bugfix note to 1.8.0 release;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1784
https://github.com/scverse/scanpy/pull/1785:10,deployability,releas,release,10,Set 1.7.2 release date; Will tag a release on merge,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1785
https://github.com/scverse/scanpy/pull/1785:35,deployability,releas,release,35,Set 1.7.2 release date; Will tag a release on merge,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1785
https://github.com/scverse/scanpy/pull/1786:25,deployability,releas,release,25,Add 1.7.3.rst; Add 1.7.3 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1786
https://github.com/scverse/scanpy/pull/1787:0,deployability,Updat,Update,0,Update release notes; Update 1.7.2 release notes on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1787
https://github.com/scverse/scanpy/pull/1787:7,deployability,releas,release,7,Update release notes; Update 1.7.2 release notes on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1787
https://github.com/scverse/scanpy/pull/1787:22,deployability,Updat,Update,22,Update release notes; Update 1.7.2 release notes on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1787
https://github.com/scverse/scanpy/pull/1787:35,deployability,releas,release,35,Update release notes; Update 1.7.2 release notes on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1787
https://github.com/scverse/scanpy/pull/1787:0,safety,Updat,Update,0,Update release notes; Update 1.7.2 release notes on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1787
https://github.com/scverse/scanpy/pull/1787:22,safety,Updat,Update,22,Update release notes; Update 1.7.2 release notes on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1787
https://github.com/scverse/scanpy/pull/1787:0,security,Updat,Update,0,Update release notes; Update 1.7.2 release notes on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1787
https://github.com/scverse/scanpy/pull/1787:22,security,Updat,Update,22,Update release notes; Update 1.7.2 release notes on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1787
https://github.com/scverse/scanpy/pull/1789:34,security,Sign,Signed-off-by,34,Fix malformed flake8 config file; Signed-off-by: zethson <lukas.heumos@posteo.net>. Fixes #1783 .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1789
https://github.com/scverse/scanpy/issues/1791:36,deployability,version,version,36,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1791:166,deployability,version,version,166,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1791:36,integrability,version,version,36,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1791:166,integrability,version,version,166,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1791:36,modifiability,version,version,36,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1791:166,modifiability,version,version,166,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1791:126,usability,confirm,confirmed,126,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1791:209,usability,confirm,confirmed,209,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1791:300,usability,guid,guide,300,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1791:355,usability,minim,minimal-bug-reports,355,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1791:461,usability,Minim,Minimal,461,low-resolution plots for the latest version; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env. ```bash. conda create -n test_scanpy python=3.7 ipykernel scanpy -y. ```. 2) tutorial notebook. [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1793:7,energy efficiency,GPU,GPU,7,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:59,energy efficiency,GPU,GPU,59,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:308,energy efficiency,GPU,GPU,308,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:372,energy efficiency,GPU,GPUs,372,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:602,energy efficiency,GPU,GPU,602,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:655,energy efficiency,GPU,GPU,655,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:530,integrability,repositor,repository,530,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:530,interoperability,repositor,repository,530,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:7,performance,GPU,GPU,7,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:59,performance,GPU,GPU,59,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:308,performance,GPU,GPU,308,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:372,performance,GPU,GPUs,372,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:602,performance,GPU,GPU,602,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:655,performance,GPU,GPU,655,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:120,safety,except,exception,120,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:664,safety,test,tests,664,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:488,testability,Hook,Hook,488,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:664,testability,test,tests,664,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:467,usability,custom,custom,467,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:500,usability,custom,custom,500,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1793:582,usability,custom,custom,582,"Enable GPU accelerated CI Jobs; A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs. - [ ] Set them up with CUDA etc. - [ ] Explore whether GA or Azure suits us better for a custom runner. - [ ] Hook up the custom runner with the ScanPy repository. - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them. - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1794:625,deployability,contain,contains,625,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:536,energy efficiency,Current,Currently,536,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:1031,integrability,sub,submit,1031,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:28,interoperability,specif,specify,28,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:592,interoperability,specif,specify,592,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:156,modifiability,paramet,parameters,156,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:433,modifiability,pac,package,433,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:653,reliability,doe,doesn,653,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:900,reliability,doe,does,900,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:238,testability,simpl,simple,238,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:230,usability,tool,tool,230,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:238,usability,simpl,simple,238,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:254,usability,tool,tool,254,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:302,usability,tool,tools,302,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:402,usability,tool,tools,402,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1794:994,usability,close,closely,994,Violin plot should allow to specify gene_symbols column in .var to use; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR. .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1795:740,availability,error,error,740,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:274,deployability,version,version,274,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:797,deployability,Version,Versions,797,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:846,deployability,log,logging,846,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:274,integrability,version,version,274,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:797,integrability,Version,Versions,797,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:274,modifiability,version,version,274,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:797,modifiability,Version,Versions,797,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:740,performance,error,error,740,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:740,safety,error,error,740,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:846,safety,log,logging,846,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:846,security,log,logging,846,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:846,testability,log,logging,846,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:47,usability,command,command,47,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:90,usability,command,command,90,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:234,usability,confirm,confirmed,234,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:317,usability,confirm,confirmed,317,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:408,usability,guid,guide,408,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:463,usability,minim,minimal-bug-reports,463,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:569,usability,Minim,Minimal,569,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:658,usability,command,command,658,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:740,usability,error,error,740,"Hello I am trying to save the object with this command but it is not working. I used this command to save the objects before and it was working always.; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. ## save command. adata.write(folder + ""before_regression.h5ad""). ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1796:5923,availability,error,error,5923,"G00000033845 Mrpl15 False ... -0.469772 0.349803 0.824321. ENSMUSG00000025903 ENSMUSG00000025903 Lypla1 False ... -0.396586 0.136585 0.531308. ENSMUSG00000104217 ENSMUSG00000104217 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (defa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:255,deployability,version,version,255,"pl.rank_genes_groups_[heatmap|dotplot|matrixplot|stacked_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1054,deployability,log,log,1054,"_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plottin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1274,deployability,modul,module,1274," ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:4459,deployability,stack,stacked,4459,"38871', 'ENSMUSG00000038943', 'ENSMUSG00000039221', 'ENSMUSG00000040274', 'ENSMUSG00000044533', 'ENSMUSG00000045328', 'ENSMUSG00000046364', 'ENSMUSG00000049775', 'ENSMUSG00000052305', 'ENSMUSG00000053044', 'ENSMUSG00000053977', 'ENSMUSG00000054717', 'ENSMUSG00000056290', 'ENSMUSG00000057113', 'ENSMUSG00000057322', 'ENSMUSG00000060802', 'ENSMUSG00000061232', 'ENSMUSG00000061311', 'ENSMUSG00000061787', 'ENSMUSG00000061983', 'ENSMUSG00000062328', 'ENSMUSG00000063316', 'ENSMUSG00000063856', 'ENSMUSG00000064351', 'ENSMUSG00000066551', 'ENSMUSG00000067288', 'ENSMUSG00000069917', 'ENSMUSG00000069919', 'ENSMUSG00000073411', 'ENSMUSG00000073421', 'ENSMUSG00000073940', 'ENSMUSG00000076498', 'ENSMUSG00000076749', 'ENSMUSG00000076752', 'ENSMUSG00000076928', 'ENSMUSG00000078812', 'ENSMUSG00000079435', 'ENSMUSG00000079523', 'ENSMUSG00000094777']' in columns of `adata.obs` or in adata.var['Symbol']."". ```. The same happens with the equivalents `pl.rank_genes_groups_*` for heatmap, matrixplot and stacked violin. In contrast, with the same dataset:. ```. sc.pl.rank_genes_groups(. adata,. save='.png',. show=False,. n_genes=10,. gene_symbols='Symbol',. fontsize=8,. ncols=4,. sharey=True). ``` . works well. I suspect that this is due to the dataset not having symbols as index:. ```. >>> adata.var. ID Symbol NA. ... dispersions_norm mean std. index ... ENSMUSG00000103922 ENSMUSG00000103922 Gm6123 False ... -2.190900 0.001387 0.043064. ENSMUSG00000033845 ENSMUSG00000033845 Mrpl15 False ... -0.469772 0.349803 0.824321. ENSMUSG00000025903 ENSMUSG00000025903 Lypla1 False ... -0.396586 0.136585 0.531308. ENSMUSG00000104217 ENSMUSG00000104217 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6093,deployability,Version,Versions,6093,"000104217 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6121,deployability,log,logging,6121,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7018,deployability,log,logical,7018,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7064,deployability,updat,updated,7064,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:22,energy efficiency,heat,heatmap,22,"pl.rank_genes_groups_[heatmap|dotplot|matrixplot|stacked_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:4435,energy efficiency,heat,heatmap,4435,"0038642', 'ENSMUSG00000038871', 'ENSMUSG00000038943', 'ENSMUSG00000039221', 'ENSMUSG00000040274', 'ENSMUSG00000044533', 'ENSMUSG00000045328', 'ENSMUSG00000046364', 'ENSMUSG00000049775', 'ENSMUSG00000052305', 'ENSMUSG00000053044', 'ENSMUSG00000053977', 'ENSMUSG00000054717', 'ENSMUSG00000056290', 'ENSMUSG00000057113', 'ENSMUSG00000057322', 'ENSMUSG00000060802', 'ENSMUSG00000061232', 'ENSMUSG00000061311', 'ENSMUSG00000061787', 'ENSMUSG00000061983', 'ENSMUSG00000062328', 'ENSMUSG00000063316', 'ENSMUSG00000063856', 'ENSMUSG00000064351', 'ENSMUSG00000066551', 'ENSMUSG00000067288', 'ENSMUSG00000069917', 'ENSMUSG00000069919', 'ENSMUSG00000073411', 'ENSMUSG00000073421', 'ENSMUSG00000073940', 'ENSMUSG00000076498', 'ENSMUSG00000076749', 'ENSMUSG00000076752', 'ENSMUSG00000076928', 'ENSMUSG00000078812', 'ENSMUSG00000079435', 'ENSMUSG00000079523', 'ENSMUSG00000094777']' in columns of `adata.obs` or in adata.var['Symbol']."". ```. The same happens with the equivalents `pl.rank_genes_groups_*` for heatmap, matrixplot and stacked violin. In contrast, with the same dataset:. ```. sc.pl.rank_genes_groups(. adata,. save='.png',. show=False,. n_genes=10,. gene_symbols='Symbol',. fontsize=8,. ncols=4,. sharey=True). ``` . works well. I suspect that this is due to the dataset not having symbols as index:. ```. >>> adata.var. ID Symbol NA. ... dispersions_norm mean std. index ... ENSMUSG00000103922 ENSMUSG00000103922 Gm6123 False ... -2.190900 0.001387 0.043064. ENSMUSG00000033845 ENSMUSG00000033845 Mrpl15 False ... -0.469772 0.349803 0.824321. ENSMUSG00000025903 ENSMUSG00000025903 Lypla1 False ... -0.396586 0.136585 0.531308. ENSMUSG00000104217 ENSMUSG00000104217 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.19",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7026,energy efficiency,CPU,CPU,7026,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7030,energy efficiency,core,cores,7030,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:255,integrability,version,version,255,"pl.rank_genes_groups_[heatmap|dotplot|matrixplot|stacked_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6093,integrability,Version,Versions,6093,"000104217 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:4638,interoperability,share,sharey,4638,"305', 'ENSMUSG00000053044', 'ENSMUSG00000053977', 'ENSMUSG00000054717', 'ENSMUSG00000056290', 'ENSMUSG00000057113', 'ENSMUSG00000057322', 'ENSMUSG00000060802', 'ENSMUSG00000061232', 'ENSMUSG00000061311', 'ENSMUSG00000061787', 'ENSMUSG00000061983', 'ENSMUSG00000062328', 'ENSMUSG00000063316', 'ENSMUSG00000063856', 'ENSMUSG00000064351', 'ENSMUSG00000066551', 'ENSMUSG00000067288', 'ENSMUSG00000069917', 'ENSMUSG00000069919', 'ENSMUSG00000073411', 'ENSMUSG00000073421', 'ENSMUSG00000073940', 'ENSMUSG00000076498', 'ENSMUSG00000076749', 'ENSMUSG00000076752', 'ENSMUSG00000076928', 'ENSMUSG00000078812', 'ENSMUSG00000079435', 'ENSMUSG00000079523', 'ENSMUSG00000094777']' in columns of `adata.obs` or in adata.var['Symbol']."". ```. The same happens with the equivalents `pl.rank_genes_groups_*` for heatmap, matrixplot and stacked violin. In contrast, with the same dataset:. ```. sc.pl.rank_genes_groups(. adata,. save='.png',. show=False,. n_genes=10,. gene_symbols='Symbol',. fontsize=8,. ncols=4,. sharey=True). ``` . works well. I suspect that this is due to the dataset not having symbols as index:. ```. >>> adata.var. ID Symbol NA. ... dispersions_norm mean std. index ... ENSMUSG00000103922 ENSMUSG00000103922 Gm6123 False ... -2.190900 0.001387 0.043064. ENSMUSG00000033845 ENSMUSG00000033845 Mrpl15 False ... -0.469772 0.349803 0.824321. ENSMUSG00000025903 ENSMUSG00000025903 Lypla1 False ... -0.396586 0.136585 0.531308. ENSMUSG00000104217 ENSMUSG00000104217 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:255,modifiability,version,version,255,"pl.rank_genes_groups_[heatmap|dotplot|matrixplot|stacked_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1274,modifiability,modul,module,1274," ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1353,modifiability,pac,packages,1353,"--. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 167, in _check_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1508,modifiability,pac,packages,1508,"ion for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 167, in _check_indices. raise KeyError(. KeyError: ""Could not find keys '['ENSMUSG00000000682', 'ENSMUSG00000000782', 'ENSMUSG00000001403', 'ENSMUSG00000002222', 'ENSMUSG0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1644,modifiability,pac,packages,1644,"sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 167, in _check_indices. raise KeyError(. KeyError: ""Could not find keys '['ENSMUSG00000000682', 'ENSMUSG00000000782', 'ENSMUSG00000001403', 'ENSMUSG00000002222', 'ENSMUSG00000003038', 'ENSMUSG00000004207', 'ENSMUSG00000004642', 'ENSMUSG00000005732', 'ENSMUSG00000015176', 'ENSMUSG00000016256', 'ENSMUSG00000",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1756,modifiability,pac,packages,1756,"/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 167, in _check_indices. raise KeyError(. KeyError: ""Could not find keys '['ENSMUSG00000000682', 'ENSMUSG00000000782', 'ENSMUSG00000001403', 'ENSMUSG00000002222', 'ENSMUSG00000003038', 'ENSMUSG00000004207', 'ENSMUSG00000004642', 'ENSMUSG00000005732', 'ENSMUSG00000015176', 'ENSMUSG00000016256', 'ENSMUSG00000020423', 'ENSMUSG00000020641', 'ENSMUSG00000020649', 'ENSMUSG00000020914', 'ENSMUSG00000021213', 'ENSMUSG0000002",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1874,modifiability,pac,packages,1874,"c94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 167, in _check_indices. raise KeyError(. KeyError: ""Could not find keys '['ENSMUSG00000000682', 'ENSMUSG00000000782', 'ENSMUSG00000001403', 'ENSMUSG00000002222', 'ENSMUSG00000003038', 'ENSMUSG00000004207', 'ENSMUSG00000004642', 'ENSMUSG00000005732', 'ENSMUSG00000015176', 'ENSMUSG00000016256', 'ENSMUSG00000020423', 'ENSMUSG00000020641', 'ENSMUSG00000020649', 'ENSMUSG00000020914', 'ENSMUSG00000021213', 'ENSMUSG00000022051', 'ENSMUSG00000022528', 'ENSMUSG00000023087', 'ENSMUSG00000023274', 'ENSMUSG00000023944', 'ENSMUSG00000024397', '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:2033,modifiability,pac,packages,2033,"',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 167, in _check_indices. raise KeyError(. KeyError: ""Could not find keys '['ENSMUSG00000000682', 'ENSMUSG00000000782', 'ENSMUSG00000001403', 'ENSMUSG00000002222', 'ENSMUSG00000003038', 'ENSMUSG00000004207', 'ENSMUSG00000004642', 'ENSMUSG00000005732', 'ENSMUSG00000015176', 'ENSMUSG00000016256', 'ENSMUSG00000020423', 'ENSMUSG00000020641', 'ENSMUSG00000020649', 'ENSMUSG00000020914', 'ENSMUSG00000021213', 'ENSMUSG00000022051', 'ENSMUSG00000022528', 'ENSMUSG00000023087', 'ENSMUSG00000023274', 'ENSMUSG00000023944', 'ENSMUSG00000024397', 'ENSMUSG00000025270', 'ENSMUSG00000025362', 'ENSMUSG00000025647', 'ENSMUSG00000025889', 'ENSMUSG00000025980', 'ENSMUSG00000026234', 'ENSMUSG00000026238', 'ENSMU",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:2166,modifiability,pac,packages,2166,"vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 167, in _check_indices. raise KeyError(. KeyError: ""Could not find keys '['ENSMUSG00000000682', 'ENSMUSG00000000782', 'ENSMUSG00000001403', 'ENSMUSG00000002222', 'ENSMUSG00000003038', 'ENSMUSG00000004207', 'ENSMUSG00000004642', 'ENSMUSG00000005732', 'ENSMUSG00000015176', 'ENSMUSG00000016256', 'ENSMUSG00000020423', 'ENSMUSG00000020641', 'ENSMUSG00000020649', 'ENSMUSG00000020914', 'ENSMUSG00000021213', 'ENSMUSG00000022051', 'ENSMUSG00000022528', 'ENSMUSG00000023087', 'ENSMUSG00000023274', 'ENSMUSG00000023944', 'ENSMUSG00000024397', 'ENSMUSG00000025270', 'ENSMUSG00000025362', 'ENSMUSG00000025647', 'ENSMUSG00000025889', 'ENSMUSG00000025980', 'ENSMUSG00000026234', 'ENSMUSG00000026238', 'ENSMUSG00000026581', 'ENSMUSG00000026605', 'ENSMUSG00000026770', 'ENSMUSG00000027306', 'ENSMUSG00000027447', 'ENSMUSG00000027863', 'ENSMUS",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:2307,modifiability,pac,packages,2307,"lot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 167, in _check_indices. raise KeyError(. KeyError: ""Could not find keys '['ENSMUSG00000000682', 'ENSMUSG00000000782', 'ENSMUSG00000001403', 'ENSMUSG00000002222', 'ENSMUSG00000003038', 'ENSMUSG00000004207', 'ENSMUSG00000004642', 'ENSMUSG00000005732', 'ENSMUSG00000015176', 'ENSMUSG00000016256', 'ENSMUSG00000020423', 'ENSMUSG00000020641', 'ENSMUSG00000020649', 'ENSMUSG00000020914', 'ENSMUSG00000021213', 'ENSMUSG00000022051', 'ENSMUSG00000022528', 'ENSMUSG00000023087', 'ENSMUSG00000023274', 'ENSMUSG00000023944', 'ENSMUSG00000024397', 'ENSMUSG00000025270', 'ENSMUSG00000025362', 'ENSMUSG00000025647', 'ENSMUSG00000025889', 'ENSMUSG00000025980', 'ENSMUSG00000026234', 'ENSMUSG00000026238', 'ENSMUSG00000026581', 'ENSMUSG00000026605', 'ENSMUSG00000026770', 'ENSMUSG00000027306', 'ENSMUSG00000027447', 'ENSMUSG00000027863', 'ENSMUSG00000028212', 'ENSMUSG00000028639', 'ENSMUSG00000029322', 'ENSMUSG00000029530', 'ENSMUSG00000029580', 'ENSMUSG00000029922', 'ENSMUSG00000031",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6093,modifiability,Version,Versions,6093,"000104217 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6627,modifiability,pac,packaging,6627,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6895,modifiability,pac,packaged,6895,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:5923,performance,error,error,5923,"G00000033845 Mrpl15 False ... -0.469772 0.349803 0.824321. ENSMUSG00000025903 ENSMUSG00000025903 Lypla1 False ... -0.396586 0.136585 0.531308. ENSMUSG00000104217 ENSMUSG00000104217 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (defa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7026,performance,CPU,CPU,7026,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1054,safety,log,log,1054,"_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plottin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1274,safety,modul,module,1274," ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe. obs_tidy = get.obs_df(. File ""/usr/local/lib/python3.8/site-packages/scanpy/get/get.py"", line 272, in obs_df. obs_cols, var_idx_keys, var_symbols = _check_indices(. File """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:5923,safety,error,error,5923,"G00000033845 Mrpl15 False ... -0.469772 0.349803 0.824321. ENSMUSG00000025903 ENSMUSG00000025903 Lypla1 False ... -0.396586 0.136585 0.531308. ENSMUSG00000104217 ENSMUSG00000104217 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (defa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6121,safety,log,logging,6121,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7018,safety,log,logical,7018,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7064,safety,updat,updated,7064,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1054,security,log,log,1054,"_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plottin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6121,security,log,logging,6121,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7018,security,log,logical,7018,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7044,security,Session,Session,7044,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7064,security,updat,updated,7064,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1054,testability,log,log,1054,"_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plottin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1099,testability,Trace,Traceback,1099," way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6121,testability,log,logging,6121,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:7018,testability,log,logical,7018,"17 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]. Linux-4.19.121-linuxkit-x86_64-with-debian-10.8. 2 logical CPU cores. -----. Session information updated at 2021-04-12 15:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:215,usability,confirm,confirmed,215,"pl.rank_genes_groups_[heatmap|dotplot|matrixplot|stacked_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:298,usability,confirm,confirmed,298,"pl.rank_genes_groups_[heatmap|dotplot|matrixplot|stacked_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:389,usability,guid,guide,389,"pl.rank_genes_groups_[heatmap|dotplot|matrixplot|stacked_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:444,usability,minim,minimal-bug-reports,444,"pl.rank_genes_groups_[heatmap|dotplot|matrixplot|stacked_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:550,usability,Minim,Minimal,550,"pl.rank_genes_groups_[heatmap|dotplot|matrixplot|stacked_violin] don't work with gene_symbol in the same way as pl.rank_genes_groups; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. import pandas as pd. import numpy as np. import urllib.request. . url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad"". # 75 MB anndata. urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(. adata,. save='.png',. show=False,. gene_symbols='Symbol',. n_genes=10,. log=False,. use_raw=False,. ). ```. ```pytb. Traceback (most recent call last):. File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>. sc.pl.rank_genes_groups_dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot. return _rank_genes_groups_plot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot. _pl = dotplot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot. dp = DotPlot(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__. BasePlot.__init__(. File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__. self.categories, self.obs_tidy = _prepare_dataframe(. Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:5923,usability,error,error,5923,"G00000033845 Mrpl15 False ... -0.469772 0.349803 0.824321. ENSMUSG00000025903 ENSMUSG00000025903 Lypla1 False ... -0.396586 0.136585 0.531308. ENSMUSG00000104217 ENSMUSG00000104217 Gm37988 False ... -1.059987 0.036154 0.246548. ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880. ... ... ... ... ... ... ... ... ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330. ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670. ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574. ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460. ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347. ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks! #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. cairo 1.20.0. cffi 1.14.5. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. packaging 20.9. pandas 1.1.5. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.5.3. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sphinxcontrib NA. tables 3.6.1. texttable 1.6.3. typing_extensions NA. zipp NA. -----. Python 3.6.13 | packaged by conda-forge | (defa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1797:2060,availability,error,errors,2060,"genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2994,availability,error,errors,2994,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3630,availability,error,errors,3630,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:364,deployability,API,API,364,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1198,deployability,scale,scale,1198,"mportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:47,energy efficiency,core,core,47,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1198,energy efficiency,scale,scale,1198,"mportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1872,energy efficiency,core,core,1872,"processing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2014,energy efficiency,core,core,2014,"ter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serial",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2055,energy efficiency,core,core,2055,"iable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2183,energy efficiency,core,core,2183,"log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/en",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2374,energy efficiency,core,core,2374,"rom ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2454,energy efficiency,core,core,2454,"nes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2605,energy efficiency,core,core,2605,"8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2642,energy efficiency,core,core,2642," Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2703,energy efficiency,core,core,2703,"ba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metacl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2742,energy efficiency,cpu,cpu,2742,"ipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2888,energy efficiency,core,core,2888,"port (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.con",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2968,energy efficiency,core,core,2968,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3063,energy efficiency,core,core,3063,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3125,energy efficiency,core,core,3125,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3229,energy efficiency,core,core,3229,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3264,energy efficiency,core,core,3264,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3331,energy efficiency,core,core,3331,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3393,energy efficiency,core,core,3393,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3513,energy efficiency,core,core,3513,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3557,energy efficiency,core,core,3557,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3618,energy efficiency,core,core,3618,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3677,energy efficiency,core,core,3677,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3723,energy efficiency,core,core,3723,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3763,energy efficiency,core,core,3763,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3859,energy efficiency,core,core,3859,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3939,energy efficiency,core,core,3939,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:364,integrability,API,API,364,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1205,integrability,sub,subsample,1205,"r Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extendi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2531,integrability,Abstract,AbstractTemplate,2531,"npy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3438,integrability,Translat,TranslateByteCode,3438,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3646,integrability,transform,transforms,3646,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3743,integrability,event,event,3743,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:364,interoperability,API,API,364,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2224,interoperability,registr,registry,2224,"s/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2430,interoperability,registr,registry,2430,"_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2610,interoperability,registr,registry,2610,"typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3438,interoperability,Translat,TranslateByteCode,3438,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3646,interoperability,transform,transforms,3646,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:320,modifiability,pac,packages,320,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:614,modifiability,pac,packages,614,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:855,modifiability,pac,packages,855,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1198,modifiability,scal,scale,1198,"mportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1256,modifiability,pac,packages,1256,"mport scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1562,modifiability,pac,packages,1562," as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1795,modifiability,pac,packages,1795,"ort draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # ---------------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1841,modifiability,deco,decorators,1841,"3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1877,modifiability,deco,decorators,1877,"ng/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1999,modifiability,pac,packages,1999,"er_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2019,modifiability,deco,decorators,2019,"s. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, con",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2203,modifiability,exten,extending,2203,"sample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2278,modifiability,pac,packages,2278,"ing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2531,modifiability,Abstract,AbstractTemplate,2531,"npy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2590,modifiability,pac,packages,2590,"imple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2873,modifiability,pac,packages,2873,"decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3214,modifiability,pac,packages,3214,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3498,modifiability,pac,packages,3498,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3924,modifiability,pac,packages,3924,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:1198,performance,scale,scale,1198,"mportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2060,performance,error,errors,2060,"genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2742,performance,cpu,cpu,2742,"ipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2994,performance,error,errors,2994,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3630,performance,error,errors,3630,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2060,safety,error,errors,2060,"genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2994,safety,error,errors,2994,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3630,safety,error,errors,3630,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2502,security,sign,signature,2502,"rmalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:212,testability,Trace,Traceback,212,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:448,usability,tool,tools,448,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:490,usability,tool,tools,490,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:630,usability,tool,tools,630,"cannot import name 'add_metaclass' from 'numba.core.utils' in Scanpy; Hi:. When I entered `import scanpy as sc` as usual, and it came out as below, it never happened before, what should I do? Thanks. ImportError Traceback (most recent call last). in. ----> 1 import scanpy as sc. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/init.py in. 34 # the actual API. 35 from ._settings import settings, Verbosity # start with settings as several tools are using it. ---> 36 from . import tools as tl. 37 from . import preprocessing as pp. 38 from . import plotting as pl. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/init.py in. ----> 1 from ..preprocessing import pca. 2 from ._tsne import tsne. 3 from ._umap import umap. 4 from ._diffmap import diffmap. 5 from ._draw_graph import draw_graph. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/init.py in. ----> 1 from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat. 2 from ._simple import filter_cells, filter_genes. 3 from ._deprecated.highly_variable_genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2060,usability,error,errors,2060,"genes import filter_genes_dispersion. 4 from ._highly_variable_genes import highly_variable_genes. 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in. 4 from anndata import AnnData. 5. ----> 6 from . import _simple as pp. 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated. 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in. 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable. 9. ---> 10 import numba. 11 import numpy as np. 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in. 32. 33 # Re-export decorators. ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,. 35 jit_module). 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2994,usability,error,errors,2994,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3630,usability,error,errors,3630,". 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in. 10. 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning. ---> 12 from numba.stencils.stencil import stencil. 13 from numba.core import config, extending, sigutils, registry. 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in. 9 from llvmlite import ir as lir. 10. ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry. 12 from numba.core.typing.templates import (CallableTemplate, signature,. 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in. 2. 3 from numba.core.descriptors import TargetDescriptor. ----> 4 from numba.core import utils, typing, dispatcher, cpu. 5. 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in. 13. 14 from numba import _dispatcher. ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils. 16 from numba.core.compiler_lock import global_compiler_lock. 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in. 11 from numba.core.environment import lookup_environment. 12. ---> 13 from numba.core.compiler_machinery import PassManager. 14. 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in. 5 from numba.core.compiler_lock import global_compiler_lock. 6 from numba.core import errors, config, transforms. ----> 7 from numba.core.utils import add_metaclass. 8 from numba.core.tracing import event. 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1798:111,energy efficiency,measur,measured,111,"Changing the use_raw behavior without breaking things; It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1798:202,integrability,sub,subset,202,"Changing the use_raw behavior without breaking things; It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1798:332,modifiability,layer,layers,332,"Changing the use_raw behavior without breaking things; It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1798:693,performance,time,times,693,"Changing the use_raw behavior without breaking things; It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1798:268,safety,except,except,268,"Changing the use_raw behavior without breaking things; It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1798:857,security,sign,significant,857,"Changing the use_raw behavior without breaking things; It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1798:21,usability,behavi,behavior,21,"Changing the use_raw behavior without breaking things; It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1798:426,usability,visual,visualizing,426,"Changing the use_raw behavior without breaking things; It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1798:869,usability,behavi,behavior,869,"Changing the use_raw behavior without breaking things; It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1798:1242,usability,behavi,behavior,1242,"Changing the use_raw behavior without breaking things; It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1799:54,availability,error,errors,54,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:250,availability,error,error,250,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:573,availability,error,errors,573,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3912,availability,error,errors,3912,"# Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4438,availability,error,errors,4438,"e3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5251,availability,state,state,5251,"cVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5279,availability,state,state,5279,"kages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5548,availability,state,state,5548,"numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5753,availability,state,state,5753,"getdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compile",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5867,availability,avail,available,5867,"n compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6048,availability,state,state,6048,"urn_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6068,availability,state,state,6068,"als). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, inter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6203,availability,state,state,6203,"er.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= chec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6475,availability,state,state,6475,"core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6617,availability,state,state,6617,"f _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7750,availability,state,state,7750,"iler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_bod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7843,availability,state,state,7843,"*kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7865,availability,state,state,7865,"f:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lower",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7911,availability,state,state,7911,"eturn _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7931,availability,state,state,7931,"le_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8044,availability,state,state,8044,"(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9686,availability,error,errors,9686,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1482,deployability,modul,module,1482,"most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_conn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2665,deployability,instal,installed,2665,"ighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2867,deployability,modul,module,2867,"s(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3066,deployability,modul,module,3066,"lf, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3342,deployability,modul,module,3342,". 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4980,deployability,pipelin,pipeline,4980,"/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5092,deployability,pipelin,pipeline,5092,"ef compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5877,deployability,pipelin,pipelines,5877,"extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7799,deployability,pipelin,pipeline,7799,"rgs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/mi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8944,deployability,build,builder,8944,"miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . Lowering",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9955,deployability,Fail,Failed,9955,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9979,deployability,pipelin,pipeline,9979,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:568,energy efficiency,core,core,568,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:743,energy efficiency,core,core,743,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:952,energy efficiency,core,core,952,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1148,energy efficiency,core,core,1148,"nda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, me",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3396,energy efficiency,Reduc,Reduced,3396,"envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3490,energy efficiency,core,core,3490,"ies_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3729,energy efficiency,core,core,3729,"388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4031,energy efficiency,core,core,4031,"/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, libra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4294,energy efficiency,core,core,4294,"b/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4557,energy efficiency,core,core,4557,"atcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4854,energy efficiency,core,core,4854,"= self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise Compiler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5195,energy efficiency,core,core,5195,"). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5478,energy efficiency,core,core,5478,"cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5703,energy efficiency,core,core,5703,"xtra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5961,energy efficiency,core,core,5961,"line_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6163,energy efficiency,core,core,6163,"python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6435,energy efficiency,core,core,6435,"scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(fu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6744,energy efficiency,core,core,6744,"3 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7009,energy efficiency,core,core,7009," None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7399,energy efficiency,core,core,7399,"lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlowe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7711,energy efficiency,core,core,7711,"/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 en",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8005,energy efficiency,core,core,8005,"a/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8315,energy efficiency,core,core,8315,"er, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8579,energy efficiency,core,core,8579,"64 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8858,energy efficiency,core,core,8858,"ed = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FU",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9119,energy efficiency,core,core,9119,"etadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/pytho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9681,energy efficiency,core,core,9681,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9846,energy efficiency,core,core,9846,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2615,integrability,filter,filterwarnings,2615,"nvs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2640,integrability,messag,message,2640,".8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3160,integrability,sub,submatrix,3160,"ds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3512,integrability,wrap,wrapper,3512,"n_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4980,integrability,pipelin,pipeline,4980,"/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5092,integrability,pipelin,pipeline,5092,"ef compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5251,integrability,state,state,5251,"cVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5279,integrability,state,state,5279,"kages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5548,integrability,state,state,5548,"numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5753,integrability,state,state,5753,"getdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compile",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5877,integrability,pipelin,pipelines,5877,"extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6048,integrability,state,state,6048,"urn_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6068,integrability,state,state,6068,"als). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, inter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6203,integrability,state,state,6203,"er.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= chec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6475,integrability,state,state,6475,"core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6617,integrability,state,state,6617,"f _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7750,integrability,state,state,7750,"iler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_bod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7799,integrability,pipelin,pipeline,7799,"rgs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/mi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7843,integrability,state,state,7843,"*kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7865,integrability,state,state,7865,"f:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lower",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7911,integrability,state,state,7911,"eturn _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7931,integrability,state,state,7931,"le_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8044,integrability,state,state,8044,"(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9979,integrability,pipelin,pipeline,9979,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:116,interoperability,architectur,architecture,116,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2640,interoperability,messag,message,2640,".8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3512,interoperability,wrapper,wrapper,3512,"n_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:553,modifiability,pac,packages,553,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:728,modifiability,pac,packages,728,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:937,modifiability,pac,packages,937,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1133,modifiability,pac,packages,1133," created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_kn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1482,modifiability,modul,module,1482,"most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_conn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1652,modifiability,pac,packages,1652," except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2008,modifiability,pac,packages,2008,"ower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2431,modifiability,pac,packages,2431,"all last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/mi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2837,modifiability,pac,packages,2837,"()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2867,modifiability,modul,module,2867,"s(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3039,modifiability,pac,packages,3039,"py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3066,modifiability,modul,module,3066,"lf, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3313,modifiability,pac,packages,3313,"compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3342,modifiability,modul,module,3342,". 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3475,modifiability,pac,packages,3475,"e_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3495,modifiability,deco,decorators,3495,"(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3714,modifiability,pac,packages,3714,"plicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.tar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4016,modifiability,pac,packages,4016,"lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, tar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4279,modifiability,pac,packages,4279,"nvs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.stat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4542,modifiability,pac,packages,4542,"register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4839,modifiability,pac,packages,4839,"--> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5180,modifiability,pac,packages,5180,", return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5463,modifiability,pac,packages,5463,"self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in ru",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5688,modifiability,pac,packages,5688,"ler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/minif",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5946,modifiability,pac,packages,5946,"library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6148,modifiability,pac,packages,6148,"s/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 wit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6420,modifiability,pac,packages,6420,"iforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6729,modifiability,pac,packages,6729,"ore(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:6994,modifiability,pac,packages,6994,"f). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7384,modifiability,pac,packages,7384,"/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7696,modifiability,pac,packages,7696,"vs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7990,modifiability,pac,packages,7990,"packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8300,modifiability,pac,packages,8300,"s.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(ins",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8564,modifiability,pac,packages,8564,"e, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8843,modifiability,pac,packages,8843,"e). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9104,modifiability,pac,packages,9104,"nterp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scV",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9666,modifiability,pac,packages,9666,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:10131,modifiability,pac,packages,10131,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:10433,modifiability,pac,packages,10433,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:54,performance,error,errors,54,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:250,performance,error,error,250,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:573,performance,error,errors,573,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3912,performance,error,errors,3912,"# Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4438,performance,error,errors,4438,"e3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9686,performance,error,errors,9686,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5867,reliability,availab,available,5867,"n compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9955,reliability,Fail,Failed,9955,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:54,safety,error,errors,54,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:250,safety,error,error,250,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:573,safety,error,errors,573,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:657,safety,except,except,657,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1355,safety,except,exception,1355,"to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1374,safety,except,exception,1374,"`. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1455,safety,input,input-,1455," AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1482,safety,modul,module,1482,"most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_conn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2867,safety,modul,module,2867,"s(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3066,safety,modul,module,3066,"lf, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3342,safety,modul,module,3342,". 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 385 # umap 0.5.0. 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""). --> 387 from umap.umap_ import fuzzy_simplicial_set. 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>. ----> 1 from .umap_ import UMAP. 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3905,safety,except,except,3905," 2 . 3 # Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3912,safety,error,errors,3912,"# Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4431,safety,except,except,4431,"iniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/en",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4438,safety,error,errors,4438,"e3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5867,safety,avail,available,5867,"n compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9522,safety,except,except,9522,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9604,safety,except,exception,9604,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9686,safety,error,errors,9686,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5867,security,availab,available,5867,"n compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7882,security,sign,signature,7882,"func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7901,security,sign,signature,7901,"s). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:259,testability,understand,understand,259,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:459,testability,Assert,AssertionError,459,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:474,testability,Trace,Traceback,474,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1228,testability,Assert,AssertionError,1228,"` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1258,testability,Assert,AssertionError,1258,"tand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1411,testability,Trace,Traceback,1411,"-----------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5536,testability,assert,assert,5536,"te-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7154,testability,Simpl,SimpleTimer,7154,"ba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7248,testability,Simpl,SimpleTimer,7248,"tched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9383,testability,context,contextlib,9383," self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9428,testability,trace,traceback,9428,"mal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9506,testability,trace,traceback,9506,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:54,usability,error,errors,54,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:250,usability,error,error,250,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:300,usability,learn,learn,300,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:573,usability,error,errors,573,"Running scanpy on M1 apple silicon clashes with Numba errors; Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1455,usability,input,input-,1455," AssertionError Traceback (most recent call last). ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 743 try:. --> 744 yield. 745 except NumbaError as e:. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst). 327 val = self.lower_assign(ty, inst). --> 328 self.storevar(val, inst.target.name). 329 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name). 1277 name=name). -> 1278 raise AssertionError(msg). 1279 . . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. . During handling of the above exception, another exception occurred:. . LoweringError Traceback (most recent call last). <ipython-input-19-ef300851c737> in <module>. 1 n_neighbors = int(np.sqrt(adata.shape[0])/2). ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3912,usability,error,errors,3912,"# Workaround: https://github.com/numba/numba/issues/3341. 4 import numba. 5 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>. 52 from umap.spectral import spectral_layout. 53 from umap.utils import deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4142,usability,statu,status,4142,"t deheap_sort, submatrix. ---> 54 from umap.layouts import (. 55 optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/minifor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4206,usability,statu,status,4206," optimize_layout_euclidean,. 56 optimize_layout_generic,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>. 37 },. 38 ). ---> 39 def rdist(x, y):. 40 """"""Reduced Euclidean distance. 41 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4438,usability,error,errors,4438,"e3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func). 219 with typeinfer.register_dispatcher(disp):. 220 for sig in sigs:. --> 221 disp.compile(sig). 222 disp.disable_compile(). 223 return disp. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig). 907 with ev.trigger_event(""numba:compile"", data=ev_details):. 908 try:. --> 909 cres = self._compiler.compile(args, return_type). 910 except errors.ForceLiteralArg as e:. 911 def folded(args, kws):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type). 77 . 78 def compile(self, args, return_type):. ---> 79 status, retval = self._compile_cached(args, return_type). 80 if status:. 81 return retval. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type). 91 . 92 try:. ---> 93 retval = self._compile_core(args, return_type). 94 except errors.TypingError as e:. 95 self._failed_cache[key] = e. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type). 104 . 105 impl = self._get_implementation(args, {}). --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,. 107 self.targetdescr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5759,usability,statu,status,5759,"cr.target_context,. 108 impl,. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 604 pipeline = pipeline_class(typingctx, targetctx, library,. 605 args, return_type, flags, locals). --> 606 return pipeline.compile_extra(func). 607 . 608 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func). 351 self.state.lifted = (). 352 self.state.lifted_from = None. --> 353 return self._compile_bytecode(). 354 . 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self). 413 """""". 414 assert self.state.func_ir is None. --> 415 return self._compile_core(). 416 . 417 def _compile_ir(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 393 self.state.status.fail_reason = e. 394 if is_final_pipeline:. --> 395 raise e. 396 else:. 397 raise CompilerError(""All available pipelines exhausted""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self). 384 res = None. 385 try:. --> 386 pm.run(self.state). 387 if self.state.cr is not None:. 388 break. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7154,usability,Simpl,SimpleTimer,7154,"ba/core/compiler_machinery.py in run(self, state). 337 (self.pipeline_name, pass_desc). 338 patched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7248,usability,Simpl,SimpleTimer,7248,"tched_exception = self._patch_error(msg, e). --> 339 raise patched_exception. 340 . 341 def dependency_analysis(self):. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state). 328 pass_inst = _pass_registry.get(pss).pass_inst. 329 if isinstance(pass_inst, CompilerPass):. --> 330 self._runPass(idx, pass_inst, state). 331 else:. 332 raise BaseException(""Legacy pass in use""). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 33 def _acquire_compile_lock(*args, **kwargs):. 34 with self:. ---> 35 return func(*args, **kwargs). 36 return _acquire_compile_lock. 37 . . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state). 287 mutated |= check(pss.run_initialization, internal_state). 288 with SimpleTimer() as pass_time:. --> 289 mutated |= check(pss.run_pass, internal_state). 290 with SimpleTimer() as finalize_time:. 291 mutated |= check(pss.run_finalizer, internal_state). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state). 260 . 261 def check(func, compiler_state):. --> 262 mangled = func(compiler_state). 263 if mangled not in (True, False):. 264 msg = (""CompilerPass implementations should return True/False. "". . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 461 . 462 # TODO: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:8770,usability,Close,Close,8770,"O: Pull this out into the pipeline. --> 463 NativeLowering().run_pass(state). 464 lowered = state['cr']. 465 signature = typing.signature(state.return_type, *state.args). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state). 382 lower = lowering.Lower(targetctx, library, fndesc, interp,. 383 metadata=metadata). --> 384 lower.lower(). 385 if not flags.no_cpython_wrapper:. 386 lower.create_cpython_wrapper(flags.release_gil). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self). 134 if self.generator_info is None:. 135 self.genlower = None. --> 136 self.lower_normal_function(self.fndesc). 137 else:. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_conte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9529,usability,Stop,StopIteration,9529,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9567,usability,Stop,StopIteration,9567,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9686,usability,error,errors,9686,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:10368,usability,User,Users,10368,":. 138 self.genlower = self.GeneratorLower(self). . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc). 188 # Init argument values. 189 self.extract_function_arguments(). --> 190 entry_block_tail = self.lower_function_body(). 191 . 192 # Close tail of entry block. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self). 214 bb = self.blkmap[offset]. 215 self.builder.position_at_end(bb). --> 216 self.lower_block(block). 217 self.post_lower(). 218 return entry_block_tail. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block). 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 229 loc=self.loc, errcls_=defaulterrcls):. --> 230 self.lower_inst(inst). 231 self.post_block(block). 232 . . ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback). 129 value = type(). 130 try:. --> 131 self.gen.throw(type, value, traceback). 132 except StopIteration as exc:. 133 # Suppress StopIteration *unless* it's the same exception that. . ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs). 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)). 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None. --> 751 raise newerr.with_traceback(tb). 752 . 753 . . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Storing i64 to ptr of i32 ('dim'). FE type int32. . File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:. def rdist(x, y):. <source elided>. result = 0.0. dim = x.shape[0]. ^. . During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1800:12,deployability,log,logFC,12,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:192,deployability,log,logFC,192,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:231,deployability,log,logFC,231,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:12,safety,log,logFC,12,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:192,safety,log,logFC,192,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:231,safety,log,logFC,231,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:12,security,log,logFC,12,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:192,security,log,logFC,192,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:231,security,log,logFC,231,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:12,testability,log,logFC,12,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:192,testability,log,logFC,192,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:231,testability,log,logFC,231,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:407,usability,help,help,407,"No negative logFC values after running scanpy.tl.rank_genes_groups(); Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ? I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1801:75,usability,Document,Document,75,Increase visibility of ecosystem page; As discussed at last meeting. - [ ] Document process for adding entries (note this on top of ecosystem page). - [ ] Link from external. - [ ] Clarify goals/ differences b/w ecosystem and external,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1801
https://github.com/scverse/scanpy/issues/1802:93,integrability,sub,subplots,93,"sc.pl.umap ax argument not working; I'm trying to plot UMAP plots on predefined axes in `plt.subplots`. ```. fig, ax = plt.subplots(1,3). sns.boxplot(x=""CytoTRACE"", data=adata.obs, ax=ax[0]). sc.pl.umap(adata, color='Batch', ax=ax[1]). sc.pl.umap(adata, color='CytoTRACE', ax=ax[2]). ```. However, after the first call, the axes argument does not seem to work anymore:. ![image](https://user-images.githubusercontent.com/56223326/115447250-905f1f80-a218-11eb-8675-f1be00ea1e5e.png). Is there any additional flag I am missing?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1802
https://github.com/scverse/scanpy/issues/1802:123,integrability,sub,subplots,123,"sc.pl.umap ax argument not working; I'm trying to plot UMAP plots on predefined axes in `plt.subplots`. ```. fig, ax = plt.subplots(1,3). sns.boxplot(x=""CytoTRACE"", data=adata.obs, ax=ax[0]). sc.pl.umap(adata, color='Batch', ax=ax[1]). sc.pl.umap(adata, color='CytoTRACE', ax=ax[2]). ```. However, after the first call, the axes argument does not seem to work anymore:. ![image](https://user-images.githubusercontent.com/56223326/115447250-905f1f80-a218-11eb-8675-f1be00ea1e5e.png). Is there any additional flag I am missing?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1802
https://github.com/scverse/scanpy/issues/1802:217,integrability,Batch,Batch,217,"sc.pl.umap ax argument not working; I'm trying to plot UMAP plots on predefined axes in `plt.subplots`. ```. fig, ax = plt.subplots(1,3). sns.boxplot(x=""CytoTRACE"", data=adata.obs, ax=ax[0]). sc.pl.umap(adata, color='Batch', ax=ax[1]). sc.pl.umap(adata, color='CytoTRACE', ax=ax[2]). ```. However, after the first call, the axes argument does not seem to work anymore:. ![image](https://user-images.githubusercontent.com/56223326/115447250-905f1f80-a218-11eb-8675-f1be00ea1e5e.png). Is there any additional flag I am missing?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1802
https://github.com/scverse/scanpy/issues/1802:217,performance,Batch,Batch,217,"sc.pl.umap ax argument not working; I'm trying to plot UMAP plots on predefined axes in `plt.subplots`. ```. fig, ax = plt.subplots(1,3). sns.boxplot(x=""CytoTRACE"", data=adata.obs, ax=ax[0]). sc.pl.umap(adata, color='Batch', ax=ax[1]). sc.pl.umap(adata, color='CytoTRACE', ax=ax[2]). ```. However, after the first call, the axes argument does not seem to work anymore:. ![image](https://user-images.githubusercontent.com/56223326/115447250-905f1f80-a218-11eb-8675-f1be00ea1e5e.png). Is there any additional flag I am missing?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1802
https://github.com/scverse/scanpy/issues/1802:338,reliability,doe,does,338,"sc.pl.umap ax argument not working; I'm trying to plot UMAP plots on predefined axes in `plt.subplots`. ```. fig, ax = plt.subplots(1,3). sns.boxplot(x=""CytoTRACE"", data=adata.obs, ax=ax[0]). sc.pl.umap(adata, color='Batch', ax=ax[1]). sc.pl.umap(adata, color='CytoTRACE', ax=ax[2]). ```. However, after the first call, the axes argument does not seem to work anymore:. ![image](https://user-images.githubusercontent.com/56223326/115447250-905f1f80-a218-11eb-8675-f1be00ea1e5e.png). Is there any additional flag I am missing?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1802
https://github.com/scverse/scanpy/issues/1802:387,usability,user,user-images,387,"sc.pl.umap ax argument not working; I'm trying to plot UMAP plots on predefined axes in `plt.subplots`. ```. fig, ax = plt.subplots(1,3). sns.boxplot(x=""CytoTRACE"", data=adata.obs, ax=ax[0]). sc.pl.umap(adata, color='Batch', ax=ax[1]). sc.pl.umap(adata, color='CytoTRACE', ax=ax[2]). ```. However, after the first call, the axes argument does not seem to work anymore:. ![image](https://user-images.githubusercontent.com/56223326/115447250-905f1f80-a218-11eb-8675-f1be00ea1e5e.png). Is there any additional flag I am missing?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1802
https://github.com/scverse/scanpy/issues/1803:151,modifiability,design decis,design decisions,151,"dispersions_norm definition; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... How is the dispersions_norm defined in Scanpy? --.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1803
https://github.com/scverse/scanpy/issues/1803:49,usability,help,help,49,"dispersions_norm definition; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... How is the dispersions_norm defined in Scanpy? --.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1803
https://github.com/scverse/scanpy/issues/1804:677,availability,state,state,677,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:677,integrability,state,state,677,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:10,interoperability,distribut,distribution,10,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:593,interoperability,distribut,distribution,593,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:145,modifiability,paramet,parameters,145,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:422,modifiability,pac,package,422,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:707,security,expos,exposure,707,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:803,security,expos,exposure,803,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:906,security,expos,exposure,906,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:227,testability,simpl,simple,227,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:219,usability,tool,tool,219,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:227,usability,simpl,simple,227,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:243,usability,tool,tool,243,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:291,usability,tool,tools,291,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:391,usability,tool,tools,391,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/issues/1804:878,usability,statu,status,878,"comparing distribution of cell types per cohort per groups ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/pull/1805:61,availability,cluster,clustering,61,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:132,availability,cluster,clustering,132,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:217,availability,cluster,clustering,217,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:61,deployability,cluster,clustering,61,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:132,deployability,cluster,clustering,132,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:217,deployability,cluster,clustering,217,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:252,deployability,api,api,252,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:271,deployability,api,api,271,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:280,deployability,modul,module-cugraph,280,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:252,integrability,api,api,252,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:271,integrability,api,api,271,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:252,interoperability,api,api,252,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:271,interoperability,api,api,271,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:20,modifiability,paramet,parameter,20,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:100,modifiability,paramet,parameter,100,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:180,modifiability,paramet,parameter,180,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:280,modifiability,modul,module-cugraph,280,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:280,safety,modul,module-cugraph,280,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:314,safety,Test,Tested,314,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/pull/1805:314,testability,Test,Tested,314,Allowing resolution parameter to be used with RAPIDS Louvain clustering; I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/issues/1806:124,availability,down,down,124,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:279,availability,error,errors,279,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:496,availability,consist,consistently,496,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:573,availability,error,error,573,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:918,availability,consist,consistent,918,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:528,deployability,Depend,Depending,528,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:974,deployability,instal,install,974,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:528,integrability,Depend,Depending,528,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:341,interoperability,specif,specifically,341,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:1034,interoperability,specif,specific,1034,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:308,modifiability,variab,variable,308,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:528,modifiability,Depend,Depending,528,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:263,performance,parallel,parallelization,263,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:279,performance,error,errors,279,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:573,performance,error,error,573,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:668,performance,parallel,parallel,668,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:799,performance,parallel,parallel,799,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:279,safety,error,errors,279,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:528,safety,Depend,Depending,528,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:573,safety,error,error,573,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:642,security,control,control,642,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:528,testability,Depend,Depending,528,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:642,testability,control,control,642,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:279,usability,error,errors,279,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:496,usability,consist,consistently,496,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:573,usability,error,error,573,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:685,usability,interact,interacts,685,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:918,usability,consist,consistent,918,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:936,usability,person,personally,936,"Address edge cases in gearys_c and morans_i; Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values). * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear. * I don't think we can throw a warning from numba code, let alone parallel numba code. * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/pull/1807:289,deployability,log,logging,289,add pynndescent to print_header; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:253,safety,review,review,253,add pynndescent to print_header; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:289,safety,log,logging,289,add pynndescent to print_header; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:289,security,log,logging,289,add pynndescent to print_header; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:253,testability,review,review,253,add pynndescent to print_header; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:289,testability,log,logging,289,add pynndescent to print_header; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:104,usability,guid,guidelines,104,add pynndescent to print_header; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:135,usability,guid,guide,135,add pynndescent to print_header; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:231,usability,workflow,workflow,231,add pynndescent to print_header; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:314,usability,Close,Close,314,add pynndescent to print_header; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1808:255,safety,review,review,255,Plot documentation for matrixplot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Inline documentation for the matrixplot. Addressing issue #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1808
https://github.com/scverse/scanpy/pull/1808:255,testability,review,review,255,Plot documentation for matrixplot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Inline documentation for the matrixplot. Addressing issue #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1808
https://github.com/scverse/scanpy/pull/1808:5,usability,document,documentation,5,Plot documentation for matrixplot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Inline documentation for the matrixplot. Addressing issue #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1808
https://github.com/scverse/scanpy/pull/1808:106,usability,guid,guidelines,106,Plot documentation for matrixplot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Inline documentation for the matrixplot. Addressing issue #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1808
https://github.com/scverse/scanpy/pull/1808:137,usability,guid,guide,137,Plot documentation for matrixplot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Inline documentation for the matrixplot. Addressing issue #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1808
https://github.com/scverse/scanpy/pull/1808:233,usability,workflow,workflow,233,Plot documentation for matrixplot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Inline documentation for the matrixplot. Addressing issue #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1808
https://github.com/scverse/scanpy/pull/1808:275,usability,document,documentation,275,Plot documentation for matrixplot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Inline documentation for the matrixplot. Addressing issue #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1808
https://github.com/scverse/scanpy/pull/1809:330,energy efficiency,heat,heatmap,330,add various inline examples; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. part of #1664. add inline examples for. - sc.pl.draw_graph. - sc.pl.heatmap. - sc.pl.dendrogram. - sc.pl.tsne. - sc.pl.diffmap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1809
https://github.com/scverse/scanpy/pull/1809:249,safety,review,review,249,add various inline examples; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. part of #1664. add inline examples for. - sc.pl.draw_graph. - sc.pl.heatmap. - sc.pl.dendrogram. - sc.pl.tsne. - sc.pl.diffmap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1809
https://github.com/scverse/scanpy/pull/1809:249,testability,review,review,249,add various inline examples; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. part of #1664. add inline examples for. - sc.pl.draw_graph. - sc.pl.heatmap. - sc.pl.dendrogram. - sc.pl.tsne. - sc.pl.diffmap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1809
https://github.com/scverse/scanpy/pull/1809:100,usability,guid,guidelines,100,add various inline examples; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. part of #1664. add inline examples for. - sc.pl.draw_graph. - sc.pl.heatmap. - sc.pl.dendrogram. - sc.pl.tsne. - sc.pl.diffmap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1809
https://github.com/scverse/scanpy/pull/1809:131,usability,guid,guide,131,add various inline examples; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. part of #1664. add inline examples for. - sc.pl.draw_graph. - sc.pl.heatmap. - sc.pl.dendrogram. - sc.pl.tsne. - sc.pl.diffmap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1809
https://github.com/scverse/scanpy/pull/1809:227,usability,workflow,workflow,227,add various inline examples; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. part of #1664. add inline examples for. - sc.pl.draw_graph. - sc.pl.heatmap. - sc.pl.dendrogram. - sc.pl.tsne. - sc.pl.diffmap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1809
https://github.com/scverse/scanpy/pull/1810:284,safety,review,review,284,Add example plots to sc.pl.rank_genes_groups_dotplot docstring; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Adress one point in #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1810
https://github.com/scverse/scanpy/pull/1810:284,testability,review,review,284,Add example plots to sc.pl.rank_genes_groups_dotplot docstring; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Adress one point in #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1810
https://github.com/scverse/scanpy/pull/1810:135,usability,guid,guidelines,135,Add example plots to sc.pl.rank_genes_groups_dotplot docstring; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Adress one point in #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1810
https://github.com/scverse/scanpy/pull/1810:166,usability,guid,guide,166,Add example plots to sc.pl.rank_genes_groups_dotplot docstring; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Adress one point in #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1810
https://github.com/scverse/scanpy/pull/1810:262,usability,workflow,workflow,262,Add example plots to sc.pl.rank_genes_groups_dotplot docstring; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Adress one point in #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1810
https://github.com/scverse/scanpy/pull/1812:55,usability,document,documentation,55,"Added example plot for pca overview; Adds examples for documentation of `pca_overview()`, see issue #1661",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1812
https://github.com/scverse/scanpy/pull/1814:245,safety,review,review,245,add violin plot example; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add violin plot examples according to https://github.com/theislab/scanpy/issues/1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1814
https://github.com/scverse/scanpy/pull/1814:245,testability,review,review,245,add violin plot example; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add violin plot examples according to https://github.com/theislab/scanpy/issues/1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1814
https://github.com/scverse/scanpy/pull/1814:96,usability,guid,guidelines,96,add violin plot example; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add violin plot examples according to https://github.com/theislab/scanpy/issues/1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1814
https://github.com/scverse/scanpy/pull/1814:127,usability,guid,guide,127,add violin plot example; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add violin plot examples according to https://github.com/theislab/scanpy/issues/1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1814
https://github.com/scverse/scanpy/pull/1814:223,usability,workflow,workflow,223,add violin plot example; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Add violin plot examples according to https://github.com/theislab/scanpy/issues/1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1814
https://github.com/scverse/scanpy/pull/1815:22,energy efficiency,load,loadings,22,added example for PCA loadings plot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ref #1664 sc.pl.pca_loadings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1815
https://github.com/scverse/scanpy/pull/1815:22,performance,load,loadings,22,added example for PCA loadings plot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ref #1664 sc.pl.pca_loadings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1815
https://github.com/scverse/scanpy/pull/1815:257,safety,review,review,257,added example for PCA loadings plot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ref #1664 sc.pl.pca_loadings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1815
https://github.com/scverse/scanpy/pull/1815:257,testability,review,review,257,added example for PCA loadings plot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ref #1664 sc.pl.pca_loadings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1815
https://github.com/scverse/scanpy/pull/1815:108,usability,guid,guidelines,108,added example for PCA loadings plot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ref #1664 sc.pl.pca_loadings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1815
https://github.com/scverse/scanpy/pull/1815:139,usability,guid,guide,139,added example for PCA loadings plot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ref #1664 sc.pl.pca_loadings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1815
https://github.com/scverse/scanpy/pull/1815:235,usability,workflow,workflow,235,added example for PCA loadings plot; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. ref #1664 sc.pl.pca_loadings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1815
https://github.com/scverse/scanpy/issues/1816:34,deployability,updat,updating,34,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:165,deployability,version,version,165,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:577,deployability,Version,Versions,577,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2104,deployability,log,logical,2104,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2156,deployability,updat,updated,2156,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:771,energy efficiency,cloud,cloudpickle,771,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2112,energy efficiency,CPU,CPU,2112,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2116,energy efficiency,core,cores,2116,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:165,integrability,version,version,165,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:435,integrability,compon,components,435,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:577,integrability,Version,Versions,577,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:435,interoperability,compon,components,435,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:165,modifiability,version,version,165,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:435,modifiability,compon,components,435,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:577,modifiability,Version,Versions,577,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:885,modifiability,deco,decorator,885,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:1297,modifiability,pac,packaging,1297,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:740,performance,bottleneck,bottleneck,740,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2112,performance,CPU,CPU,2112,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:34,safety,updat,updating,34,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2104,safety,log,logical,2104,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2156,safety,updat,updated,2156,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:34,security,updat,updating,34,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2104,security,log,logical,2104,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2136,security,Session,Session,2136,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2156,security,updat,updated,2156,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2104,testability,log,logical,2104,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:125,usability,confirm,confirmed,125,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:208,usability,confirm,confirmed,208,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:275,usability,Minim,Minimal,275,"sc.datasets.pbmc68k_reduced needs updating; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:1785,usability,tool,toolz,1785,"nal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.datasets.pbmc68k_reduced(). sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb. ValueError: Axis limits cannot be NaN or Inf. ```. **Note**: recalculating pca solves the problem . #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.8.0.dev78+gc488909a. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appnope 0.1.0. attr 19.3.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.20.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.33.0+1.g022ab0f. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.2.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.0. nbformat 5.0.7. numba 0.50.1. numexpr 2.7.1. numpy 1.18.5. packaging 20.4. pandas 1.0.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pvectorc NA. pygments 2.6.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. scanpy 1.8.0.dev78+gc488909a. scipy 1.5.0. seaborn 0.10.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.1. sphinxcontrib NA. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.3. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-04-27 11:22. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1817:24,availability,recov,recover,24,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:195,availability,recov,recover,195,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:253,availability,slo,slow,253,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:24,deployability,recov,recover,24,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:195,deployability,recov,recover,195,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:24,reliability,recov,recover,24,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:195,reliability,recov,recover,195,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:253,reliability,slo,slow,253,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:24,safety,recov,recover,24,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:118,safety,input,input,118,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:195,safety,recov,recover,195,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:24,security,recov,recover,24,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:64,security,team,team,64,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:195,security,recov,recover,195,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:118,usability,input,input,118,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:275,usability,tip,tips,275,"What is the best way to recover raw count to adata.X; Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips? ```. ad.X = ad.obsm['raw_data'].copy(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1818:698,deployability,integr,integrate,698,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:698,integrability,integr,integrate,698,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:698,interoperability,integr,integrate,698,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:1091,interoperability,specif,specific,1091,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:127,modifiability,paramet,parameters,127,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:404,modifiability,pac,package,404,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:615,modifiability,layer,layer-multiplex,615,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:698,modifiability,integr,integrate,698,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:935,modifiability,extens,extensively,935,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:0,performance,Multiplex,Multiplex,0,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:514,performance,multiplex,multiplex,514,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:600,performance,multiplex,multiplex,600,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:621,performance,multiplex,multiplex,621,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:698,reliability,integr,integrate,698,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:20,safety,detect,detection,20,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:534,safety,detect,detection,534,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:20,security,detect,detection,20,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:534,security,detect,detection,534,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:698,security,integr,integrate,698,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:209,testability,simpl,simple,209,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:684,testability,simpl,simple,684,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:698,testability,integr,integrate,698,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:201,usability,tool,tool,201,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:209,usability,simpl,simple,209,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:225,usability,tool,tool,225,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:273,usability,tool,tools,273,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:373,usability,tool,tools,373,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:684,usability,simpl,simple,684,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:872,usability,multi-mod,multi-modal,872,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:1148,usability,user,users,1148,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:1567,usability,tool,tool,1567,"Multiplex community detection with Leiden; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:. - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph. - creating a separate function `sc.tl.leiden_multiplex`. Any thoughts on this @ivirshup @Koncopd ? I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts! worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580. although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/pull/1819:0,deployability,Updat,Update,0,Update _louvain.py; i added a resolution parameter for the flavor rapids within the louvain function. Since it right now doesn't allow this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1819
https://github.com/scverse/scanpy/pull/1819:41,modifiability,paramet,parameter,41,Update _louvain.py; i added a resolution parameter for the flavor rapids within the louvain function. Since it right now doesn't allow this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1819
https://github.com/scverse/scanpy/pull/1819:121,reliability,doe,doesn,121,Update _louvain.py; i added a resolution parameter for the flavor rapids within the louvain function. Since it right now doesn't allow this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1819
https://github.com/scverse/scanpy/pull/1819:0,safety,Updat,Update,0,Update _louvain.py; i added a resolution parameter for the flavor rapids within the louvain function. Since it right now doesn't allow this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1819
https://github.com/scverse/scanpy/pull/1819:0,security,Updat,Update,0,Update _louvain.py; i added a resolution parameter for the flavor rapids within the louvain function. Since it right now doesn't allow this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1819
https://github.com/scverse/scanpy/pull/1820:17,modifiability,paramet,parameter,17,added resolution parameter for flavor rapids with the louvain fuction; I added resolution parameter for flavor rapids with the louvain fuction.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1820
https://github.com/scverse/scanpy/pull/1820:90,modifiability,paramet,parameter,90,added resolution parameter for flavor rapids with the louvain fuction; I added resolution parameter for flavor rapids with the louvain fuction.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1820
https://github.com/scverse/scanpy/pull/1821:39,deployability,continu,continuous,39,remove colorbar if legend_loc=None for continuous colorbars; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1821:352,deployability,continu,continuous,352,remove colorbar if legend_loc=None for continuous colorbars; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1821:281,safety,review,review,281,remove colorbar if legend_loc=None for continuous colorbars; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1821:281,testability,review,review,281,remove colorbar if legend_loc=None for continuous colorbars; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1821:132,usability,guid,guidelines,132,remove colorbar if legend_loc=None for continuous colorbars; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1821:163,usability,guid,guide,163,remove colorbar if legend_loc=None for continuous colorbars; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1821:259,usability,workflow,workflow,259,remove colorbar if legend_loc=None for continuous colorbars; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1821:294,usability,close,closes,294,remove colorbar if legend_loc=None for continuous colorbars; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1822:457,modifiability,paramet,parameter,457,"bug fix: hue in sc.pl.violin; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closses #1174 . hue key is now added to keys if hue is in kwds. before obs_tidy did not include this keyword, so this resulted in an ValueError. an alternative would be to add hue as a function parameter to `sc.pl.violin`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1822
https://github.com/scverse/scanpy/pull/1822:250,safety,review,review,250,"bug fix: hue in sc.pl.violin; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closses #1174 . hue key is now added to keys if hue is in kwds. before obs_tidy did not include this keyword, so this resulted in an ValueError. an alternative would be to add hue as a function parameter to `sc.pl.violin`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1822
https://github.com/scverse/scanpy/pull/1822:250,testability,review,review,250,"bug fix: hue in sc.pl.violin; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closses #1174 . hue key is now added to keys if hue is in kwds. before obs_tidy did not include this keyword, so this resulted in an ValueError. an alternative would be to add hue as a function parameter to `sc.pl.violin`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1822
https://github.com/scverse/scanpy/pull/1822:101,usability,guid,guidelines,101,"bug fix: hue in sc.pl.violin; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closses #1174 . hue key is now added to keys if hue is in kwds. before obs_tidy did not include this keyword, so this resulted in an ValueError. an alternative would be to add hue as a function parameter to `sc.pl.violin`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1822
https://github.com/scverse/scanpy/pull/1822:132,usability,guid,guide,132,"bug fix: hue in sc.pl.violin; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closses #1174 . hue key is now added to keys if hue is in kwds. before obs_tidy did not include this keyword, so this resulted in an ValueError. an alternative would be to add hue as a function parameter to `sc.pl.violin`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1822
https://github.com/scverse/scanpy/pull/1822:228,usability,workflow,workflow,228,"bug fix: hue in sc.pl.violin; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. closses #1174 . hue key is now added to keys if hue is in kwds. before obs_tidy did not include this keyword, so this resulted in an ValueError. an alternative would be to add hue as a function parameter to `sc.pl.violin`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1822
https://github.com/scverse/scanpy/issues/1823:7,deployability,fail,fails,7,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:166,deployability,version,version,166,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:503,deployability,instal,installation,503,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:745,deployability,Version,Versions,745,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:659,energy efficiency,core,core,659,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:166,integrability,version,version,166,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:745,integrability,Version,Versions,745,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:166,modifiability,version,version,166,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:745,modifiability,Version,Versions,745,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:7,reliability,fail,fails,7,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:126,usability,confirm,confirmed,126,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:209,usability,confirm,confirmed,209,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1823:408,usability,Minim,Minimal,408,scanpy fails in conda env with python 3.9.4; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---. ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python. import scanpy as sc. ```. returns:. ```pytb. Illegal instruction (core dumped). ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions. scanpy 1.7.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1824:628,deployability,stack,stacked,628,"how to plot cell types, medication per cohort in one figure ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1824:671,interoperability,distribut,distribution,671,"how to plot cell types, medication per cohort in one figure ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1824:146,modifiability,paramet,parameters,146,"how to plot cell types, medication per cohort in one figure ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1824:423,modifiability,pac,package,423,"how to plot cell types, medication per cohort in one figure ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1824:228,testability,simpl,simple,228,"how to plot cell types, medication per cohort in one figure ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1824:220,usability,tool,tool,220,"how to plot cell types, medication per cohort in one figure ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1824:228,usability,simpl,simple,228,"how to plot cell types, medication per cohort in one figure ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1824:244,usability,tool,tool,244,"how to plot cell types, medication per cohort in one figure ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1824:292,usability,tool,tools,292,"how to plot cell types, medication per cohort in one figure ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1824:392,usability,tool,tools,392,"how to plot cell types, medication per cohort in one figure ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1825:190,deployability,version,version,190,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:868,deployability,modul,module,868,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:1422,deployability,Version,Versions,1422,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2262,deployability,log,logical,2262,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2314,deployability,updat,updated,2314,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:1292,energy efficiency,model,model,1292," The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2270,energy efficiency,CPU,CPU,2270,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2274,energy efficiency,core,cores,2274,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:190,integrability,version,version,190,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:646,integrability,sub,subset,646,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:966,integrability,sub,subset,966,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:1422,integrability,Version,Versions,1422,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:190,modifiability,version,version,190,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:868,modifiability,modul,module,868,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:1016,modifiability,pac,packages,1016,"highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:1188,modifiability,pac,packages,1188,"rsion of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [C",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:1422,modifiability,Version,Versions,1422,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:1854,modifiability,pac,packaging,1854,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2270,performance,CPU,CPU,2270,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:346,safety,input,inputs,346,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:868,safety,modul,module,868,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2262,safety,log,logical,2262,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2314,safety,updat,updated,2314,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:735,security,ident,ident,735,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:1292,security,model,model,1292," The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2262,security,log,logical,2262,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2294,security,Session,Session,2294,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2314,security,updat,updated,2314,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:802,testability,Trace,Traceback,802,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2262,testability,log,logical,2262,"See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.22.2.post1. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. -----. Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2021-05-03 11:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:150,usability,confirm,confirmed,150,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:233,usability,confirm,confirmed,233,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:346,usability,input,inputs,346,"ValueError at sc.pp.highly_variable_genes() using seurat_v3 flavor.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The seurat_v3 flavor for HVGs can not run on some inputs. See below. ```python. import scanpy as sc. x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'). x.var_names_make_unique(). print(x). sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). ```. ```pytb. AnnData object with n_obs × n_vars = 600 × 32838. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'. var: 'features'. Traceback (most recent call last):. File ""./main.py"", line 8, in <module>. sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True). File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3. model.fit(). File ""_loess.pyx"", line 899, in _loess.loess.fit. ValueError: b'reciprocal condition number 3.9554e-16\n'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.3. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.18.1. packaging 20.8. pandas 1.0.1. pkg_resources NA. psutil 5.8.0. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.4.1. setuptools_scm NA. sinfo 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1826:608,energy efficiency,frequenc,frequency,608,correlation between cell types and obs variables ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1826:39,modifiability,variab,variables,39,correlation between cell types and obs variables ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1826:135,modifiability,paramet,parameters,135,correlation between cell types and obs variables ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1826:412,modifiability,pac,package,412,correlation between cell types and obs variables ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1826:217,testability,simpl,simple,217,correlation between cell types and obs variables ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1826:209,usability,tool,tool,209,correlation between cell types and obs variables ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1826:217,usability,simpl,simple,217,correlation between cell types and obs variables ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1826:233,usability,tool,tool,233,correlation between cell types and obs variables ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1826:281,usability,tool,tools,281,correlation between cell types and obs variables ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1826:381,usability,tool,tools,381,correlation between cell types and obs variables ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1827:223,deployability,version,version,223,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:1233,deployability,Version,Versions,1233,"npy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3184,deployability,log,logical,3184,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3238,deployability,updat,updated,3238,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:692,energy efficiency,cool,coolwarm,692,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:1487,energy efficiency,cloud,cloudpickle,1487,"in_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3192,energy efficiency,CPU,CPU,3192,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3196,energy efficiency,core,cores,3196,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:223,integrability,version,version,223,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:788,integrability,filter,filtering,788,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:907,integrability,filter,filtering,907,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:1022,integrability,filter,filtering,1022,"th ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:1233,integrability,Version,Versions,1233,"npy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:2932,integrability,wrap,wrapt,2932,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:2282,interoperability,plug,pluggy,2282,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:85,modifiability,layer,layer,85,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:223,modifiability,version,version,223,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:389,modifiability,layer,layer,389,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:735,modifiability,layer,layer,735,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:860,modifiability,layer,layer,860,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:1233,modifiability,Version,Versions,1233,"npy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:1639,modifiability,deco,decorator,1639,"_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:2169,modifiability,pac,packaging,2169,"change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3192,performance,CPU,CPU,3192,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:71,reliability,doe,does,71,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:775,safety,input,input,775,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3184,safety,log,logical,3184,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3238,safety,updat,updated,3238,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:1439,security,certif,certifi,1439,"es_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3184,security,log,logical,3184,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3218,security,Session,Session,3218,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3238,security,updat,updated,3238,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3184,testability,log,logical,3184,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:183,usability,confirm,confirmed,183,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:251,usability,Minim,Minimal,251,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:775,usability,input,input,775,"rank_genes_groups issues with ZScore data and filter_rank_genes_groups does not have layer option ; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(adz,groupby='Phenograph_cluster',layer='norm',use_raw=0,method='wilcoxon',key='rank_genes_groups'). sc.tl.filter_rank_genes_groups(adz, min_fold_change=1,min_in_group_fraction=0.2,max_out_group_fraction=0.5,key='rank_genes_groups',use_raw=0). sc.pl.rank_genes_groups_dotplot(adz,key='rank_genes_groups_filtered',n_genes=10,vmax=5,cmap='coolwarm'). ```. 1. When I did not provide layer option and only work with z score input. After filtering there is no genes left. 2. When I add non-z score data into a layer and provide it to rank gene group. after filtering, no genes left even when I do min_fold 0, min_in_group 0, max out group 1. I think something is wrong on filtering step... I dont know what are the data it is looking. I checked the fold change stuff and it all looks normal after rank_genes_groups. 3. if I change the X data to non- z score one, all look fine. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:2807,usability,tool,toolz,2807,"anpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. attr 20.1.0. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.3. colorlog NA. cupy 7.8.0. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.1. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fastrlock 0.5. fsspec 0.8.7. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. iniconfig NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. pluggy 0.13.1. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. py 1.9.0. pyarrow 0.16.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytest 6.1.2. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. skmisc 0.1.3. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. tblib 1.7.0. texttable 1.6.2. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. typing_extensions NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-03 16:30. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/pull/1828:391,energy efficiency,current,currently,391,"Bugfix in RAPIDS usage for neighbors(), and support for additional distance metrics; Now that RAPIDS/cuML [supports multiple distance metrics for kNN graphs](https://github.com/rapidsai/cuml/issues/2104):. 1. cuML no longer returns squared Euclidean distances by default. I believe we should not be square-rooting the kNN distance matrix. 2. Calling `sc.pp.neighbors` with `method='rapids'` currently requires `metric='euclidean'`. I believe we should loosen this restriction and pass the requested `metric` on to cuML. (Big fan — thanks for the excellent library!).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1828
https://github.com/scverse/scanpy/pull/1828:44,usability,support,support,44,"Bugfix in RAPIDS usage for neighbors(), and support for additional distance metrics; Now that RAPIDS/cuML [supports multiple distance metrics for kNN graphs](https://github.com/rapidsai/cuml/issues/2104):. 1. cuML no longer returns squared Euclidean distances by default. I believe we should not be square-rooting the kNN distance matrix. 2. Calling `sc.pp.neighbors` with `method='rapids'` currently requires `metric='euclidean'`. I believe we should loosen this restriction and pass the requested `metric` on to cuML. (Big fan — thanks for the excellent library!).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1828
https://github.com/scverse/scanpy/pull/1828:107,usability,support,supports,107,"Bugfix in RAPIDS usage for neighbors(), and support for additional distance metrics; Now that RAPIDS/cuML [supports multiple distance metrics for kNN graphs](https://github.com/rapidsai/cuml/issues/2104):. 1. cuML no longer returns squared Euclidean distances by default. I believe we should not be square-rooting the kNN distance matrix. 2. Calling `sc.pp.neighbors` with `method='rapids'` currently requires `metric='euclidean'`. I believe we should loosen this restriction and pass the requested `metric` on to cuML. (Big fan — thanks for the excellent library!).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1828
https://github.com/scverse/scanpy/issues/1829:929,availability,robust,robust,929,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:991,deployability,observ,observation,991,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:968,energy efficiency,cool,cool,968,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:1143,integrability,filter,filtering,1143,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:122,modifiability,paramet,parameters,122,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:399,modifiability,pac,package,399,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:572,modifiability,variab,variables,572,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:929,reliability,robust,robust,929,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:929,safety,robust,robust,929,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:940,safety,avoid,avoid,940,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:204,testability,simpl,simple,204,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:991,testability,observ,observation,991,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:0,usability,Minim,Minimum,0,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:196,usability,tool,tool,196,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:204,usability,simpl,simple,204,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:220,usability,tool,tool,220,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:268,usability,tool,tools,268,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:368,usability,tool,tools,368,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:521,usability,visual,visualize,521,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:983,usability,minim,minimum,983,"Minimum cell cutoff in sc.pl.dotplot; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1831:54,energy efficiency,frequenc,frequency,54,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:570,energy efficiency,frequenc,frequency,570,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:173,modifiability,paramet,parameters,173,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:450,modifiability,pac,package,450,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:18,safety,test,test,18,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:604,safety,test,test,604,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:619,security,ident,identify,619,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:628,security,sign,significant,628,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:18,testability,test,test,18,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:255,testability,simpl,simple,255,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:604,testability,test,test,604,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:247,usability,tool,tool,247,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:255,usability,simpl,simple,255,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:271,usability,tool,tool,271,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:319,usability,tool,tools,319,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:419,usability,tool,tools,419,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:680,usability,user,user-images,680,"Which statistical test to use to see which cell types frequency differ between cohorts?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi, . If this is frequency table per cohort. which test to use to identify significant cell type per group? . ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1832:113,availability,consist,consistent,113,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:397,availability,consist,consistent,397,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:658,availability,mainten,maintenance,658,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1378,availability,consist,consistent,1378," encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `Ann",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:221,deployability,build,building,221,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:417,deployability,API,API,417,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1480,deployability,API,API,1480,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1794,deployability,stack,stacked,1794,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1849,deployability,stack,stackedbarplot,1849,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1912,deployability,modul,modules,1912,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1939,deployability,stack,stackedbarplot,1939,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1978,deployability,stack,stackedbarplot,1978,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:2020,deployability,api,api,2020,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:2133,deployability,api,api,2133,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:621,energy efficiency,Reduc,Reducing,621,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:646,energy efficiency,reduc,reduces,646,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:417,integrability,API,API,417,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:439,integrability,abstract,abstract,439,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1480,integrability,API,API,1480,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:2020,integrability,api,api,2020,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:2133,integrability,api,api,2133,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:417,interoperability,API,API,417,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1480,interoperability,API,API,1480,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:2020,interoperability,api,api,2020,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:2133,interoperability,api,api,2133,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:439,modifiability,abstract,abstract,439,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1912,modifiability,modul,modules,1912,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:658,reliability,mainten,maintenance,658,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1912,safety,modul,modules,1912,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:113,usability,consist,consistent,113,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:321,usability,help,helper,321,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:397,usability,consist,consistent,397,"Common plotting library for the Scanpy ecosystem; I was wondering if plotting could be facilitated and made more consistent across . the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1217,usability,help,helper,1217," building blocks for single-cell-related plots which can be re-used across the ecosystem. * provides helper functions for handling colors, saving figures, etc. . * encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abunda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1378,usability,consist,consistent,1378," encourages a consistent plotting API (e.g. by defining abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `Ann",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:1547,usability,help,helper,1547,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:2078,usability,tool,toolbox,2078,"ning abstract base classes). * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:. * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:. - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. . - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db). - scvelo has its own `scatter`. * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). . * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_stacked_barplot`](https://sc-toolbox.readthedocs.io/en/latest/usage.html#sc_toolbox.api.plot.cluster_composition_stacked_barplot) by @Zethson, and [`scirpy.pl.group_abundance`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.group_abundance.html#scirpy.pl.group_abundance) by myself). Maybe such more general plots based on `AnnData` could be part of a central library as well. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1833:263,usability,user,user-images,263,"ingest after bbknn produces poor results; Hi,. I tried ingest using the reference made with BBKNN. As @ivirshup said, ingest was worked by adding `adata_ref.uns['neighbors']['params']['metric'] = 'euclidean'`. However, the result was quite poor. ![image](https://user-images.githubusercontent.com/19543497/117822090-2aaa0480-b2a7-11eb-80ea-a31240861a4b.png). In contrast, if I merge all datasets (eg references and query), it worked well, but when we want to take over the reference embedding, I actually want to use ingest rather than run bbknn again. Is there any option to feed in this case? or should I ask this in the BBKNN repo? ![image](https://user-images.githubusercontent.com/19543497/117822235-562cef00-b2a7-11eb-875f-262452baff0d.png). This is the notebook can reproduce the problem. https://nbviewer.jupyter.org/github/yyoshiaki/ingest_after_bbknn/blob/main/notebook.ipynb. https://github.com/yyoshiaki/ingest_after_bbknn/blob/main/notebook.ipynb. _Originally posted by @yyoshiaki in https://github.com/theislab/scanpy/issues/1122#issuecomment-838476193_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1833
https://github.com/scverse/scanpy/issues/1833:652,usability,user,user-images,652,"ingest after bbknn produces poor results; Hi,. I tried ingest using the reference made with BBKNN. As @ivirshup said, ingest was worked by adding `adata_ref.uns['neighbors']['params']['metric'] = 'euclidean'`. However, the result was quite poor. ![image](https://user-images.githubusercontent.com/19543497/117822090-2aaa0480-b2a7-11eb-80ea-a31240861a4b.png). In contrast, if I merge all datasets (eg references and query), it worked well, but when we want to take over the reference embedding, I actually want to use ingest rather than run bbknn again. Is there any option to feed in this case? or should I ask this in the BBKNN repo? ![image](https://user-images.githubusercontent.com/19543497/117822235-562cef00-b2a7-11eb-875f-262452baff0d.png). This is the notebook can reproduce the problem. https://nbviewer.jupyter.org/github/yyoshiaki/ingest_after_bbknn/blob/main/notebook.ipynb. https://github.com/yyoshiaki/ingest_after_bbknn/blob/main/notebook.ipynb. _Originally posted by @yyoshiaki in https://github.com/theislab/scanpy/issues/1122#issuecomment-838476193_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1833
https://github.com/scverse/scanpy/issues/1835:8,availability,sla,slack,8,Add dev slack link to docs; Like numpy: https://numpy.org/community/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1835
https://github.com/scverse/scanpy/issues/1835:8,reliability,sla,slack,8,Add dev slack link to docs; Like numpy: https://numpy.org/community/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1835
https://github.com/scverse/scanpy/issues/1837:274,availability,error,error,274,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:462,deployability,version,version,462,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1112,deployability,modul,module,1112,"doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1695,deployability,updat,update,1695,"he necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1986,deployability,Version,Versions,1986,"----------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4710,deployability,log,logical,4710,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4764,deployability,updat,updated,4764,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:2322,energy efficiency,cloud,cloudpickle,2322," method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4718,energy efficiency,CPU,CPU,4718,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4722,energy efficiency,core,cores,4722,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:462,integrability,version,version,462,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1986,integrability,Version,Versions,1986,"----------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4408,integrability,wrap,wrapt,4408,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1937,interoperability,format,format,1937,"ve not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:2647,interoperability,distribut,distributed,2647,"y in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynnd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:462,modifiability,version,version,462,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1112,modifiability,modul,module,1112,"doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1170,modifiability,pac,packages,1170,".umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. att",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1613,modifiability,pac,packages,1613,"wrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1732,modifiability,paramet,parameters,1732,"oduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. futu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1844,modifiability,deco,decorator,1844,"adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1986,modifiability,Version,Versions,1986,"----------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:2630,modifiability,deco,decorator,2630,"s/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:3351,modifiability,pac,packaging,3351, cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. u,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4589,modifiability,pac,packaged,4589,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:274,performance,error,error,274,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1096,performance,time,timed,1096,"ince cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:2227,performance,cach,cachetools,2227,", n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:3264,performance,network,networkx,3264, 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4718,performance,CPU,CPU,4718,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:14,reliability,doe,doesn,14,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:115,reliability,doe,doesn,115,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:274,safety,error,error,274,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1112,safety,modul,module,1112,"doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1372,safety,valid,valid,1372,"ue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1695,safety,updat,update,1695,"he necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1819,safety,prevent,prevent,1819,"a). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4710,safety,log,logical,4710,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4764,safety,updat,updated,4764,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1695,security,updat,update,1695,"he necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1819,security,preven,prevent,1819,"a). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:2261,security,certif,certifi,2261,"amma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel 2.9.0. backcall 0.2.0. brotli 1.0.9. cachetools 4.2.2. cellrank 1.3.1. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:3264,security,network,networkx,3264, 2020.12.05. cffi 1.14.4. chardet 4.0.0. click 7.1.2. cloudpickle 1.6.0. colorama 0.4.4. cudf 0.20.0a+294.gfbb9a988fa. cugraph 0.20.0a+65.g924f6782.dirty. cuml 0.20.0a+110.gab47f2e11. cupy 9.0.0. cupy_backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:3970,security,soc,socks,3970,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4710,security,log,logical,4710,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4744,security,Session,Session,4744,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4764,security,updat,updated,4764,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1060,testability,Trace,Traceback,1060," issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4710,testability,log,logical,4710,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:274,usability,error,error,274,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:324,usability,user,user,324,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:422,usability,confirm,confirmed,422,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:505,usability,confirm,confirmed,505,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:596,usability,guid,guide,596,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:651,usability,minim,minimal-bug-reports,651,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:757,usability,Minim,Minimal,757,"UMAP init_pos doesn't work with method rapids; Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1186,usability,tool,tools,1186,"eck if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.umap(adata, init_pos='paga', method='rapids'). ```. ```pytb. WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 221 ) # 0 is not a valid value for rapids, unlike original umap. 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32). --> 223 umap = UMAP(. 224 n_neighbors=n_neighbors,. 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs). 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). 793 . --> 794 return func(**kwargs). 795 . 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. PIL 8.1.2. absl NA. anndata 0.7.6. anyio NA. astunparse 1.6.3. attr 20.3.0. babel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:3463,usability,progress,progressbar,3463,backends NA. cupyx NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dask_cuda 0+unknown. dask_cudf 0.20.0a+294.gfbb9a988fa. dateutil 2.8.1. decorator 4.4.2. distributed 2021.04.0. docrep 0.3.2. fastrlock 0.5. flatbuffers NA. fsspec 2021.04.0. future_fstrings NA. gast NA. get_version 2.1. google NA. h5py 3.1.0. heapdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. --,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4212,usability,tool,toolz,4212,"apdict NA. idna 2.10. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.2. keras_preprocessing 1.1.2. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.4.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. netifaces 0.10.9. networkx 2.5.1. numba 0.53.1. numexpr 2.7.3. numpy 1.19.5. nvtx NA. opt_einsum v3.3.0. packaging 20.8. pandas 1.2.4. parso 0.8.1. petsc4py 3.14.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prometheus_client NA. prompt_toolkit 3.0.10. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 1.0.1. pycparser 2.20. pygam 0.8.0. pygments 2.7.4. pygpcca 1.0.2. pynndescent 0.5.2. pynvml 8.0.4. pyparsing 2.4.7. pyrsistent NA. python_utils NA. pytz 2021.1. requests 2.25.1. rmm 0.20.0a+28.g7768d4d. scanpy 1.7.2. scanpy_gpu_funcs NA. scipy 1.6.3. scvelo 0.2.3. seaborn 0.11.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.2. slepc4py 3.14.0. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.6.0a20210510. tensorflow 2.6.0-dev20210510. termcolor 1.1.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. treelite 1.1.0. treelite_runtime 1.1.0. typing_extensions NA. ucp 0.20.0a+30.g2aa87da. umap 0.5.1. urllib3 1.26.4. virtualenvwrapper NA. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zict 2.0.0. zipp NA. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]. Linux-5.8.0-50-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2021-05-12 13:23. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1838:600,availability,error,errors,600,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:153,deployability,version,version,153,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:1108,deployability,modul,module,1108,"e confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:2046,deployability,Version,Versions,2046,"st recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. backcall 0.2.0. cached_property 1.5.2. cffi 1.14.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. h5py 3.2.1. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. loompy 3.0.6. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.52.0. numexpr 2.7.3. numpy 1.20.2. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.14. ptyprocess 0.7.0. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.6.2. seaborn 0.11.1. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. zipp NA. zmq 20.0.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:153,integrability,version,version,153,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:2046,integrability,Version,Versions,2046,"st recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. backcall 0.2.0. cached_property 1.5.2. cffi 1.14.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. h5py 3.2.1. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. loompy 3.0.6. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.52.0. numexpr 2.7.3. numpy 1.20.2. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.14. ptyprocess 0.7.0. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.6.2. seaborn 0.11.1. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. zipp NA. zmq 20.0.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:153,modifiability,version,version,153,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:652,modifiability,paramet,parameters,652,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:1108,modifiability,modul,module,1108,"e confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:1228,modifiability,pac,packages,1228,"ter branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. backcall 0.2.0. cached_property 1.5.2. cffi 1.14.4. cycler 0.10.0. cython_runtime NA. dat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:1458,modifiability,pac,packages,1458,"ample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. backcall 0.2.0. cached_property 1.5.2. cffi 1.14.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. h5py 3.2.1. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:1700,modifiability,pac,packages,1700,"e-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. backcall 0.2.0. cached_property 1.5.2. cffi 1.14.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. h5py 3.2.1. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. loompy 3.0.6. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.52.0. numexpr 2.7.3. numpy 1.20.2. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:2046,modifiability,Version,Versions,2046,"st recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. backcall 0.2.0. cached_property 1.5.2. cffi 1.14.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. h5py 3.2.1. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. loompy 3.0.6. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.52.0. numexpr 2.7.3. numpy 1.20.2. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.14. ptyprocess 0.7.0. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.6.2. seaborn 0.11.1. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. zipp NA. zmq 20.0.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:2245,modifiability,deco,decorator,2245,"Blood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. backcall 0.2.0. cached_property 1.5.2. cffi 1.14.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. h5py 3.2.1. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. loompy 3.0.6. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.52.0. numexpr 2.7.3. numpy 1.20.2. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.14. ptyprocess 0.7.0. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.6.2. seaborn 0.11.1. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 7.20.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 2.2.9. notebook 6.2.0]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:2614,modifiability,pac,packaging,2614,"Blood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.2.0. anndata 0.7.5. backcall 0.2.0. cached_property 1.5.2. cffi 1.14.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. h5py 3.2.1. igraph 0.9.1. ipykernel 5.4.3. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0. loompy 3.0.6. matplotlib 3.4.1. mpl_toolkits NA. natsort 7.1.1. numba 0.52.0. numexpr 2.7.3. numpy 1.20.2. numpy_groupies 0.9.13. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.14. ptyprocess 0.7.0. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.6.2. seaborn 0.11.1. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 7.20.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 2.2.9. notebook 6.2.0]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:600,performance,error,errors,600,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:600,safety,error,errors,600,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:1081,safety,input,input-,1081," been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:1108,safety,modul,module,1108,"e confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:1037,testability,Trace,Traceback,1037,"ve checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:113,usability,confirm,confirmed,113,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:196,usability,confirm,confirmed,196,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:287,usability,guid,guide,287,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:342,usability,minim,minimal-bug-reports,342,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:448,usability,Minim,Minimal,448,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:550,usability,command,command,550,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:600,usability,error,errors,600,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:782,usability,command,command,782,"Reading csv files with sc.read; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:1081,usability,input,input-,1081," been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though. # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue. # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks. ```. ```pytb. [---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-2f4062a9e25b> in <module>. ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype). 46 Numpy data type. 47 """""". ---> 48 return read_text(filename, delimiter, first_column_names, dtype). 49 . 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype). 323 else:. 324 with filename.open() as f:. --> 325 return _read_text(f, delimiter, first_column_names, dtype). 326 . 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype). 386 first_column_names = True. 387 row_names.append(line_list[0]). --> 388 data.append(np.array(line_list[1:], dtype=dtype)). 389 else:. 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cells']. ```. #### Versions. <details>. [anndata 0.7.5. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1839:448,interoperability,specif,specified,448,"regress_out polynomial effect; I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:. I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677. It seems that the code performs the fitting for all specified variables at once, but I am not sure:. https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701. If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:225,modifiability,variab,variable,225,"regress_out polynomial effect; I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:. I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677. It seems that the code performs the fitting for all specified variables at once, but I am not sure:. https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701. If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:458,modifiability,variab,variables,458,"regress_out polynomial effect; I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:. I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677. It seems that the code performs the fitting for all specified variables at once, but I am not sure:. https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701. If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:419,performance,perform,performs,419,"regress_out polynomial effect; I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:. I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677. It seems that the code performs the fitting for all specified variables at once, but I am not sure:. https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701. If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:155,reliability,nonlinear,nonlinear,155,"regress_out polynomial effect; I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:. I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677. It seems that the code performs the fitting for all specified variables at once, but I am not sure:. https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701. If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:143,testability,regress,regress,143,"regress_out polynomial effect; I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:. I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677. It seems that the code performs the fitting for all specified variables at once, but I am not sure:. https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701. If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:798,testability,understand,understand,798,"regress_out polynomial effect; I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:. I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677. It seems that the code performs the fitting for all specified variables at once, but I am not sure:. https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701. If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:103,usability,confirm,confirm,103,"regress_out polynomial effect; I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:. I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677. It seems that the code performs the fitting for all specified variables at once, but I am not sure:. https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701. If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:419,usability,perform,performs,419,"regress_out polynomial effect; I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:. I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677. It seems that the code performs the fitting for all specified variables at once, but I am not sure:. https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701. If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:785,usability,confirm,confirm,785,"regress_out polynomial effect; I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:. I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677. It seems that the code performs the fitting for all specified variables at once, but I am not sure:. https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701. If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1840:284,availability,error,errors,284,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:0,deployability,Instal,Installing,0,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:68,deployability,instal,installing,68,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:114,deployability,instal,installing,114,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:135,deployability,version,version,135,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:249,deployability,instal,installation,249,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:278,deployability,build,build,278,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:135,integrability,version,version,135,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:333,integrability,discover,discovered,333,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:333,interoperability,discover,discovered,333,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:135,modifiability,version,version,135,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:284,performance,error,errors,284,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:284,safety,error,errors,284,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:225,usability,document,documentation,225,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:284,usability,error,errors,284,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:312,usability,command,commands,312,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:333,usability,discov,discovered,333,"Installing scanpy on M1 Apple Silicone; I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1841:0,deployability,Fail,Failing,0,"Failing to detect ipython; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Initially reported by @VolkerBergen in #1477. From within ipython:. ```python. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). # False. getattr(__builtins__, ""__IPYTHON__""). # True. ```. I'm not sure if/ how this ever worked, [since `__builtins__` is supposed to be a `dict` unless you're in the `__main__` namespace](https://docs.python.org/3/reference/executionmodel.html#builtins-and-restricted-execution). We can probably replace this with:. ```python. import builtins. getattr(builtins, ""__IPYTHON__"", False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1841
https://github.com/scverse/scanpy/issues/1841:148,deployability,version,version,148,"Failing to detect ipython; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Initially reported by @VolkerBergen in #1477. From within ipython:. ```python. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). # False. getattr(__builtins__, ""__IPYTHON__""). # True. ```. I'm not sure if/ how this ever worked, [since `__builtins__` is supposed to be a `dict` unless you're in the `__main__` namespace](https://docs.python.org/3/reference/executionmodel.html#builtins-and-restricted-execution). We can probably replace this with:. ```python. import builtins. getattr(builtins, ""__IPYTHON__"", False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1841
https://github.com/scverse/scanpy/issues/1841:148,integrability,version,version,148,"Failing to detect ipython; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Initially reported by @VolkerBergen in #1477. From within ipython:. ```python. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). # False. getattr(__builtins__, ""__IPYTHON__""). # True. ```. I'm not sure if/ how this ever worked, [since `__builtins__` is supposed to be a `dict` unless you're in the `__main__` namespace](https://docs.python.org/3/reference/executionmodel.html#builtins-and-restricted-execution). We can probably replace this with:. ```python. import builtins. getattr(builtins, ""__IPYTHON__"", False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1841
https://github.com/scverse/scanpy/issues/1841:148,modifiability,version,version,148,"Failing to detect ipython; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Initially reported by @VolkerBergen in #1477. From within ipython:. ```python. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). # False. getattr(__builtins__, ""__IPYTHON__""). # True. ```. I'm not sure if/ how this ever worked, [since `__builtins__` is supposed to be a `dict` unless you're in the `__main__` namespace](https://docs.python.org/3/reference/executionmodel.html#builtins-and-restricted-execution). We can probably replace this with:. ```python. import builtins. getattr(builtins, ""__IPYTHON__"", False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1841
https://github.com/scverse/scanpy/issues/1841:0,reliability,Fail,Failing,0,"Failing to detect ipython; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Initially reported by @VolkerBergen in #1477. From within ipython:. ```python. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). # False. getattr(__builtins__, ""__IPYTHON__""). # True. ```. I'm not sure if/ how this ever worked, [since `__builtins__` is supposed to be a `dict` unless you're in the `__main__` namespace](https://docs.python.org/3/reference/executionmodel.html#builtins-and-restricted-execution). We can probably replace this with:. ```python. import builtins. getattr(builtins, ""__IPYTHON__"", False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1841
https://github.com/scverse/scanpy/issues/1841:11,safety,detect,detect,11,"Failing to detect ipython; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Initially reported by @VolkerBergen in #1477. From within ipython:. ```python. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). # False. getattr(__builtins__, ""__IPYTHON__""). # True. ```. I'm not sure if/ how this ever worked, [since `__builtins__` is supposed to be a `dict` unless you're in the `__main__` namespace](https://docs.python.org/3/reference/executionmodel.html#builtins-and-restricted-execution). We can probably replace this with:. ```python. import builtins. getattr(builtins, ""__IPYTHON__"", False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1841
https://github.com/scverse/scanpy/issues/1841:11,security,detect,detect,11,"Failing to detect ipython; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Initially reported by @VolkerBergen in #1477. From within ipython:. ```python. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). # False. getattr(__builtins__, ""__IPYTHON__""). # True. ```. I'm not sure if/ how this ever worked, [since `__builtins__` is supposed to be a `dict` unless you're in the `__main__` namespace](https://docs.python.org/3/reference/executionmodel.html#builtins-and-restricted-execution). We can probably replace this with:. ```python. import builtins. getattr(builtins, ""__IPYTHON__"", False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1841
https://github.com/scverse/scanpy/issues/1841:108,usability,confirm,confirmed,108,"Failing to detect ipython; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Initially reported by @VolkerBergen in #1477. From within ipython:. ```python. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). # False. getattr(__builtins__, ""__IPYTHON__""). # True. ```. I'm not sure if/ how this ever worked, [since `__builtins__` is supposed to be a `dict` unless you're in the `__main__` namespace](https://docs.python.org/3/reference/executionmodel.html#builtins-and-restricted-execution). We can probably replace this with:. ```python. import builtins. getattr(builtins, ""__IPYTHON__"", False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1841
https://github.com/scverse/scanpy/issues/1841:191,usability,confirm,confirmed,191,"Failing to detect ipython; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Initially reported by @VolkerBergen in #1477. From within ipython:. ```python. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). # False. getattr(__builtins__, ""__IPYTHON__""). # True. ```. I'm not sure if/ how this ever worked, [since `__builtins__` is supposed to be a `dict` unless you're in the `__main__` namespace](https://docs.python.org/3/reference/executionmodel.html#builtins-and-restricted-execution). We can probably replace this with:. ```python. import builtins. getattr(builtins, ""__IPYTHON__"", False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1841
https://github.com/scverse/scanpy/issues/1842:179,deployability,version,version,179,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:538,deployability,api,api,538,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:1045,energy efficiency,current,current,1045,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:179,integrability,version,version,179,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:538,integrability,api,api,538,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:446,interoperability,format,format,446,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:474,interoperability,format,format,474,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:538,interoperability,api,api,538,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:1007,interoperability,compatib,compatible,1007,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:1061,interoperability,format,format,1061,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:1150,interoperability,format,format,1150,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:179,modifiability,version,version,179,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:687,modifiability,pac,package,687,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:344,safety,detect,detects,344,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:344,security,detect,detects,344,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:380,security,session,session,380,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:139,usability,confirm,confirmed,139,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:222,usability,confirm,confirmed,222,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:1101,usability,undo,undocumented,1101,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:1139,usability,document,documented,1139,"Deprecated use of IPython.display.set_matplotlib_formats; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python. import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format). ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/pull/1843:14,deployability,build,builds,14,Remove travis builds; Gets rid of travis builds.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1843
https://github.com/scverse/scanpy/pull/1843:41,deployability,build,builds,41,Remove travis builds; Gets rid of travis builds.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1843
https://github.com/scverse/scanpy/pull/1844:253,deployability,Releas,Release,253,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:133,reliability,doe,doesn,133,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:207,reliability,doe,does,207,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:12,safety,detect,detection,12,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:56,safety,test,test,56,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:120,safety,test,test,120,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:194,safety,test,test,194,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:275,safety,Test,Test,275,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:12,security,detect,detection,12,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:158,security,session,session,158,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:231,security,session,session,231,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:56,testability,test,test,56,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:120,testability,test,test,120,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:194,testability,test,test,194,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:275,testability,Test,Test,275,"Fix ipython detection; Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note. - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/issues/1845:123,modifiability,paramet,parameters,123,correlation between celltypes and age; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to do correlation between celltypes and age in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845
https://github.com/scverse/scanpy/issues/1845:400,modifiability,pac,package,400,correlation between celltypes and age; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to do correlation between celltypes and age in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845
https://github.com/scverse/scanpy/issues/1845:205,testability,simpl,simple,205,correlation between celltypes and age; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to do correlation between celltypes and age in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845
https://github.com/scverse/scanpy/issues/1845:197,usability,tool,tool,197,correlation between celltypes and age; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to do correlation between celltypes and age in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845
https://github.com/scverse/scanpy/issues/1845:205,usability,simpl,simple,205,correlation between celltypes and age; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to do correlation between celltypes and age in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845
https://github.com/scverse/scanpy/issues/1845:221,usability,tool,tool,221,correlation between celltypes and age; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to do correlation between celltypes and age in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845
https://github.com/scverse/scanpy/issues/1845:269,usability,tool,tools,269,correlation between celltypes and age; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to do correlation between celltypes and age in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845
https://github.com/scverse/scanpy/issues/1845:369,usability,tool,tools,369,correlation between celltypes and age; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... How to do correlation between celltypes and age in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845
https://github.com/scverse/scanpy/issues/1846:511,availability,sli,slight,511,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:328,deployability,version,version,328,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2140,deployability,Version,Versions,2140,". sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3884,deployability,log,logical,3884," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3938,deployability,updat,updated,3938," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:1797,energy efficiency,current,current,1797,"adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2403,energy efficiency,cloud,cloudpickle,2403,"and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3892,energy efficiency,CPU,CPU,3892," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3896,energy efficiency,core,cores,3896," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:30,integrability,sub,subset,30,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:328,integrability,version,version,328,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2140,integrability,Version,Versions,2140,". sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:328,modifiability,version,version,328,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2140,modifiability,Version,Versions,2140,". sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2505,modifiability,deco,decorator,2505,"ors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2938,modifiability,pac,packaging,2938,"2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2305,performance,cach,cachecontrol,2305,"rcontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2881,performance,network,networkx,2881,"= 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3892,performance,CPU,CPU,3892," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:22,reliability,doe,doesn,22,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:511,reliability,sli,slight,511,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:1751,reliability,doe,does,1751," without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3884,safety,log,logical,3884," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3938,safety,updat,updated,3938," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2340,security,certif,certifi,2340,"ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2881,security,network,networkx,2881,"= 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3415,security,soc,socks,3415," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3884,security,log,logical,3884," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3918,security,Session,Session,3918," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3938,security,updat,updated,3938," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3884,testability,log,logical,3884," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:288,usability,confirm,confirmed,288,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:371,usability,confirm,confirmed,371,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:684,usability,Minim,Minimal,684,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:944,usability,user,user-images,944,"sc.pp.neighbors n_pcs doesn't subset if use_rep isn't X_pca; Smaller reproducible example below: https://github.com/theislab/scanpy/issues/1846#issuecomment-863823148 –@ivirshup. --------------------------. - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:1290,usability,user,user-images,1290,"d this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, . not sure whether this is the right place to post this but i'm having a slight issue after running harmony from scanpy. It's producing very different results and i'm not sure why. It didn't used to be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. br",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:1630,usability,user,user-images,1630," be a problem when i was using scanpy 1.6x. ### Minimal code sample (that we can copy&paste without having any data). without running harmony:. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_pcs = 20). sc.tl.umap(adata). sc.pl.umap(adata, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118844728-1aa3ad80-b8c3-11eb-82d8-57f3b6346c44.png). with harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2039,usability,user,user-images,2039,"harmony. ```python. adata1 = adata.copy(). sc.external.pp.harmony_integrate(adata1, key = 'sample'). sc.pp.neighbors(adata1, n_pcs = 20, use_rep = 'X_pca_harmony'). sc.tl.umap(adata1). sc.pl.umap(adata1, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar. ```python. adatax = adata.copy(). sc.pp.neighbors(adatax, n_pcs = 50). sc.tl.umap(adatax, min_dist = .3). sc.pl.umap(adatax, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then? ```python. # my current workaround. adata2 = adata.copy(). sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'). sc.pp.neighbors(adata2, n_pcs = 20). sc.tl.umap(adata2). sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3539,usability,tool,toolz,3539," sc.pl.umap(adata2, color = 'sample'). ```. ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. Bio 1.78. PIL 8.2.0. adjustText NA. anndata 0.7.5. annoy NA. backcall 0.2.0. brotli NA. cachecontrol 0.12.6. cairo 1.19.1. certifi 2020.06.20. cffi 1.14.5. changeo 1.0.2. chardet 4.0.0. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. dandelion 0.1.2. dask 2021.03.0. dateutil 2.8.1. decorator 5.0.6. descartes NA. distance NA. get_version 2.1. google NA. h5py 2.10.0. harmonypy NA. hdmedians NA. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.34.0. matplotlib 3.3.4. mizani 0.7.2. mpl_toolkits NA. msgpack 1.0.2. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.20.2. packaging 20.9. palettable 3.3.0. pandas 1.2.4. parso 0.8.2. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotnine 0.7.1. polyleven NA. presto 0.6.2. prompt_toolkit 3.0.17. ptyprocess 0.7.0. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pytoml NA. pytz 2021.1. pywt 1.1.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.3. scrublet NA. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skbio 0.5.6. skimage 0.18.1. sklearn 0.23.2. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.1. toolz 0.11.1. tornado 6.1. tqdm 4.59.0. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-4.15.0-142-generic-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-05-19 16:44. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1847:845,availability,cluster,clusters,845,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/issues/1847:845,deployability,cluster,clusters,845,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/issues/1847:836,interoperability,specif,specific,836,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/issues/1847:147,modifiability,paramet,parameters,147,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/issues/1847:424,modifiability,pac,package,424,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/issues/1847:229,testability,simpl,simple,229,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/issues/1847:221,usability,tool,tool,221,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/issues/1847:229,usability,simpl,simple,229,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/issues/1847:245,usability,tool,tool,245,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/issues/1847:293,usability,tool,tools,293,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/issues/1847:393,usability,tool,tools,393,"Project query dataset onto umap of existing reference dataset; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [X] Other? <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/pull/1848:173,interoperability,conflict,conflict,173,"Add more pre-commit checks; Hey,. finally solves #1563 . I added: . ```. - id: trailing-whitespace. - id: end-of-file-fixer. - id: check-added-large-files. - id: check-case-conflict. - id: check-toml. - id: check-yaml. - id: check-merge-conflict. - id: detect-private-key. ```. They are super super fast, so speed is not a concern. Signed-off-by: zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848
https://github.com/scverse/scanpy/pull/1848:237,interoperability,conflict,conflict,237,"Add more pre-commit checks; Hey,. finally solves #1563 . I added: . ```. - id: trailing-whitespace. - id: end-of-file-fixer. - id: check-added-large-files. - id: check-case-conflict. - id: check-toml. - id: check-yaml. - id: check-merge-conflict. - id: detect-private-key. ```. They are super super fast, so speed is not a concern. Signed-off-by: zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848
https://github.com/scverse/scanpy/pull/1848:323,modifiability,concern,concern,323,"Add more pre-commit checks; Hey,. finally solves #1563 . I added: . ```. - id: trailing-whitespace. - id: end-of-file-fixer. - id: check-added-large-files. - id: check-case-conflict. - id: check-toml. - id: check-yaml. - id: check-merge-conflict. - id: detect-private-key. ```. They are super super fast, so speed is not a concern. Signed-off-by: zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848
https://github.com/scverse/scanpy/pull/1848:253,safety,detect,detect-private-key,253,"Add more pre-commit checks; Hey,. finally solves #1563 . I added: . ```. - id: trailing-whitespace. - id: end-of-file-fixer. - id: check-added-large-files. - id: check-case-conflict. - id: check-toml. - id: check-yaml. - id: check-merge-conflict. - id: detect-private-key. ```. They are super super fast, so speed is not a concern. Signed-off-by: zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848
https://github.com/scverse/scanpy/pull/1848:253,security,detect,detect-private-key,253,"Add more pre-commit checks; Hey,. finally solves #1563 . I added: . ```. - id: trailing-whitespace. - id: end-of-file-fixer. - id: check-added-large-files. - id: check-case-conflict. - id: check-toml. - id: check-yaml. - id: check-merge-conflict. - id: detect-private-key. ```. They are super super fast, so speed is not a concern. Signed-off-by: zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848
https://github.com/scverse/scanpy/pull/1848:332,security,Sign,Signed-off-by,332,"Add more pre-commit checks; Hey,. finally solves #1563 . I added: . ```. - id: trailing-whitespace. - id: end-of-file-fixer. - id: check-added-large-files. - id: check-case-conflict. - id: check-toml. - id: check-yaml. - id: check-merge-conflict. - id: detect-private-key. ```. They are super super fast, so speed is not a concern. Signed-off-by: zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848
https://github.com/scverse/scanpy/pull/1848:323,testability,concern,concern,323,"Add more pre-commit checks; Hey,. finally solves #1563 . I added: . ```. - id: trailing-whitespace. - id: end-of-file-fixer. - id: check-added-large-files. - id: check-case-conflict. - id: check-toml. - id: check-yaml. - id: check-merge-conflict. - id: detect-private-key. ```. They are super super fast, so speed is not a concern. Signed-off-by: zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848
https://github.com/scverse/scanpy/issues/1850:36,availability,error,error,36,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:369,availability,error,error,369,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:482,availability,error,error,482,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:164,deployability,version,version,164,"Plotting categorical data throws an error; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey! I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:1307,deployability,modul,module,1307," can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors. Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`. ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here? ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). <ipython-input-39-d43e888a7389> in <module>. ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. 602 """""". --> 603 return embedding(adata, 'umap', **kwargs). 604 . 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5622,deployability,Version,Versions,5622,"_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7062,deployability,log,logical,7062,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7116,deployability,updat,updated,7116,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:2731,energy efficiency,core,core,2731,"ta, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:3019,energy efficiency,core,core,3019,"legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 244 groups=groups,. 245 ). --> 246 color_vector, categorical = _color_vector(. 247 adata,. 248 value_to_plot,. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:3334,energy efficiency,core,core,3334,"y/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1129 else: # is_categorical_dtype(values). 1130 color_map = _get_palette(adata, values_key, palette=palette). -> 1131 color_vector = values.map(color_map).map(to_hex). 1132 . 1133 # Set color to 'missing color' for all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categorie",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:3645,energy efficiency,core,core,3645,"r all missing values. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in map(self, mapper). 1196 new_categories = self.categories.map(mapper). 1197 try:. -> 1198 return self.from_codes(. 1199 self._codes.copy(), categories=new_categories, ordered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:3928,energy efficiency,core,core,3928,"ered=self.ordered. 1200 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/arrays/categorical.py in from_codes(cls, codes, categories, ordered, dtype). 567 Categories (2, object): ['a' < 'b']. 568 """""". --> 569 dtype = CategoricalDtype._from_values_or_dtype(. 570 categories=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:4220,energy efficiency,core,core,4220,"=categories, ordered=ordered, dtype=dtype. 571 ). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _from_values_or_dtype(cls, values, categories, ordered, dtype). 271 # Note: This could potentially have categories=None and. 272 # ordered=None. --> 273 dtype = CategoricalDtype(categories, ordered). 274 . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:4560,energy efficiency,core,core,4560," . 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered). 158 . 159 def __init__(self, categories=None, ordered: Ordered = False):. --> 160 self._finalize(categories, ordered, fastpath=False). 161 . 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:4851,energy efficiency,core,core,4851,"classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath). 312 . 313 if categories is not None:. --> 314 categories = self.validate_categories(categories, fastpath=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5101,energy efficiency,core,core,5101,"th=fastpath). 315 . 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5274,energy efficiency,core,core,5274," fastpath). 505 if not fastpath:. 506 . --> 507 if categories.hasnans:. 508 raise ValueError(""Categorical categories cannot be null""). 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self). 2193 """""". 2194 if self._can_hold_na:. -> 2195 return bool(self._isnan.any()). 2196 else:. 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self). 2172 """""". 2173 if self._can_hold_na:. -> 2174 return isna(self). 2175 else:. 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj). 125 Name: 1, dtype: bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7070,energy efficiency,CPU,CPU,7070,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7074,energy efficiency,core,cores,7074,": bool. 126 """""". --> 127 return _isna(obj). 128 . 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na). 154 # hack (for now) because MI registers as ndarray. 155 elif isinstance(obj, ABCMultiIndex):. --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""). 157 elif isinstance(obj, type):. 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. backcall 0.2.0. bbknn NA. bottleneck 1.3.2. cairo 1.19.1. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. fcsparser 0.2.1. future_fstrings NA. get_version 2.1. google NA. h5py 2.10.0. igraph 0.7.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 0.0.0. leidenalg 0.8.2. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. palantir 1.0.0. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.1. pyparsing 2.4.7. pytz 2020.1. scanpy 1.7.2. scipy 1.5.2. scvelo 0.2.3. seaborn 0.11.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]. Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10. 4 logical CPU cores, x86_64. -----. Session information updated at 2021-05-24 12:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
